/**
 * Cross-language hash validation tests.
 *
 * This test validates that our TypeScript hash implementation produces
 * IDENTICAL results to the Rust server implementation.
 *
 * Test vectors are generated by:
 * crates/norikv-placement/tests/generate_test_vectors.rs
 */

import { describe, test, expect, beforeAll } from 'vitest';
import { xxhash64, jumpConsistentHash, getShardForKey, initializeHasher } from '../../src/hash.js';
import * as fs from 'fs';
import * as path from 'path';

// Load test vectors generated by Rust
const vectorsPath = path.join(__dirname, '../../../../test-vectors/hash-vectors.json');
const vectors = JSON.parse(fs.readFileSync(vectorsPath, 'utf-8'));

describe('Cross-Language Hash Parity', () => {
  beforeAll(async () => {
    await initializeHasher();
  });

  describe('xxhash64 parity', () => {
    test('should match Rust xxhash64 for all test keys', () => {
      for (const vector of vectors.key_hash_vectors) {
        const key = vector.key;
        const expectedHash = BigInt(vector.xxhash64);
        const actualHash = xxhash64(key);

        expect(actualHash).toBe(expectedHash);
      }
    });

    test('should match Rust xxhash64 for hex-decoded keys', () => {
      for (const vector of vectors.key_hash_vectors) {
        const keyBytes = Buffer.from(vector.key_hex, 'hex');
        const expectedHash = BigInt(vector.xxhash64);
        const actualHash = xxhash64(keyBytes);

        expect(actualHash).toBe(expectedHash);
      }
    });
  });

  describe('jumpConsistentHash parity', () => {
    test('should match Rust jump hash for specific hash values (100 buckets)', () => {
      for (const vector of vectors.jump_hash_vectors) {
        const hash = BigInt(vector.hash);
        const expectedBucket = vector.buckets_100;
        const actualBucket = jumpConsistentHash(hash, 100);

        expect(actualBucket).toBe(expectedBucket);
      }
    });

    test('should match Rust jump hash for specific hash values (1024 buckets)', () => {
      for (const vector of vectors.jump_hash_vectors) {
        const hash = BigInt(vector.hash);
        const expectedBucket = vector.buckets_1024;
        const actualBucket = jumpConsistentHash(hash, 1024);

        expect(actualBucket).toBe(expectedBucket);
      }
    });
  });

  describe('getShardForKey parity (end-to-end)', () => {
    test('should match Rust shard assignment for 1024 shards', () => {
      for (const vector of vectors.key_hash_vectors) {
        const key = vector.key;
        const expectedShard = vector.shard_1024;
        const actualShard = getShardForKey(key, 1024);

        expect(actualShard).toBe(expectedShard);
      }
    });

    test('should match Rust shard assignment for 256 shards', () => {
      for (const vector of vectors.key_hash_vectors) {
        const key = vector.key;
        const expectedShard = vector.shard_256;
        const actualShard = getShardForKey(key, 256);

        expect(actualShard).toBe(expectedShard);
      }
    });
  });

  describe('Edge cases from test vectors', () => {
    test('should handle empty key', () => {
      const emptyVector = vectors.key_hash_vectors.find((v: any) => v.key === '');
      expect(emptyVector).toBeDefined();

      const hash = xxhash64('');
      expect(hash).toBe(BigInt(emptyVector.xxhash64));

      const shard = getShardForKey('', 1024);
      expect(shard).toBe(emptyVector.shard_1024);
    });

    test('should handle single character key', () => {
      const singleCharVector = vectors.key_hash_vectors.find((v: any) => v.key === 'a');
      expect(singleCharVector).toBeDefined();

      const hash = xxhash64('a');
      expect(hash).toBe(BigInt(singleCharVector.xxhash64));
    });

    test('should handle UTF-8 keys (ä¸–ç•Œ)', () => {
      const utf8Vector = vectors.key_hash_vectors.find((v: any) => v.key.includes('ä¸–ç•Œ'));
      expect(utf8Vector).toBeDefined();

      const hash = xxhash64(utf8Vector.key);
      expect(hash).toBe(BigInt(utf8Vector.xxhash64));
    });

    test('should handle emoji keys (ðŸŒðŸš€)', () => {
      const emojiVector = vectors.key_hash_vectors.find((v: any) => v.key === 'ðŸŒðŸš€');
      expect(emojiVector).toBeDefined();

      const hash = xxhash64('ðŸŒðŸš€');
      expect(hash).toBe(BigInt(emojiVector.xxhash64));
    });

    test('should handle very long key (1000 chars)', () => {
      const longVector = vectors.key_hash_vectors.find((v: any) => v.key.length === 1000);
      expect(longVector).toBeDefined();

      const hash = xxhash64(longVector.key);
      expect(hash).toBe(BigInt(longVector.xxhash64));
    });
  });

  describe('Jump hash edge cases', () => {
    test('should handle hash = 0', () => {
      const zeroVector = vectors.jump_hash_vectors.find((v: any) => v.hash === '0');
      expect(zeroVector).toBeDefined();

      const bucket = jumpConsistentHash(0n, 100);
      expect(bucket).toBe(zeroVector.buckets_100);
    });

    test('should handle hash = 1', () => {
      const oneVector = vectors.jump_hash_vectors.find((v: any) => v.hash === '1');
      expect(oneVector).toBeDefined();

      const bucket = jumpConsistentHash(1n, 1024);
      expect(bucket).toBe(oneVector.buckets_1024);
    });

    test('should handle max u64 hash', () => {
      const maxVector = vectors.jump_hash_vectors.find(
        (v: any) => v.hash === '18446744073709551615'
      );
      expect(maxVector).toBeDefined();

      const bucket = jumpConsistentHash(18446744073709551615n, 100);
      expect(bucket).toBe(maxVector.buckets_100);
    });
  });

  test('test vectors metadata', () => {
    expect(vectors.description).toContain('NoriKV');
    expect(vectors.key_hash_vectors).toHaveLength(15);
    expect(vectors.jump_hash_vectors).toHaveLength(7);
  });
});
