{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"NoriKV","text":"<ul> <li> <p> Distributed by Design</p> <p>Raft consensus for strong consistency with automatic leader election and failover. No single point of failure.</p> <p> Architecture</p> </li> <li> <p> LSM-Tree Storage</p> <p>High-performance log-structured merge tree with WAL, SSTables, bloom filters, and automatic compaction.</p> <p> Storage Crates</p> </li> <li> <p> Smart Sharding</p> <p>Jump consistent hashing with 1024 virtual shards. Client-side routing directly to shard leaders.</p> <p> Multi-Shard Server</p> </li> <li> <p> Multi-Language SDKs</p> <p>Production-ready clients for Java, Go, TypeScript, and Python with identical APIs and behavior.</p> <p> Client SDKs</p> </li> </ul>"},{"location":"#distributed-kv-store-built-for-scale","title":"Distributed KV Store Built for Scale","text":"<p>A sharded, Raft-replicated, log-structured key-value store with first-class observability and multi-language SDKs.</p> <p>Get Started View on GitHub</p>"},{"location":"#quick-example","title":"Quick Example","text":"JavaGoTypeScriptPython <pre><code>ClientConfig config = ClientConfig.builder()\n    .nodes(\"localhost:9001\", \"localhost:9002\", \"localhost:9003\")\n    .totalShards(1024)\n    .build();\n\ntry (NoriKVClient client = new NoriKVClient(config)) {\n    // Put a value\n    Version version = client.put(\"user:123\".getBytes(),\n        \"{\\\"name\\\":\\\"Alice\\\"}\".getBytes(), null);\n\n    // Get the value\n    GetResult result = client.get(\"user:123\".getBytes(), null);\n    System.out.println(new String(result.getValue()));\n\n    // Conditional update (CAS)\n    PutOptions options = PutOptions.builder()\n        .ifMatchVersion(version)\n        .build();\n    client.put(\"user:123\".getBytes(), newValue, options);\n}\n</code></pre> <pre><code>config := norikv.ClientConfig{\n    Nodes:       []string{\"localhost:9001\", \"localhost:9002\", \"localhost:9003\"},\n    TotalShards: 1024,\n}\n\nclient, err := norikv.NewClient(ctx, config)\nif err != nil {\n    log.Fatal(err)\n}\ndefer client.Close()\n\n// Put a value\nversion, err := client.Put(ctx, []byte(\"user:123\"),\n    []byte(`{\"name\":\"Alice\"}`), nil)\n\n// Get the value\nresult, err := client.Get(ctx, []byte(\"user:123\"), nil)\nfmt.Println(string(result.Value))\n\n// Conditional update (CAS)\n_, err = client.Put(ctx, []byte(\"user:123\"), newValue,\n    &amp;norikv.PutOptions{IfMatchVersion: version})\n</code></pre> <pre><code>const client = new NoriKVClient({\n  nodes: ['localhost:9001', 'localhost:9002', 'localhost:9003'],\n  totalShards: 1024,\n});\n\nawait client.connect();\n\n// Put a value\nconst version = await client.put('user:123', '{\"name\":\"Alice\"}');\n\n// Get the value\nconst result = await client.get('user:123');\nconsole.log(bytesToString(result.value));\n\n// Conditional update (CAS)\nawait client.put('user:123', newValue, { ifMatchVersion: version });\n\nawait client.close();\n</code></pre> <pre><code>config = ClientConfig(\n    nodes=[\"localhost:9001\", \"localhost:9002\", \"localhost:9003\"],\n    total_shards=1024,\n)\n\nasync with NoriKVClient(config) as client:\n    # Put a value\n    version = await client.put(\"user:123\", '{\"name\":\"Alice\"}')\n\n    # Get the value\n    result = await client.get(\"user:123\")\n    print(result.value.decode())\n\n    # Conditional update (CAS)\n    await client.put(\"user:123\", new_value,\n        PutOptions(if_match_version=version))\n</code></pre>"},{"location":"#architecture-overview","title":"Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          NoriKV Cluster                              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502\n\u2502  \u2502    Node 1    \u2502  \u2502    Node 2    \u2502  \u2502    Node 3    \u2502              \u2502\n\u2502  \u2502   (Leader)   \u2502  \u2502  (Follower)  \u2502  \u2502  (Follower)  \u2502              \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502\n\u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                       \u2502\n\u2502                           \u2502 Raft                                    \u2502\n\u2502         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502\n\u2502  \u2502  LSM Engine  \u2502  \u2502  LSM Engine  \u2502  \u2502  LSM Engine  \u2502              \u2502\n\u2502  \u2502  WAL + SST   \u2502  \u2502  WAL + SST   \u2502  \u2502  WAL + SST   \u2502              \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u25b2\n                           \u2502 gRPC\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Smart Clients                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502  Java   \u2502  \u2502   Go    \u2502  \u2502TypeScript\u2502  \u2502 Python \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p> Learn more about Architecture</p>"},{"location":"#design-principles","title":"Design Principles","text":"<p>Strong Consistency</p> <p>Raft consensus ensures linearizable operations. Every write is replicated to a quorum before acknowledgment.</p> <p>Smart Routing</p> <p>Clients route directly to shard leaders. No proxy layer bottleneck. Automatic retry on failover.</p> <p>Observable</p> <p>First-class Prometheus metrics, structured logging, and distributed tracing support.</p> <p>Production-Ready</p> <p>Comprehensive test suites across all SDKs. Battle-tested at scale.</p>"},{"location":"#choose-your-sdk","title":"Choose Your SDK","text":"Language Status Tests Key Features Java Production 123+ Thread-safe, connection pooling Go Production 102+ Zero-allocation routing, context support TypeScript Production 100+ Full type safety, async/await Python Production 40+ Asyncio-based, type hints"},{"location":"#get-started","title":"Get Started","text":"<ul> <li> <p> Quick Start</p> <p>Get up and running in 5 minutes with a simple key-value example.</p> <p> Quick Start</p> </li> <li> <p> SDK Documentation</p> <p>Comprehensive guides for Java, Go, TypeScript, and Python clients.</p> <p> Client SDKs</p> </li> <li> <p> Operations Guide</p> <p>Deploy, configure, and monitor your NoriKV cluster.</p> <p> Operations</p> </li> </ul>"},{"location":"architecture/","title":"Architecture","text":"<p>Understanding how NoriKV components fit together to build a distributed key-value store.</p>"},{"location":"architecture/#system-overview","title":"System Overview","text":"<p>NoriKV is a sharded, Raft-replicated, log-structured key-value store built from composable components. Each component solves a specific problem and can be used independently or as part of the complete system.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Client SDKs (TypeScript, Python, Go, Java)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502 gRPC\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  NoriKV Server Node (DI composition)            \u2502\n\u2502                                                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502  Adapters Layer                         \u2502   \u2502\n\u2502  \u2502  - LSM Storage Adapter                  \u2502   \u2502\n\u2502  \u2502  - Raft Consensus Adapter               \u2502   \u2502\n\u2502  \u2502  - SWIM Membership Adapter              \u2502   \u2502\n\u2502  \u2502  - gRPC/HTTP Transport Adapter          \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502  Ports (Traits)                         \u2502   \u2502\n\u2502  \u2502  - Storage                              \u2502   \u2502\n\u2502  \u2502  - ReplicatedLog                        \u2502   \u2502\n\u2502  \u2502  - Membership                           \u2502   \u2502\n\u2502  \u2502  - Transport, Router                    \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502  Domain Layer                           \u2502   \u2502\n\u2502  \u2502  - Types, IDs, Versions                 \u2502   \u2502\n\u2502  \u2502  - Sharding (Jump Consistent Hash)      \u2502   \u2502\n\u2502  \u2502  - Error handling                       \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/#layering-model","title":"Layering Model","text":"<p>NoriKV uses Hexagonal Architecture (Ports &amp; Adapters) for clean separation of concerns:</p>"},{"location":"architecture/#domain-layer","title":"Domain Layer","text":"<p>Core business logic, types, and rules. No dependencies on infrastructure.</p> <ul> <li>Key/value types</li> <li>Shard IDs, replica placement</li> <li>Versioning and conflict resolution</li> <li>Error codes</li> </ul>"},{"location":"architecture/#ports-traits","title":"Ports (Traits)","text":"<p>Abstract interfaces defining what the system needs.</p> <pre><code>pub trait Storage {\n    async fn get(&amp;self, key: &amp;[u8]) -&gt; Result&lt;Option&lt;Bytes&gt;&gt;;\n    async fn put(&amp;self, key: &amp;[u8], value: &amp;[u8]) -&gt; Result&lt;()&gt;;\n    async fn delete(&amp;self, key: &amp;[u8]) -&gt; Result&lt;()&gt;;\n    async fn scan(&amp;self, start: &amp;[u8], end: &amp;[u8]) -&gt; Result&lt;Vec&lt;(Bytes, Bytes)&gt;&gt;;\n}\n\npub trait ReplicatedLog {\n    async fn append(&amp;self, entry: &amp;[u8]) -&gt; Result&lt;LogIndex&gt;;\n    async fn read(&amp;self, index: LogIndex) -&gt; Result&lt;Option&lt;Bytes&gt;&gt;;\n    async fn wait_committed(&amp;self, index: LogIndex) -&gt; Result&lt;()&gt;;\n}\n\npub trait Membership {\n    fn alive_members(&amp;self) -&gt; Vec&lt;NodeId&gt;;\n    fn is_alive(&amp;self, node: NodeId) -&gt; bool;\n    async fn join(&amp;self, seeds: Vec&lt;SocketAddr&gt;) -&gt; Result&lt;()&gt;;\n}\n</code></pre>"},{"location":"architecture/#adapters","title":"Adapters","text":"<p>Concrete implementations of ports using specific technologies.</p> <ul> <li>LSM Adapter - Implements <code>Storage</code> using nori-lsm (WAL + SSTables)</li> <li>Raft Adapter - Implements <code>ReplicatedLog</code> using nori-raft</li> <li>SWIM Adapter - Implements <code>Membership</code> using nori-swim</li> <li>gRPC Adapter - Implements <code>Transport</code> using Tonic</li> </ul>"},{"location":"architecture/#data-flow","title":"Data Flow","text":""},{"location":"architecture/#write-path","title":"Write Path","text":"<pre><code>Client PUT(\"user:42\", \"alice\")\n  \u2193 gRPC\nRouter (hash key \u2192 shard 15)\n  \u2193\nRaft Leader (shard 15 replica 0)\n  \u2193 replicate to followers\n[Follower 1, Follower 2] ack\n  \u2193 commit to LSM\nWAL append (fsync)\n  \u2193\nMemtable (in-memory)\n  \u2193 (later, async compaction)\nSSTable flush to disk\n  \u2193\nClient receives success\n</code></pre> <p>Latency breakdown: - gRPC: ~1ms - Raft replication: ~5ms (2 RTTs + fsync) - WAL append: ~100\u00b5s (batched fsync) - Total p95: ~20ms</p>"},{"location":"architecture/#read-path-linearizable","title":"Read Path (Linearizable)","text":"<pre><code>Client GET(\"user:42\")\n  \u2193 gRPC\nRouter (hash key \u2192 shard 15)\n  \u2193\nRaft Leader (read-index or lease)\n  \u2193 check committed index\nLSM read (memtable \u2192 L0 \u2192 L1...)\n  \u2193\nReturn value to client\n</code></pre> <p>Latency breakdown: - gRPC: ~1ms - Raft read-index: ~1ms (with leases: ~0\u00b5s) - LSM read (cache hit): ~5\u00b5s - Total p95: ~10ms</p>"},{"location":"architecture/#component-details","title":"Component Details","text":""},{"location":"architecture/#storage-nori-lsm","title":"Storage: nori-lsm","text":"<p>The LSM engine combines: - nori-wal - Append-only write-ahead log - nori-sstable - Immutable sorted tables - Memtable (in-memory skip list) - Background compaction (leveled strategy)</p> <p>Learn more about LSM \u2192</p>"},{"location":"architecture/#consensus-nori-raft","title":"Consensus: nori-raft","text":"<p>Raft provides: - Leader election - Log replication with majority quorum - Read-index optimization for consistent reads - Lease-based reads (linearizable without log appends) - Joint consensus for membership changes - Snapshot support for log compaction</p> <p>Learn more about Raft \u2192</p>"},{"location":"architecture/#membership-nori-swim","title":"Membership: nori-swim","text":"<p>SWIM provides: - Gossip-based failure detection - Scalable health checks (O(log N) message overhead) - Eventual consistency for cluster state - Integration with Raft for automatic reconfiguration</p> <p>Learn more about SWIM \u2192</p>"},{"location":"architecture/#sharding-placement","title":"Sharding &amp; Placement","text":"<p>NoriKV uses Jump Consistent Hash for deterministic shard assignment:</p> <pre><code>fn key_to_shard(key: &amp;[u8], num_shards: u32) -&gt; u32 {\n    let hash = xxhash64(key, seed: 0);\n    jump_consistent_hash(hash, num_shards)\n}\n</code></pre> <p>Why Jump Consistent Hash? - Deterministic (no routing table) - Minimal movement on resize (only K/N keys move) - Lock-free lookups - Simple implementation (~10 lines of code)</p> <p>Default configuration: - 1024 virtual shards - Replication factor: 3 - Replica placement: Hash mod ring + offset</p> <p>Learn more about placement \u2192</p>"},{"location":"architecture/#observability-nori-observe","title":"Observability: nori-observe","text":"<p>Every component emits typed events via the <code>Meter</code> trait:</p> <pre><code>pub trait Meter: Send + Sync {\n    fn emit(&amp;self, event: VizEvent);\n}\n\npub enum VizEvent {\n    Wal(WalEvt),      // WAL operations\n    Lsm(LsmEvt),      // LSM compactions\n    Raft(RaftEvt),    // Raft elections, commits\n    Swim(SwimEvt),    // Membership changes\n}\n</code></pre> <p>Exporters: - Prometheus/OpenMetrics - OTLP (with trace exemplars) - Live dashboard (WebSocket stream)</p> <p>Learn more about observability \u2192</p>"},{"location":"architecture/#deployment-topologies","title":"Deployment Topologies","text":""},{"location":"architecture/#single-node-development","title":"Single Node (Development)","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  NoriKV Node    \u2502\n\u2502  - All shards   \u2502\n\u2502  - RF=1         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Use case: Local development, testing, single-machine workloads.</p>"},{"location":"architecture/#3-node-cluster-production","title":"3-Node Cluster (Production)","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Node 0  \u2502   \u2502 Node 1  \u2502   \u2502 Node 2  \u2502\n\u2502 Shards: \u2502   \u2502 Shards: \u2502   \u2502 Shards: \u2502\n\u2502 0,1,2   \u2502   \u2502 0,1,2   \u2502   \u2502 0,1,2   \u2502\n\u2502 (leader)\u2502   \u2502(follower\u2502   \u2502(follower\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Configuration: - 3 nodes, 3 shards (1024 virtual) - RF=3 (full replication) - Each shard has 1 leader, 2 followers</p> <p>Use case: Small production deployments.</p>"},{"location":"architecture/#9-node-cluster-large-scale","title":"9-Node Cluster (Large Scale)","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Node 0  \u2502   \u2502 Node 1  \u2502  ...  \u2502 Node 8  \u2502\n\u2502 Shards: \u2502   \u2502 Shards: \u2502       \u2502 Shards: \u2502\n\u2502 0-340   \u2502   \u2502 341-681 \u2502       \u2502 682-1023\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Configuration: - 9 nodes, 1024 virtual shards - RF=3 (each shard on 3 nodes) - Leader election per shard</p> <p>Use case: High-throughput production workloads.</p>"},{"location":"architecture/#consistency-guarantees","title":"Consistency Guarantees","text":""},{"location":"architecture/#strong-consistency-default","title":"Strong Consistency (Default)","text":"<ul> <li>Linearizable reads via Raft read-index or leases</li> <li>Serializable writes via Raft log replication</li> <li>Exactly-once semantics for committed writes</li> </ul>"},{"location":"architecture/#tunable-consistency","title":"Tunable Consistency","text":"<pre><code>// Linearizable read (default)\nclient.get(\"key\").await?;\n\n// Stale read (follower, faster)\nclient.get_with_consistency(\"key\", Consistency::Stale).await?;\n</code></pre>"},{"location":"architecture/#failure-modes","title":"Failure Modes","text":""},{"location":"architecture/#node-failure","title":"Node Failure","text":"<ul> <li>SWIM detects failure within ~5 seconds</li> <li>Raft elects new leader for affected shards</li> <li>Clients retry with exponential backoff</li> <li>No data loss (majority quorum)</li> </ul>"},{"location":"architecture/#network-partition","title":"Network Partition","text":"<ul> <li>Minority partition: Can't commit writes (no quorum)</li> <li>Majority partition: Continues operating</li> <li>Partition heals: Minority catches up via log replication</li> </ul>"},{"location":"architecture/#disk-corruption","title":"Disk Corruption","text":"<ul> <li>CRC32C checksums detect corruption</li> <li>WAL recovery: Prefix-valid truncation</li> <li>SSTable: Block-level checksums</li> </ul>"},{"location":"architecture/#performance-characteristics","title":"Performance Characteristics","text":"Operation Latency (p95) Throughput PUT 20ms 50K/sec/node GET (linearizable) 10ms 100K/sec/node GET (stale) 5ms 200K/sec/node SCAN (1KB range) 15ms - <p>Assumptions: 3-node cluster, SSD, 1Gbps network, 1KB values</p>"},{"location":"architecture/#next-steps","title":"Next Steps","text":""},{"location":"architecture/#server-architecture-deep-dives","title":"Server Architecture Deep-Dives","text":"<ul> <li>Multi-Shard Server Architecture - How 1024 virtual shards are managed</li> <li>SWIM Topology Tracking - Failure detection and cluster membership</li> </ul>"},{"location":"architecture/#learn-about-specific-components","title":"Learn About Specific Components","text":"<ul> <li>Storage Layer (LSM)</li> <li>Consensus (Raft)</li> <li>Membership (SWIM)</li> <li>Observability</li> </ul>"},{"location":"architecture/#understand-sharding","title":"Understand Sharding","text":"<ul> <li>Placement &amp; Hashing</li> </ul>"},{"location":"architecture/#operations-monitoring","title":"Operations &amp; Monitoring","text":"<ul> <li>REST API Reference - HTTP endpoints for health and metrics</li> <li>Metrics Reference - Complete Prometheus metrics guide</li> <li>Operations Guide</li> </ul>"},{"location":"architecture/#build-with-norikv","title":"Build with NoriKV","text":"<ul> <li>Client SDKs</li> </ul>"},{"location":"architecture/multi-shard-server/","title":"Multi-Shard Server Architecture","text":"<p>How NoriKV servers manage 1024 virtual shards with lazy initialization and consistent hashing.</p>"},{"location":"architecture/multi-shard-server/#overview","title":"Overview","text":"<p>NoriKV uses virtual sharding to achieve horizontal scalability. Each server can host multiple shards, each shard is a separate Raft group with its own LSM engine.</p> <p>Key Concepts: - 1024 virtual shards - Fixed shard count, independent of node count - Lazy initialization - Shards created on first access - Jump Consistent Hash - Deterministic key-to-shard mapping - Multi-shard routing - Requests routed to correct shard - Per-shard isolation - Independent Raft leaders, LSM compaction</p>"},{"location":"architecture/multi-shard-server/#architecture","title":"Architecture","text":""},{"location":"architecture/multi-shard-server/#component-layering","title":"Component Layering","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  gRPC Server (Tonic)                             \u2502\n\u2502  - KvServer::put/get/delete                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  MultiShardBackend                               \u2502\n\u2502  - Routes key \u2192 shard_id                         \u2502\n\u2502  - Lazy shard creation                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  ShardManager                                    \u2502\n\u2502  - HashMap&lt;ShardId, Arc&lt;ReplicatedLSM&gt;&gt;          \u2502\n\u2502  - RwLock for concurrent access                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u25bc                \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Shard 0      \u2502  \u2502  Shard N      \u2502\n\u2502  ReplicatedLSM\u2502  \u2502  ReplicatedLSM\u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Raft     \u2502 \u2502  \u2502  \u2502 Raft     \u2502 \u2502\n\u2502  \u2502 - Term 5 \u2502 \u2502  \u2502  \u2502 - Term 3 \u2502 \u2502\n\u2502  \u2502 - Leader \u2502 \u2502  \u2502  \u2502 - Leader \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 LSM      \u2502 \u2502  \u2502  \u2502 LSM      \u2502 \u2502\n\u2502  \u2502 - Memtab \u2502 \u2502  \u2502  \u2502 - Memtab \u2502 \u2502\n\u2502  \u2502 - L0-L6  \u2502 \u2502  \u2502  \u2502 - L0-L6  \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/multi-shard-server/#request-flow","title":"Request Flow","text":"<p>PUT Request:</p> <pre><code>Client: PUT(\"user:42\", \"alice\")\n  \u2193 gRPC\nKvService::put(key, value)\n  \u2193\nMultiShardBackend::put(key, value)\n  \u2193 hash key\nRouter::shard_for_key(\"user:42\")\n  \u2192 xxhash64(\"user:42\") = 0x1a2b3c4d5e6f7890\n  \u2192 jump_consistent_hash(0x1a2b3c4d5e6f7890, 1024) = 42\n  \u2193\nShardManager::get_or_create_shard(42)\n  \u2193 if not exists\nCreate Raft + LSM for shard 42\n  \u2193\nShard42::put(\"user:42\", \"alice\")\n  \u2193 Raft replication\nWAL append \u2192 replicate to followers \u2192 commit\n  \u2193\nLSM apply \u2192 memtable\n  \u2193\nReturn version to client\n</code></pre>"},{"location":"architecture/multi-shard-server/#shardmanager","title":"ShardManager","text":""},{"location":"architecture/multi-shard-server/#responsibilities","title":"Responsibilities","text":"<p>The ShardManager is the central component that: 1. Manages shard lifecycle - Create, start, shutdown 2. Lazy initialization - Shards created on first access 3. Concurrent access - Thread-safe via RwLock 4. Shared config - Raft and LSM config for all shards</p>"},{"location":"architecture/multi-shard-server/#code-structure","title":"Code Structure","text":"<p>Location: <code>apps/norikv-server/src/shard_manager.rs</code></p> <pre><code>pub struct ShardManager {\n    /// Server configuration (node_id, total_shards, etc.)\n    config: ServerConfig,\n\n    /// Raft configuration (election timeout, heartbeat, etc.)\n    raft_config: RaftConfig,\n\n    /// LSM configuration (compaction, bloom, cache)\n    lsm_config: ATLLConfig,\n\n    /// Raft transport (in-memory or gRPC)\n    transport: Arc&lt;dyn RaftTransport&gt;,\n\n    /// Initial cluster configuration (single-node or multi-node)\n    initial_config: ConfigEntry,\n\n    /// Active shards: ShardId \u2192 ReplicatedLSM\n    shards: Arc&lt;RwLock&lt;HashMap&lt;ShardId, Arc&lt;ReplicatedLSM&gt;&gt;&gt;&gt;,\n}\n</code></pre>"},{"location":"architecture/multi-shard-server/#lazy-shard-creation","title":"Lazy Shard Creation","text":"<p>get_or_create_shard() - The core method:</p> <pre><code>pub async fn get_or_create_shard(\n    &amp;self,\n    shard_id: ShardId,\n) -&gt; Result&lt;Arc&lt;ReplicatedLSM&gt;, ShardManagerError&gt; {\n    // Fast path: shard already exists\n    {\n        let shards = self.shards.read();\n        if let Some(shard) = shards.get(&amp;shard_id) {\n            return Ok(shard.clone());\n        }\n    }\n\n    // Slow path: create new shard\n    let mut shards = self.shards.write();\n\n    // Double-check (another thread may have created it)\n    if let Some(shard) = shards.get(&amp;shard_id) {\n        return Ok(shard.clone());\n    }\n\n    tracing::info!(\"Creating shard {}\", shard_id);\n\n    // Create directories\n    let raft_dir = self.config.raft_dir().join(format!(\"shard-{}\", shard_id));\n    let lsm_dir = self.config.lsm_dir().join(format!(\"shard-{}\", shard_id));\n    std::fs::create_dir_all(&amp;raft_dir)?;\n    std::fs::create_dir_all(&amp;lsm_dir)?;\n\n    // Update LSM config with shard-specific directory\n    let mut lsm_config = self.lsm_config.clone();\n    lsm_config.data_dir = lsm_dir;\n\n    // Create ReplicatedLSM (Raft + LSM)\n    let node_id = NodeId::new(&amp;self.config.node_id);\n    let shard = Arc::new(\n        ReplicatedLSM::new(\n            node_id.clone(),\n            raft_dir,\n            self.raft_config.clone(),\n            lsm_config,\n            self.transport.clone(),\n            self.initial_config.clone(),\n        ).await?\n    );\n\n    // Store in map\n    shards.insert(shard_id, shard.clone());\n\n    tracing::info!(\"Shard {} created and started\", shard_id);\n\n    Ok(shard)\n}\n</code></pre> <p>Key Design Decisions:</p> <ol> <li>Double-checked locking pattern</li> <li>Fast path: Read lock only (99% of requests)</li> <li>Slow path: Write lock for creation (1% of requests)</li> <li> <p>Prevents duplicate creation by concurrent requests</p> </li> <li> <p>Separate directories per shard</p> </li> <li>Raft WAL: <code>/data/raft/shard-0/</code>, <code>/data/raft/shard-1/</code>, ...</li> <li>LSM data: <code>/data/lsm/shard-0/</code>, <code>/data/lsm/shard-1/</code>, ...</li> <li> <p>Enables shard migration (copy directory)</p> </li> <li> <p>Shared config, separate state</p> </li> <li>All shards use same <code>RaftConfig</code> (election timeout, etc.)</li> <li>All shards use same <code>ATLLConfig</code> (compaction strategy, etc.)</li> <li>But each shard has independent Raft term, LSM levels</li> </ol>"},{"location":"architecture/multi-shard-server/#multishardbackend","title":"MultiShardBackend","text":""},{"location":"architecture/multi-shard-server/#responsibilities_1","title":"Responsibilities","text":"<p>MultiShardBackend implements the KvBackend trait and routes requests to the correct shard:</p> <pre><code>#[async_trait]\npub trait KvBackend: Send + Sync {\n    async fn put(&amp;self, key: &amp;[u8], value: &amp;[u8], options: PutOptions)\n        -&gt; Result&lt;Version, KvError&gt;;\n    async fn get(&amp;self, key: &amp;[u8], options: GetOptions)\n        -&gt; Result&lt;Option&lt;GetResult&gt;, KvError&gt;;\n    async fn delete(&amp;self, key: &amp;[u8], options: DeleteOptions)\n        -&gt; Result&lt;(), KvError&gt;;\n}\n</code></pre>"},{"location":"architecture/multi-shard-server/#implementation","title":"Implementation","text":"<p>Location: <code>apps/norikv-server/src/multi_shard_backend.rs</code></p> <pre><code>pub struct MultiShardBackend {\n    shard_manager: Arc&lt;ShardManager&gt;,\n    router: Router,\n}\n\nimpl MultiShardBackend {\n    pub fn new(shard_manager: Arc&lt;ShardManager&gt;, total_shards: u32) -&gt; Self {\n        Self {\n            shard_manager,\n            router: Router::new(total_shards),\n        }\n    }\n\n    async fn get_shard_for_key(&amp;self, key: &amp;[u8]) -&gt; Result&lt;Arc&lt;ReplicatedLSM&gt;, KvError&gt; {\n        // Hash key to shard\n        let shard_id = self.router.shard_for_key(key);\n\n        // Get or create shard\n        self.shard_manager\n            .get_or_create_shard(shard_id)\n            .await\n            .map_err(|e| KvError::Internal(e.to_string()))\n    }\n}\n\n#[async_trait]\nimpl KvBackend for MultiShardBackend {\n    async fn put(&amp;self, key: &amp;[u8], value: &amp;[u8], options: PutOptions)\n        -&gt; Result&lt;Version, KvError&gt;\n    {\n        let shard = self.get_shard_for_key(key).await?;\n        shard.put(key, value).await\n            .map_err(|e| KvError::Internal(e.to_string()))\n    }\n\n    async fn get(&amp;self, key: &amp;[u8], options: GetOptions)\n        -&gt; Result&lt;Option&lt;GetResult&gt;, KvError&gt;\n    {\n        let shard = self.get_shard_for_key(key).await?;\n        match shard.get(key).await {\n            Ok(Some(value)) =&gt; Ok(Some(GetResult {\n                value: value.into(),\n                version: 1, // TODO: track versions\n            })),\n            Ok(None) =&gt; Ok(None),\n            Err(e) =&gt; Err(KvError::Internal(e.to_string())),\n        }\n    }\n\n    async fn delete(&amp;self, key: &amp;[u8], options: DeleteOptions) -&gt; Result&lt;(), KvError&gt; {\n        let shard = self.get_shard_for_key(key).await?;\n        shard.delete(key).await\n            .map_err(|e| KvError::Internal(e.to_string()))\n    }\n}\n</code></pre> <p>Benefits: - Transparent routing - KvService doesn't know about shards - Lazy creation - Shards created only when needed - Consistent hashing - Same key always routes to same shard</p>"},{"location":"architecture/multi-shard-server/#routing-algorithm","title":"Routing Algorithm","text":""},{"location":"architecture/multi-shard-server/#jump-consistent-hash","title":"Jump Consistent Hash","text":"<p>norikv-placement/src/router.rs:</p> <pre><code>pub struct Router {\n    total_shards: u32,\n}\n\nimpl Router {\n    pub fn shard_for_key(&amp;self, key: &amp;[u8]) -&gt; ShardId {\n        // Step 1: Hash key with xxhash64\n        let hash = xxhash64(key, seed: 0);\n\n        // Step 2: Map hash to shard with Jump Consistent Hash\n        jump_consistent_hash(hash, self.total_shards)\n    }\n}\n\n/// Jump Consistent Hash - deterministic, minimal-movement hash function.\nfn jump_consistent_hash(mut key: u64, num_buckets: u32) -&gt; u32 {\n    let mut b: i64 = -1;\n    let mut j: i64 = 0;\n\n    while j &lt; num_buckets as i64 {\n        b = j;\n        key = key.wrapping_mul(2862933555777941757).wrapping_add(1);\n        j = ((b + 1) as f64 * (((1i64 &lt;&lt; 31) as f64) / (((key &gt;&gt; 33) + 1) as f64))) as i64;\n    }\n\n    b as u32\n}\n</code></pre>"},{"location":"architecture/multi-shard-server/#why-jump-consistent-hash","title":"Why Jump Consistent Hash?","text":"<p>vs. Traditional Consistent Hash (ring with virtual nodes):</p> Feature Jump Hash Ring Hash Deterministic Yes Yes Minimal movement K/N keys move K/N keys move Routing table None (computed) Required (O(N)) Latency ~20ns ~100ns (binary search) Code complexity ~10 lines ~100 lines Memory 0 bytes 100KB (1024 vnodes) <p>Trade-offs:</p> <p>Pros: - Zero memory overhead (no routing table) - Lock-free (pure function) - Fast (&lt;20ns per lookup) - Simple implementation</p> <p>Cons: - Can't skip buckets (all N buckets must exist) - Adding/removing buckets affects distribution - Not suitable for heterogeneous node capacities</p> <p>NoriKV's choice: - Fixed 1024 virtual shards \u2192 perfect for Jump Hash - Clients compute routing locally \u2192 no network RTT - All SDKs use same algorithm \u2192 consistent routing</p>"},{"location":"architecture/multi-shard-server/#shard-lifecycle","title":"Shard Lifecycle","text":""},{"location":"architecture/multi-shard-server/#1-server-startup","title":"1. Server Startup","text":"<pre><code>// Node::new()\nlet shard_manager = ShardManager::new(\n    config,\n    raft_config,\n    lsm_config,\n    transport,\n    initial_config,\n);\n\n// Node::start()\n// Create shard 0 (primary shard for bootstrapping)\nlet shard_0 = shard_manager.get_or_create_shard(0).await?;\n</code></pre> <p>Why create shard 0 on startup? - Ensures at least one shard is ready - Health checks use shard 0 - Faster first request (no creation latency)</p>"},{"location":"architecture/multi-shard-server/#2-first-request-to-shard-n","title":"2. First Request to Shard N","text":"<pre><code>Client: PUT(\"product:123\", \"laptop\")\n  \u2193\nRouter: shard_for_key(\"product:123\") = 42\n  \u2193\nShardManager: get_or_create_shard(42)\n  \u2193 shard 42 doesn't exist\nCreate directories: /data/raft/shard-42, /data/lsm/shard-42\n  \u2193\nCreate ReplicatedLSM(raft_config, lsm_config, transport)\n  \u2193 Raft initialization\nLoad WAL, elect leader (single-node: immediate)\n  \u2193 LSM initialization\nCreate memtable, load SSTables\n  \u2193\nInsert into shards map\n  \u2193\nReturn Arc&lt;ReplicatedLSM&gt;\n  \u2193\nPUT(\"product:123\", \"laptop\") \u2192 Raft \u2192 LSM\n</code></pre> <p>Latency impact: - Shard creation: ~50-100ms (one-time cost) - Subsequent requests: &lt;1ms (shard already exists)</p>"},{"location":"architecture/multi-shard-server/#3-steady-state","title":"3. Steady State","text":"<pre><code>Client: GET(\"product:123\")\n  \u2193\nRouter: shard_for_key(\"product:123\") = 42\n  \u2193\nShardManager: get_or_create_shard(42)\n  \u2193 Fast path (shard exists)\nRead lock \u2192 HashMap lookup \u2192 return Arc&lt;ReplicatedLSM&gt;\n  \u2193\nGET(\"product:123\") \u2192 Raft read-index \u2192 LSM read\n  \u2193\nReturn value\n</code></pre> <p>Performance: - Routing: ~20ns (hash computation) - Shard lookup: ~50ns (read lock + HashMap) - Raft+LSM read: ~5-10ms</p>"},{"location":"architecture/multi-shard-server/#4-server-shutdown","title":"4. Server Shutdown","text":"<pre><code>// Node::shutdown()\nshard_manager.shutdown().await?;\n\n// ShardManager::shutdown()\nlet shards = self.shards.write();\nfor (shard_id, shard) in shards.iter() {\n    tracing::info!(\"Shutting down shard {}\", shard_id);\n    shard.shutdown().await?;\n}\n</code></pre> <p>Graceful shutdown: 1. Stop accepting new requests 2. Flush all memtables to disk 3. Close WAL files 4. Stop Raft heartbeats 5. Wait for in-flight requests 6. Exit</p>"},{"location":"architecture/multi-shard-server/#design-decisions","title":"Design Decisions","text":""},{"location":"architecture/multi-shard-server/#1-fixed-1024-virtual-shards","title":"1. Fixed 1024 Virtual Shards","text":"<p>Decision: Use 1024 shards, regardless of cluster size.</p> <p>Rationale: - Rebalancing: Easy to move shards between nodes (1024 / 3 nodes = ~341 shards/node) - Granularity: Fine-grained load balancing (vs. 8 shards = coarse) - Jump Hash: Works best with fixed bucket count - Memory: 1024 shards \u00d7 10MB memtable = 10GB worst case (acceptable)</p> <p>Alternative: Dynamic shard count -  Complicates Jump Hash (need consistent rehashing) -  Client routing complexity (need to know current shard count) -  Rebalancing: All keys rehash</p> <p>Trade-off: - More shards = more Raft overhead (more leaders, more heartbeats) - Fewer shards = less granular rebalancing</p> <p>1024 is a sweet spot: - Enough for 100-node clusters (~10 shards/node) - Small enough for low overhead (1024 heartbeats/sec \u2248 negligible)</p>"},{"location":"architecture/multi-shard-server/#2-lazy-shard-initialization","title":"2. Lazy Shard Initialization","text":"<p>Decision: Create shards on first access, not at startup.</p> <p>Rationale: - Fast startup: Don't create 1024 shards upfront (1024 \u00d7 100ms = 102 seconds!) - Memory efficiency: Only create shards that receive requests - Small workloads: A single-node cluster may only use 10-20 shards</p> <p>Example: - Single-node server starts: Creates shard 0 only (~100ms) - First PUT to \"user:42\": Creates shard 42 (~100ms) - Subsequent PUTs to \"user:*\": Reuse existing shards (~0ms creation)</p> <p>Alternative: Create all shards at startup -  102-second startup time -  10GB memory (1024 \u00d7 10MB memtables) -  Unnecessary for small workloads</p> <p>Trade-off: - First request to each shard is slower (~100ms) - Acceptable for production (amortized over millions of requests)</p>"},{"location":"architecture/multi-shard-server/#3-shared-config-separate-state","title":"3. Shared Config, Separate State","text":"<p>Decision: All shards use same RaftConfig and LSMConfig, but separate directories.</p> <p>Rationale: - Consistency: All shards behave identically - Simplicity: One config for all shards - Tuning: Change one config, affects all shards</p> <p>Separate directories: - Enables shard migration (copy <code>/data/lsm/shard-42/</code> to another node) - Isolation (corruption in shard 0 doesn't affect shard 1) - Debugging (inspect specific shard's WAL/SSTables)</p> <p>Alternative: Per-shard config -  Complex: 1024 different configs -  Hard to tune: Which shard is slow? -  No clear benefit</p>"},{"location":"architecture/multi-shard-server/#4-rwlock-for-shard-map","title":"4. RwLock for Shard Map","text":"<p>Decision: Use <code>RwLock&lt;HashMap&lt;ShardId, Arc&lt;ReplicatedLSM&gt;&gt;&gt;</code> for shard map.</p> <p>Rationale: - Read-heavy workload: 99% of requests are reads (shard already exists) - RwLock performance: Multiple readers, no contention - Write-rare: Shard creation happens once per shard (1024 times max)</p> <p>Performance: - Read lock: ~10ns (uncontended) - Write lock: ~50ns (rare)</p> <p>Alternative: DashMap (lock-free concurrent HashMap) -  Better write performance -  Larger dependency -  Overkill for 1024-entry map with rare writes</p> <p>Alternative: Mutex -  Serializes all reads (slower)</p>"},{"location":"architecture/multi-shard-server/#5-replicatedlsm-per-shard","title":"5. ReplicatedLSM per Shard","text":"<p>Decision: Each shard is a separate <code>ReplicatedLSM</code> (Raft + LSM).</p> <p>Rationale: - Independent leadership: Shard 0 leader \u2260 shard 1 leader (load balancing) - Parallel compaction: Each shard compacts independently - Fault isolation: Failure in shard 0 doesn't affect shard 1</p> <p>Alternative: Shared LSM, separate Raft -  LSM global lock (serializes all writes) -  Compaction blocks all shards -  No clear benefit</p> <p>Alternative: Shared Raft, separate LSM -  Single Raft leader (bottleneck) -  Large Raft log (all shards mixed) -  No clear benefit</p>"},{"location":"architecture/multi-shard-server/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"architecture/multi-shard-server/#memory-usage","title":"Memory Usage","text":"<p>Per shard: - Memtable: ~4-16MB (configurable) - Raft log: ~10MB (truncated after snapshots) - Block cache: ~64MB (shared across shards)</p> <p>Total: - 1024 shards \u00d7 16MB memtable = 16GB - 1024 shards \u00d7 10MB Raft log = 10GB - Block cache: 64MB (shared) - Total: ~26GB worst case (all shards active)</p> <p>Typical production: - Active shards: 100-200 (depends on key distribution) - Memory: 3-5GB (100 shards \u00d7 30MB)</p>"},{"location":"architecture/multi-shard-server/#cpu-usage","title":"CPU Usage","text":"<p>Raft heartbeats: - 1024 shards \u00d7 10 heartbeats/sec = 10,240 heartbeats/sec - Each heartbeat: ~10\u00b5s (serialize + send) - Total CPU: ~100ms/sec = 10% of one core</p> <p>LSM compaction: - Independent per shard (parallelized) - Typically 1-2 shards compacting at once - CPU: ~50% of one core during compaction</p> <p>Request handling: - Routing: ~20ns (hash) - Raft replication: ~5ms (network + fsync) - LSM write: ~100\u00b5s (memtable)</p>"},{"location":"architecture/multi-shard-server/#disk-io","title":"Disk I/O","text":"<p>WAL writes: - 1024 shards \u00d7 1000 writes/sec = 1M writes/sec - Batched by Raft (100 entries/batch) - Actual fsyncs: ~10,000/sec - Throughput: 10,000 \u00d7 4KB = 40MB/sec</p> <p>SSTable compaction: - Runs in background (per shard) - Read: ~100MB/sec per shard - Write: ~100MB/sec per shard - Parallelized across shards (saturates disk)</p>"},{"location":"architecture/multi-shard-server/#failure-scenarios","title":"Failure Scenarios","text":""},{"location":"architecture/multi-shard-server/#shard-leader-failure","title":"Shard Leader Failure","text":"<p>Scenario: Node hosting leader for shard 42 crashes.</p> <p>Timeline:</p> <pre><code>t=0:     Leader crashes\nt=500ms: Followers detect (missed heartbeat)\nt=1s:    Election starts\nt=1.5s:  New leader elected\nt=2s:    Client retries, succeeds\n</code></pre> <p>Impact: - Writes to shard 42: Blocked 1-2 seconds (election time) - Reads from shard 42: Blocked 1-2 seconds (need new leader) - Other shards: Unaffected (independent Raft groups)</p> <p>Recovery: - Automatic (Raft election) - No data loss (majority quorum)</p>"},{"location":"architecture/multi-shard-server/#disk-full-one-shard","title":"Disk Full (One Shard)","text":"<p>Scenario: Shard 42's LSM fills disk.</p> <p>Timeline:</p> <pre><code>t=0:     Shard 42 compaction fails (disk full)\nt=1s:    Shard 42 stops accepting writes\nt=5s:    Health check detects shard 42 unhealthy\nt=10s:   Operator adds disk space or migrates shard\n</code></pre> <p>Impact: - Writes to shard 42: Fail with \"disk full\" error - Other shards: Unaffected (separate directories)</p> <p>Mitigation: - Monitor disk space per shard - Alert before full (&gt;80% usage) - Migrate shard to another node with space</p>"},{"location":"architecture/multi-shard-server/#hot-shard","title":"Hot Shard","text":"<p>Scenario: All requests go to shard 42 (poor key distribution).</p> <p>Timeline:</p> <pre><code>t=0:     Shard 42 receives 100K QPS\nt=10s:   Memtable flushes frequently (high write rate)\nt=30s:   L0 storm (10+ SSTables in L0)\nt=60s:   Compaction throttling (slow writes)\nt=120s:  Latency degrades (p95 = 100ms)\n</code></pre> <p>Impact: - Writes to shard 42: Slow (throttled by compaction) - Reads from shard 42: Slow (many L0 files to check) - Other shards: Unaffected</p> <p>Mitigation: - Use better key distribution (add randomness) - Increase shard 42's memtable size (reduce flushes) - Add more replicas for shard 42 (spread read load)</p>"},{"location":"architecture/multi-shard-server/#monitoring","title":"Monitoring","text":""},{"location":"architecture/multi-shard-server/#key-metrics","title":"Key Metrics","text":"<pre><code># Active shards\ncount(lsm_memtable_size_bytes)\n\n# Shards per node\ncount by (node_id) (raft_commit_index)\n\n# Hot shards (high write rate)\ntopk(10, rate(raft_commit_index[5m]))\n\n# Shards without leader\ncount(raft_term) - count(raft_leader == 1)\n</code></pre>"},{"location":"architecture/multi-shard-server/#shard-health-dashboard","title":"Shard Health Dashboard","text":"<p>Grafana panel:</p> <pre><code>{\n  \"targets\": [\n    {\n      \"expr\": \"count(lsm_sstable_count{level=\\\"L0\\\"} &gt; 10)\",\n      \"legendFormat\": \"L0 storms\"\n    },\n    {\n      \"expr\": \"count(lsm_memtable_size_bytes &gt; 67108864)\",\n      \"legendFormat\": \"Large memtables (&gt;64MB)\"\n    },\n    {\n      \"expr\": \"count(raft_leader == 0)\",\n      \"legendFormat\": \"Shards without leader\"\n    }\n  ]\n}\n</code></pre>"},{"location":"architecture/multi-shard-server/#best-practices","title":"Best Practices","text":""},{"location":"architecture/multi-shard-server/#key-distribution","title":"Key Distribution","text":"<p>Good: <pre><code>user:{uuid}     \u2192 Uniform distribution\norder:{timestamp}:{uuid} \u2192 Uniform distribution\n</code></pre></p> <p>Bad: <pre><code>user:admin      \u2192 All requests to one shard\ncounter         \u2192 All requests to one shard (hot key)\n</code></pre></p> <p>Solution: Add randomness or use composite keys.</p>"},{"location":"architecture/multi-shard-server/#capacity-planning","title":"Capacity Planning","text":"<p>Rule of thumb: - 1 shard per 1GB of data - 10 shards per CPU core - 100 shards per node (max)</p> <p>Example: 100GB dataset, 3-node cluster: - 100 shards total (1 per GB) - 33 shards per node - Replication factor 3 \u2192 100 shards \u00d7 3 replicas = 300GB total</p>"},{"location":"architecture/multi-shard-server/#rebalancing","title":"Rebalancing","text":"<p>When to rebalance: - Adding nodes (move shards from heavy \u2192 light nodes) - Removing nodes (move shards from departing node) - Hot shards (move replicas to spread read load)</p> <p>How to rebalance: 1. Identify target shard to move 2. Add new replica on destination node 3. Wait for Raft catch-up (log replication) 4. Promote new replica to voting member (joint consensus) 5. Remove old replica</p> <p>Tools: <pre><code># List shards per node\nnorikv-admin list-shards --group-by node\n\n# Move shard 42 from node0 to node1\nnorikv-admin move-shard --shard-id 42 --from node0 --to node1\n</code></pre></p>"},{"location":"architecture/multi-shard-server/#next-steps","title":"Next Steps","text":"<ul> <li>SWIM Topology Tracking - How cluster membership is tracked</li> <li>Placement &amp; Hashing - Deep dive into Jump Consistent Hash</li> <li>Operations Guide - Production deployment</li> </ul>"},{"location":"architecture/swim-topology/","title":"SWIM Topology Tracking","text":"<p>How NoriKV uses SWIM for failure detection and maintains a consistent cluster topology view.</p>"},{"location":"architecture/swim-topology/#overview","title":"Overview","text":"<p>NoriKV uses SWIM (Scalable Weakly-consistent Infection-style Process Group Membership Protocol) for distributed failure detection and cluster membership management. The topology watcher integrates SWIM events with the ClusterView system to provide clients with up-to-date routing information.</p> <p>Key Features: - Gossip-based failure detection - O(log N) message complexity - Scalable - Works efficiently in clusters of 100+ nodes - Eventually consistent - Membership view converges across cluster - Integration with Raft - Automatic reconfiguration on membership changes - Client routing - Live topology updates via Meta.WatchCluster</p>"},{"location":"architecture/swim-topology/#architecture","title":"Architecture","text":""},{"location":"architecture/swim-topology/#component-interaction","title":"Component Interaction","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  SWIM Membership                           \u2502\n\u2502  - Gossip protocol                         \u2502\n\u2502  - Failure detection                       \u2502\n\u2502  - Incarnation numbers                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502 MembershipEvent stream\n             \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Topology Watcher (background task)        \u2502\n\u2502  - Subscribes to SWIM events               \u2502\n\u2502  - Updates ClusterView                     \u2502\n\u2502  - Triggers refresh on changes             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502\n             \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  ClusterViewManager                        \u2502\n\u2502  - Epoch-versioned cluster state           \u2502\n\u2502  - Node list with roles                    \u2502\n\u2502  - Shard assignments                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502 Broadcast channel\n             \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Meta.WatchCluster (gRPC streaming)        \u2502\n\u2502  - Streams updates to clients              \u2502\n\u2502  - Clients update routing tables           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/swim-topology/#data-flow","title":"Data Flow","text":"<pre><code>Node join:\n  SWIM detects new member\n    \u2193 MembershipEvent::MemberJoined\n  Topology Watcher receives event\n    \u2193\n  ClusterView.add_node(id, addr)\n    \u2193 epoch++\n  Notify subscribers\n    \u2193\n  Clients receive update\n    \u2193\n  Routing table updated\n\nNode failure:\n  SWIM suspects member (missed pings)\n    \u2193 MembershipEvent::MemberSuspect\n  Topology Watcher receives event\n    \u2193\n  ClusterView.update_node_role(id, \"suspect\")\n    \u2193 epoch++\n  Clients route away from suspect node\n    \u2193 MembershipEvent::MemberFailed (timeout)\n  ClusterView.update_node_role(id, \"failed\")\n    \u2193\n  Raft reconfiguration triggered\n    \u2193\n  New leaders elected for affected shards\n</code></pre>"},{"location":"architecture/swim-topology/#swim-protocol","title":"SWIM Protocol","text":""},{"location":"architecture/swim-topology/#how-swim-works","title":"How SWIM Works","text":"<p>SWIM uses a gossip-based approach for scalable failure detection:</p> <p>1. Ping Protocol</p> <p>Each node periodically (every 1 second): 1. Selects a random member to ping 2. Sends PING message 3. Waits for ACK (timeout: 500ms)</p> <p>2. Indirect Ping (Suspicion)</p> <p>If no ACK received: 1. Mark member as \"suspect\" 2. Select k random members (k=3) 3. Ask them to ping the suspect 4. If any ACK received \u2192 member alive 5. If no ACK from anyone \u2192 member failed</p> <p>3. Incarnation Numbers</p> <p>Each node has an incarnation number that increases on: - Refuting a suspicion (node is alive) - Recovering from a crash</p> <p>Higher incarnation number wins in conflict resolution.</p> <p>4. Gossip Piggyback</p> <p>Membership updates piggyback on PING/ACK messages: - MemberJoined events - MemberLeft events - MemberFailed events - MemberAlive refutations</p>"},{"location":"architecture/swim-topology/#why-swim","title":"Why SWIM?","text":"<p>vs. Heartbeat-based (all-to-all pings): - SWIM: O(log N) messages per period - Heartbeat: O(N\u00b2) messages per period - SWIM scales to 100+ nodes efficiently</p> <p>vs. Consul (uses SWIM): - NoriKV uses nori-swim, a minimal SWIM implementation - No external dependencies - Integrated directly with Raft</p> <p>vs. Raft membership: - Raft: Strong consistency, requires quorum - SWIM: Eventually consistent, faster detection - Used together: SWIM detects, Raft reconfigures</p>"},{"location":"architecture/swim-topology/#topology-watcher-implementation","title":"Topology Watcher Implementation","text":""},{"location":"architecture/swim-topology/#code-structure","title":"Code Structure","text":"<p>Location: <code>apps/norikv-server/src/cluster_view.rs</code></p> <pre><code>impl ClusterViewManager {\n    /// Start topology watcher task.\n    pub fn start_topology_watcher(\n        self: Arc&lt;Self&gt;,\n        swim: Arc&lt;nori_swim::SwimMembership&gt;,\n    ) -&gt; tokio::task::JoinHandle&lt;()&gt; {\n        tokio::spawn(async move {\n            let mut events = swim.events();\n            tracing::info!(\"Topology watcher started, listening for SWIM events\");\n\n            loop {\n                match events.recv().await {\n                    Ok(event) =&gt; {\n                        if let Err(e) = self.handle_membership_event(event).await {\n                            tracing::error!(\"Failed to handle membership event: {:?}\", e);\n                        }\n                    }\n                    Err(tokio::sync::broadcast::error::RecvError::Lagged(skipped)) =&gt; {\n                        tracing::warn!(\"Topology watcher lagged, skipped {} events\", skipped);\n                    }\n                    Err(tokio::sync::broadcast::error::RecvError::Closed) =&gt; {\n                        tracing::info!(\"SWIM event channel closed, topology watcher exiting\");\n                        break;\n                    }\n                }\n            }\n        })\n    }\n}\n</code></pre>"},{"location":"architecture/swim-topology/#event-handling","title":"Event Handling","text":"<p>Five Event Types:</p> <pre><code>pub enum MembershipEvent {\n    MemberJoined { id: String, addr: SocketAddr },\n    MemberSuspect { id: String, incarnation: u64 },\n    MemberFailed { id: String },\n    MemberLeft { id: String },\n    MemberAlive { id: String, incarnation: u64 },\n}\n</code></pre> <p>Handler Logic:</p> <pre><code>async fn handle_membership_event(\n    &amp;self,\n    event: nori_swim::MembershipEvent,\n) -&gt; Result&lt;(), ClusterViewError&gt; {\n    use nori_swim::MembershipEvent;\n\n    match event {\n        MembershipEvent::MemberJoined { id, addr } =&gt; {\n            tracing::info!(\"Member joined: {} at {}\", id, addr);\n            self.add_node(id, addr.to_string()).await?;\n        }\n        MembershipEvent::MemberSuspect { id, incarnation } =&gt; {\n            tracing::warn!(\"Member suspected: {} (incarnation {})\", id, incarnation);\n            self.update_node_role(&amp;id, \"suspect\").await?;\n        }\n        MembershipEvent::MemberFailed { id } =&gt; {\n            tracing::warn!(\"Member failed: {}\", id);\n            self.update_node_role(&amp;id, \"failed\").await?;\n        }\n        MembershipEvent::MemberLeft { id } =&gt; {\n            tracing::info!(\"Member left: {}\", id);\n            self.remove_node(&amp;id).await?;\n        }\n        MembershipEvent::MemberAlive { id, incarnation } =&gt; {\n            tracing::info!(\"Member alive: {} (incarnation {})\", id, incarnation);\n            self.update_node_role(&amp;id, \"follower\").await?;\n        }\n    }\n\n    // Trigger a refresh to update shard assignments\n    self.refresh().await?;\n\n    Ok(())\n}\n</code></pre>"},{"location":"architecture/swim-topology/#epoch-versioning","title":"Epoch Versioning","text":"<p>ClusterView uses monotonic epoch numbers for conflict-free updates:</p> <pre><code>pub struct ClusterView {\n    /// Monotonically increasing version number\n    pub epoch: u64,\n\n    /// All nodes in the cluster\n    pub nodes: Vec&lt;ClusterNode&gt;,\n\n    /// Shard assignments and leadership\n    pub shards: Vec&lt;ShardInfo&gt;,\n}\n</code></pre> <p>Update Pattern:</p> <pre><code>async fn update_node_role(&amp;self, node_id: &amp;str, role: &amp;str) -&gt; Result&lt;(), ClusterViewError&gt; {\n    let mut view = self.view.write();\n\n    // Check if update is needed\n    let needs_update = view.nodes.iter()\n        .find(|n| n.id == node_id)\n        .map(|n| n.role != role)\n        .unwrap_or(false);\n\n    if needs_update {\n        // Increment epoch first\n        view.epoch += 1;\n        let new_epoch = view.epoch;\n\n        // Then update the role\n        if let Some(node) = view.nodes.iter_mut().find(|n| n.id == node_id) {\n            node.role = role.to_string();\n            tracing::info!(\"Updated node {} role to {} (epoch {})\", node_id, role, new_epoch);\n        }\n    }\n\n    Ok(())\n}\n</code></pre> <p>Why epochs? - Clients can detect stale views (older epoch) - No need for vector clocks or version vectors - Simple monotonic counter - Works across network partitions (highest epoch wins)</p>"},{"location":"architecture/swim-topology/#design-decisions","title":"Design Decisions","text":""},{"location":"architecture/swim-topology/#1-separate-watcher-task","title":"1. Separate Watcher Task","text":"<p>Decision: Run topology watcher as a separate tokio task.</p> <p>Rationale: - Non-blocking: SWIM events don't block main server - Isolation: Failures in watcher don't crash server - Clean shutdown: Can abort task independently - Testable: Can mock SWIM events</p> <p>Alternative: Handle events in Node::start() loop -  Blocks server startup -  Harder to test -  Mixed concerns</p>"},{"location":"architecture/swim-topology/#2-broadcast-channel-for-updates","title":"2. Broadcast Channel for Updates","text":"<p>Decision: Use <code>tokio::sync::broadcast</code> for ClusterView updates.</p> <p>Rationale: - Multiple subscribers: Meta.WatchCluster, internal monitoring - No missed updates: New subscribers get current view - Backpressure: Lagging subscribers skip old events - Efficient: Lock-free, clone-on-read</p> <p>Code:</p> <pre><code>pub struct ClusterViewManager {\n    /// Current cluster view\n    view: Arc&lt;RwLock&lt;ClusterView&gt;&gt;,\n\n    /// Broadcast channel for cluster view updates\n    update_tx: broadcast::Sender&lt;ClusterView&gt;,\n}\n\nimpl ClusterViewManager {\n    pub fn subscribe(&amp;self) -&gt; broadcast::Receiver&lt;ClusterView&gt; {\n        self.update_tx.subscribe()\n    }\n}\n</code></pre> <p>Alternative: Polling current() -  High CPU usage -  Delayed updates -  No event-driven routing</p>"},{"location":"architecture/swim-topology/#3-refresh-after-every-event","title":"3. Refresh After Every Event","text":"<p>Decision: Call <code>refresh()</code> after handling each SWIM event.</p> <p>Rationale: - Shard assignments: Update which shards are on which nodes - Leader info: Query Raft for current leaders - Consistency: Single atomic view update</p> <p>Code:</p> <pre><code>match event {\n    MembershipEvent::MemberJoined { id, addr } =&gt; {\n        self.add_node(id, addr.to_string()).await?;\n    }\n    // ... other events\n}\n\n// Trigger a refresh to update shard assignments\nself.refresh().await?;\n</code></pre> <p>Alternative: Periodic refresh only -  Delayed routing updates -  Clients may route to dead nodes -  Longer recovery time</p>"},{"location":"architecture/swim-topology/#4-role-based-status","title":"4. Role-Based Status","text":"<p>Decision: Track node roles: <code>follower</code>, <code>suspect</code>, <code>failed</code>, <code>leader</code>.</p> <p>Rationale: - Client routing: Avoid suspected nodes - Debugging: Understand cluster state - Gradual degradation: Suspect \u2192 Failed transition</p> <p>Status Transitions:</p> <pre><code>                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502   Unknown   \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502 MemberJoined\n                           \u25bc\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502  Follower   \u2502\u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502 MemberAlive\n            \u2502              \u2502               \u2502\n            \u2502              \u2502 MemberSuspect \u2502\n            \u2502              \u25bc               \u2502\n            \u2502       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n            \u2502       \u2502   Suspect   \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2502       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2502              \u2502 timeout\n            \u2502              \u25bc\n            \u2502       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502       \u2502   Failed    \u2502\n            \u2502       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2502              \u2502 MemberLeft\n            \u2502              \u25bc\n            \u2502       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502   Removed   \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/swim-topology/#5-borrow-checker-workaround","title":"5. Borrow Checker Workaround","text":"<p>Problem: Can't mutate <code>view.epoch</code> while holding mutable iterator to <code>view.nodes</code>.</p> <p>Code (broken):</p> <pre><code>// This doesn't compile!\nif let Some(node) = view.nodes.iter_mut().find(|n| n.id == node_id) {\n    if node.role != role {\n        view.epoch += 1;  //  Error: can't borrow view again\n        node.role = role.to_string();\n    }\n}\n</code></pre> <p>Solution: Check if update is needed first, then increment epoch before calling iter_mut():</p> <pre><code>// Check if update is needed\nlet needs_update = view.nodes.iter()\n    .find(|n| n.id == node_id)\n    .map(|n| n.role != role)\n    .unwrap_or(false);\n\nif needs_update {\n    // Increment epoch first\n    view.epoch += 1;\n    let new_epoch = view.epoch;\n\n    // Then update the role (no conflict)\n    if let Some(node) = view.nodes.iter_mut().find(|n| n.id == node_id) {\n        node.role = role.to_string();\n        tracing::info!(\"Updated node {} role to {} (epoch {})\", node_id, role, new_epoch);\n    }\n}\n</code></pre> <p>Lesson: Separate read and write phases when working with complex data structures.</p>"},{"location":"architecture/swim-topology/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"architecture/swim-topology/#swim-overhead","title":"SWIM Overhead","text":"<p>Message complexity: - Per-node: O(log N) messages per gossip interval - Cluster-wide: O(N log N) total messages per interval - Bandwidth: ~1KB per message \u00d7 10 messages/sec = 10KB/sec per node</p> <p>Detection time: - Suspect: 500ms (ping timeout) - Failed: 5 seconds (indirect ping + suspicion timeout) - Propagation: O(log N) gossip rounds = ~5 seconds for 100 nodes</p>"},{"location":"architecture/swim-topology/#topology-watcher-overhead","title":"Topology Watcher Overhead","text":"<p>CPU: - Event handling: &lt;100\u00b5s per event - ClusterView update: &lt;500\u00b5s (RwLock + epoch increment) - Refresh: ~5-10ms (queries all active shards)</p> <p>Memory: - ClusterView: ~1KB per node (100 nodes = 100KB) - Broadcast channel: 16-slot ring buffer (~16KB)</p> <p>Event rate: - Steady state: 0-1 events/sec (gossip updates) - Failure scenario: 5-10 events/sec (suspect \u2192 failed) - Cluster expansion: 100 events (all nodes join)</p>"},{"location":"architecture/swim-topology/#failure-scenarios","title":"Failure Scenarios","text":""},{"location":"architecture/swim-topology/#node-crash","title":"Node Crash","text":"<p>Timeline:</p> <pre><code>t=0:     Node B crashes\nt=500ms: Node A pings B, no ACK \u2192 suspects B\nt=1s:    Node A gossips \"B suspected\"\nt=2s:    Cluster converges on \"B suspected\"\nt=5s:    Suspicion timeout \u2192 B marked failed\nt=5.5s:  ClusterView updated, epoch++\nt=6s:    Clients receive update, reroute\nt=7s:    Raft reconfiguration for B's shards\n</code></pre> <p>Recovery:</p> <p>Node B restarts \u2192 increments incarnation \u2192 gossips \"B alive\" \u2192 role updated to \"follower\"</p>"},{"location":"architecture/swim-topology/#network-partition","title":"Network Partition","text":"<p>Scenario: Cluster splits into [A, B] and [C, D, E]</p> <p>Minority partition [A, B]: - A and B suspect C, D, E - Update ClusterView (epoch++) - Cannot commit writes (no Raft quorum) - Clients see \"not_leader\" errors</p> <p>Majority partition [C, D, E]: - C, D, E suspect A, B - Update ClusterView (epoch++) - Continue operating (Raft quorum) - New leaders elected for A/B's shards</p> <p>Partition heals: - A and B receive higher epoch view from C/D/E - A and B adopt majority view - A and B catch up via Raft log replication</p> <p>Winner: Highest epoch view wins (majority partition)</p>"},{"location":"architecture/swim-topology/#split-brain-prevention","title":"Split-Brain Prevention","text":"<p>SWIM alone doesn't prevent split-brain - both partitions can accept writes.</p> <p>NoriKV uses Raft for consistency: - Writes require Raft quorum (majority) - Minority partition cannot commit writes - Clients automatically retry on majority partition</p> <p>Combined approach: - SWIM: Fast failure detection (5 seconds) - Raft: Strong consistency (quorum required) - ClusterView: Client routing (avoid failed nodes)</p>"},{"location":"architecture/swim-topology/#client-integration","title":"Client Integration","text":""},{"location":"architecture/swim-topology/#metawatchcluster-service","title":"Meta.WatchCluster Service","text":"<p>gRPC streaming API:</p> <pre><code>service Meta {\n  rpc WatchCluster(WatchClusterRequest) returns (stream ClusterView);\n}\n\nmessage ClusterView {\n  uint64 epoch = 1;\n  repeated ClusterNode nodes = 2;\n  repeated ShardInfo shards = 3;\n}\n\nmessage ClusterNode {\n  string id = 1;\n  string addr = 2;\n  string role = 3;  // \"leader\", \"follower\", \"suspect\", \"failed\"\n}\n</code></pre> <p>Client usage:</p> <pre><code>let mut stream = client.watch_cluster().await?;\n\nwhile let Some(view) = stream.next().await {\n    let view = view?;\n\n    // Update local routing table\n    routing_table.update(view.epoch, view.nodes, view.shards);\n\n    tracing::info!(\"Cluster view updated to epoch {}\", view.epoch);\n}\n</code></pre>"},{"location":"architecture/swim-topology/#smart-routing","title":"Smart Routing","text":"<p>Client routing logic:</p> <pre><code>fn route_key(&amp;self, key: &amp;[u8]) -&gt; Result&lt;String, Error&gt; {\n    // Hash key to shard\n    let shard_id = self.router.shard_for_key(key);\n\n    // Find leader for shard\n    let shard = self.routing_table.get_shard(shard_id)?;\n    let leader = shard.replicas.iter()\n        .find(|r| r.is_leader &amp;&amp; r.role != \"suspect\" &amp;&amp; r.role != \"failed\")\n        .ok_or(Error::NoLeader)?;\n\n    Ok(leader.addr.clone())\n}\n</code></pre> <p>Benefits: - Direct routing to leader (no redirects) - Avoid failed/suspected nodes - Automatic failover (new view pushed)</p>"},{"location":"architecture/swim-topology/#monitoring","title":"Monitoring","text":""},{"location":"architecture/swim-topology/#key-metrics","title":"Key Metrics","text":"<pre><code># Cluster size\nswim_cluster_size\n\n# Failure rate\nrate(swim_failed_members_total[5m])\n\n# Topology updates per minute\nrate(cluster_view_epoch[1m]) * 60\n\n# Nodes in suspect state\ncount(cluster_nodes{role=\"suspect\"})\n</code></pre>"},{"location":"architecture/swim-topology/#logging","title":"Logging","text":"<p>Structured logs with context:</p> <pre><code>tracing::info!(\n    node_id = %id,\n    addr = %addr,\n    incarnation = incarnation,\n    \"Member joined cluster\"\n);\n\ntracing::warn!(\n    node_id = %id,\n    incarnation = incarnation,\n    \"Member suspected, starting indirect ping\"\n);\n</code></pre> <p>Log aggregation query (JSON logs):</p> <pre><code># Count suspect events per hour\njq 'select(.fields.event == \"MemberSuspect\") | .fields.node_id' \\\n  | sort | uniq -c\n\n# Detect flapping nodes (frequent suspect/alive cycles)\njq 'select(.fields.event == \"MemberAlive\" or .fields.event == \"MemberSuspect\") | .fields.node_id' \\\n  | uniq -c | sort -rn\n</code></pre>"},{"location":"architecture/swim-topology/#testing","title":"Testing","text":""},{"location":"architecture/swim-topology/#unit-tests","title":"Unit Tests","text":"<p>Test event handling:</p> <pre><code>#[tokio::test]\nasync fn test_member_joined() {\n    let cluster_view = ClusterViewManager::new(...);\n\n    cluster_view.handle_membership_event(\n        MembershipEvent::MemberJoined {\n            id: \"node1\".to_string(),\n            addr: \"10.0.1.1:6000\".parse().unwrap(),\n        }\n    ).await.unwrap();\n\n    let view = cluster_view.current();\n    assert_eq!(view.nodes.len(), 2); // includes self\n    assert_eq!(view.epoch, 1);\n}\n</code></pre>"},{"location":"architecture/swim-topology/#integration-tests","title":"Integration Tests","text":"<p>Test failure detection:</p> <pre><code>#[tokio::test]\nasync fn test_node_failure_detection() {\n    // Start 3-node cluster\n    let nodes = start_cluster(3).await;\n\n    // Kill node 2\n    nodes[2].shutdown().await;\n\n    // Wait for SWIM to detect failure\n    tokio::time::sleep(Duration::from_secs(10)).await;\n\n    // Check cluster view\n    let view = nodes[0].cluster_view().current();\n    assert!(view.nodes.iter().any(|n| n.id == \"node2\" &amp;&amp; n.role == \"failed\"));\n}\n</code></pre>"},{"location":"architecture/swim-topology/#next-steps","title":"Next Steps","text":"<ul> <li>Multi-Shard Architecture - How shards are managed</li> <li>SWIM Protocol (nori-swim) - Deep dive into SWIM implementation</li> <li>Client Routing  - SDK integration with ClusterView</li> </ul>"},{"location":"crates/","title":"Crates","text":"<p>NoriKV is built from composable, production-ready crates that can be used individually or together.</p>"},{"location":"crates/#published-crates","title":"Published Crates","text":"<p>Each crate solves a specific problem and can be used standalone in your Rust projects.</p>"},{"location":"crates/#storage-layer","title":"Storage Layer","text":"Crate Purpose Status nori-wal Write-ahead log with recovery Production-ready nori-sstable Immutable sorted string tables Production-ready nori-lsm LSM storage engine \ud83d\udea7 In development"},{"location":"crates/#consensus-membership","title":"Consensus &amp; Membership","text":"Crate Purpose Status nori-raft Raft consensus algorithm \ud83d\udea7 In development nori-swim SWIM membership protocol \ud83d\udea7 In development"},{"location":"crates/#observability","title":"Observability","text":"Crate Purpose Status nori-observe Vendor-neutral observability ABI Ready nori-observe-prom Prometheus exporter \ud83d\udea7 Planned nori-observe-otlp OTLP exporter \ud83d\udea7 Planned"},{"location":"crates/#internal-crates","title":"Internal Crates","text":"<p>These crates are used by the NoriKV server but not published separately:</p> <ul> <li>norikv-types - Shared types, IDs, error codes</li> <li>norikv-placement - Sharding and replica placement</li> <li>norikv-transport-grpc - gRPC transport adapter</li> <li>norikv-testkit - Chaos testing and linearizability checking</li> </ul>"},{"location":"crates/#how-crates-fit-together","title":"How Crates Fit Together","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  NoriKV Server (DI composition)                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Adapters: LSM, Raft, SWIM, gRPC, HTTP         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Ports: Storage, ReplicatedLog, Membership,    \u2502\n\u2502         Transport, Router traits                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Domain: Types, IDs, Versions, Errors          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Key principle: Each crate is independently usable. You can use just <code>nori-wal</code> in your project, or combine <code>nori-wal</code> + <code>nori-sstable</code> + <code>nori-lsm</code> for a complete storage engine.</p>"},{"location":"crates/#using-crates-individually","title":"Using Crates Individually","text":""},{"location":"crates/#example-just-the-wal","title":"Example: Just the WAL","text":"<pre><code>[dependencies]\nnori-wal = \"0.1\"\n\nuse nori_wal::{Wal, WalConfig};\n// Use as append-only log\n</code></pre>"},{"location":"crates/#example-full-storage-stack","title":"Example: Full Storage Stack","text":"<pre><code>[dependencies]\nnori-lsm = \"0.1\"  // Includes WAL + SSTable\n\nuse nori_lsm::LsmEngine;\n// Complete key-value storage\n</code></pre>"},{"location":"crates/#documentation-navigation","title":"Documentation Navigation","text":"<p>Click on any crate above to see its complete documentation:</p> <ul> <li>Getting Started - Installation and quickstart</li> <li>API Reference - Complete API documentation</li> <li>Core Concepts - Understanding the fundamentals</li> <li>Performance - Benchmarks and tuning</li> <li>How It Works - Internal implementation details</li> <li>Recipes - Common usage patterns</li> </ul>"},{"location":"crates/#next-steps","title":"Next Steps","text":"<p>New to NoriKV? Start with nori-wal to understand the foundation, then explore nori-sstable for immutable storage.</p> <p>Building a storage engine? Check out the Architecture section to see how components fit together.</p> <p>Need observability? See nori-observe for vendor-neutral metrics and events.</p>"},{"location":"crates/nori-lsm/","title":"nori-lsm","text":"<p>Embeddable LSM storage engine with ATLL (Adaptive Tiered-Leveled) compaction for heterogeneous workloads.</p> <p>Core Concepts Design Decisions</p>"},{"location":"crates/nori-lsm/#what-is-nori-lsm","title":"What is nori-lsm?","text":"<p>nori-lsm is a production-ready Log-Structured Merge (LSM) storage engine that implements ATLL (Adaptive Tiered-Leveled) compaction\u2014a novel hybrid strategy that adapts between tiered and leveled compaction per key range based on access patterns.</p>"},{"location":"crates/nori-lsm/#key-innovation-atll","title":"Key Innovation: ATLL","text":"<p>Traditional LSMs force a global choice: - Leveled (RocksDB): Fast reads, slow writes (40-100x write amplification) - Tiered (Cassandra): Fast writes, slow reads (10-15 read amplification)</p> <p>ATLL adapts per key range: - Hot ranges \u2192 Leveled (K=1, fast reads) - Cold ranges \u2192 Tiered (K&gt;1, fast writes) - Result: 8-20x WA, 5-12 RA (near-Pareto-optimal for Zipfian workloads)</p>"},{"location":"crates/nori-lsm/#key-features","title":"Key Features","text":"<ul> <li>Adaptive Compaction: ATLL automatically optimizes per key range</li> <li>Guard-Based Partitioning: Range-partitioned slots with fixed boundaries</li> <li>EWMA Heat Tracking: Online access pattern detection with exponential decay</li> <li>Bandit Scheduler: Reinforcement learning for compaction decisions (epsilon-greedy UCB)</li> <li>Bloom Filters: 10 bits/key (0.9% FP rate, 460x faster negative lookups)</li> <li>WAL Integration: Built on nori-wal for durability and recovery</li> <li>Memory Pressure System: 4-zone adaptive backpressure (green/yellow/orange/red)</li> <li>Snapshot Support: Point-in-time consistent snapshots</li> </ul>"},{"location":"crates/nori-lsm/#quick-example","title":"Quick Example","text":"<pre><code>use nori_lsm::{LsmEngine, ATLLConfig};\n\n#[tokio::main]\nasync fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {\n    // Open LSM engine with ATLL\n    let config = ATLLConfig::default();\n    let engine = LsmEngine::open(config).await?;\n\n    // Write data\n    engine.put(b\"user:123\", b\"alice@example.com\").await?;\n    engine.put(b\"user:456\", b\"bob@example.com\").await?;\n\n    // Read data\n    if let Some(value) = engine.get(b\"user:123\").await? {\n        println!(\"Value: {:?}\", value);\n    }\n\n    // Range scan\n    let results = engine.scan(b\"user:\", b\"user:~\").await?;\n    for (key, value) in results {\n        println!(\"{:?} \u2192 {:?}\", key, value);\n    }\n\n    // Snapshot\n    let snapshot = engine.snapshot().await?;\n    let snapshot_value = snapshot.get(b\"user:123\").await?;\n\n    Ok(())\n}\n</code></pre>"},{"location":"crates/nori-lsm/#performance-characteristics","title":"Performance Characteristics","text":"Metric ATLL Pure Leveled Pure Tiered Write Amplification 8-20x 40-100x 6-8x Read Amplification 5-12 (adaptive) 5-10 10-15 Space Amplification 1.1-1.3x 1.1x 1.33x Read Latency (p95) &lt;10ms (hot) &lt;10ms 20-50ms Write Throughput High Low Very High <p>Benchmark highlights (Apple M2 Pro): - Point reads (memtable hit): &lt;1\u00b5s - Point reads (cache hit): ~1\u00b5s - Point reads (cache miss): ~110\u00b5s - Range scans (100 keys): &lt;5ms - Write latency: 1-2ms (WAL fsync)</p>"},{"location":"crates/nori-lsm/#documentation","title":"Documentation","text":""},{"location":"crates/nori-lsm/#core-concepts","title":"Core Concepts","text":"<p>Learn the fundamentals of LSM trees and ATLL's innovations.</p> <p>Core Concepts \u2192</p> <p>Start here if you're new to LSM trees. Topics include: - What is an LSM Tree? (history, math, RUM conjecture) - LSM Compaction Variants (leveled, tiered, universal) - ATLL Architecture (guard keys, K-way fanout, heat tracking, bandit scheduler) - Write Path (WAL \u2192 memtable \u2192 L0 \u2192 slots) - Read Path (memtable \u2192 L0 \u2192 slot with bloom filters) - When to Use ATLL (decision tree, migration guides)</p>"},{"location":"crates/nori-lsm/#design-decisions","title":"Design Decisions","text":"<p>Deep dives into ATLL's design rationale and trade-offs.</p> <p>Design Decisions \u2192</p> <p>Topics include: - Guard-Based Partitioning (why fixed boundaries?) - Bandit Scheduler (epsilon-greedy UCB, reward function) - Amplification Trade-offs (RUM optimization per slot) - Dynamic K-Fanout (heat \u2192 K mapping formula) - Heat Tracking (EWMA convergence analysis)</p>"},{"location":"crates/nori-lsm/#how-it-works","title":"How It Works","text":"<p>Implementation details, algorithms, and internals.</p> <p>How It Works \u2192</p> <p>Topics include: - L0 Admission Control (backpressure, soft throttling) - Slot-Local Tiering (size-tiered merging within slots) - Manifest Format (slot metadata, guard keys) - Compaction Triggering (bandit selection, UCB scoring) - Bloom Filter Implementation (xxHash64, double hashing)</p>"},{"location":"crates/nori-lsm/#performance","title":"Performance","text":"<p>Benchmarks, optimization techniques, and tuning guides.</p> <p>Performance \u2192</p> <p>Topics include: - Write Amplification Analysis (per-slot WA, weighted average) - Read Amplification Analysis (bloom filter impact, cache hit rates) - Tuning Guide (num_slots, k_global, heat_alpha, epsilon) - Benchmark Results (Zipfian workloads, sustained writes, p95 latency)</p>"},{"location":"crates/nori-lsm/#recipes","title":"Recipes","text":"<p>Common usage patterns and integration examples.</p> <p>Recipes \u2192</p> <p>Topics include: - Time-Series Data (recent-heavy reads, TTL integration) - Hot-Cold Separation (multi-tenant systems) - Basic Key-Value Store (session store, cache backend) - Migration Patterns (from RocksDB, Cassandra, B-trees)</p>"},{"location":"crates/nori-lsm/#when-to-use-nori-lsm","title":"When to Use nori-lsm","text":""},{"location":"crates/nori-lsm/#great-fit","title":"Great Fit","text":"<ul> <li>Skewed access patterns (80/20 rule, Zipfian distribution)</li> <li>Mixed workloads (40-60% reads/writes)</li> <li>Time-series with recent-heavy reads (metrics, logs)</li> <li>Multi-tenant systems (active + dormant tenants)</li> <li>Large datasets (&gt;100 GB)</li> <li>SSD wear concerns (lower WA than pure leveled)</li> <li>Need automatic adaptation (no manual tuning)</li> </ul>"},{"location":"crates/nori-lsm/#not-the-right-tool","title":"Not the Right Tool","text":"<ul> <li>Uniform access (all keys equally hot \u2192 use pure leveled)</li> <li>Pure scans (no point queries \u2192 use columnar storage)</li> <li>Tiny datasets (&lt;100 MB \u2192 use in-memory hash table)</li> <li>Need transactions (use SQL database with ACID)</li> <li>Append-only writes (use log, not LSM)</li> </ul>"},{"location":"crates/nori-lsm/#architecture-overview","title":"Architecture Overview","text":""},{"location":"crates/nori-lsm/#atll-structure","title":"ATLL Structure","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  L0: Overlapping files (global)                        \u2502\n\u2502  \u250c\u2500\u2500\u2510 \u250c\u2500\u2500\u2510 \u250c\u2500\u2500\u2510 \u250c\u2500\u2500\u2510 \u250c\u2500\u2500\u2510 \u250c\u2500\u2500\u2510                        \u2502\n\u2502  \u2502  \u2502 \u2502  \u2502 \u2502  \u2502 \u2502  \u2502 \u2502  \u2502 \u2502  \u2502                        \u2502\n\u2502  \u2514\u2500\u2500\u2518 \u2514\u2500\u2500\u2518 \u2514\u2500\u2500\u2518 \u2514\u2500\u2500\u2518 \u2514\u2500\u2500\u2518 \u2514\u2500\u2500\u2518                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2193 L0 Compaction\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  L1+: Range-partitioned slots (adaptive K-way fanout) \u2502\n\u2502                                                        \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 Slot 0  \u2502 Slot 1  \u2502 Slot 2  \u2502 Slot 3  \u2502 Slot 4  \u2502  \u2502\n\u2502  \u2502 (HOT)   \u2502 (COLD)  \u2502 (COLD)  \u2502 (HOT)   \u2502 (COLD)  \u2502  \u2502\n\u2502  \u2502 K=1     \u2502 K=3     \u2502 K=2     \u2502 K=1     \u2502 K=4     \u2502  \u2502\n\u2502  \u2502 [a..d)  \u2502 [d..g)  \u2502 [g..m)  \u2502 [m..t)  \u2502 [t..z)  \u2502  \u2502\n\u2502  \u2502         \u2502         \u2502         \u2502         \u2502         \u2502  \u2502\n\u2502  \u2502 RA=7    \u2502 RA=9    \u2502 RA=8    \u2502 RA=7    \u2502 RA=10   \u2502  \u2502\n\u2502  \u2502 WA=20x  \u2502 WA=8x   \u2502 WA=12x  \u2502 WA=20x  \u2502 WA=6x   \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"crates/nori-lsm/#write-path-flow","title":"Write Path Flow","text":"<pre><code>put(key, value)\n  \u2193\n1. WAL Append (1-2ms, fsync)\n  \u2193\n2. Memtable Insert (50ns, skiplist)\n  \u2193\n[Background Tasks]\n  \u2193\n3. Memtable Flush \u2192 L0 (50-200ms)\n  \u2193\n4. L0 \u2192 Slot Compaction (200-500ms)\n  \u2193\n5. Slot-Local Tiering (500-2000ms, adaptive frequency)\n</code></pre>"},{"location":"crates/nori-lsm/#read-path-flow","title":"Read Path Flow","text":"<pre><code>get(key)\n  \u2193\n1. Check Memtable (50ns)\n  \u2193 (miss)\n2. L0 Bloom Filters (400ns, 6 files)\n  \u2193 (maybe)\n3. Find Slot (10ns binary search)\n  \u2193\n4. Slot Bloom Filters (67-268ns, K runs)\n  \u2193 (maybe)\n5. Block Cache or Disk (500ns cached, 100\u00b5s disk)\n</code></pre>"},{"location":"crates/nori-lsm/#dependencies","title":"Dependencies","text":"<p>nori-lsm is built on: - nori-wal - Write-ahead log for durability - nori-sstable - Immutable sorted tables - nori-observe - Vendor-neutral observability</p> <p>All dependencies are production-ready.</p>"},{"location":"crates/nori-lsm/#configuration-example","title":"Configuration Example","text":"<pre><code>use nori_lsm::{ATLLConfig, L0Config, ResourceConfig};\n\nlet config = ATLLConfig {\n    // L0 configuration\n    l0: L0Config {\n        max_files: 12,                        // Hard stall threshold\n        soft_throttle_threshold: 6,           // 50% of max_files\n        soft_throttle_base_delay_ms: 1,\n    },\n\n    // Slot configuration\n    num_slots: 16,                            // Range partitions\n    k_global: 4,                              // Max runs per cold slot\n\n    // Heat tracking\n    heat_alpha: 0.1,                          // EWMA smoothing\n    heat_decay_interval_secs: 60,\n\n    // Bandit scheduler\n    compaction_epsilon: 0.1,                  // 10% exploration\n    compaction_ucb_c: 2.0,                    // UCB exploration constant\n\n    // Resources\n    resources: ResourceConfig {\n        block_cache_mib: 1024,                // 1 GB block cache\n        index_cache_mib: 128,                 // 128 MB index cache\n        memtables_mib: 512,                   // 512 MB memtable budget\n        filters_mib: 256,                     // 256 MB bloom filters\n    },\n\n    ..Default::default()\n};\n\nlet engine = LsmEngine::open(config).await?;\n</code></pre>"},{"location":"crates/nori-lsm/#status","title":"Status","text":"<p>nori-lsm is production-ready (as of 2025-10-31).</p> <p>Completed features: -  ATLL compaction with guard-based partitioning -  EWMA heat tracking and dynamic K-way fanout -  Bandit-based compaction scheduler (epsilon-greedy UCB) -  Bloom filters (10 bits/key, xxHash64, double hashing) -  Memory pressure system with 4-zone backpressure -  WAL integration for durability -  Snapshot support -  Range scans and iterators -  Comprehensive test suite (108 tests passing) -  Benchmarks (Zipfian workloads, sustained writes)</p> <p>Planned features: - \ud83d\udea7 Dynamic guard key adjustment (adaptive rebalancing) - \ud83d\udea7 Multi-dimensional heat tracking (read/write/scan heat) - \ud83d\udea7 Contextual bandit scheduler (system state as context) - \ud83d\udea7 Learned guard keys (ML-based key space partitioning)</p>"},{"location":"crates/nori-lsm/#real-world-examples","title":"Real-World Examples","text":""},{"location":"crates/nori-lsm/#e-commerce-order-database","title":"E-Commerce Order Database","text":"<pre><code>// 10M orders, 100 GB data\n// Hot: Recent orders (last 30 days, 20% data, 80% reads)\n// Cold: Historical orders (&gt;1 year, 80% data, 20% reads)\n\nlet config = ATLLConfig {\n    num_slots: 32,      // More slots for large dataset\n    k_global: 4,        // Allow cold slots to tier\n    ..Default::default()\n};\n\nlet engine = LsmEngine::open(config).await?;\n\n// Recent orders \u2192 k_max=1 (leveled, fast reads)\n// Historical orders \u2192 k_max=4 (tiered, low WA)\n\n// Result:\n// - p95 latency: &lt;10ms (hot orders)\n// - Write throughput: 10K orders/day sustained\n// - Space amplification: 1.2x\n</code></pre>"},{"location":"crates/nori-lsm/#iot-sensor-metrics","title":"IoT Sensor Metrics","text":"<pre><code>// 1000 sensors \u00d7 1 metric/sec = 86M metrics/day\n// Hot: Last 24 hours (dashboards, alerts)\n// Cold: Last 30 days (historical charts)\n\nlet config = ATLLConfig {\n    num_slots: 64,      // Fine-grained time ranges\n    k_global: 8,        // Higher K for write-heavy\n    compaction_epsilon: 0.15,  // More exploration (shifting patterns)\n    ..Default::default()\n};\n\nlet engine = LsmEngine::open(config).await?;\n\n// Recent metrics \u2192 k_max=1 (fast dashboard queries)\n// Old metrics \u2192 k_max=8 (low compaction overhead)\n\n// Result:\n// - Write throughput: 1K writes/sec sustained\n// - Query latency: &lt;5ms (last 24h), &lt;50ms (last 30d)\n</code></pre>"},{"location":"crates/nori-lsm/#next-steps","title":"Next Steps","text":"<p>New to LSM trees? Start with What is an LSM Tree? to build foundational knowledge.</p> <p>Understand ATLL's innovation? Read ATLL Architecture for the full design.</p> <p>Ready to use nori-lsm? Check out Recipes for common patterns and integration examples.</p> <p>Migrating from another LSM? See When to Use ATLL for migration checklists.</p> <p>Last Updated: 2025-10-31 License: MIT</p>"},{"location":"crates/nori-lsm/core-concepts/","title":"Core Concepts","text":"<p>Foundational knowledge for understanding ATLL (Adaptive Tiered-Leveled LSM) and log-structured storage.</p>"},{"location":"crates/nori-lsm/core-concepts/#overview","title":"Overview","text":"<p>This section covers the theoretical foundations and core architectural concepts behind nori-lsm's ATLL implementation. Read these documents in order to build a complete mental model of how LSM trees work and why ATLL's adaptive approach is effective.</p>"},{"location":"crates/nori-lsm/core-concepts/#learning-path","title":"Learning Path","text":""},{"location":"crates/nori-lsm/core-concepts/#1-what-is-an-lsm-tree","title":"1. What is an LSM Tree?","text":"<p>Start here if you're new to LSM trees.</p> <p>Learn about: - Log-structured storage fundamentals - Historical evolution (1996 LSM paper \u2192 modern variants) - Mathematical foundations (write/read/space amplification) - RUM conjecture (trade-off analysis) - LSM vs B-tree comparison</p> <p>Key takeaway: LSM trees trade read performance for write throughput by deferring merge work to background compaction.</p>"},{"location":"crates/nori-lsm/core-concepts/#2-lsm-compaction-variants","title":"2. LSM Compaction Variants","text":"<p>Understand the landscape of compaction strategies.</p> <p>Learn about: - Leveled Compaction (LCS) - RocksDB's default - Size-Tiered Compaction (STCS) - Cassandra's default - Universal Compaction - RocksDB's hybrid - Mathematical comparison (WA, RA, SA formulas) - When to use each strategy</p> <p>Key takeaway: Traditional LSM strategies are global (one strategy for entire database), forcing suboptimal trade-offs for heterogeneous workloads.</p>"},{"location":"crates/nori-lsm/core-concepts/#3-atll-architecture","title":"3. ATLL Architecture","text":"<p>The flagship document - ATLL's innovation.</p> <p>Learn about: - Guard-based range partitioning (slots) - Dynamic K-way fanout per slot (adaptive tiering) - EWMA heat tracking (access pattern detection) - Bandit-based compaction scheduler (reinforcement learning) - RUM optimization per slot (Pareto-efficient trade-offs)</p> <p>Key takeaway: ATLL adapts compaction strategy per key range, achieving near-optimal performance for Zipfian/skewed workloads.</p>"},{"location":"crates/nori-lsm/core-concepts/#4-write-path","title":"4. Write Path","text":"<p>How data gets into the system.</p> <p>Learn about: - WAL append (durability guarantee) - Memtable insert (in-memory buffer) - Memtable flush (L0 SSTable creation) - L0 compaction (merge to slots) - Backpressure and flow control</p> <p>Key takeaway: Writes are fast (1-2ms) due to sequential WAL + memtable buffering, with compaction happening asynchronously in the background.</p>"},{"location":"crates/nori-lsm/core-concepts/#5-read-path","title":"5. Read Path","text":"<p>How queries retrieve data.</p> <p>Learn about: - Memtable \u2192 L0 \u2192 Slot traversal - Bloom filter optimization (460x faster negative lookups) - Block cache (200x faster cache hits) - Read amplification analysis - Point queries vs range scans</p> <p>Key takeaway: Reads check newest-to-oldest, with bloom filters preventing 99% of unnecessary disk I/O.</p>"},{"location":"crates/nori-lsm/core-concepts/#6-when-to-use-atll","title":"6. When to Use ATLL","text":"<p>Decision guidance for choosing storage engines.</p> <p>Learn about: - Ideal workloads (Zipfian, time-series, multi-tenant) - Edge cases where ATLL struggles - Comparison to alternatives (B-tree, pure leveled, pure tiered) - Migration checklist - Real-world examples</p> <p>Key takeaway: ATLL excels for heterogeneous workloads with hot/cold data; avoid for uniform access or pure scans.</p>"},{"location":"crates/nori-lsm/core-concepts/#quick-reference","title":"Quick Reference","text":""},{"location":"crates/nori-lsm/core-concepts/#performance-characteristics","title":"Performance Characteristics","text":"Metric ATLL Pure Leveled Pure Tiered B-tree Write Amplification 8-20x 40-100x 6-8x 2-10x Read Amplification 5-12 5-10 10-15 1 Space Amplification 1.1-1.3x 1.1x 1.33x 1.1-2.0x Read Latency (p95) &lt;10ms (hot) &lt;10ms 20-50ms &lt;5ms* Write Throughput High Low Very High Medium Adaptation Dynamic Manual Manual N/A <p>*B-tree latency assumes data fits in buffer pool</p>"},{"location":"crates/nori-lsm/core-concepts/#key-formulas","title":"Key Formulas","text":"<p>Write Amplification (Leveled): <pre><code>WA = T \u00d7 (L - 1)\n\nWhere:\n  T = fanout (default: 10)\n  L = number of levels\n</code></pre></p> <p>Read Amplification (ATLL): <pre><code>RA = L0_files + k_max\n\nWhere:\n  L0_files = 6 (typical)\n  k_max = 1 (hot slot) or 4 (cold slot)\n</code></pre></p> <p>ATLL K-Max Formula: <pre><code>k_max = 1 + floor((1 - heat_score) \u00d7 (K_global - 1))\n\nWhere:\n  heat_score \u2208 [0, 1]  (0 = cold, 1 = hot)\n  K_global = 4 (default)\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/#visual-overview","title":"Visual Overview","text":""},{"location":"crates/nori-lsm/core-concepts/#atll-architecture-diagram","title":"ATLL Architecture Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  L0: Overlapping files (global)                        \u2502\n\u2502  \u250c\u2500\u2500\u2510 \u250c\u2500\u2500\u2510 \u250c\u2500\u2500\u2510 \u250c\u2500\u2500\u2510 \u250c\u2500\u2500\u2510 \u250c\u2500\u2500\u2510                        \u2502\n\u2502  \u2502  \u2502 \u2502  \u2502 \u2502  \u2502 \u2502  \u2502 \u2502  \u2502 \u2502  \u2502                        \u2502\n\u2502  \u2514\u2500\u2500\u2518 \u2514\u2500\u2500\u2518 \u2514\u2500\u2500\u2518 \u2514\u2500\u2500\u2518 \u2514\u2500\u2500\u2518 \u2514\u2500\u2500\u2518                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  L1+: Range-partitioned slots (adaptive K-way fanout) \u2502\n\u2502                                                        \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 Slot 0  \u2502 Slot 1  \u2502 Slot 2  \u2502 Slot 3  \u2502 Slot 4  \u2502  \u2502\n\u2502  \u2502 (HOT)   \u2502 (COLD)  \u2502 (COLD)  \u2502 (HOT)   \u2502 (COLD)  \u2502  \u2502\n\u2502  \u2502 K=1     \u2502 K=3     \u2502 K=2     \u2502 K=1     \u2502 K=4     \u2502  \u2502\n\u2502  \u2502 [a..d)  \u2502 [d..g)  \u2502 [g..m)  \u2502 [m..t)  \u2502 [t..z)  \u2502  \u2502\n\u2502  \u2502         \u2502         \u2502         \u2502         \u2502         \u2502  \u2502\n\u2502  \u2502 RA=7    \u2502 RA=9    \u2502 RA=8    \u2502 RA=7    \u2502 RA=10   \u2502  \u2502\n\u2502  \u2502 WA=20x  \u2502 WA=8x   \u2502 WA=12x  \u2502 WA=20x  \u2502 WA=6x   \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nLegend:\n  K = max sorted runs per slot\n  RA = read amplification (L0 + K)\n  WA = write amplification (depends on compaction frequency)\n</code></pre>"},{"location":"crates/nori-lsm/core-concepts/#write-path-flow","title":"Write Path Flow","text":"<pre><code>put(key, value)\n  \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 1. WAL Append    \u2502  \u2190 Durability (fsync, 1-2ms)\n\u2502    (sequential)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n  \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 2. Memtable      \u2502  \u2190 In-memory (skiplist, 50ns)\n\u2502    Insert        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n  \u2193\n[Background Tasks]\n  \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 3. Memtable      \u2502  \u2190 Async (50-200ms)\n\u2502    Flush \u2192 L0    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n  \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 4. L0 \u2192 Slot     \u2502  \u2190 Async (200-500ms)\n\u2502    Compaction    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n  \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 5. Slot-Local    \u2502  \u2190 Async (500-2000ms)\n\u2502    Tiering       \u2502     Adaptive (hot slots more frequent)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"crates/nori-lsm/core-concepts/#read-path-flow","title":"Read Path Flow","text":"<pre><code>get(key)\n  \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 1. Check         \u2502  \u2190 In-memory (50ns)\n\u2502    Memtable      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n  \u2193 (miss)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 2. L0 Bloom      \u2502  \u2190 In-memory (400ns)\n\u2502    Filters       \u2502     99% skip disk reads\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n  \u2193 (maybe)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 3. Find Slot     \u2502  \u2190 Binary search (10ns)\n\u2502    (guard keys)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n  \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 4. Slot Bloom    \u2502  \u2190 In-memory (67-268ns)\n\u2502    Filters       \u2502     Check K runs\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n  \u2193 (maybe)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 5. Block Cache   \u2502  \u2190 Cache hit: 500ns\n\u2502    or Disk       \u2502     Cache miss: 100\u00b5s\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"crates/nori-lsm/core-concepts/#common-questions","title":"Common Questions","text":""},{"location":"crates/nori-lsm/core-concepts/#why-not-just-use-rocksdb","title":"Why not just use RocksDB?","text":"<p>RocksDB's leveled compaction is excellent for uniform workloads, but: - High write amplification (40-100x) wastes I/O on cold data - Manual tuning required (bloom bits, compaction threads, L0 thresholds) - No adaptation to changing access patterns</p> <p>ATLL provides: - 2-5x lower write amplification via adaptive per-slot strategy - Automatic tuning via bandit scheduler - Online adaptation to workload shifts</p>"},{"location":"crates/nori-lsm/core-concepts/#how-does-atll-compare-to-scylladb-ics","title":"How does ATLL compare to ScyllaDB ICS?","text":"<p>ScyllaDB's Incremental Compaction Strategy (ICS) uses time-window bucketing: - Assumes time-series workload (recent = hot, old = cold) - Requires manual time-window configuration - Not general-purpose</p> <p>ATLL: - Access-pattern-based (not time-based, works for any workload) - Automatic adaptation via EWMA heat tracking - General-purpose key-value store</p>"},{"location":"crates/nori-lsm/core-concepts/#does-atll-support-transactions","title":"Does ATLL support transactions?","text":"<p>No. ATLL provides: - Single-key atomicity: <code>put()</code>/<code>delete()</code> are atomic per key - Durability: WAL fsync before returning - Isolation: No read-your-writes guarantees across keys - Consistency: Last-write-wins semantics</p> <p>For full ACID transactions, use: - PostgreSQL (SQL, relational) - CockroachDB (distributed SQL) - TiKV (distributed key-value)</p>"},{"location":"crates/nori-lsm/core-concepts/#can-i-tune-atll-parameters","title":"Can I tune ATLL parameters?","text":"<p>Yes, but typically not needed. Tunable parameters: - <code>num_slots</code>: 16 (default), increase for larger datasets - <code>k_global</code>: 4 (default), increase for write-heavy workloads - <code>heat_alpha</code>: 0.1 (default), increase for rapidly changing patterns - <code>compaction_epsilon</code>: 0.1 (default), increase for non-stationary workloads</p> <p>See Performance Tuning for detailed guidance.</p>"},{"location":"crates/nori-lsm/core-concepts/#next-steps","title":"Next Steps","text":"<p>After completing Core Concepts: 1. Design Decisions - Dive deeper into ATLL's design rationale 2. How It Works - Implementation details and algorithms 3. Performance - Benchmarking, tuning, and optimization 4. Recipes - Common use cases and integration patterns</p> <p>Last Updated: 2025-10-31 Total Reading Time: ~2 hours</p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/","title":"ATLL Architecture","text":"<p>ATLL (Adaptive Tiered-Leveled LSM) is nori-lsm's core innovation: a hybrid compaction strategy that adapts between tiered and leveled behavior per key range, optimizing for heterogeneous workloads.</p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#executive-summary","title":"Executive Summary","text":"<p>ATLL combines the best of both worlds: - Leveled compaction for hot ranges (low read amplification) - Tiered compaction for cold ranges (low write amplification) - Adaptive switching based on real-time access patterns</p> <p>Key Innovation: Instead of choosing one strategy for the entire database, ATLL chooses the optimal strategy per key range dynamically.</p> <p>Result: <pre><code>Write Amplification: 8-20x   (vs 40-100x for pure leveled)\nRead Amplification:  5-12x   (vs 10-15x for pure tiered)\nSpace Amplification: 1.1-1.3x (comparable to leveled)\n</code></pre></p> <p>ATLL achieves near-Pareto-optimal trade-offs for heterogeneous workloads (mixed hot/cold data).</p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#the-problem-one-size-doesnt-fit-all","title":"The Problem: One Size Doesn't Fit All","text":""},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#traditional-lsm-dilemma","title":"Traditional LSM Dilemma","text":"<p>Leveled Compaction (LCS): - Pros: Fast reads (low RA), compact storage - Cons: Slow writes (high WA), constant I/O - Best for: Read-heavy workloads with uniform access</p> <p>Tiered Compaction (STCS): - Pros: Fast writes (low WA), low I/O - Cons: Slow reads (high RA), space overhead - Best for: Write-heavy workloads with sequential scans</p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#real-world-workloads-are-heterogeneous","title":"Real-World Workloads are Heterogeneous","text":"<p>80/20 Rule (Zipfian Distribution): - 80% of accesses hit 20% of keys (hot data) - 20% of accesses hit 80% of keys (cold data)</p> <p>Example: E-commerce database <pre><code>Hot data:\n  Recent orders (last 30 days)      \u2192 Heavy reads + writes\n  Active user sessions              \u2192 Heavy reads + writes\n  Popular product inventory         \u2192 Heavy reads\n\nCold data:\n  Historical orders (&gt;1 year old)   \u2192 Rare reads\n  Archived user data                \u2192 Rare reads\n  Deleted product history           \u2192 Rare reads\n</code></pre></p> <p>Traditional LSMs fail here: - Leveled: Wastes I/O compacting cold data (unnecessary WA) - Tiered: Slows down hot reads with high RA</p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#atlls-solution-adaptive-per-range-strategy","title":"ATLL's Solution: Adaptive Per-Range Strategy","text":""},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#core-idea","title":"Core Idea","text":"<p>Split the key space into range-partitioned slots (like shards): - Each slot is a contiguous key range <code>[guard_min, guard_max)</code> - Each slot independently chooses its compaction strategy - Hot slots \u2192 Leveled (K=1 sorted run) - Cold slots \u2192 Tiered (K&gt;1 sorted runs)</p> <p>Visual: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  L0: Overlapping files (global)                        \u2502\n\u2502  \u250c\u2500\u2500\u2510 \u250c\u2500\u2500\u2510 \u250c\u2500\u2500\u2510 \u250c\u2500\u2500\u2510                                  \u2502\n\u2502  \u2502  \u2502 \u2502  \u2502 \u2502  \u2502 \u2502  \u2502                                  \u2502\n\u2502  \u2514\u2500\u2500\u2518 \u2514\u2500\u2500\u2518 \u2514\u2500\u2500\u2518 \u2514\u2500\u2500\u2518                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  L1: Range-partitioned slots                           \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 Slot 0  \u2502 Slot 1  \u2502 Slot 2  \u2502 Slot 3  \u2502 Slot 4  \u2502  \u2502\n\u2502  \u2502 (HOT)   \u2502 (COLD)  \u2502 (COLD)  \u2502 (HOT)   \u2502 (COLD)  \u2502  \u2502\n\u2502  \u2502 K=1     \u2502 K=3     \u2502 K=2     \u2502 K=1     \u2502 K=4     \u2502  \u2502\n\u2502  \u2502 [a..d)  \u2502 [d..g)  \u2502 [g..m)  \u2502 [m..t)  \u2502 [t..z)  \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nLegend:\n  K = max sorted runs per slot\n  K=1 \u2192 Leveled (no overlaps)\n  K&gt;1 \u2192 Tiered (bounded overlaps)\n</code></pre></p> <p>Result: Hot ranges get fast reads, cold ranges get fast writes.</p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#architectural-components","title":"Architectural Components","text":""},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#1-guard-based-range-partitioning","title":"1. Guard-Based Range Partitioning","text":"<p>Purpose: Divide key space into fixed-size range shards.</p> <p>Implementation: <pre><code>pub struct Slot {\n    pub slot_id: u32,\n    pub guard_key_min: Vec&lt;u8&gt;,    // Inclusive lower bound\n    pub guard_key_max: Vec&lt;u8&gt;,    // Exclusive upper bound\n    pub runs: Vec&lt;SortedRun&gt;,      // Sorted runs in this slot\n    pub k_max: usize,              // Dynamic fanout (1=leveled, &gt;1=tiered)\n    pub heat_score: f32,           // EWMA access frequency\n}\n</code></pre></p> <p>Invariants: 1. No gaps: Every key falls into exactly one slot 2. No overlaps: <code>slot[i].guard_key_max = slot[i+1].guard_key_min</code> 3. Sorted runs: Within each slot, runs are time-ordered (newest first)</p> <p>Example (4 slots, 10 keys): <pre><code>Keys: a, b, c, d, e, f, g, h, i, j\n\nSlot 0: [a, c)  \u2192 Contains a, b\nSlot 1: [c, f)  \u2192 Contains c, d, e\nSlot 2: [f, h)  \u2192 Contains f, g\nSlot 3: [h, \u221e)  \u2192 Contains h, i, j\n</code></pre></p> <p>Why guard keys? - Fixed boundaries: Unlike dynamic range splitting, guards are stable - Predictable behavior: Same key always maps to same slot - Simple recovery: Manifest records guard keys, not dynamic splits</p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#2-dynamic-k-way-fanout","title":"2. Dynamic K-Way Fanout","text":"<p>Purpose: Control overlaps per slot based on heat.</p> <p>K-Max Formula: <pre><code>k_max[slot] = 1 + floor((1 - heat_score) \u00d7 (K_global - 1))\n\nWhere:\n  heat_score \u2208 [0, 1]  (0 = cold, 1 = hot)\n  K_global = 4         (maximum allowed runs per slot)\n</code></pre></p> <p>Examples: <pre><code>Hot slot (heat_score = 0.9):\n  k_max = 1 + floor((1 - 0.9) \u00d7 3) = 1 + floor(0.3) = 1\n  \u2192 Leveled (single sorted run, no overlaps)\n\nWarm slot (heat_score = 0.5):\n  k_max = 1 + floor((1 - 0.5) \u00d7 3) = 1 + floor(1.5) = 2\n  \u2192 Hybrid (up to 2 runs, limited overlaps)\n\nCold slot (heat_score = 0.1):\n  k_max = 1 + floor((1 - 0.1) \u00d7 3) = 1 + floor(2.7) = 3\n  \u2192 Tiered (up to 3 runs, more overlaps)\n</code></pre></p> <p>Read Amplification Impact: <pre><code>RA_slot = L0_files + k_max\n\nHot slot (k_max=1):  RA = 6 + 1 = 7   (fast reads)\nCold slot (k_max=3): RA = 6 + 3 = 9   (acceptable for rare reads)\n</code></pre></p> <p>Write Amplification Impact: <pre><code>WA_slot \u221d compaction_frequency\n\nHot slot (k_max=1):  WA = high (frequent compactions to maintain K=1)\nCold slot (k_max=3): WA = low  (infrequent compactions, allow K&gt;1)\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#3-ewma-heat-tracking","title":"3. EWMA Heat Tracking","text":"<p>Purpose: Track access frequency per slot with exponential decay.</p> <p>Algorithm (Exponential Weighted Moving Average): <pre><code>// On each read/write to a slot:\nheat_score_new = \u03b1 \u00d7 1.0 + (1 - \u03b1) \u00d7 heat_score_old\n\nWhere:\n  \u03b1 = 0.1  (smoothing factor, hardcoded)\n  1.0      (instant heat contribution)\n  heat_score_old (historical heat)\n</code></pre></p> <p>Properties: - Recency bias: Recent accesses weigh more than old ones - Decay: Heat score decays if slot isn't accessed - Stability: Smoothing prevents thrashing on bursty workloads</p> <p>Example Evolution (slot accessed every 10 queries): <pre><code>Initial: heat_score = 0.0\n\nAccess 1:  0.1 \u00d7 1.0 + 0.9 \u00d7 0.0   = 0.100\nNo access: 0.1 \u00d7 0.0 + 0.9 \u00d7 0.100 = 0.090\nNo access: 0.1 \u00d7 0.0 + 0.9 \u00d7 0.090 = 0.081\n...\nAccess 2:  0.1 \u00d7 1.0 + 0.9 \u00d7 0.073 = 0.166\n...\n\nAfter 100 accesses: heat_score \u2192 0.9+ (hot)\nAfter 100 idle:     heat_score \u2192 0.0  (cold)\n</code></pre></p> <p>Convergence: - Hot slot steady-state: ~0.9-1.0 (with regular access) - Cold slot steady-state: ~0.0-0.1 (with no access) - Time to converge: ~20-30 accesses (\u03b1=0.1)</p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#4-bandit-based-scheduler","title":"4. Bandit-Based Scheduler","text":"<p>Purpose: Choose which slot to compact using reinforcement learning.</p> <p>Algorithm: Epsilon-Greedy Multi-Armed Bandit with Upper Confidence Bound (UCB)</p> <p>Decision Process: <pre><code>// With probability \u03b5 (exploration):\nif random() &lt; \u03b5 {\n    select_random_slot()\n}\n// With probability (1-\u03b5) (exploitation):\nelse {\n    select_slot_with_highest_ucb_score()\n}\n</code></pre></p> <p>UCB Score Formula: <pre><code>ucb_score[slot] = avg_reward[slot] + c \u00d7 sqrt(ln(total_selections) / slot_selections)\n                  \u2514\u2500 exploitation \u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500 exploration bonus \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nWhere:\n  avg_reward[slot]    = EMA of historical rewards\n  c = 2.0             = exploration constant\n  total_selections    = total compaction decisions made\n  slot_selections     = times this slot was selected\n</code></pre></p> <p>Reward Function: <pre><code>reward = (predicted_latency_reduction \u00d7 heat_score) / bytes_written\n\nComponents:\n  predicted_latency_reduction: Benefit from reducing RA\n  heat_score:                  Weight hot slots higher\n  bytes_written:               Penalty for write amplification\n</code></pre></p> <p>Intuition: - High reward: Hot slots with high RA (good targets for leveling) - Low reward: Cold slots with low RA (avoid unnecessary compaction) - Exploration bonus: Prefer slots we haven't compacted recently (avoid starvation)</p> <p>Parameters: - \u03b5 = 0.1 (10% exploration, 90% exploitation) - c = 2.0 (standard UCB exploration constant) - \u03b1 = 0.1 (EMA smoothing for reward history)</p> <p>Example: <pre><code>Slot 0 (hot):\n  avg_reward = 8.5\n  selections = 100\n  ucb_score = 8.5 + 2.0 \u00d7 sqrt(ln(1000) / 100)\n            = 8.5 + 2.0 \u00d7 sqrt(6.9 / 100)\n            = 8.5 + 2.0 \u00d7 0.26\n            = 9.0 \u2190 High score (selected often)\n\nSlot 1 (cold):\n  avg_reward = 2.0\n  selections = 10\n  ucb_score = 2.0 + 2.0 \u00d7 sqrt(ln(1000) / 10)\n            = 2.0 + 2.0 \u00d7 sqrt(6.9 / 10)\n            = 2.0 + 2.0 \u00d7 0.83\n            = 3.7 \u2190 Lower score (selected rarely)\n</code></pre></p> <p>Convergence: - Over time, hot slots get compacted more frequently \u2192 K\u21921 (leveled) - Cold slots get compacted less frequently \u2192 K\u2192K_global (tiered)</p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#mathematical-foundations","title":"Mathematical Foundations","text":""},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#rum-optimization-per-slot","title":"RUM Optimization Per Slot","text":"<p>RUM Conjecture (Athanassoulis et al., 2016): <pre><code>For any data structure:\n  R \u00d7 U \u00d7 M \u2265 Constant\n\nWhere:\n  R = Read cost\n  U = Update cost\n  M = Memory cost\n</code></pre></p> <p>ATLL's Insight: Optimize R-U-M per slot, not globally.</p> <p>Hot Slot Strategy (minimize R): <pre><code>k_max = 1  \u2192 Leveled\nR = L0 + 1 = 7 reads     \u2190 Minimize read cost\nU = high                 \u2190 Accept high update cost\nM = low                  \u2190 Compact storage\n</code></pre></p> <p>Cold Slot Strategy (minimize U): <pre><code>k_max = 4  \u2192 Tiered\nR = L0 + 4 = 10 reads    \u2190 Accept higher read cost\nU = low                  \u2190 Minimize update cost\nM = medium               \u2190 Some space overhead\n</code></pre></p> <p>Result: Each slot operates on a different point on the RUM Pareto frontier.</p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#write-amplification-analysis","title":"Write Amplification Analysis","text":"<p>ATLL WA Formula: <pre><code>WA_total = \u03a3(WA_slot[i] \u00d7 write_fraction[i])\n\nWhere:\n  WA_slot[i] = T \u00d7 (1 / compaction_frequency[i])\n  write_fraction[i] = fraction of writes to slot i\n</code></pre></p> <p>Example (4 slots, 80/20 hot/cold distribution): <pre><code>Slot 0 (hot, 40% writes, compacted every 10 writes):\n  WA = 10 \u00d7 (1 / 0.1) = 100 per 10 writes = 10x\n\nSlot 1 (warm, 30% writes, compacted every 20 writes):\n  WA = 10 \u00d7 (1 / 0.05) = 200 per 20 writes = 10x\n\nSlots 2-3 (cold, 15% writes each, compacted every 50 writes):\n  WA = 10 \u00d7 (1 / 0.02) = 500 per 50 writes = 10x each\n\nWeighted average:\n  WA_total = 0.4\u00d710 + 0.3\u00d710 + 0.15\u00d710 + 0.15\u00d710\n           = 4 + 3 + 1.5 + 1.5\n           = 10x\n</code></pre></p> <p>Comparison: - Pure Leveled: 40-100x (compact everything frequently) - ATLL: 8-20x (compact only hot data frequently) - Pure Tiered: 6-8x (but high RA penalty)</p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#space-amplification-analysis","title":"Space Amplification Analysis","text":"<p>ATLL SA Formula: <pre><code>SA_total = \u03a3(SA_slot[i] \u00d7 size_fraction[i])\n\nWhere:\n  SA_slot[i] = 1 + (k_max[i] - 1) / T\n  size_fraction[i] = fraction of total data in slot i\n</code></pre></p> <p>Example (4 slots, uniform data distribution): <pre><code>Slot 0 (hot, k_max=1):\n  SA = 1 + (1 - 1) / 10 = 1.0  (no overhead)\n\nSlot 1 (warm, k_max=2):\n  SA = 1 + (2 - 1) / 10 = 1.1\n\nSlots 2-3 (cold, k_max=4):\n  SA = 1 + (4 - 1) / 10 = 1.3 each\n\nWeighted average:\n  SA_total = 0.25\u00d71.0 + 0.25\u00d71.1 + 0.25\u00d71.3 + 0.25\u00d71.3\n           = 0.25 + 0.275 + 0.325 + 0.325\n           = 1.175x\n</code></pre></p> <p>Comparison: - Leveled: 1.1x (minimal overhead) - ATLL: 1.1-1.3x (close to leveled) - Tiered: 1.33x (higher overhead)</p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#comparison-to-prior-art","title":"Comparison to Prior Art","text":""},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#rocksdb-leveled-compaction","title":"RocksDB (Leveled Compaction)","text":"<p>Strategy: Global leveled compaction across all key ranges</p> <p>Configuration: <pre><code>Level 0: Overlapping files\nLevel 1: 256 MB (partitioned into files)\nLevel 2: 2.56 GB\nLevel 3: 25.6 GB\n...\n</code></pre></p> <p>Pros: - Predictable read latency - Compact storage - Well-tuned implementation</p> <p>Cons: - High write amplification (40-100x) - Constant background I/O - Slow for write-heavy workloads</p> <p>ATLL Improvement: - Adaptive K per slot reduces WA by 2-5x - Maintains comparable RA for hot data - Lower I/O pressure on cold data</p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#cassandra-size-tiered-compaction","title":"Cassandra (Size-Tiered Compaction)","text":"<p>Strategy: Global size-tiered compaction with bucketing</p> <p>Configuration: <pre><code>Tier 1: Files 0-10 MB\nTier 2: Files 10-100 MB\nTier 3: Files 100-1000 MB\n...\n</code></pre></p> <p>Pros: - Low write amplification (6-8x) - Good for write-heavy workloads - Low I/O pressure</p> <p>Cons: - High read amplification (10-15x) - Space overhead (1.33x) - Slow point queries</p> <p>ATLL Improvement: - Hot slots converge to K=1 (leveled) for fast reads - Cold slots remain tiered (low WA) - Best of both worlds</p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#scylladb-incremental-compaction-strategy-ics","title":"ScyllaDB (Incremental Compaction Strategy, ICS)","text":"<p>Strategy: Time-window bucketing + size-based merging</p> <p>Configuration: <pre><code>Window 1: Last 1 hour (small files, tiered)\nWindow 2: Last 24 hours (medium files, hybrid)\nWindow 3: Last 30 days (large files, leveled)\n...\n</code></pre></p> <p>Pros: - Time-series optimized - Good for TTL workloads - Lower WA than pure leveled</p> <p>Cons: - Complex configuration - Time-window assumptions (not general-purpose) - Manual tuning required</p> <p>ATLL Improvement: - Access-pattern-based (not time-based) - Automatic adaptation via bandit scheduler - General-purpose (works for any workload)</p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#monkey-tuning-lsm-via-learning","title":"Monkey (Tuning LSM via Learning)","text":"<p>Strategy: ML-based global parameter tuning</p> <p>Approach: <pre><code>Learn optimal T (fanout) and Bloom filter bits\nbased on workload characteristics\n</code></pre></p> <p>Pros: - Theoretically optimal for static workloads - Academic rigor</p> <p>Cons: - Global tuning (one T for entire tree) - Requires offline learning phase - Not adaptive to dynamic workloads</p> <p>ATLL Improvement: - Per-slot adaptation (finer granularity) - Online learning via bandit (no offline phase) - Handles dynamic workloads (EWMA decay)</p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#when-atll-excels","title":"When ATLL Excels","text":""},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#ideal-workloads","title":"Ideal Workloads","text":"<p>1. Zipfian Access Patterns (80/20 rule) - Hot keys: Recent orders, active sessions - Cold keys: Historical logs, archived data</p> <p>Example: E-commerce database <pre><code>Hot ranges (20% of keys, 80% of accesses):\n  \u2192 k_max=1 (leveled)\n  \u2192 RA = 7, WA = 20x\n\nCold ranges (80% of keys, 20% of accesses):\n  \u2192 k_max=4 (tiered)\n  \u2192 RA = 10, WA = 6x\n\nResult:\n  Overall WA = 0.8\u00d720 + 0.2\u00d76 = 17.2x (vs 40x for pure leveled)\n  Overall RA = 0.8\u00d77 + 0.2\u00d710 = 7.6  (vs 10-15 for pure tiered)\n</code></pre></p> <p>2. Time-Series with Recent-Heavy Reads - Recent data: Heavy reads + writes - Old data: Rare reads, no writes</p> <p>Example: Metrics database <pre><code>Last 24 hours:  k_max=1 (leveled, fast queries)\nLast 7 days:    k_max=2 (hybrid)\nOlder than 30d: k_max=4 (tiered, low WA for compaction)\n</code></pre></p> <p>3. Multi-Tenant Systems - Some tenants active (hot), others dormant (cold)</p> <p>Example: SaaS database <pre><code>Active tenants:   k_max=1 (fast reads for paying users)\nDormant tenants:  k_max=4 (low WA, acceptable slow reads)\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#when-atll-struggles","title":"When ATLL Struggles","text":"<p>1. Uniform Access Patterns - All keys accessed equally often - No hot/cold distinction</p> <p>Result: ATLL converges to global leveled (no benefit)</p> <p>2. Pure Scan Workloads - Sequential scans of entire dataset - No point queries</p> <p>Result: Tiered compaction would be simpler (less overhead)</p> <p>3. Extremely Skewed Writes - Writes concentrated in one slot - Other slots idle</p> <p>Result: Bandit scheduler overhead without benefit</p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#theoretical-guarantees","title":"Theoretical Guarantees","text":""},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#convergence-properties","title":"Convergence Properties","text":"<p>Heat Score Convergence (EWMA): <pre><code>Theorem: For \u03b1=0.1 and stable access pattern,\n         heat_score converges to steady-state within 30 accesses.\n\nProof:\n  heat_t = \u03b1 \u00d7 1 + (1-\u03b1) \u00d7 heat_{t-1}\n         = \u03b1 + (1-\u03b1) \u00d7 heat_{t-1}\n\n  Steady-state (accessed every step):\n    heat_\u221e = \u03b1 / (1 - (1-\u03b1)) = 0.1 / 0.1 = 1.0\n\n  Convergence rate: (1-\u03b1)^t\n    After 30 steps: (0.9)^30 \u2248 0.04 (4% error)\n</code></pre></p> <p>Bandit Regret Bound (UCB): <pre><code>Theorem: UCB with c=2.0 achieves O(log T) regret over T selections.\n\nRegret = \u03a3(reward_optimal - reward_actual)\n\nUpper bound:\n  Regret \u2264 O(K \u00d7 log(T))\n\n  Where:\n    K = number of slots\n    T = total selections\n\nInterpretation:\n  Over 1000 compactions with 16 slots:\n    Regret \u2264 16 \u00d7 log(1000) \u2248 110 suboptimal decisions\n    Efficiency: 89% optimal (after warmup)\n</code></pre></p> <p>K-Max Stability: <pre><code>Theorem: If heat_score stabilizes, k_max stabilizes.\n\nProof:\n  k_max = 1 + floor((1 - heat_score) \u00d7 (K_global - 1))\n\n  Heat stable \u2192 k_max stable (deterministic mapping)\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#configuration-and-tuning","title":"Configuration and Tuning","text":""},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#default-configuration","title":"Default Configuration","text":"<pre><code>pub struct ATLLConfig {\n    // L0 configuration\n    pub l0: L0Config {\n        max_files: 12,                         // Hard stall threshold\n        soft_throttle_threshold: 6,            // 50% of max_files\n        soft_throttle_base_delay_ms: 1,        // Gradual backpressure\n    },\n\n    // Slot configuration\n    pub num_slots: 16,                         // Number of range partitions\n    pub k_global: 4,                           // Max runs per slot (cold slots)\n\n    // Heat tracking\n    pub heat_alpha: 0.1,                       // EWMA smoothing factor\n    pub heat_decay_interval_secs: 60,          // Decay every 60s\n\n    // Bandit scheduler\n    pub compaction_epsilon: 0.1,               // 10% exploration\n    pub compaction_ucb_c: 2.0,                 // UCB exploration constant\n    pub compaction_reward_alpha: 0.1,          // Reward EMA smoothing\n}\n</code></pre>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#tuning-guidelines","title":"Tuning Guidelines","text":"<p>Increase num_slots (32, 64, 128): - When: Large datasets (&gt;1 TB), many distinct ranges - Benefit: Finer-grained adaptation - Cost: More metadata, slower manifest operations</p> <p>Increase k_global (8, 16): - When: Write-heavy workloads, low read QPS - Benefit: Lower WA for cold slots - Cost: Higher RA for cold reads</p> <p>Increase heat_alpha (0.2, 0.3): - When: Rapidly changing workloads - Benefit: Faster adaptation to new patterns - Cost: Less stable (more thrashing)</p> <p>Increase compaction_epsilon (0.15, 0.20): - When: Non-stationary workloads, multi-tenant - Benefit: Better exploration of new strategies - Cost: More suboptimal compactions (higher WA during exploration)</p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#observability-and-monitoring","title":"Observability and Monitoring","text":""},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#key-metrics","title":"Key Metrics","text":"<p>Heat Scores (per slot): <pre><code>heat_score[slot_id]: f32  // Range: [0.0, 1.0]\n</code></pre></p> <p>Interpretation: - <code>0.0 - 0.2</code>: Cold (rarely accessed) - <code>0.2 - 0.5</code>: Warm (occasional access) - <code>0.5 - 0.8</code>: Hot (frequent access) - <code>0.8 - 1.0</code>: Very hot (constant access)</p> <p>K-Max Values (per slot): <pre><code>k_max[slot_id]: usize  // Range: [1, k_global]\n</code></pre></p> <p>Interpretation: - <code>k=1</code>: Leveled (hot slot) - <code>k&gt;1</code>: Tiered (cold slot) - <code>k=k_global</code>: Fully tiered (very cold)</p> <p>Bandit Metrics: <pre><code>BanditSelection {\n    slot_id: u32,           // Which slot was selected\n    explored: bool,         // true = exploration, false = exploitation\n    ucb_score: f64,         // UCB score\n    avg_reward: f64,        // Historical reward\n    selection_count: u64,   // Selection frequency\n}\n\nBanditReward {\n    slot_id: u32,           // Which slot was compacted\n    reward: f64,            // Calculated reward\n    bytes_written: u64,     // Write amplification cost\n    heat_score: f32,        // Access frequency weight\n}\n</code></pre></p> <p>Dashboard Queries: <pre><code>-- Hot slots (candidates for leveling)\nSELECT slot_id, heat_score, k_max\nFROM lsm_stats\nWHERE heat_score &gt; 0.8\nORDER BY heat_score DESC;\n\n-- Compaction frequency by slot\nSELECT slot_id, COUNT(*) as compactions\nFROM bandit_selection\nWHERE timestamp &gt; NOW() - INTERVAL '1 hour'\nGROUP BY slot_id\nORDER BY compactions DESC;\n\n-- Reward trends (should stabilize over time)\nSELECT slot_id, AVG(reward) as avg_reward, STDDEV(reward) as reward_variance\nFROM bandit_reward\nGROUP BY slot_id;\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#implementation-notes","title":"Implementation Notes","text":""},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#guard-key-selection","title":"Guard Key Selection","text":"<p>Problem: How to choose initial guard keys?</p> <p>Strategy 1: Uniform Split (current implementation) <pre><code>// Split key space into equal-sized ranges\nguard_keys = [\n    vec![0x00],              // Slot 0: [0x00, 0x10)\n    vec![0x10],              // Slot 1: [0x10, 0x20)\n    vec![0x20],              // Slot 2: [0x20, 0x30)\n    ...\n    vec![0xF0],              // Slot 15: [0xF0, \u221e)\n]\n</code></pre></p> <p>Strategy 2: Data-Driven Split (future work) <pre><code>// Sample existing data, split by size\n// Goal: Each slot contains ~equal bytes\n</code></pre></p> <p>Trade-off: - Uniform: Simple, predictable, but may create imbalanced slots - Data-driven: Balanced, but requires sampling (expensive on startup)</p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#compaction-triggering","title":"Compaction Triggering","text":"<p>L0 Flush Trigger: <pre><code>if l0_files &gt;= l0.max_files {\n    // Hard stall: Reject writes\n    return Err(Error::SystemPressure);\n} else if l0_files &gt;= l0.soft_throttle_threshold {\n    // Soft throttle: Apply backpressure\n    delay = l0.soft_throttle_base_delay_ms * (l0_files - threshold);\n    sleep(delay);\n}\n</code></pre></p> <p>Slot Compaction Trigger: <pre><code>for slot in slots {\n    if slot.runs.len() &gt; slot.k_max {\n        // Trigger slot-local tiering compaction\n        scheduler.schedule_compaction(slot.slot_id);\n    }\n}\n</code></pre></p> <p>Bandit Selection: <pre><code>// Called periodically (e.g., every 10 L0 flushes)\nfn select_slot_for_compaction() -&gt; u32 {\n    if random() &lt; epsilon {\n        random_slot()  // Exploration\n    } else {\n        argmax(slot.ucb_score)  // Exploitation\n    }\n}\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#future-directions","title":"Future Directions","text":""},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#1-dynamic-guard-key-adjustment","title":"1. Dynamic Guard Key Adjustment","text":"<p>Problem: Fixed guard keys may become imbalanced over time</p> <p>Proposed Solution: Periodically re-partition based on slot sizes <pre><code>// Every 1M writes, rebalance slots:\nif write_count % 1_000_000 == 0 {\n    adjust_guard_keys_to_balance_sizes();\n}\n</code></pre></p> <p>Challenges: Requires moving data across slots (expensive)</p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#2-multi-dimensional-heat-tracking","title":"2. Multi-Dimensional Heat Tracking","text":"<p>Current: Single heat score (access frequency)</p> <p>Proposed: Multiple dimensions <pre><code>pub struct HeatMetrics {\n    pub read_heat: f32,   // Read frequency\n    pub write_heat: f32,  // Write frequency\n    pub scan_heat: f32,   // Range scan frequency\n}\n</code></pre></p> <p>Benefit: Optimize for read-heavy vs write-heavy vs scan-heavy per slot</p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#3-contextual-bandit-scheduler","title":"3. Contextual Bandit Scheduler","text":"<p>Current: Multi-armed bandit (no context)</p> <p>Proposed: Use system state as context <pre><code>// Context: L0 count, slot size, recent query latency\nreward = f(context, action)\n</code></pre></p> <p>Benefit: Better adaptation to system pressure and query patterns</p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#4-learned-guard-keys","title":"4. Learned Guard Keys","text":"<p>Current: Manual uniform split</p> <p>Proposed: ML-based key space partitioning <pre><code>// Learn guard keys that minimize cross-slot queries\nguard_keys = learn_optimal_splits(query_log);\n</code></pre></p> <p>Benefit: Reduce read amplification by aligning slots with query patterns</p>"},{"location":"crates/nori-lsm/core-concepts/atll-architecture/#summary","title":"Summary","text":"<p>ATLL (Adaptive Tiered-Leveled LSM) achieves near-Pareto-optimal trade-offs for heterogeneous workloads by:</p> <ol> <li>Range partitioning key space into slots with fixed guard keys</li> <li>Dynamic K-way fanout per slot based on EWMA heat tracking</li> <li>Bandit-based scheduler for adaptive compaction decisions</li> <li>Slot-local optimization on the RUM Pareto frontier</li> </ol> <p>Result: - Hot ranges \u2192 Leveled (K=1, fast reads, low RA) - Cold ranges \u2192 Tiered (K&gt;1, fast writes, low WA) - Overall: 8-20x WA, 5-12x RA, 1.1-1.3x SA</p> <p>Comparison: - Better than Leveled: 2-5x lower WA, comparable RA for hot data - Better than Tiered: 2x lower RA for hot data, comparable WA - Better than Universal: Simpler, more predictable, better read performance</p> <p>When to use ATLL: - Zipfian/skewed access patterns (80/20 rule) - Time-series with recent-heavy reads - Multi-tenant with mixed activity - General-purpose key-value workloads</p> <p>When to avoid ATLL: - Uniform access patterns (no hot/cold distinction) - Pure scan workloads (sequential only) - Tiny datasets (&lt;100 MB, overhead not worth it)</p> <p>Next steps: Read Write Path and Read Path to understand how ATLL works in practice.</p> <p>Last Updated: 2025-10-31 References: Dayan et al. (Monkey, 2017), Hao et al. (LSM-Bush, 2019), Athanassoulis et al. (RUM, 2016)</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/","title":"LSM Compaction Strategies","text":"<p>Deep dive into Leveled, Tiered, and Universal compaction with mathematical analysis.</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#the-compaction-problem","title":"The Compaction Problem","text":"<p>All LSM-trees face the same fundamental challenge: How to merge sorted runs to reclaim space while minimizing I/O amplification?</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#the-trade-off-space","title":"The Trade-off Space","text":"<pre><code>           Low Write Amp\n                 \u2191\n                 \u2502\n        Tiered   \u2502\n           \u25cf     \u2502\n                 \u2502        Universal\n                 \u2502           \u25cf\n                 \u2502\n      \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192\n                           Low Read Amp\n                 \u2502\n                 \u2502\n                 \u2502     \u25cf Leveled\n                 \u2502\n</code></pre> <p>No free lunch: Every compaction strategy makes a choice on the write amplification vs read amplification spectrum.</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#strategy-1-leveled-compaction-lcs","title":"Strategy 1: Leveled Compaction (LCS)","text":"<p>Origin: LevelDB (Google, 2011), RocksDB default</p> <p>Core principle: Maintain one sorted run per level (except L0).</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#structure","title":"Structure","text":"<pre><code>L0:  [Run 1]  [Run 2]  [Run 3]  [Run 4]\n     \u2193 (overlapping, unsorted by level)\n\nL1:  [\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Single Run \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500]\n     \u2193 (100 MB, non-overlapping ranges)\n\nL2:  [\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Single Run \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500]\n     \u2193 (1 GB, non-overlapping)\n\nL3:  [\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Single Run \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500]\n     \u2193 (10 GB, non-overlapping)\n</code></pre> <p>Invariant: For all <code>L \u2265 1</code>, each level contains exactly 1 sorted run (may be split into multiple SSTables for parallelism, but logically one run).</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#compaction-algorithm","title":"Compaction Algorithm","text":"<p>Trigger: Level <code>L_i</code> exceeds size threshold <code>T^i * base_size</code></p> <p>Action:</p> <ol> <li>Select file(s) in <code>L_i</code> that cover a key range</li> <li>Find overlapping files in <code>L_(i+1)</code></li> <li>Merge the selected files with overlapping files</li> <li>Write output to <code>L_(i+1)</code></li> <li>Delete inputs from <code>L_i</code> and <code>L_(i+1)</code></li> </ol> <p>Example:</p> <pre><code>Before compaction:\nL1: [A-D][E-H][I-L]  (30 MB total, threshold: 100 MB Yes)\nL2: [A-F][G-M][N-Z]  (300 MB total, threshold: 1 GB Yes)\n\nL1 grows to 120 MB (exceeds threshold!)\n\nCompact L1 \u2192 L2:\n  Pick L1: [A-D] (10 MB)\n  Overlapping L2: [A-F] (100 MB)\n  Merge: [A-D] + [A-F] \u2192 [A-F]' (105 MB)\n\nAfter compaction:\nL1: [E-H][I-L]  (20 MB)\nL2: [A-F]'[G-M][N-Z]  (305 MB)\n</code></pre>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#write-amplification-analysis","title":"Write Amplification Analysis","text":"<p>Formula:</p> <pre><code>WA = \u03a3(i=0 to L-1) T\n\nWhere:\n  T = fanout (size ratio between levels)\n  L = number of levels\n\nSimplified: WA = T * L\n\nExample (T=10, L=5):\n  WA = 10 * 5 = 50\n</code></pre> <p>Derivation:</p> <pre><code>Assume 1 MB flush from memtable:\n\nL0 \u2192 L1:\n  Write 1 MB to L1\n  Cost: 1 MB written\n\nL1 \u2192 L2 (when L1 reaches 10 MB):\n  Merge 10 MB (all of L1) with ~10 MB (overlapping L2)\n  Write 10 MB to L2\n  Cost: 10 MB written (10x amplification)\n\nL2 \u2192 L3 (when L2 reaches 100 MB):\n  Merge 100 MB (all of L2) with ~100 MB (overlapping L3)\n  Write 100 MB to L3\n  Cost: 100 MB written (10x amplification)\n\nTotal for 1 MB logical:\n  Physical writes: 1 + 10 + 100 + 1,000 + ... = 1,111 MB\n  WA \u2248 1,111x\n</code></pre> <p>Why so high? Each level compaction rewrites data as it moves down.</p> <p>Optimization: Incremental compaction (compact subsets, not entire levels).</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#read-amplification-analysis","title":"Read Amplification Analysis","text":"<p>Formula:</p> <pre><code>RA = L0_files + \u03a3(i=1 to L) 1\n\nSimplified: RA = L0_files + L\n\nExample (L0=4, L=5):\n  RA = 4 + 5 = 9\n</code></pre> <p>Why is this optimal? Each level (L \u2265 1) has exactly one run, so at most one SSTable overlaps with any query key.</p> <p>Best case: Key in memtable \u2192 RA = 0 Worst case: Key not present \u2192 RA = L0 + L \u2248 10-15</p> <p>With Bloom filters:</p> <pre><code>Expected disk reads: RA * FP_rate\n  = 9 * 0.009 (10 bits/key)\n  = 0.081 SSTables\n\nAverage latency: 9 * 67ns (blooms) + 0.081 * 100\u00b5s \u2248 8\u00b5s\n</code></pre> <p>Conclusion: Leveled compaction has the lowest read amplification of any LSM strategy.</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#space-amplification","title":"Space Amplification","text":"<p>Formula:</p> <pre><code>SA = 1 + (1 / T)\n\nExample (T=10):\n  SA = 1 + 0.1 = 1.1x\n\nExplanation:\n  - Logical data in largest level: 100%\n  - Pending compaction in L-1: ~10% (1/T)\n  - Total physical: 110%\n</code></pre> <p>Why so low? Only one compaction \"lag\" (unmerged data) per level.</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#pros-and-cons","title":"Pros and Cons","text":"<p>** Advantages:**</p> <ol> <li>Lowest read amplification (RA = L0 + L)</li> <li>Predictable query latency (bounded fan-in)</li> <li>Best space efficiency (SA \u2248 1.1x)</li> <li>Simple reasoning (one run per level)</li> </ol> <p>** Disadvantages:**</p> <ol> <li>Highest write amplification (WA = T * L, typically 40-100x)</li> <li>Compaction overhead (continuous background I/O)</li> <li>Write stalls (L0 backlog causes pauses)</li> <li>SSD wear (high write volume)</li> </ol>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#when-to-use-leveled-compaction","title":"When to Use Leveled Compaction","text":"<p>** Use when:** - Read-dominated workload (read:write &gt; 10:1) - Strict read latency SLOs (p99 &lt; 10ms) - Large dataset (&gt; 1 TB) where read amp matters - Point queries dominate (vs range scans)</p> <p>** Avoid when:** - Write-heavy workload (write:read &gt; 1:1) - SSD endurance critical (limited P/E cycles) - Compaction CPU overhead intolerable - Append-only/log-structured use case</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#strategy-2-tiered-compaction-stcs","title":"Strategy 2: Tiered Compaction (STCS)","text":"<p>Origin: Cassandra (2010), inspired by original LSM paper</p> <p>Core principle: Allow multiple runs per level, merge runs of similar size.</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#structure_1","title":"Structure","text":"<pre><code>L0:  [1MB][1MB][1MB][1MB]\n     \u2193 Merge when 4 runs \u2192 4MB run\n\nL1:  [4MB][4MB][4MB][4MB]\n     \u2193 Merge when 4 runs \u2192 16MB run\n\nL2:  [16MB][16MB][16MB][16MB]\n     \u2193 Merge when 4 runs \u2192 64MB run\n\nL3:  [64MB][64MB][64MB]\n     ...\n</code></pre> <p>Key insight: Merge runs when <code>count(runs_of_similar_size) \u2265 threshold</code> (typically 4).</p> <p>Invariant: Runs grow exponentially in size, but multiple runs coexist at each level.</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#compaction-algorithm_1","title":"Compaction Algorithm","text":"<p>Trigger: <code>count(runs with size ~ S) \u2265 T</code> (T = fanout, typically 4)</p> <p>Action:</p> <ol> <li>Select T runs of similar size (e.g., 4 runs of ~4MB each)</li> <li>Merge all T runs into one larger run (size: T * S)</li> <li>Write output (size: ~T * S = 16MB)</li> <li>Delete inputs (4 runs of 4MB each)</li> </ol> <p>Example:</p> <pre><code>Before:\nL1: [4MB][4MB][4MB][4MB][4MB]\n     \u2514\u2500\u2500\u2500 Similar size \u2500\u2500\u2500\u2518\n\nCompact: Merge 4 runs \u2192 1 run\n  Input: 4 * 4MB = 16MB\n  Output: 16MB run\n\nAfter:\nL1: [4MB]\nL2: [16MB] \u2190 new run promoted to next level\n</code></pre>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#write-amplification-analysis_1","title":"Write Amplification Analysis","text":"<p>Formula:</p> <pre><code>WA = \u03a3(i=0 to L-1) T / (T - 1)\n\nSimplified: WA \u2248 T / (T - 1) * L\n\nExample (T=4, L=5):\n  WA \u2248 (4/3) * 5 = 6.67\n\nWith T=10:\n  WA \u2248 (10/9) * 5 = 5.56\n</code></pre> <p>Derivation:</p> <pre><code>Assume 1 MB flush from memtable:\n\nFirst merge (4 * 1MB \u2192 4MB):\n  Read: 4 MB\n  Write: 4 MB\n  Amplification: 4x for inputs, but averaged over 4 flushes \u2192 1x per flush\n\nSecond merge (4 * 4MB \u2192 16MB):\n  Read: 16 MB\n  Write: 16 MB\n  Amplification: 1x per original byte\n\nPattern: Each merge multiplies size by T, but each byte participates in ~log_T(N) merges\n\nWA \u2248 T/(T-1) per level \u2248 1.33x (for T=4)\nTotal: 1.33 * L \u2248 6.67x\n</code></pre> <p>Why much lower than Leveled? Data doesn't rewrite at every level\u2014only when similar-sized runs accumulate.</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#read-amplification-analysis_1","title":"Read Amplification Analysis","text":"<p>Formula:</p> <pre><code>RA = \u03a3(i=0 to L) K_i\n\nWhere K_i = number of runs at level i\n\nWorst case: K_i = T-1 (one less than merge threshold)\n  RA_max = (T-1) * L\n\nExample (T=4, L=5):\n  RA_max = 3 * 5 = 15\n\nAverage case: K_i \u2248 T/2\n  RA_avg \u2248 (T/2) * L = 2 * 5 = 10\n</code></pre> <p>Why higher than Leveled? Multiple runs per level \u2192 more SSTables to check.</p> <p>With Bloom filters:</p> <pre><code>Expected disk reads: RA * FP_rate\n  = 15 * 0.009\n  = 0.135 SSTables\n\nAverage latency: 15 * 67ns + 0.135 * 100\u00b5s \u2248 14\u00b5s\n\nvs Leveled: 9 * 67ns + 0.081 * 100\u00b5s \u2248 8\u00b5s\n\nTiered is ~1.75x slower for point queries\n</code></pre>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#space-amplification_1","title":"Space Amplification","text":"<p>Formula:</p> <pre><code>SA = T / (T - 1)\n\nExample (T=4):\n  SA = 4/3 \u2248 1.33x\n\nExample (T=10):\n  SA = 10/9 \u2248 1.11x\n</code></pre> <p>Explanation: In worst case, each level has <code>T-1</code> runs pending merge. Largest level dominates space, with <code>(T-1)/T</code> extra space for pending runs.</p> <p>Observation: Tiered has slightly higher SA than Leveled, but still reasonable.</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#pros-and-cons_1","title":"Pros and Cons","text":"<p>** Advantages:**</p> <ol> <li>Lowest write amplification (WA \u2248 6-8x vs Leveled 40-100x)</li> <li>Minimal compaction overhead (less frequent merges)</li> <li>Longer SSD lifespan (lower write volume)</li> <li>Excellent for write-heavy workloads</li> </ol> <p>** Disadvantages:**</p> <ol> <li>Higher read amplification (RA \u2248 10-15 vs Leveled 5-10)</li> <li>Unpredictable query latency (variable run count)</li> <li>Worse space efficiency (SA \u2248 1.33x vs Leveled 1.1x)</li> <li>Read performance degrades over time (before compaction)</li> </ol>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#when-to-use-tiered-compaction","title":"When to Use Tiered Compaction","text":"<p>** Use when:** - Write-dominated workload (write:read &gt; 5:1) - Append-only or time-series data - SSD endurance critical (extend lifespan) - Eventual consistency tolerable (async reads)</p> <p>** Avoid when:** - Read latency sensitive (strict p99 SLOs) - Point queries dominate (vs range scans) - Space-constrained (need minimal SA) - Workload has random deletes (tombstone accumulation)</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#strategy-3-universal-compaction","title":"Strategy 3: Universal Compaction","text":"<p>Origin: RocksDB (2014), Facebook</p> <p>Core principle: Hybrid of leveled and tiered\u2014multiple runs per level, but bounded.</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#structure_2","title":"Structure","text":"<pre><code>L0:  [1MB][1MB][1MB][1MB]\n     \u2193 Compact when ratio violated\n\nLn:  [100MB][80MB][60MB][40MB]\n     \u2514\u2500\u2500 Size ratio maintained \u2500\u2500\u2518\n\nInvariant: size(run_i) / size(run_{i+1}) \u2264 R (ratio threshold)\n</code></pre> <p>Key idea: Allow multiple runs, but enforce size-sorted ordering with bounded ratios.</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#compaction-algorithm_2","title":"Compaction Algorithm","text":"<p>Trigger conditions (multiple):</p> <ol> <li>Space amplification: <code>Total_size / Oldest_run_size &gt; SA_threshold</code></li> <li>Size ratio: <code>size(run_i) / size(run_{i+1}) &gt; R</code></li> <li>Run count: <code>count(runs) &gt; max_runs</code></li> </ol> <p>Action: Select consecutive runs that violate ratio, merge them.</p> <p>Example:</p> <pre><code>Before:\nRuns: [10MB][30MB][80MB][200MB]\nRatios: 10/30=0.33, 30/80=0.375, 80/200=0.4\n\nAfter flush (5MB run):\nRuns: [5MB][10MB][30MB][80MB][200MB]\nRatios: 5/10=0.5, 10/30=0.33, 30/80=0.375, 80/200=0.4\n\nSpace amp: 325MB / 200MB = 1.625 &gt; threshold (1.5)\nAction: Merge all runs \u2192 [325MB]\n</code></pre>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#write-amplification-analysis_2","title":"Write Amplification Analysis","text":"<p>Formula (approximate):</p> <pre><code>WA \u2248 1 + log_R(N / M)\n\nWhere:\n  R = size ratio\n  N = total data size\n  M = memtable size\n\nExample (R=2, N=100GB, M=64MB):\n  WA \u2248 1 + log_2(100GB / 64MB)\n     \u2248 1 + log_2(1,600)\n     \u2248 1 + 10.6\n     \u2248 11.6x\n</code></pre> <p>Range: - Best case (like tiered): WA \u2248 5-10x - Worst case (like leveled): WA \u2248 20-40x - Typical: WA \u2248 10-15x</p> <p>Tuning: Increase <code>R</code> \u2192 lower WA, higher RA</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#read-amplification-analysis_2","title":"Read Amplification Analysis","text":"<p>Formula:</p> <pre><code>RA \u2248 log_R(N / M)\n\nExample (R=2, N=100GB, M=64MB):\n  RA \u2248 log_2(1,600) \u2248 10.6\n\nWith R=10:\n  RA \u2248 log_10(1,600) \u2248 3.2\n</code></pre> <p>Range: - Best case (high R): RA \u2248 3-5 (like leveled) - Worst case (low R): RA \u2248 10-20 (like tiered) - Typical: RA \u2248 6-12</p> <p>Observation: Universal provides tunable trade-off between leveled and tiered.</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#space-amplification_2","title":"Space Amplification","text":"<p>Formula:</p> <pre><code>SA = 1 + \u03a3(i=1 to k-1) R^(-i)\n   \u2248 1 + 1/(R-1)\n\nExample (R=2):\n  SA \u2248 1 + 1/1 = 2.0x\n\nExample (R=10):\n  SA \u2248 1 + 1/9 \u2248 1.11x\n</code></pre> <p>Tuning: Higher R \u2192 lower SA (closer to leveled)</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#pros-and-cons_2","title":"Pros and Cons","text":"<p>** Advantages:**</p> <ol> <li>Tunable trade-off (adjust R for workload)</li> <li>Better than tiered for reads (bounded run count)</li> <li>Better than leveled for writes (fewer merges)</li> <li>Adaptive behavior (multiple trigger conditions)</li> </ol> <p>** Disadvantages:**</p> <ol> <li>Complex to tune (many parameters: R, SA threshold, max runs)</li> <li>Unpredictable behavior (heuristic-driven)</li> <li>Neither optimal (middle ground on both WA and RA)</li> <li>Large compactions (can merge many runs at once \u2192 pauses)</li> </ol>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#when-to-use-universal-compaction","title":"When to Use Universal Compaction","text":"<p>** Use when:** - Workload characteristics change over time - Need flexibility to tune WA/RA trade-off - Willing to experiment with parameters - Running RocksDB (well-tested implementation)</p> <p>** Avoid when:** - Predictability critical (SLAs, latency guarantees) - Simple operations preferred (fewer knobs to turn) - Small engineering team (tuning complexity)</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#comparison-matrix","title":"Comparison Matrix","text":"Dimension Leveled (LCS) Tiered (STCS) Universal ATLL (Ours) Write Amplification 40-100x 6-8x 10-15x 8-20x Read Amplification 5-10 10-15 6-12 5-12 (adaptive) Space Amplification 1.1x 1.33x 1.1-2.0x 1.1-1.3x Read Latency (p99) &lt;10ms &lt;20ms &lt;15ms &lt;10ms (hot ranges) Write Throughput Low Highest Medium High Complexity Low Low High Medium Tuning Required Minimal Minimal Extensive Adaptive Best For Read-heavy Write-heavy Mixed (tunable) Heterogeneous"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#mathematical-deep-dive-wa-vs-ra-trade-off","title":"Mathematical Deep Dive: WA vs RA Trade-off","text":""},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#the-fundamental-constraint","title":"The Fundamental Constraint","text":"<p>Theorem (informal): For LSM-trees, <code>WA * RA \u2265 C</code> for some constant C.</p> <p>Intuition: Lower WA requires more runs (to avoid merging) \u2192 higher RA (more runs to check).</p> <p>Proof sketch:</p> <pre><code>Let:\n  K = number of runs at steady state\n  T = fanout\n\nWrite Amplification:\n  WA \u2248 T / K  (fewer runs \u2192 more merges per level)\n\nRead Amplification:\n  RA \u2248 K  (more runs \u2192 more to check)\n\nProduct:\n  WA * RA \u2248 (T / K) * K = T\n\nConclusion: WA * RA \u2248 constant (T)\n</code></pre> <p>Implication: Can't optimize both simultaneously. Must choose a position on the trade-off curve.</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#pareto-frontier","title":"Pareto Frontier","text":"<pre><code>RA\n \u2502\n \u2502  Tiered \u25cf\n15\u2502\n \u2502\n10\u2502               \u25cf Universal\n \u2502\n 5\u2502                         \u25cf Leveled\n \u2502\n 0\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 WA\n   0     5    10   15   20   40   100\n\nPareto-optimal strategies lie on this curve\nInterior points (below curve) are inefficient\n</code></pre> <p>ATLL approach: Move along the curve per workload region (hot ranges \u2192 leveled, cold ranges \u2192 tiered).</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#workload-decision-tree","title":"Workload Decision Tree","text":"<pre><code>graph TD\n    A[What is your workload?] --&gt; B{Write:Read Ratio}\n    B --&gt;|&gt; 5:1| C[Write-Heavy]\n    B --&gt;|1:1 to 5:1| D[Mixed]\n    B --&gt;|&lt; 1:1| E[Read-Heavy]\n\n    C --&gt; F{SSD Endurance Critical?}\n    F --&gt;|Yes| G[Tiered Yes]\n    F --&gt;|No| H[Universal or ATLL]\n\n    D --&gt; I{Workload Changes?}\n    I --&gt;|Yes| J[Universal or ATLL Yes]\n    I --&gt;|No| K[Leveled with tuning]\n\n    E --&gt; L{Strict Latency SLOs?}\n    L --&gt;|Yes| M[Leveled Yes]\n    L --&gt;|No| N[Leveled or ATLL]</code></pre>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#hybrid-and-adaptive-strategies","title":"Hybrid and Adaptive Strategies","text":""},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#rocksdb-level-aware-compaction","title":"RocksDB Level-Aware Compaction","text":"<p>Idea: Use tiered for L0, leveled for L1+.</p> <p>Benefit: Absorb write bursts (tiered L0), maintain read performance (leveled L1+).</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#scylladb-incremental-compaction-ics","title":"ScyllaDB Incremental Compaction (ICS)","text":"<p>Idea: Tiered strategy with aggressive space reclamation.</p> <p>Optimization: Merge smaller runs more frequently to reduce space amplification.</p> <p>Trade-off: Slightly higher WA than pure tiered, but much better SA.</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#dostoevsky","title":"Dostoevsky","text":"<p>Paper: \"Dostoevsky: Better Space-Time Trade-Offs for LSM-Tree Based Key-Value Stores via Adaptive Removal of Superfluous Merging\" (Dayan et al., SIGMOD 2018)</p> <p>Idea: Lazy leveling\u2014delay merging at higher levels.</p> <p>Formula:</p> <pre><code>WA_Dostoevsky \u2248 (T * L) / 2\n  vs\nWA_Leveled \u2248 T * L\n\nSavings: 50% write amplification reduction\n</code></pre> <p>Cost: Slightly higher RA (2 runs per level at L2+).</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#atll-adaptive-tiered-leveled","title":"ATLL (Adaptive Tiered-Leveled)","text":"<p>Our approach: Covered in depth in ATLL Architecture.</p> <p>Key innovation: Per-slot K value (number of runs): - Hot slots: K=1 (leveled, low RA) - Cold slots: K=3-5 (tiered, low WA) - Adaptation: Based on EWMA heat tracking</p> <p>Result: Best of both worlds for heterogeneous workloads.</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#practical-guidance","title":"Practical Guidance","text":""},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#choosing-a-strategy","title":"Choosing a Strategy","text":"<p>Start with Leveled if: - Unsure about workload characteristics - General-purpose key-value store - Read latency matters - Total dataset &gt; 100 GB</p> <p>Switch to Tiered if: - Observing high write stalls - SSD wearing out quickly - Compaction CPU overhead &gt; 30% - Write:read ratio &gt; 5:1</p> <p>Consider Universal if: - Using RocksDB already - Workload varies seasonally - Willing to tune parameters - Need balance between WA and RA</p> <p>Use ATLL if: - Workload has hot/cold regions - Want automatic adaptation - Can't predict access patterns - Building on nori-lsm \ud83d\ude0a</p>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#monitoring-metrics","title":"Monitoring Metrics","text":"<p>Key metrics to track:</p> <pre><code>Write Amplification:\n  physical_bytes_written / logical_bytes_written\n\nRead Amplification:\n  sstables_accessed_per_query\n\nSpace Amplification:\n  physical_storage / logical_data_size\n\nCompaction Backlog:\n  pending_compaction_bytes\n  l0_file_count\n\nLatency Percentiles:\n  p50, p99, p999 for GET/PUT/SCAN\n</code></pre> <p>Actionable thresholds:</p> <pre><code>WA &gt; 50: Consider tiered or tune fanout\nRA &gt; 15: Enable blooms or switch to leveled\nSA &gt; 1.5: Trigger manual compaction\nL0 count &gt; 12: Write stall imminent\n</code></pre>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#summary","title":"Summary","text":""},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#leveled-compaction","title":"Leveled Compaction","text":"<ul> <li>Best for: Read-heavy, large datasets, predictable latency</li> <li>Worst for: Write-heavy, SSD wear-sensitive</li> <li>WA: 40-100x | RA: 5-10 | SA: 1.1x</li> </ul>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#tiered-compaction","title":"Tiered Compaction","text":"<ul> <li>Best for: Write-heavy, append-only, SSD endurance</li> <li>Worst for: Read latency, point queries</li> <li>WA: 6-8x | RA: 10-15 | SA: 1.33x</li> </ul>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#universal-compaction","title":"Universal Compaction","text":"<ul> <li>Best for: Mixed workloads, tunable systems</li> <li>Worst for: Simple operations, predictability</li> <li>WA: 10-15x | RA: 6-12 | SA: 1.1-2.0x</li> </ul>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#atll-our-approach","title":"ATLL (Our Approach)","text":"<ul> <li>Best for: Heterogeneous workloads, automatic adaptation</li> <li>Worst for: Uniform access patterns (no benefit over simple strategies)</li> <li>WA: 8-20x (adaptive) | RA: 5-12 (adaptive) | SA: 1.1-1.3x</li> </ul>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#whats-next","title":"What's Next?","text":"<ul> <li>ATLL Architecture - Our guard-based partitioning and dynamic K approach</li> <li>Write Path - How writes flow through memtable \u2192 L0 \u2192 compaction</li> <li>Read Path - How reads traverse levels with Bloom filters</li> <li>Amplification Trade-offs - Deep math on RUM conjecture</li> </ul>"},{"location":"crates/nori-lsm/core-concepts/lsm-variants/#further-reading","title":"Further Reading","text":"<p>Academic Papers: - \"The Log-Structured Merge-Tree\" - O'Neil et al., 1996 (original LSM) - \"Dostoevsky: Better Space-Time Trade-Offs\" - Dayan et al., SIGMOD 2018 - \"Monkey: Optimal Navigable Key-Value Store\" - Dayan et al., SIGMOD 2017</p> <p>Implementation Docs: - RocksDB Compaction Wiki - Cassandra STCS - ScyllaDB ICS</p> <p>Books: - \"Database Internals\" by Alex Petrov - Chapter 8 (Compaction Strategies)</p>"},{"location":"crates/nori-lsm/core-concepts/read-path/","title":"Read Path","text":"<p>How reads flow through nori-lsm from <code>get()</code> call through memtable, L0, and slots, including bloom filter optimization and block caching.</p>"},{"location":"crates/nori-lsm/core-concepts/read-path/#overview","title":"Overview","text":"<p>Read path stages (newest to oldest): 1. Check memtable \u2192 In-memory buffer (hot data) 2. Check L0 files \u2192 Recently flushed SSTables (overlapping) 3. Check slot \u2192 Range-partitioned SSTables (K-way fanout) 4. Return None \u2192 Key doesn't exist</p> <p>Latency breakdown (typical values): <pre><code>get(\"key\"):\n  \u251c\u2500 Memtable lookup:     50ns     (in-memory skiplist)\n  \u251c\u2500 L0 bloom filters:    400ns    (6 files \u00d7 67ns each)\n  \u251c\u2500 Slot bloom filter:   67ns     (1 slot)\n  \u251c\u2500 Block index lookup:  100ns    (binary search)\n  \u251c\u2500 Block read (cached): 500ns    (LRU cache hit)\n  \u2514\u2500 Block read (disk):   100\u00b5s    (SSD read)\n\nTotal (cache hit):  ~1-2\u00b5s\nTotal (cache miss): ~100\u00b5s\n</code></pre></p> <p>Key optimization: Bloom filters prevent 99% of unnecessary disk reads.</p>"},{"location":"crates/nori-lsm/core-concepts/read-path/#stage-1-memtable-lookup","title":"Stage 1: Memtable Lookup","text":""},{"location":"crates/nori-lsm/core-concepts/read-path/#purpose","title":"Purpose","text":"<p>Fastest path: Check in-memory buffer for recent writes</p> <p>Data Structure: Skip list (sorted, lock-free) <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Active Memtable (current writes)      \u2502\n\u2502  Skip List: [a][b][c][g][m][z]        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>Lookup Algorithm: <pre><code>pub fn get(&amp;self, key: &amp;[u8]) -&gt; Option&lt;Vec&lt;u8&gt;&gt; {\n    // O(log N) expected, lock-free\n    self.skiplist.get(key)\n}\n</code></pre></p> <p>Result Handling: <pre><code>match memtable.get(key) {\n    Some(value) =&gt; return Ok(Some(value)),  // Cache hit (fast path)\n    None =&gt; continue to L0,                   // Cache miss\n}\n</code></pre></p> <p>Performance: - Latency: 50-100ns (in-memory, no I/O) - Hit Rate: Depends on workload   - Write-heavy: 20-40% (recent writes in memtable)   - Read-heavy: 5-10% (most reads hit older data)</p>"},{"location":"crates/nori-lsm/core-concepts/read-path/#stage-2-l0-bloom-filters","title":"Stage 2: L0 Bloom Filters","text":""},{"location":"crates/nori-lsm/core-concepts/read-path/#problem-l0-overlaps","title":"Problem: L0 Overlaps","text":"<p>L0 files overlap (contain arbitrary key ranges): <pre><code>L0-001.sst: [a, g, m, z]  (4 keys)\nL0-002.sst: [b, c, n]     (3 keys)\nL0-003.sst: [d, p, q]     (3 keys)\n</code></pre></p> <p>Naive Approach (without bloom filters): <pre><code>// Check every L0 file (slow!)\nfor l0_file in l0_files {\n    if let Some(value) = l0_file.get(key)? {\n        return Ok(Some(value));\n    }\n}\n// Worst case: 6 disk reads for negative lookup\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/read-path/#bloom-filter-optimization","title":"Bloom Filter Optimization","text":"<p>Bloom Filter: Probabilistic set membership test <pre><code>Bloom filter for L0-001.sst: [a, g, m, z]\n\nQuery \"m\":  bloom.contains(\"m\") \u2192 true   (might exist)\nQuery \"x\":  bloom.contains(\"x\") \u2192 false  (definitely doesn't exist)\n</code></pre></p> <p>False Positive Rate: 0.9% (10 bits/key) <pre><code>FP rate \u2248 0.6185^(m/n)\n        \u2248 0.6185^10\n        \u2248 0.009 (0.9%)\n</code></pre></p> <p>Optimized Lookup: <pre><code>for l0_file in l0_files {\n    // 1. Check bloom filter (67ns, in-memory)\n    if !l0_file.bloom.contains(key) {\n        continue;  // Skip this file (definite miss)\n    }\n\n    // 2. Read SSTable (100\u00b5s, disk I/O)\n    if let Some(value) = l0_file.get(key)? {\n        return Ok(Some(value));\n    }\n}\n</code></pre></p> <p>Performance: - Bloom check: 67ns per file (in-memory) - Disk reads avoided: 99.1% of negative lookups - Total bloom overhead: 6 files \u00d7 67ns = 400ns</p> <p>Example (6 L0 files): <pre><code>Without blooms:\n  Negative lookup: 6 disk reads \u00d7 100\u00b5s = 600\u00b5s\n\nWith blooms:\n  Bloom checks: 6 \u00d7 67ns = 400ns\n  Disk reads: 0 (0.9% false positive rate)\n  Average latency: 400ns + (0.009 \u00d7 100\u00b5s) \u2248 1.3\u00b5s\n\nImprovement: 600\u00b5s / 1.3\u00b5s \u2248 460x faster\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/read-path/#stage-3-slot-selection","title":"Stage 3: Slot Selection","text":""},{"location":"crates/nori-lsm/core-concepts/read-path/#guard-key-routing","title":"Guard Key Routing","text":"<p>Problem: Which slot contains the key?</p> <p>Guard Keys: Fixed boundaries for each slot <pre><code>Slot 0: [0x00, 0x40)  (a-d)\nSlot 1: [0x40, 0x80)  (e-m)\nSlot 2: [0x80, 0xC0)  (n-t)\nSlot 3: [0xC0, \u221e)     (u-z)\n</code></pre></p> <p>Binary Search (O(log num_slots)): <pre><code>fn find_slot_for_key(&amp;self, key: &amp;[u8]) -&gt; u32 {\n    // Binary search on guard keys\n    self.slots\n        .binary_search_by(|slot| {\n            if key &lt; slot.guard_key_min {\n                Ordering::Greater\n            } else if key &gt;= slot.guard_key_max {\n                Ordering::Less\n            } else {\n                Ordering::Equal\n            }\n        })\n        .unwrap()\n}\n</code></pre></p> <p>Example: <pre><code>Query: get(\"m\")\n\nBinary search:\n  Compare \"m\" vs Slot 1 ([e..m))  \u2192 \"m\" &gt;= 0x80 (Slot 2)\n  Compare \"m\" vs Slot 2 ([n..t))  \u2192 \"m\" &lt; 0x80 (Slot 1)\n  Found: Slot 1\n\nResult: Check Slot 1 SSTables only (not Slots 0, 2, 3)\n</code></pre></p> <p>Performance: - Latency: 10-20ns (binary search on 16 slots) - Benefit: Reduces search space from all slots to 1 slot</p>"},{"location":"crates/nori-lsm/core-concepts/read-path/#stage-4-slot-bloom-filters","title":"Stage 4: Slot Bloom Filters","text":""},{"location":"crates/nori-lsm/core-concepts/read-path/#k-way-fanout","title":"K-Way Fanout","text":"<p>Slot structure (K sorted runs): <pre><code>Slot 1 (k_max=3):\n  Run 0 (newest): [e, f, g]\n  Run 1:          [h, i, j]\n  Run 2 (oldest): [k, l, m]\n</code></pre></p> <p>Bloom Filter Check (same as L0): <pre><code>for run in slot.runs {\n    // 1. Check bloom filter (67ns)\n    if !run.bloom.contains(key) {\n        continue;\n    }\n\n    // 2. Read SSTable if bloom says \"maybe\"\n    if let Some(value) = run.get(key)? {\n        return Ok(Some(value));\n    }\n}\n</code></pre></p> <p>Read Amplification: <pre><code>Hot slot (k_max=1):\n  RA = 1 bloom check + 1 disk read (worst case)\n\nCold slot (k_max=4):\n  RA = 4 bloom checks + 4 disk reads (worst case)\n</code></pre></p> <p>ATLL Advantage: Hot slots converge to k_max=1 <pre><code>get(\"hot_key\"):\n  Slot bloom checks: 1 \u00d7 67ns = 67ns\n  Disk reads (worst): 1 \u00d7 100\u00b5s = 100\u00b5s\n\nget(\"cold_key\"):\n  Slot bloom checks: 4 \u00d7 67ns = 268ns\n  Disk reads (worst): 4 \u00d7 100\u00b5s = 400\u00b5s\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/read-path/#stage-5-sstable-lookup","title":"Stage 5: SSTable Lookup","text":""},{"location":"crates/nori-lsm/core-concepts/read-path/#block-index","title":"Block Index","text":"<p>SSTable Structure (refresher): <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Data Blocks (4KB each)                \u2502\n\u2502   \u251c\u2500 Block 0: [a..f]   offset=0       \u2502\n\u2502   \u251c\u2500 Block 1: [g..m]   offset=4096    \u2502\n\u2502   \u2514\u2500 Block 2: [n..z]   offset=8192    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Block Index (in-memory)               \u2502\n\u2502   \u251c\u2500 Block 0: first_key=\"a\"           \u2502\n\u2502   \u251c\u2500 Block 1: first_key=\"g\"           \u2502\n\u2502   \u2514\u2500 Block 2: first_key=\"n\"           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Bloom Filter (loaded on open)         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>Index Lookup (binary search): <pre><code>fn find_block_for_key(&amp;self, key: &amp;[u8]) -&gt; usize {\n    // Binary search on block index (O(log num_blocks))\n    self.index\n        .binary_search_by(|block| block.first_key.cmp(key))\n        .unwrap_or_else(|i| i - 1)\n}\n</code></pre></p> <p>Example: <pre><code>Query: get(\"m\")\n\nBlock index:\n  Block 0: first_key=\"a\"\n  Block 1: first_key=\"g\"\n  Block 2: first_key=\"n\"\n\nBinary search:\n  \"m\" &gt;= \"g\" (Block 1) and \"m\" &lt; \"n\" (Block 2)\n  \u2192 Read Block 1\n\nResult: Read 1 block (4KB) instead of entire SSTable (64KB)\n</code></pre></p> <p>Performance: - Latency: 50-100ns (binary search on ~16 blocks) - I/O Saved: 94% (read 1 block instead of 16)</p>"},{"location":"crates/nori-lsm/core-concepts/read-path/#stage-6-block-cache","title":"Stage 6: Block Cache","text":""},{"location":"crates/nori-lsm/core-concepts/read-path/#lru-cache","title":"LRU Cache","text":"<p>Purpose: Cache hot blocks in memory (avoid repeated disk reads)</p> <p>Configuration: <pre><code>pub struct ResourceConfig {\n    pub block_cache_mib: usize,  // Default: 1024 MB\n}\n</code></pre></p> <p>Lookup: <pre><code>async fn read_block(&amp;self, block_id: u64) -&gt; Result&lt;Block&gt; {\n    // 1. Check cache (fast path)\n    if let Some(block) = self.cache.get(&amp;block_id) {\n        return Ok(block);  // Cache hit (~500ns)\n    }\n\n    // 2. Read from disk (slow path)\n    let block = self.read_block_from_disk(block_id).await?;  // ~100\u00b5s\n\n    // 3. Cache for future reads\n    self.cache.put(block_id, block.clone());\n\n    Ok(block)\n}\n</code></pre></p> <p>Cache Hit Rate: <pre><code>Working set &lt; cache size:\n  Hit rate: 95-99% (steady state)\n  Average latency: ~500ns\n\nWorking set &gt; cache size:\n  Hit rate: 50-80% (cache thrashing)\n  Average latency: ~50\u00b5s (50% cache miss)\n</code></pre></p> <p>Performance: - Cache hit: 500ns (in-memory read) - Cache miss: 100\u00b5s (SSD read) - Improvement: 200x faster when cached</p>"},{"location":"crates/nori-lsm/core-concepts/read-path/#read-amplification-analysis","title":"Read Amplification Analysis","text":""},{"location":"crates/nori-lsm/core-concepts/read-path/#formula","title":"Formula","text":"<p>Read Amplification (RA) = Number of SSTables checked for one key</p>"},{"location":"crates/nori-lsm/core-concepts/read-path/#per-stage-ra","title":"Per-Stage RA","text":"<p>1. Memtable: <pre><code>RA_memtable = 0 (in-memory, no I/O)\n</code></pre></p> <p>2. L0 Files: <pre><code>RA_l0 = l0_file_count\n\nExample:\n  6 L0 files \u2192 RA = 6\n  (Bloom filters avoid actual reads 99% of the time)\n</code></pre></p> <p>3. Slot Runs: <pre><code>RA_slot = k_max\n\nHot slot (k_max=1):  RA = 1\nCold slot (k_max=4): RA = 4\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/read-path/#total-ra","title":"Total RA","text":"<p>Formula: <pre><code>RA_total = RA_l0 + RA_slot\n         = l0_file_count + k_max\n</code></pre></p> <p>Example (6 L0 files, hot slot): <pre><code>RA_total = 6 + 1 = 7 SSTables checked\n\nWith bloom filters:\n  Bloom checks: 7 (all in-memory)\n  Disk reads: 1-2 (bloom filters eliminate 5-6)\n</code></pre></p> <p>Comparison: <pre><code>ATLL (hot slot, k_max=1):\n  RA = 6 + 1 = 7\n\nLeveled Compaction:\n  RA = L0 + L \u2248 6 + 5 = 11\n\nTiered Compaction:\n  RA = 10-15 (multiple runs per level)\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/read-path/#point-queries-vs-range-scans","title":"Point Queries vs Range Scans","text":""},{"location":"crates/nori-lsm/core-concepts/read-path/#point-query-get","title":"Point Query (get)","text":"<p>Optimized path: <pre><code>pub async fn get(&amp;self, key: &amp;[u8]) -&gt; Result&lt;Option&lt;Vec&lt;u8&gt;&gt;&gt; {\n    // 1. Check memtable (50ns)\n    if let Some(value) = self.memtable.get(key) {\n        return Ok(Some(value));\n    }\n\n    // 2. Check L0 with bloom filters (400ns + 1-2 disk reads)\n    for l0_file in &amp;self.l0_files {\n        if l0_file.bloom.contains(key) {\n            if let Some(value) = l0_file.get(key).await? {\n                return Ok(Some(value));\n            }\n        }\n    }\n\n    // 3. Find slot (10ns binary search)\n    let slot_id = self.find_slot_for_key(key);\n\n    // 4. Check slot runs with bloom filters (67ns + 1 disk read)\n    for run in &amp;self.slots[slot_id].runs {\n        if run.bloom.contains(key) {\n            if let Some(value) = run.get(key).await? {\n                return Ok(Some(value));\n            }\n        }\n    }\n\n    // 4. Not found\n    Ok(None)\n}\n</code></pre></p> <p>Performance: - Memtable hit: 50ns - L0/Slot hit (cached): 1-2\u00b5s - L0/Slot hit (disk): 100-200\u00b5s - Miss (not found): 500ns (bloom filters only)</p>"},{"location":"crates/nori-lsm/core-concepts/read-path/#range-scan-scan","title":"Range Scan (scan)","text":"<p>Problem: Bloom filters don't help <pre><code>Scan [a..z]:\n  \u2192 Must read all blocks in range (no bloom filter skip)\n</code></pre></p> <p>Merge-Sort Algorithm: <pre><code>pub async fn scan(&amp;self, start: &amp;[u8], end: &amp;[u8]) -&gt; Result&lt;Vec&lt;(Vec&lt;u8&gt;, Vec&lt;u8&gt;)&gt;&gt; {\n    // 1. Create iterators for each source\n    let mut iterators = vec![];\n\n    // Memtable iterator\n    iterators.push(self.memtable.range(start, end));\n\n    // L0 iterators (all files overlap range)\n    for l0_file in &amp;self.l0_files {\n        iterators.push(l0_file.range(start, end).await?);\n    }\n\n    // Slot iterator (only relevant slot)\n    let slot_id = self.find_slot_for_key(start);\n    for run in &amp;self.slots[slot_id].runs {\n        iterators.push(run.range(start, end).await?);\n    }\n\n    // 2. K-way merge (keep newest version)\n    let mut merger = KWayMerge::new(iterators);\n    let mut results = vec![];\n\n    while let Some((key, value)) = merger.next().await? {\n        if key &gt;= end {\n            break;\n        }\n        results.push((key, value));\n    }\n\n    Ok(results)\n}\n</code></pre></p> <p>Read Amplification: <pre><code>Scan [a..z]:\n  Sources = 1 memtable + 6 L0 + k_max slot runs\n          = 1 + 6 + 1 (hot slot)\n          = 8 sources\n\nK-way merge: O(N \u00d7 log(8)) comparisons\n</code></pre></p> <p>Performance: - Small scans (&lt;100 keys): 1-10ms - Large scans (1M keys): 100-1000ms - Bottleneck: Disk I/O (sequential reads faster than random)</p>"},{"location":"crates/nori-lsm/core-concepts/read-path/#caching-strategy","title":"Caching Strategy","text":""},{"location":"crates/nori-lsm/core-concepts/read-path/#three-level-cache-hierarchy","title":"Three-Level Cache Hierarchy","text":"<p>1. Memtable (in-memory, no cache): <pre><code>Size: 64 MB (configurable)\nPurpose: Recent writes\nEviction: Flush to L0 when full\n</code></pre></p> <p>2. Block Cache (LRU, configurable): <pre><code>Size: 1024 MB (default)\nPurpose: Hot data blocks\nEviction: LRU (least recently used)\n</code></pre></p> <p>3. Index Cache (LRU, configurable): <pre><code>Size: 128 MB (default)\nPurpose: Block index metadata\nEviction: LRU\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/read-path/#cache-warming","title":"Cache Warming","text":"<p>Problem: Cold cache after restart (all misses)</p> <p>Solution: Proactive warming <pre><code>pub async fn warm_cache(&amp;self, hot_keys: &amp;[Vec&lt;u8&gt;]) -&gt; Result&lt;()&gt; {\n    for key in hot_keys {\n        // Trigger reads to populate cache\n        let _ = self.get(key).await?;\n    }\n    Ok(())\n}\n</code></pre></p> <p>Example: <pre><code>Startup:\n  1. Load bloom filters (125 KB per 100K keys)\n  2. Load block indexes (10 KB per SSTable)\n  3. Warm cache with recent keys (proactive reads)\n\nResult:\n  95% cache hit rate within 1 minute\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/read-path/#performance-optimization-techniques","title":"Performance Optimization Techniques","text":""},{"location":"crates/nori-lsm/core-concepts/read-path/#1-bloom-filter-tuning","title":"1. Bloom Filter Tuning","text":"<p>Trade-off: <pre><code>10 bits/key:\n  Size: 125 KB per 100K keys\n  FP rate: 0.9%\n  Wasted reads: 900 per 100K misses\n\n12 bits/key:\n  Size: 150 KB per 100K keys (+20%)\n  FP rate: 0.3%\n  Wasted reads: 300 per 100K misses\n\nDecision: 10 bits/key (default)\n  \u2192 20% more memory not worth 600 fewer wasted reads\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/read-path/#2-block-size-tuning","title":"2. Block Size Tuning","text":"<p>Trade-off: <pre><code>Small blocks (2 KB):\n   Lower read amplification (read less data)\n   More index overhead (more blocks)\n   Worse compression (less context)\n\nLarge blocks (16 KB):\n   Better compression (more context)\n   Less index overhead\n   Higher read amplification (read more data)\n\nDefault: 4 KB\n  \u2192 Good balance for SSD page size\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/read-path/#3-prefetching","title":"3. Prefetching","text":"<p>Idea: Speculatively load next block during sequential scans <pre><code>async fn scan_with_prefetch(&amp;self, start: &amp;[u8], end: &amp;[u8]) -&gt; Result&lt;Vec&lt;(Vec&lt;u8&gt;, Vec&lt;u8&gt;)&gt;&gt; {\n    let block_id = self.find_block_for_key(start);\n\n    // Prefetch next N blocks in background\n    for i in 1..=prefetch_distance {\n        tokio::spawn(self.read_block(block_id + i));\n    }\n\n    // Read current block\n    let block = self.read_block(block_id).await?;\n    // ... process block ...\n}\n</code></pre></p> <p>Performance: - Random reads: No benefit (unpredictable pattern) - Sequential scans: 2-3x faster (hide disk latency)</p>"},{"location":"crates/nori-lsm/core-concepts/read-path/#4-adaptive-read-ahead","title":"4. Adaptive Read-Ahead","text":"<p>Idea: Increase prefetch distance for sequential patterns <pre><code>// Detect sequential access pattern\nif access_pattern == Sequential {\n    prefetch_distance = 8;  // Aggressive\n} else {\n    prefetch_distance = 2;  // Conservative\n}\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/read-path/#latency-targets","title":"Latency Targets","text":""},{"location":"crates/nori-lsm/core-concepts/read-path/#p95-latency-goals","title":"p95 Latency Goals","text":"<p>Point Queries: <pre><code>p50: &lt; 1ms    (memtable or cache hit)\np95: &lt; 10ms   (1-2 disk reads)\np99: &lt; 20ms   (multiple disk reads)\n</code></pre></p> <p>Range Scans (100 keys): <pre><code>p50: &lt; 5ms    (mostly cached)\np95: &lt; 50ms   (some disk reads)\np99: &lt; 100ms  (cold cache)\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/read-path/#breakdown-p95","title":"Breakdown (p95)","text":"<p>Cache hit: <pre><code>Memtable lookup:     50ns\nL0 bloom checks:     400ns (6 files)\nSlot bloom check:    67ns\nBlock cache read:    500ns\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nTotal:               ~1\u00b5s\n</code></pre></p> <p>Cache miss (hot slot): <pre><code>Memtable lookup:     50ns\nL0 bloom checks:     400ns\nSlot bloom check:    67ns\nDisk read:           100\u00b5s  (SSD)\nBlock decompression: 10\u00b5s\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nTotal:               ~110\u00b5s\n</code></pre></p> <p>Cache miss (cold slot, k_max=4): <pre><code>Memtable lookup:     50ns\nL0 bloom checks:     400ns\nSlot bloom checks:   268ns (4 runs)\nDisk reads:          400\u00b5s  (4 SSTables)\nBlock decompression: 40\u00b5s   (4 blocks)\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nTotal:               ~441\u00b5s\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/read-path/#monitoring-and-diagnostics","title":"Monitoring and Diagnostics","text":""},{"location":"crates/nori-lsm/core-concepts/read-path/#key-metrics","title":"Key Metrics","text":"<p>Read Amplification: <pre><code>pub struct ReadStats {\n    pub memtable_checks: u64,   // Always 1\n    pub l0_files_checked: u64,  // Bloom filter checks\n    pub slot_runs_checked: u64, // Bloom filter checks\n    pub disk_reads: u64,        // Actual disk I/O\n}\n</code></pre></p> <p>Cache Metrics: <pre><code>pub struct CacheStats {\n    pub block_cache_hits: u64,\n    pub block_cache_misses: u64,\n    pub index_cache_hits: u64,\n    pub index_cache_misses: u64,\n}\n</code></pre></p> <p>Bloom Filter Effectiveness: <pre><code>pub struct BloomStats {\n    pub bloom_checks: u64,        // Total bloom queries\n    pub bloom_negatives: u64,     // Definite misses (saved disk reads)\n    pub bloom_false_positives: u64, // Wasted disk reads\n}\n</code></pre></p> <p>Dashboard Queries: <pre><code>-- Cache hit rate\nSELECT\n  block_cache_hits / (block_cache_hits + block_cache_misses) AS hit_rate\nFROM cache_stats;\n\n-- Bloom filter false positive rate\nSELECT\n  bloom_false_positives / bloom_checks AS fp_rate\nFROM bloom_stats;\n\n-- Read amplification trend\nSELECT\n  AVG(l0_files_checked + slot_runs_checked) AS avg_ra\nFROM read_stats\nWHERE timestamp &gt; NOW() - INTERVAL '1 hour';\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/read-path/#summary","title":"Summary","text":"<p>Read Path Stages: 1. Memtable (50ns) \u2192 Recent writes 2. L0 bloom filters (400ns) \u2192 6 files, 99% skip 3. Slot selection (10ns) \u2192 Binary search 4. Slot bloom filters (67-268ns) \u2192 K-way fanout 5. Block cache (500ns) or disk (100\u00b5s)</p> <p>Read Amplification: - ATLL (hot slot): RA = 7 (6 L0 + 1 slot) - ATLL (cold slot): RA = 10 (6 L0 + 4 slot) - Leveled: RA = 11 (6 L0 + 5 levels) - Tiered: RA = 10-15 (multiple runs)</p> <p>Optimization: - Bloom filters: 460x faster negative lookups - Block cache: 200x faster cache hits - Slot partitioning: 4x fewer SSTables checked</p> <p>Latency: - Cache hit: ~1\u00b5s (99<sup>th</sup> percentile) - Cache miss (hot): ~110\u00b5s - Cache miss (cold): ~441\u00b5s - Target p95: &lt; 10ms</p> <p>Next: Read When to Use ATLL for workload guidance.</p> <p>Last Updated: 2025-10-31 See Also: ATLL Architecture, Write Path, Bloom Filter Strategy</p>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/","title":"What is an LSM Tree?","text":"<p>Understanding the Log-Structured Merge Tree: history, theory, and fundamental concepts.</p>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#the-problem-write-amplification-in-traditional-databases","title":"The Problem: Write Amplification in Traditional Databases","text":"<p>Traditional database systems (B-trees, B+ trees) face a fundamental challenge: in-place updates.</p>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#b-tree-write-pattern","title":"B-Tree Write Pattern","text":"<pre><code>User writes 1 KB:\n1. Find leaf page (multiple random reads)\n2. Read entire page (4 KB) into memory\n3. Modify 1 KB in the page\n4. Write entire page (4 KB) back to disk\n5. Update parent pages for splits (more I/O)\n\nPhysical I/O: 12-20 KB for 1 KB logical write\nWrite Amplification: 12-20x\n</code></pre> <p>Why is this problematic?</p> <ul> <li>Random I/O dominates latency (~100\u00b5s per seek on SSD, ~10ms on HDD)</li> <li>SSD wear: Flash cells have limited P/E cycles (~3,000 for TLC, ~10,000 for MLC)</li> <li>Throughput bottleneck: Random writes are 10-100x slower than sequential writes</li> </ul> <p>Concrete example:</p> <pre><code>Workload: 1M writes/sec of 1KB records\nB-tree physical writes: 12-20 GB/sec\nSequential LSM writes: 1-2 GB/sec (6-10x less)\n\nSSD lifetime with B-tree: ~1 year\nSSD lifetime with LSM: ~6-10 years\n</code></pre>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#the-solution-log-structured-merge-trees","title":"The Solution: Log-Structured Merge Trees","text":"<p>Core insight: Trade read performance for write performance by appending instead of updating in-place.</p>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#lsm-tree-invented-1996","title":"LSM-Tree: Invented 1996","text":"<p>Original paper: \"The Log-Structured Merge-Tree (LSM-Tree)\" by Patrick O'Neil, Edward Cheng, Dieter Gawlick, and Elizabeth O'Neil (1996)</p> <p>Key innovation: Defer and batch disk updates</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Memory (C0)       \u2502  \u2190 Fast in-memory component\n\u2502   (Skiplist/Tree)   \u2502     Absorbs all writes\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   Disk (C1)         \u2502  \u2190 Level 1: Periodic flushes\n\u2502   (Sorted runs)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   Disk (C2)         \u2502  \u2190 Level 2: Merged periodically\n\u2502   (Larger runs)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   ...               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Write path:</p> <ol> <li>Append to write-ahead log (WAL) - sequential write, ~100 MB/s</li> <li>Insert into in-memory tree - RAM operation, ~1 \u00b5s</li> <li>Flush to disk when full - sequential batch write, amortizes cost</li> <li>Merge in background - batch compaction, not on critical path</li> </ol> <p>Result: Writes are sequential, batched, and off the critical path.</p>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#historical-evolution","title":"Historical Evolution","text":""},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#1996-original-lsm-tree-paper","title":"1996: Original LSM-Tree Paper","text":"<p>O'Neil et al. introduced the two-component model (C0, C1): - C0: In-memory component (B-tree or AVL tree) - C1: Disk component (sorted runs) - Rolling merge process to maintain sortedness</p> <p>Limitation: Two-level design didn't scale to large datasets.</p>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#2006-google-bigtable","title":"2006: Google BigTable","text":"<p>Paper: \"Bigtable: A Distributed Storage System for Structured Data\" (Chang et al., OSDI 2006)</p> <p>Innovations: - Multi-level LSM (L0, L1, ..., Lk) - Leveled compaction strategy - SSTable file format (block-based, indexed, with Bloom filters) - Memtable + immutable memtable design</p> <p>Impact: Demonstrated LSM-trees at massive scale (petabytes of data, thousands of nodes)</p>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#2011-leveldb","title":"2011: LevelDB","text":"<p>Author: Jeff Dean and Sanjay Ghemawat (Google)</p> <p>Contribution: Open-source embeddable LSM implementation</p> <p>Features: - Leveled Compaction Strategy (LCS) - Snappy compression - Single-writer, multiple-reader concurrency - Block cache for hot data</p> <p>Adoption: Used in Chrome, Riak, Bitcoin Core, and many others</p>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#2012-rocksdb","title":"2012: RocksDB","text":"<p>Author: Facebook (Meta)</p> <p>Contribution: Production-hardened LevelDB fork</p> <p>Enhancements: - Universal Compaction (tiered strategy) - Column families (multiple LSMs in one DB) - Merge operators (atomic read-modify-write) - Transactions and optimistic concurrency control - Extensive tuning knobs (100+ configuration options)</p> <p>Scale: Handles 100s of TB per node, millions of QPS</p>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#2014-present-modern-variants","title":"2014-Present: Modern Variants","text":"<ul> <li>Cassandra (2010): Size-Tiered Compaction Strategy (STCS)</li> <li>ScyllaDB (2015): Incremental Compaction Strategy (ICS)</li> <li>WiredTiger (2014, MongoDB): LSM + B-tree hybrid</li> <li>Pebble (2019, CockroachDB): RocksDB-inspired Go implementation</li> <li>BadgerDB (2017): LSM with value log separation</li> </ul> <p>Trend: Workload-specific optimizations (time-series, key-value, wide-column)</p>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#fundamental-concepts","title":"Fundamental Concepts","text":""},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#1-log-structured-storage","title":"1. Log-Structured Storage","text":"<p>Definition: All writes are appended sequentially to a log, never updated in-place.</p> <pre><code>Time:  T0      T1      T2      T3\n       \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192\nLog:   [A:1] [B:2] [A:3] [C:4] [A:5]\n          \u2191            \u2191            \u2191\n       First      Second       Third\n       version    version      version\n                              (newest)\n</code></pre> <p>Key property: Older versions remain until compacted away.</p> <p>Implication: Reads must find the newest version by scanning multiple log segments.</p>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#2-merge-compaction","title":"2. Merge (Compaction)","text":"<p>Problem: Unbounded log growth \u2192 need to reclaim space.</p> <p>Solution: Periodically merge sorted runs, keeping only the newest version of each key.</p> <pre><code>Before merge:\n  Run 1: [A:1, C:3, E:5]\n  Run 2: [A:2, B:4, D:6]\n  Run 3: [A:3, F:7]\n\nAfter merge:\n  Run: [A:3, B:4, C:3, D:6, E:5, F:7]\n       \u2191 newest version kept\n</code></pre> <p>Merge algorithm: Multi-way k-way merge (priority queue-based)</p> <p>Cost: Reads all input runs, writes one output run \u2192 Write Amplification</p>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#3-levels-and-fanout","title":"3. Levels and Fanout","text":"<p>Multi-level organization: Each level is ~T times larger than the previous level.</p> <pre><code>Level 0:     10 MB   (unsorted, overlapping)\nLevel 1:    100 MB   (sorted, non-overlapping, T=10)\nLevel 2:  1,000 MB   (T=10 growth)\nLevel 3: 10,000 MB   (T=10 growth)\n</code></pre> <p>Fanout (T): Ratio of level sizes, typically 10.</p> <p>Formula: <code>Level_i_size = Level_(i-1)_size * T</code></p> <p>Total levels: <code>L = ceil(log_T(Total_Data_Size / Memtable_Size))</code></p>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#4-sorted-string-tables-sstables","title":"4. Sorted String Tables (SSTables)","text":"<p>Definition: Immutable, sorted file containing key-value pairs.</p> <p>Structure:</p> <pre><code>SSTable file:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Data Blocks   \u2502 \u2190 Sorted key-value pairs (compressed)\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Index Block   \u2502 \u2190 Block offsets (first key \u2192 offset)\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Filter Block  \u2502 \u2190 Bloom filter (is key present?)\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Footer        \u2502 \u2190 Metadata (index/filter offsets)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Key properties: - Immutable: Once written, never modified (enables caching, no locks) - Sorted: Enables binary search and range queries - Compressed: LZ4 or Zstd reduces disk space and I/O - Indexed: Fast lookups via sparse index - Filtered: Bloom filters skip missing keys (67ns vs 100\u00b5s disk read)</p>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#mathematical-foundations","title":"Mathematical Foundations","text":""},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#write-amplification-wa","title":"Write Amplification (WA)","text":"<p>Definition: Ratio of physical bytes written to logical bytes written.</p> <p>Formula for Leveled Compaction:</p> <pre><code>WA = T * (L - 1)\n\nWhere:\n  T = fanout (default: 10)\n  L = number of levels\n\nExample:\n  T = 10, L = 5\n  WA = 10 * (5 - 1) = 40\n\nInterpretation: Each 1 KB logical write \u2192 40 KB physical writes\n</code></pre> <p>Why? Each level compaction merges data with the next level: - L1\u2192L2: Read L1 run + overlapping L2 runs (T times larger) \u2192 Write merged output (T+1 data) - Repeat for L2\u2192L3, L3\u2192L4, ...</p> <p>Detailed derivation:</p> <pre><code>Assume 1 MB flush from memtable:\n\nL0\u2192L1: Write 1 MB to L1                        Cost: 1 MB\nL1\u2192L2: Merge 10 MB (L1) + 100 MB (L2) = 110 MB Cost: 110 MB written\nL2\u2192L3: Merge 100 MB (L2) + 1 GB (L3) = 1.1 GB  Cost: 1.1 GB written\n...\n\nTotal physical writes for 1 MB logical: ~1.21 GB\nWA \u2248 1,210\n</code></pre> <p>Optimization: Size-tiered compaction reduces WA to <code>O(log_T(N))</code> but increases read amplification.</p>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#read-amplification-ra","title":"Read Amplification (RA)","text":"<p>Definition: Number of disk reads (SSTables accessed) per point query.</p> <p>Formula for Leveled Compaction:</p> <pre><code>RA = L0_files + \u03a3(runs_per_level)\n\nFor pure leveled (1 run per level):\n  RA = L0_files + L\n\nExample:\n  L0 files: 4\n  Levels: 5\n  RA = 4 + 5 = 9\n\nInterpretation: Must check 9 SSTables to guarantee key is not present\n</code></pre> <p>Best case: Key found in memtable \u2192 RA = 0 Worst case: Key not present \u2192 RA = L0_files + L</p> <p>Bloom filter impact:</p> <pre><code>Without blooms: 9 disk reads * 100\u00b5s = 900\u00b5s\nWith blooms (10 bits/key, 0.9% FP):\n  Expected disk reads: 9 * 0.009 \u2248 0.08\n  Time: 9 * 67ns (bloom checks) + 0.08 * 100\u00b5s \u2248 8\u00b5s\n\nSpeedup: 112x\n</code></pre>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#space-amplification-sa","title":"Space Amplification (SA)","text":"<p>Definition: Ratio of physical storage to logical data size.</p> <p>Formula:</p> <pre><code>SA = Physical_Bytes / Logical_Bytes\n\nSources of space amplification:\n1. Obsolete versions (not yet compacted)\n2. Tombstones (deleted keys awaiting compaction)\n3. Compression overhead (metadata, block alignment)\n4. Bloom filters and indexes\n\nTypical SA for LSM: 1.1 - 1.5x\n</code></pre> <p>Example:</p> <pre><code>Logical data: 100 GB\nL0 (uncompacted): 5 GB\nL1-L5: 100 GB (current versions)\nObsolete versions: 10 GB (being compacted)\nIndexes + Blooms: 2 GB\n\nPhysical: 117 GB\nSA: 1.17x\n</code></pre>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#the-rum-conjecture","title":"The RUM Conjecture","text":"<p>Paper: \"Designing Access Methods: The RUM Conjecture\" (Athanassoulis et al., EDBT 2016)</p> <p>Conjecture: For any access method, one can optimize at most two out of three: - Read overhead - Update overhead - Memory (space) overhead</p> <p>Implication: LSM-trees make a specific trade-off position: -  Low Update overhead (sequential writes) -  Low Memory overhead (compact storage) -  Higher Read overhead (multiple levels to check)</p> <p>Pareto frontier:</p> <pre><code>         Read Overhead\n              \u2191\n              \u2502     B-tree \u25cf\n              \u2502         (low read, high update)\n              \u2502\n              \u2502\n              \u2502             \u25cf LSM\n              \u2502          (medium read, low update)\n              \u2502\n              \u2502  Hash table \u25cf\n              \u2502  (lowest read, highest space)\n              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192\n                     Update Overhead\n</code></pre> <p>Key insight: No single data structure dominates all workloads. LSM is optimal for write-heavy, read-tolerant workloads.</p>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#why-lsm-trees-outperform-b-trees","title":"Why LSM Trees Outperform B-Trees","text":""},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#1-sequential-vs-random-io","title":"1. Sequential vs Random I/O","text":"<p>SSD Performance Characteristics:</p> <pre><code>Operation              Latency    Bandwidth\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nRandom 4KB read        100\u00b5s      40 MB/s\nSequential 1MB read     10\u00b5s     500 MB/s\nRandom 4KB write       100\u00b5s      40 MB/s\nSequential 1MB write    10\u00b5s     500 MB/s\n\nRatio: Sequential is 12.5x faster\n</code></pre> <p>LSM write pattern:</p> <pre><code>1. Append to WAL (sequential)\n2. Insert to memtable (RAM)\n3. Flush to L0 (sequential, batched)\n4. Compact (sequential merge)\n\nAll disk writes are sequential!\n</code></pre> <p>B-tree write pattern:</p> <pre><code>1. Read page (random)\n2. Modify page (RAM)\n3. Write page (random)\n4. Update parent (random)\n\nMost disk operations are random!\n</code></pre>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#2-write-batching","title":"2. Write Batching","text":"<p>LSM batches writes:</p> <pre><code>1,000 individual writes:\n  B-tree: 1,000 random I/Os\n  LSM:    1,000 RAM inserts \u2192 1 sequential flush\n\nLatency improvement: 100-1,000x\n</code></pre> <p>Amortization: Cost of compaction is spread across many writes.</p>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#3-compression-efficiency","title":"3. Compression Efficiency","text":"<p>LSM advantages: - Immutable files \u2192 compress entire SSTable at write time - Sorted data \u2192 better compression ratios (delta encoding, prefix compression) - Batch compression \u2192 amortize compression overhead</p> <p>B-tree limitations: - Mutable pages \u2192 compression complicates updates - Fragmentation \u2192 pages not fully utilized (50-70% typical)</p> <p>Empirical results:</p> <pre><code>Dataset: 100 GB logical data\n\nB-tree on disk:       140 GB (1.4x)\nLSM (uncompressed):   110 GB (1.1x)\nLSM (LZ4):            55 GB (0.55x)\nLSM (Zstd):           40 GB (0.4x)\n\nLSM with Zstd uses 3.5x less space than B-tree\n</code></pre>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#4-read-ahead-friendly","title":"4. Read-Ahead Friendly","text":"<p>Sequential access pattern: - OS readahead works perfectly (prefetches next blocks) - Block cache hit rates higher (sequential locality)</p> <p>Random access pattern: - Readahead misses (unpredictable next access) - Cache thrashing (random evictions)</p>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#when-lsm-trees-excel","title":"When LSM Trees Excel","text":""},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#write-heavy-workloads","title":"Write-Heavy Workloads","text":"<pre><code>Write:Read ratio &gt; 1:1\nExamples:\n  - Logging systems (append-only)\n  - Time-series databases (metrics, events)\n  - Message queues (enqueue \u2192 dequeue)\n  - Session storage (frequent updates)\n</code></pre> <p>Why: Sequential writes dominate, read latency tolerable.</p>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#large-datasets-1-tb","title":"Large Datasets (&gt; 1 TB)","text":"<pre><code>Memory: 64 GB\nDataset: 10 TB\n\nB-tree working set doesn't fit in RAM:\n  Cache hit rate: 0.6%\n  Most reads hit disk: 100\u00b5s * 0.994 = 99.4\u00b5s avg\n\nLSM with Bloom filters:\n  Bloom checks: 67ns (always in RAM)\n  Disk reads (after bloom): 100\u00b5s * 0.009 (FP rate) = 0.9\u00b5s avg\n  Total: 67ns + 0.9\u00b5s = 0.967\u00b5s\n\nLSM is 100x faster for point queries on large datasets!\n</code></pre>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#ssd-optimized-systems","title":"SSD-Optimized Systems","text":"<pre><code>SSD wear leveling:\n  B-tree: Random writes \u2192 wear amplification \u2192 shorter lifespan\n  LSM: Sequential writes \u2192 even wear \u2192 longer lifespan\n\nCost savings:\n  B-tree SSD replacement: Every 1 year ($1,000/year)\n  LSM SSD replacement: Every 6 years ($167/year)\n\n6x longer SSD life = 6x lower TCO\n</code></pre>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#high-compression-requirements","title":"High Compression Requirements","text":"<pre><code>Compressed size:\n  B-tree (mutable): 1.4x logical size\n  LSM (LZ4): 0.55x logical size\n  LSM (Zstd): 0.4x logical size\n\nStorage cost at $0.02/GB/month:\n  1 TB logical:\n    B-tree: $28/month\n    LSM (LZ4): $11/month\n    LSM (Zstd): $8/month\n\nLSM saves $240/year per TB\n</code></pre>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#when-lsm-trees-struggle","title":"When LSM Trees Struggle","text":""},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#read-heavy-workloads","title":"Read-Heavy Workloads","text":"<pre><code>Write:Read ratio &lt; 1:10\nExamples:\n  - Caching layers (read-dominated)\n  - Reference data (rarely updated)\n  - Materialized views\n</code></pre> <p>Why: Read amplification dominates, B-tree's O(1) reads win.</p>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#small-datasets-100-gb","title":"Small Datasets (&lt; 100 GB)","text":"<pre><code>Dataset: 10 GB\nMemory: 64 GB\n\nB-tree: Entire dataset fits in RAM\n  Read latency: ~100ns (RAM lookup)\n\nLSM: Still checks multiple levels\n  Read latency: ~1\u00b5s (bloom + levels)\n\nB-tree is 10x faster for in-memory workloads\n</code></pre>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#random-access-patterns","title":"Random Access Patterns","text":"<pre><code>Workload: Random point queries (no locality)\n\nB-tree: O(log N) with good cache behavior\nLSM: L0_files + L levels to check, cache thrashing\n\nIf no bloom filters:\n  LSM: 9 random reads vs B-tree: 3 random reads\n  LSM is 3x slower\n</code></pre>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#strict-latency-slos","title":"Strict Latency SLOs","text":"<pre><code>SLO: p99 &lt; 1ms for all operations\n\nLSM challenges:\n  - Compaction pauses (10-100ms spikes)\n  - L0 backlog \u2192 read amplification spikes\n  - Write stalls (L0 &gt; threshold)\n\nB-tree: More predictable latency (no background compaction)\n</code></pre>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#lsm-vs-b-tree-summary","title":"LSM vs B-Tree: Summary","text":"Dimension LSM-Tree B-Tree Winner Write Throughput 10-100x higher Baseline LSM Write Latency (avg) ~50\u00b5s ~500\u00b5s LSM Write Latency (p99) ~5ms (stalls) ~1ms B-tree Point Query (in-mem) ~1\u00b5s ~100ns B-tree Point Query (on-disk) ~10\u00b5s (w/ blooms) ~100\u00b5s LSM Range Scan Similar (both sorted) Similar Tie Space Amplification 1.1-1.5x 1.4-2.0x LSM Write Amplification 10-40x 1-5x B-tree SSD Lifespan 6+ years 1-2 years LSM Operational Complexity High (tuning) Low (mature) B-tree"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>LSM-trees trade read performance for write performance</li> <li>Sequential writes \u2192 10-100x higher write throughput</li> <li> <p>Multiple levels \u2192 higher read amplification</p> </li> <li> <p>Write amplification is the key metric</p> </li> <li>Formula: <code>WA = T * (L - 1)</code> for leveled compaction</li> <li> <p>Directly impacts SSD lifespan and I/O cost</p> </li> <li> <p>Bloom filters are essential</p> </li> <li>Without blooms: LSM is slower than B-tree for reads</li> <li> <p>With blooms: LSM competitive or faster (large datasets)</p> </li> <li> <p>LSM is a family, not a single algorithm</p> </li> <li>Leveled compaction: Low read amp, high write amp</li> <li>Tiered compaction: Low write amp, high read amp</li> <li> <p>Hybrid strategies: Adapt per workload</p> </li> <li> <p>The RUM Conjecture applies</p> </li> <li>Can't optimize read, write, and space simultaneously</li> <li> <p>LSM chooses: optimize write + space, sacrifice read</p> </li> <li> <p>Workload determines winner</p> </li> <li>Write-heavy \u2192 LSM</li> <li>Read-heavy \u2192 B-tree</li> <li>Mixed \u2192 Depends on ratio and dataset size</li> </ol>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#whats-next","title":"What's Next?","text":"<p>Now that you understand LSM fundamentals, explore:</p> <ul> <li>LSM Variants - Leveled, Tiered, Universal compaction strategies</li> <li>ATLL Architecture - Our adaptive approach (guard partitioning, dynamic K)</li> <li>Write Path - How writes flow through memtable \u2192 L0 \u2192 L1+</li> <li>Read Path - How reads check memtable \u2192 L0 \u2192 levels with Bloom filters</li> </ul>"},{"location":"crates/nori-lsm/core-concepts/what-is-lsm/#further-reading","title":"Further Reading","text":"<p>Foundational Papers: - The Log-Structured Merge-Tree (LSM-Tree) - O'Neil et al., 1996 - Bigtable: A Distributed Storage System - Chang et al., 2006 - Designing Access Methods: The RUM Conjecture - Athanassoulis et al., 2016</p> <p>Implementations: - LevelDB - Google's embeddable LSM - RocksDB - Meta's production LSM - Pebble - CockroachDB's Go LSM</p> <p>Books: - \"Database Internals\" by Alex Petrov (Chapter 7: LSM Trees) - \"Designing Data-Intensive Applications\" by Martin Kleppmann (Chapter 3: Storage)</p>"},{"location":"crates/nori-lsm/core-concepts/when-to-use/","title":"When to Use ATLL","text":"<p>Guidance on when ATLL (Adaptive Tiered-Leveled LSM) is the right choice, when to use alternatives, and how to decide between storage engines.</p>"},{"location":"crates/nori-lsm/core-concepts/when-to-use/#quick-decision-tree","title":"Quick Decision Tree","text":"<pre><code>Do you need transactional guarantees (ACID)?\n\u251c\u2500 Yes \u2192 Use PostgreSQL, CockroachDB, or TiKV\n\u2514\u2500 No  \u2192 Continue\n\nIs your data small enough to fit in memory (&lt;100 GB)?\n\u251c\u2500 Yes \u2192 Use Redis, Memcached, or in-memory B-tree\n\u2514\u2500 No  \u2192 Continue\n\nIs your workload write-heavy (&gt;80% writes)?\n\u251c\u2500 Yes \u2192 Continue to \"Write-Heavy Workloads\"\n\u2514\u2500 No  \u2192 Continue to \"Read-Heavy or Mixed Workloads\"\n\nWrite-Heavy Workloads:\n  Are writes sequential (append-only)?\n    \u251c\u2500 Yes \u2192 Use append-only log (e.g., Kafka, write-ahead log)\n    \u2514\u2500 No  \u2192 Use ATLL or pure tiered LSM (e.g., Cassandra)\n\nRead-Heavy or Mixed Workloads:\n  Is access pattern uniform (no hot/cold distinction)?\n    \u251c\u2500 Yes \u2192 Use B-tree (e.g., RocksDB leveled) or pure leveled LSM\n    \u2514\u2500 No  \u2192 Use ATLL (adaptive to hot/cold)\n\nDo you need range scans?\n\u251c\u2500 Yes \u2192 Use ATLL or B-tree (sorted key order)\n\u2514\u2500 No  \u2192 Consider hash table (e.g., BitCask, WiscKey)\n</code></pre>"},{"location":"crates/nori-lsm/core-concepts/when-to-use/#atll-excels-heterogeneous-workloads","title":"ATLL Excels: Heterogeneous Workloads","text":""},{"location":"crates/nori-lsm/core-concepts/when-to-use/#1-zipfian-access-patterns-8020-rule","title":"1. Zipfian Access Patterns (80/20 Rule)","text":"<p>Problem: Most workloads have hot and cold data <pre><code>E-commerce database:\n  Hot (20% of keys, 80% of accesses):\n    - Recent orders (last 30 days)\n    - Active user sessions\n    - Popular product inventory\n\n  Cold (80% of keys, 20% of accesses):\n    - Historical orders (&gt;1 year)\n    - Archived user data\n    - Deleted product history\n</code></pre></p> <p>Why ATLL wins: <pre><code>Hot ranges \u2192 k_max=1 (leveled):\n  Read Amplification: 7 (fast)\n  Write Amplification: 20x (acceptable)\n\nCold ranges \u2192 k_max=4 (tiered):\n  Read Amplification: 10 (acceptable for rare reads)\n  Write Amplification: 6x (low)\n\nResult:\n  Overall WA: 11.4x (vs 40-100x for pure leveled)\n  Overall RA: 7.6 (vs 10-15 for pure tiered)\n</code></pre></p> <p>Alternatives: - Pure Leveled (RocksDB): 40-100x WA (wasted I/O on cold data) - Pure Tiered (Cassandra): 10-15 RA (slow hot reads) - B-tree (InnoDB): Random writes (fragmentation)</p>"},{"location":"crates/nori-lsm/core-concepts/when-to-use/#2-time-series-with-recent-heavy-reads","title":"2. Time-Series with Recent-Heavy Reads","text":"<p>Problem: Recent data queried frequently, old data rarely</p> <p>Example: Metrics database <pre><code>Recent metrics (last 24 hours):\n  - High read frequency (dashboards, alerts)\n  - High write frequency (continuous ingestion)\n\nOld metrics (&gt;30 days):\n  - Low read frequency (historical analysis)\n  - No writes (immutable)\n</code></pre></p> <p>Why ATLL wins: <pre><code>Recent data \u2192 k_max=1:\n  Fast queries for dashboards (RA=7)\n  Accept higher WA for recent data (20x)\n\nOld data \u2192 k_max=4:\n  Low WA for compaction (6x)\n  Slow reads acceptable (RA=10, rare)\n\nResult:\n  Efficient storage (SA=1.1-1.3x)\n  Fast recent queries (&lt;10ms p95)\n</code></pre></p> <p>Alternatives: - Time-windowed LSM (ScyllaDB ICS): Requires manual tuning - Pure Leveled: Wasted I/O compacting old data - Columnar storage (Parquet): Good for analytics, bad for point queries</p>"},{"location":"crates/nori-lsm/core-concepts/when-to-use/#3-multi-tenant-systems","title":"3. Multi-Tenant Systems","text":"<p>Problem: Some tenants active, others dormant</p> <p>Example: SaaS database <pre><code>Active tenants (10%):\n  - Heavy reads + writes\n  - SLO requirements (&lt;10ms p95)\n\nDormant tenants (90%):\n  - Rare reads (login once/month)\n  - No writes\n\nTrial tenants:\n  - Heavy writes (initial data load)\n  - Few reads\n</code></pre></p> <p>Why ATLL wins: <pre><code>Active tenant ranges \u2192 k_max=1:\n  Meet SLO targets (fast reads)\n\nDormant tenant ranges \u2192 k_max=4:\n  Low compaction overhead (WA=6x)\n\nTrial tenant ranges \u2192 k_max=3:\n  Balance write throughput and read latency\n\nResult:\n  Cost-efficient (low I/O for dormant tenants)\n  SLO compliant (fast reads for active tenants)\n</code></pre></p> <p>Alternatives: - Separate databases per tenant: High operational overhead - Pure Leveled: Wasted I/O on dormant tenants - Sharded MySQL: Complex sharding logic</p>"},{"location":"crates/nori-lsm/core-concepts/when-to-use/#4-general-purpose-key-value-store","title":"4. General-Purpose Key-Value Store","text":"<p>Problem: Unpredictable access patterns</p> <p>Example: Session store, cache backend <pre><code>Workload characteristics:\n  - Mixed reads/writes (40-60% split)\n  - No clear hot/cold pattern\n  - Range scans + point queries\n  - Variable value sizes (1 KB - 1 MB)\n</code></pre></p> <p>Why ATLL wins: <pre><code>Adaptive behavior:\n  - System learns access patterns via EWMA heat tracking\n  - Bandit scheduler optimizes compaction decisions\n  - No manual tuning required\n\nResult:\n  Near-optimal for any workload (Pareto-efficient)\n  Resilient to workload shifts (online learning)\n</code></pre></p> <p>Alternatives: - Redis: In-memory only (expensive for large data) - RocksDB: Requires manual tuning (bloom bits, compaction style) - B-tree: Random write overhead</p>"},{"location":"crates/nori-lsm/core-concepts/when-to-use/#atll-struggles-edge-cases","title":"ATLL Struggles: Edge Cases","text":""},{"location":"crates/nori-lsm/core-concepts/when-to-use/#1-uniform-access-patterns","title":"1. Uniform Access Patterns","text":"<p>Problem: All keys accessed equally often</p> <p>Example: Random UUID key-value store <pre><code>Workload:\n  - Uniform key distribution (no hot/cold)\n  - Equal read frequency across all keys\n  - 50/50 read/write mix\n</code></pre></p> <p>Why ATLL doesn't help: <pre><code>All slots converge to same k_max:\n  - No differentiation between hot/cold\n  - Bandit scheduler provides no benefit\n  - ATLL overhead (heat tracking, scheduling) wasted\n\nResult:\n  ATLL \u2248 Pure Leveled (no adaptive advantage)\n</code></pre></p> <p>Better alternative: - Pure Leveled (RocksDB): Simpler, less overhead - B-tree (if writes are sequential)</p>"},{"location":"crates/nori-lsm/core-concepts/when-to-use/#2-pure-sequential-scans","title":"2. Pure Sequential Scans","text":"<p>Problem: Only range scans, no point queries</p> <p>Example: Log analytics, data warehouse ETL <pre><code>Workload:\n  - 100% range scans (SELECT * WHERE timestamp &gt; ...)\n  - No point queries (get by key)\n  - Batch writes (bulk load every hour)\n</code></pre></p> <p>Why ATLL doesn't help: <pre><code>Bloom filters useless:\n  - Range scans must read all blocks in range\n  - No benefit from bloom filter skipping\n\nSlot partitioning useless:\n  - Scans cross multiple slots\n  - No benefit from k_max optimization\n\nResult:\n  ATLL overhead (bloom filters, bandit) wasted\n</code></pre></p> <p>Better alternative: - Columnar storage (Parquet, ORC): Optimized for scans - Pure Tiered (Cassandra STCS): Low WA, scans already slow</p>"},{"location":"crates/nori-lsm/core-concepts/when-to-use/#3-tiny-datasets-100-mb","title":"3. Tiny Datasets (&lt;100 MB)","text":"<p>Problem: Entire dataset fits in memory</p> <p>Example: User session cache <pre><code>Dataset:\n  - 100K keys \u00d7 1 KB = 100 MB\n  - Fits in memtable + block cache\n  - 99.9% cache hit rate\n</code></pre></p> <p>Why ATLL doesn't help: <pre><code>All reads hit cache:\n  - No disk I/O (no benefit from RA optimization)\n  - Compaction overhead still exists (WA penalty)\n\nResult:\n  ATLL complexity not justified\n</code></pre></p> <p>Better alternative: - In-memory hash table (Redis, Memcached): Simpler, faster - Embedded B-tree (SQLite in-memory mode)</p>"},{"location":"crates/nori-lsm/core-concepts/when-to-use/#4-extremely-skewed-writes","title":"4. Extremely Skewed Writes","text":"<p>Problem: Writes concentrated in one range</p> <p>Example: Monotonically increasing timestamp keys <pre><code>Workload:\n  - All writes to newest time range (append-only)\n  - Older ranges never written (immutable)\n  - Reads scattered across all ranges\n</code></pre></p> <p>Why ATLL doesn't help: <pre><code>Slot partitioning ineffective:\n  - Only one slot receives writes (hot)\n  - Other slots idle (no adaptive benefit)\n\nBandit scheduler wasted:\n  - Only one slot to compact (no choice)\n\nResult:\n  ATLL overhead without adaptive benefit\n</code></pre></p> <p>Better alternative: - Append-only log (Kafka, write-ahead log): Optimized for sequential writes - Time-windowed LSM (ScyllaDB ICS): Purpose-built for time-series</p>"},{"location":"crates/nori-lsm/core-concepts/when-to-use/#atll-vs-alternatives","title":"ATLL vs Alternatives","text":""},{"location":"crates/nori-lsm/core-concepts/when-to-use/#atll-vs-pure-leveled-compaction-rocksdb","title":"ATLL vs Pure Leveled Compaction (RocksDB)","text":"<p>Choose Pure Leveled when: - Uniform access patterns (no hot/cold distinction) - Read-heavy workload (&gt;80% reads) - Small dataset (&lt;10 GB, fits in cache) - SSD with good random write performance</p> <p>Choose ATLL when: - Skewed access patterns (Zipfian, 80/20 rule) - Mixed workload (40-60% reads/writes) - Large dataset (&gt;100 GB) - Want low WA without sacrificing read performance</p> <p>Comparison: <pre><code>Metric               Pure Leveled  ATLL\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nWrite Amplification  40-100x       8-20x\nRead Amplification   5-10          5-12 (adaptive)\nSpace Amplification  1.1x          1.1-1.3x\nConfiguration        Simple        Adaptive (no tuning)\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/when-to-use/#atll-vs-pure-tiered-compaction-cassandra-stcs","title":"ATLL vs Pure Tiered Compaction (Cassandra STCS)","text":"<p>Choose Pure Tiered when: - Write-heavy workload (&gt;80% writes) - Large value sizes (&gt;10 KB) - Range scans common (not point queries) - Can tolerate slow reads (100ms+ p95)</p> <p>Choose ATLL when: - Mixed workload (both reads and writes) - Small-medium value sizes (&lt;10 KB) - Point queries common - Need fast reads (&lt;10ms p95)</p> <p>Comparison: <pre><code>Metric               Pure Tiered  ATLL\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nWrite Amplification  6-8x         8-20x\nRead Amplification   10-15        5-12 (adaptive)\nSpace Amplification  1.33x        1.1-1.3x\nRead Latency (p95)   20-50ms      &lt;10ms (hot)\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/when-to-use/#atll-vs-b-tree-innodb-sqlite","title":"ATLL vs B-Tree (InnoDB, SQLite)","text":"<p>Choose B-tree when: - Transactional guarantees required (ACID) - In-place updates common (not append-only) - Sequential writes (e.g., auto-increment primary key) - Need secondary indexes</p> <p>Choose ATLL when: - Append-heavy workload (insert + delete, rare updates) - Write throughput critical (&gt;10K writes/sec) - Large dataset (&gt;100 GB) - SSD wear concerns (lower write amplification)</p> <p>Comparison: <pre><code>Metric               B-tree        ATLL\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nWrite Amplification  2-10x*        8-20x\nRead Amplification   1 (worst)     5-12\nSpace Amplification  1.1-2.0x      1.1-1.3x\nTransactions         Full ACID     None (single-key atomic)\nRandom Writes        Slow**        Fast\n\n* Depends on page size, fragmentation\n** Requires random I/O, page rewrites\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/when-to-use/#atll-vs-log-structured-merge-bush-monkey","title":"ATLL vs Log-Structured Merge-Bush (Monkey)","text":"<p>Choose Monkey when: - Static workload (predictable access patterns) - Can afford offline tuning phase - Academic research (explore RUM frontier)</p> <p>Choose ATLL when: - Dynamic workload (changing access patterns) - Online adaptation required (no downtime) - Production system (simplicity, reliability)</p> <p>Comparison: <pre><code>Metric               Monkey        ATLL\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nTuning               Offline ML    Online bandit\nAdaptation           Static        Dynamic\nComplexity           High          Medium\nProduction-Ready     Research      Yes\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/when-to-use/#migration-checklist","title":"Migration Checklist","text":""},{"location":"crates/nori-lsm/core-concepts/when-to-use/#from-rocksdb-leveled-compaction","title":"From RocksDB (Leveled Compaction)","text":"<p>Reasons to migrate: - [ ] Write amplification too high (&gt;40x) - [ ] Compaction backlog (can't keep up with writes) - [ ] Skewed access patterns (hot/cold data) - [ ] SSD wear concerns</p> <p>Migration steps: 1. Measure baseline metrics (WA, RA, p95 latency) 2. Export RocksDB data to SSTable format 3. Import into ATLL with <code>num_slots=16</code>, <code>k_global=4</code> 4. Monitor heat scores and k_max convergence (1-2 weeks) 5. Compare metrics (expect 2-5x lower WA)</p> <p>Expected improvements: - Write amplification: 40-100x \u2192 8-20x - Write throughput: +50-200% - Read latency (hot data): Same or better</p>"},{"location":"crates/nori-lsm/core-concepts/when-to-use/#from-cassandra-size-tiered-compaction","title":"From Cassandra (Size-Tiered Compaction)","text":"<p>Reasons to migrate: - [ ] Read latency too high (&gt;20ms p95) - [ ] Point queries common (not just scans) - [ ] Space amplification too high (&gt;1.5x) - [ ] Need faster hot data reads</p> <p>Migration steps: 1. Measure baseline metrics (RA, read latency) 2. Export Cassandra SSTables to ATLL format 3. Import into ATLL with <code>num_slots=32</code>, <code>k_global=8</code> 4. Monitor slot k_max convergence 5. Compare metrics (expect 2x lower RA for hot data)</p> <p>Expected improvements: - Read amplification (hot): 10-15 \u2192 5-7 - Read latency (hot): 20-50ms \u2192 &lt;10ms - Write amplification: 6-8x \u2192 8-12x (slight increase)</p>"},{"location":"crates/nori-lsm/core-concepts/when-to-use/#from-b-tree-mysql-innodb-postgresql","title":"From B-Tree (MySQL InnoDB, PostgreSQL)","text":"<p>Reasons to migrate: - [ ] Write throughput bottleneck (random I/O) - [ ] Large dataset (&gt;100 GB, doesn't fit in buffer pool) - [ ] Append-heavy workload (rare updates) - [ ] Don't need transactions</p> <p>Migration steps: 1. Assess transaction requirements (ATLL has no ACID) 2. Export B-tree data to key-value pairs 3. Bulk load into ATLL (batch writes) 4. Benchmark write throughput (expect 5-10x improvement) 5. Monitor read latency (may increase 2-5x)</p> <p>Expected trade-offs: - Write throughput: +500-1000% - Write amplification: 2-10x \u2192 8-20x (but sequential I/O) - Read latency: +2-5x (vs fully cached B-tree) - Transactions: Lost (implement at application layer)</p>"},{"location":"crates/nori-lsm/core-concepts/when-to-use/#real-world-examples","title":"Real-World Examples","text":""},{"location":"crates/nori-lsm/core-concepts/when-to-use/#e-commerce-order-database","title":"E-Commerce Order Database","text":"<p>Workload: - 10M orders, 100 GB data - Hot: Recent orders (last 30 days, 20% of data, 80% of reads) - Cold: Historical orders (&gt;1 year, 80% of data, 20% of reads) - Writes: 10K orders/day (inserts + status updates)</p> <p>Why ATLL: <pre><code>Recent orders \u2192 k_max=1:\n  Fast order lookups for checkout, tracking (RA=7)\n  Accept higher WA for recent data (20x)\n\nHistorical orders \u2192 k_max=4:\n  Low WA for archival (6x)\n  Slow reads acceptable (rare, analytics only)\n\nResult:\n  p95 latency: &lt;10ms (hot orders)\n  Write throughput: 10K orders/day sustained\n  Storage efficiency: 1.2x space amplification\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/when-to-use/#iot-sensor-metrics","title":"IoT Sensor Metrics","text":"<p>Workload: - 1000 sensors \u00d7 1 metric/sec = 86M metrics/day - Hot: Last 24 hours (dashboards, alerts) - Cold: Last 30 days (historical charts) - Scans: Range queries by time</p> <p>Why ATLL: <pre><code>Recent metrics \u2192 k_max=1:\n  Fast dashboard queries (RA=7)\n  Handle write burst (86M/day = 1K/sec sustained)\n\nOld metrics \u2192 k_max=4:\n  Low compaction overhead (WA=6x)\n  Range scans still fast (sequential I/O)\n\nResult:\n  Write throughput: 1K writes/sec sustained\n  Query latency: &lt;5ms (last 24h), &lt;50ms (last 30d)\n  Cost: Low (minimal compaction I/O for old data)\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/when-to-use/#user-session-store","title":"User Session Store","text":"<p>Workload: - 1M active users, 100M total users - Hot: Active sessions (1M users, 60-min TTL) - Cold: Dormant users (99M users, rare login) - Reads: Session validation (every request)</p> <p>Why ATLL: <pre><code>Active users \u2192 k_max=1:\n  Fast session validation (&lt;1ms p95)\n  High read/write frequency\n\nDormant users \u2192 k_max=4:\n  Low compaction cost (rare writes)\n  Slow reads acceptable (login once/month)\n\nResult:\n  p95 latency: &lt;1ms (active), &lt;100ms (dormant)\n  Cost: Low (99% of users don't trigger compaction)\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/when-to-use/#summary","title":"Summary","text":"<p>Use ATLL when: -  Skewed access patterns (hot/cold data) -  Mixed workload (40-60% reads/writes) -  Large dataset (&gt;100 GB) -  Need adaptive performance (no manual tuning) -  SSD wear concerns (lower WA than pure leveled)</p> <p>Avoid ATLL when: -  Uniform access (all keys equally hot) -  Pure scans (no point queries) -  Tiny dataset (&lt;100 MB, fits in memory) -  Need transactions (use SQL database instead) -  Append-only writes (use log instead)</p> <p>Key insight: ATLL optimizes for heterogeneous workloads where different key ranges have different access patterns.</p> <p>Next steps: See Recipes for implementation patterns and Performance for tuning guidance.</p> <p>Last Updated: 2025-10-31 See Also: ATLL Architecture, LSM Variants</p>"},{"location":"crates/nori-lsm/core-concepts/write-path/","title":"Write Path","text":"<p>How writes flow through nori-lsm from <code>put()</code> call to persistent storage, including WAL durability, memtable buffering, L0 flushes, and compaction.</p>"},{"location":"crates/nori-lsm/core-concepts/write-path/#overview","title":"Overview","text":"<p>Write path stages: 1. WAL append \u2192 Durability (crash recovery) 2. Memtable write \u2192 In-memory buffer (fast lookups) 3. Memtable flush \u2192 Convert to L0 SSTable (persistent) 4. L0 compaction \u2192 Merge into slots (reduce read amplification) 5. Slot compaction \u2192 Maintain K-way fanout (ATLL optimization)</p> <p>Latency breakdown (typical values): <pre><code>put() call:\n  \u251c\u2500 WAL append:        1-2ms   (fsync to disk)\n  \u251c\u2500 Memtable insert:   50ns    (skiplist insert)\n  \u2514\u2500 Total:             1-2ms   (dominated by WAL)\n\nBackground (async):\n  \u251c\u2500 Memtable flush:    50-200ms  (write SSTable)\n  \u251c\u2500 L0 compaction:     200-500ms (merge to slots)\n  \u2514\u2500 Slot compaction:   500-2000ms (slot-local tiering)\n</code></pre></p> <p>Key invariant: Every write is durable before returning to caller (via WAL).</p>"},{"location":"crates/nori-lsm/core-concepts/write-path/#stage-1-wal-append","title":"Stage 1: WAL Append","text":""},{"location":"crates/nori-lsm/core-concepts/write-path/#purpose","title":"Purpose","text":"<p>Durability: Ensure writes survive crashes/power loss</p> <p>Mechanism: <pre><code>async fn put(&amp;self, key: Vec&lt;u8&gt;, value: Vec&lt;u8&gt;) -&gt; Result&lt;()&gt; {\n    // 1. Append to WAL (synchronous fsync)\n    self.wal.append(&amp;key, &amp;value).await?;\n\n    // 2. Write to memtable (fast, in-memory)\n    self.memtable.insert(key, value);\n\n    Ok(())\n}\n</code></pre></p> <p>WAL Entry Format: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Header (12 bytes)                      \u2502\n\u2502  \u251c\u2500 Length: u32      (4 bytes)         \u2502\n\u2502  \u251c\u2500 CRC32:  u32      (4 bytes)         \u2502\n\u2502  \u2514\u2500 Type:   u8       (1 byte: Put/Del) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Key Length: u32      (4 bytes)         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Key Data:   [u8; key_len]              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Value Length: u32    (4 bytes)         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Value Data: [u8; val_len]              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>Durability Guarantee: <pre><code>// WAL append includes fsync before returning\npub async fn append(&amp;mut self, key: &amp;[u8], value: &amp;[u8]) -&gt; Result&lt;()&gt; {\n    let entry = encode_entry(key, value);\n    self.file.write_all(&amp;entry).await?;\n    self.file.sync_all().await?;  // \u2190 Blocks until kernel writes to disk\n    Ok(())\n}\n</code></pre></p> <p>Crash Recovery: <pre><code>// On startup, replay WAL to reconstruct memtable\npub async fn recover(&amp;mut self) -&gt; Result&lt;()&gt; {\n    for entry in self.wal.read_entries().await? {\n        match entry.op_type {\n            OpType::Put =&gt; self.memtable.insert(entry.key, entry.value),\n            OpType::Delete =&gt; self.memtable.delete(entry.key),\n        }\n    }\n    Ok(())\n}\n</code></pre></p> <p>Performance: - Latency: 1-2ms (dominated by <code>fsync</code> system call) - Throughput: ~10,000 writes/sec (single WAL, sequential) - Bottleneck: Disk write latency (SSD: ~100\u00b5s, HDD: ~10ms)</p>"},{"location":"crates/nori-lsm/core-concepts/write-path/#stage-2-memtable-insert","title":"Stage 2: Memtable Insert","text":""},{"location":"crates/nori-lsm/core-concepts/write-path/#purpose_1","title":"Purpose","text":"<p>Fast reads: Recent writes stay in memory (no disk I/O)</p> <p>Data Structure: Skip list (lock-free, concurrent) <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Skip List (in-memory, sorted by key)  \u2502\n\u2502                                        \u2502\n\u2502  Level 3:  [a] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500&gt; [z]     \u2502\n\u2502  Level 2:  [a] \u2500\u2500&gt; [m] \u2500\u2500\u2500\u2500\u2500\u2500&gt; [z]    \u2502\n\u2502  Level 1:  [a] \u2500\u2500&gt; [g] \u2500\u2500&gt; [m] \u2500\u2500&gt; [z]\u2502\n\u2502  Level 0:  [a][b][c][d][e][f][g]...    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>Insert Operation: <pre><code>pub fn insert(&amp;self, key: Vec&lt;u8&gt;, value: Vec&lt;u8&gt;) {\n    // Skiplist insert is lock-free (uses atomic CAS)\n    self.skiplist.insert(key, value);\n\n    // Update memory usage (for flush triggering)\n    self.memory_usage.fetch_add(\n        key.len() + value.len(),\n        Ordering::Relaxed\n    );\n}\n</code></pre></p> <p>Lookup (for reads): <pre><code>pub fn get(&amp;self, key: &amp;[u8]) -&gt; Option&lt;Vec&lt;u8&gt;&gt; {\n    // O(log N) expected, lock-free\n    self.skiplist.get(key)\n}\n</code></pre></p> <p>Performance: - Latency: 50-100ns (in-memory, cache-friendly) - Throughput: Millions of ops/sec (concurrent reads/writes) - Memory: ~24 bytes overhead per key (skip list pointers)</p>"},{"location":"crates/nori-lsm/core-concepts/write-path/#stage-3-memtable-flush","title":"Stage 3: Memtable Flush","text":""},{"location":"crates/nori-lsm/core-concepts/write-path/#flush-trigger","title":"Flush Trigger","text":"<p>Condition: Memtable size exceeds threshold <pre><code>if memtable.memory_usage() &gt;= config.memtable_size_threshold {\n    flush_memtable_to_l0().await?;\n}\n</code></pre></p> <p>Default Threshold: 64 MB (configurable via <code>ATLLConfig.memtables_mib</code>)</p> <p>Backpressure (if flush can't keep up): <pre><code>// Memory pressure system applies adaptive delays\nif memory_pressure == MemoryPressure::Moderate {\n    // Yellow zone: Soft throttle (20ms base delay)\n    tokio::time::sleep(Duration::from_millis(20)).await;\n} else if memory_pressure == MemoryPressure::High {\n    // Orange zone: Heavy throttle (200ms)\n    tokio::time::sleep(Duration::from_millis(200)).await;\n} else if memory_pressure == MemoryPressure::Critical {\n    // Red zone: Hard stall (reject writes)\n    return Err(Error::SystemPressure);\n}\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/write-path/#flush-algorithm","title":"Flush Algorithm","text":"<p>Steps: 1. Freeze memtable: Mark as read-only, create new active memtable 2. Iterate keys: Scan skiplist in sorted order 3. Write SSTable: Serialize to L0 file 4. Update manifest: Record new L0 file 5. Clear WAL: Truncate WAL (data now in SSTable)</p> <p>Pseudocode: <pre><code>async fn flush_memtable(&amp;mut self) -&gt; Result&lt;()&gt; {\n    // 1. Freeze current memtable\n    let frozen = self.memtable.freeze();\n    self.memtable = Memtable::new();\n\n    // 2. Create L0 SSTable file\n    let sst_path = format!(\"L0-{}.sst\", self.next_file_id);\n    let mut builder = SSTableBuilder::new(sst_path);\n\n    // 3. Iterate memtable in sorted order\n    for (key, value) in frozen.iter() {\n        builder.add(key, value)?;\n    }\n\n    // 4. Finalize SSTable (write bloom, index, footer)\n    let sst_metadata = builder.finish().await?;\n\n    // 5. Update manifest\n    self.manifest.add_l0_file(sst_metadata).await?;\n\n    // 6. Truncate WAL (data now durable in SSTable)\n    self.wal.truncate().await?;\n\n    Ok(())\n}\n</code></pre></p> <p>SSTable Structure (refresher): <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Data Blocks (4KB each)                \u2502\n\u2502   \u251c\u2500 Block 0: [a..f]                   \u2502\n\u2502   \u251c\u2500 Block 1: [g..m]                   \u2502\n\u2502   \u2514\u2500 Block 2: [n..z]                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Block Index                           \u2502\n\u2502   \u251c\u2500 Block 0: offset=0, first_key=\"a\"  \u2502\n\u2502   \u251c\u2500 Block 1: offset=4096, first_key=\"g\"\u2502\n\u2502   \u2514\u2500 Block 2: offset=8192, first_key=\"n\"\u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Bloom Filter (10 bits/key)            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Footer (metadata, offsets)            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>Performance: - Latency: 50-200ms (64 MB memtable \u2192 ~64 MB SSTable) - Throughput: ~320 MB/s (SSD write bandwidth) - I/O Pattern: Sequential writes (efficient)</p>"},{"location":"crates/nori-lsm/core-concepts/write-path/#stage-4-l0-compaction","title":"Stage 4: L0 Compaction","text":""},{"location":"crates/nori-lsm/core-concepts/write-path/#problem-l0-overlaps","title":"Problem: L0 Overlaps","text":"<p>L0 files overlap (contain arbitrary key ranges): <pre><code>L0-001.sst: [a..z]  (entire key space)\nL0-002.sst: [b..y]  (overlaps with L0-001)\nL0-003.sst: [m..t]  (overlaps with both)\n</code></pre></p> <p>Read Amplification: <pre><code>get(\"m\"):\n  Check L0-003 Yes (might contain \"m\")\n  Check L0-002 Yes (might contain \"m\")\n  Check L0-001 Yes (might contain \"m\")\n  \u2192 Read 3 files for 1 key\n</code></pre></p> <p>Solution: Compact L0 into range-partitioned slots (L1+)</p>"},{"location":"crates/nori-lsm/core-concepts/write-path/#compaction-trigger","title":"Compaction Trigger","text":"<p>Condition: L0 file count exceeds threshold <pre><code>if l0_file_count &gt;= config.l0.max_files {\n    // Critical: Hard stall (reject writes)\n    return Err(Error::L0Overflow);\n} else if l0_file_count &gt;= config.l0.soft_throttle_threshold {\n    // Moderate: Soft throttle (apply backpressure)\n    schedule_l0_compaction();\n}\n</code></pre></p> <p>Default Thresholds: - Soft throttle: 6 files (50% of max) - Hard stall: 12 files (100% of max)</p>"},{"location":"crates/nori-lsm/core-concepts/write-path/#l0-slot-compaction","title":"L0 \u2192 Slot Compaction","text":"<p>Algorithm: Merge L0 files into appropriate slots based on guard keys</p> <p>Pseudocode: <pre><code>async fn compact_l0_to_slots(&amp;mut self) -&gt; Result&lt;()&gt; {\n    // 1. Select all L0 files\n    let l0_files = self.manifest.l0_files();\n\n    // 2. Create iterators for each L0 file\n    let iterators = l0_files.iter()\n        .map(|f| SSTableIterator::new(f))\n        .collect();\n\n    // 3. Merge-sort all L0 keys\n    let mut merger = KWayMerge::new(iterators);\n\n    // 4. Route keys to appropriate slots based on guard keys\n    let mut slot_builders = HashMap::new();  // slot_id -&gt; SSTableBuilder\n\n    while let Some((key, value)) = merger.next().await? {\n        // Find slot for this key\n        let slot_id = self.find_slot_for_key(&amp;key);\n\n        // Add to slot's builder\n        let builder = slot_builders.entry(slot_id)\n            .or_insert_with(|| SSTableBuilder::new(slot_id));\n        builder.add(key, value)?;\n    }\n\n    // 5. Finalize all slot SSTables\n    for (slot_id, builder) in slot_builders {\n        let sst_metadata = builder.finish().await?;\n        self.manifest.add_slot_file(slot_id, sst_metadata).await?;\n    }\n\n    // 6. Delete L0 files (data now in slots)\n    for file in l0_files {\n        self.delete_sst(file).await?;\n    }\n\n    Ok(())\n}\n</code></pre></p> <p>Visual Example: <pre><code>Before:\n  L0-001: [a, b, m, n, z]\n  L0-002: [c, d, p, q]\n\n  Slots (guard keys):\n    Slot 0: [a..m)\n    Slot 1: [m..z)\n\nAfter:\n  Slot 0: [a, b, c, d]  (new SSTable)\n  Slot 1: [m, n, p, q, z] (new SSTable)\n\n  L0: (empty)\n</code></pre></p> <p>Performance: - Latency: 200-500ms (merge 6-12 files, ~384-768 MB) - Throughput: ~1.5 GB/s (read + write) - I/O Pattern: Sequential reads + writes (efficient)</p> <p>Read Amplification Improvement: <pre><code>Before L0 compaction (6 L0 files):\n  get(\"m\"): Check 6 L0 files\n\nAfter L0 compaction:\n  get(\"m\"): Check Slot 1 only (1 file)\n  \u2192 6x reduction in reads\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/write-path/#stage-5-slot-compaction","title":"Stage 5: Slot Compaction","text":""},{"location":"crates/nori-lsm/core-concepts/write-path/#purpose_2","title":"Purpose","text":"<p>Maintain K-way fanout: Ensure each slot has \u2264 k_max sorted runs</p> <p>Trigger: Slot exceeds k_max runs <pre><code>if slot.runs.len() &gt; slot.k_max {\n    schedule_slot_compaction(slot.slot_id);\n}\n</code></pre></p> <p>Slot-Local Tiering: Merge oldest runs within slot <pre><code>async fn compact_slot(&amp;mut self, slot_id: u32) -&gt; Result&lt;()&gt; {\n    let slot = &amp;self.slots[slot_id];\n\n    // 1. Select oldest K runs to merge (size-tiered)\n    let runs_to_merge = slot.runs\n        .iter()\n        .rev()  // Oldest first\n        .take(slot.k_max)\n        .cloned()\n        .collect();\n\n    // 2. Merge runs into single new run\n    let merged_run = merge_runs(runs_to_merge).await?;\n\n    // 3. Update slot (replace old runs with merged run)\n    slot.runs.retain(|r| !runs_to_merge.contains(r));\n    slot.runs.push(merged_run);\n\n    Ok(())\n}\n</code></pre></p> <p>Adaptive K-Max (ATLL innovation): <pre><code>Hot slot (heat_score = 0.9):\n  k_max = 1  \u2192 Compact frequently (maintain leveled structure)\n\nCold slot (heat_score = 0.1):\n  k_max = 4  \u2192 Compact rarely (allow tiered structure)\n</code></pre></p> <p>Bandit Scheduler: Chooses which slot to compact <pre><code>fn select_slot_for_compaction(&amp;self) -&gt; u32 {\n    if random() &lt; epsilon {\n        // Exploration (10%)\n        random_slot()\n    } else {\n        // Exploitation (90%)\n        argmax(slot.ucb_score)\n    }\n}\n</code></pre></p> <p>Performance: - Latency: 500-2000ms (depends on slot size) - Frequency: Hot slots \u2192 frequent, cold slots \u2192 rare - I/O Pattern: Sequential (merge multiple SSTables)</p>"},{"location":"crates/nori-lsm/core-concepts/write-path/#write-amplification-analysis","title":"Write Amplification Analysis","text":""},{"location":"crates/nori-lsm/core-concepts/write-path/#formula","title":"Formula","text":"<p>Write Amplification (WA) = Physical bytes written / Logical bytes written</p>"},{"location":"crates/nori-lsm/core-concepts/write-path/#per-stage-wa","title":"Per-Stage WA","text":"<p>1. WAL Append: <pre><code>WA_wal = 1.0x (write once to WAL)\n</code></pre></p> <p>2. Memtable Flush: <pre><code>WA_flush = 1.0x (write once to L0 SSTable)\n</code></pre></p> <p>3. L0 \u2192 Slot Compaction: <pre><code>WA_l0 = 1.0x (write once to slot)\n</code></pre></p> <p>4. Slot Compaction (varies by heat): <pre><code>Hot slot (k_max=1, compacted every 10 writes):\n  WA_slot = 10x (rewrite 10 times)\n\nCold slot (k_max=4, compacted every 50 writes):\n  WA_slot = 2x (rewrite 2 times)\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/write-path/#total-wa","title":"Total WA","text":"<p>Formula: <pre><code>WA_total = WA_wal + WA_flush + WA_l0 + WA_slot\n         = 1 + 1 + 1 + WA_slot\n         = 3 + WA_slot\n</code></pre></p> <p>Example (80/20 hot/cold workload): <pre><code>80% writes to hot slots (WA_slot = 10x):\n  WA_hot = 3 + 10 = 13x\n\n20% writes to cold slots (WA_slot = 2x):\n  WA_cold = 3 + 2 = 5x\n\nWeighted average:\n  WA_total = 0.8 \u00d7 13 + 0.2 \u00d7 5\n           = 10.4 + 1.0\n           = 11.4x\n</code></pre></p> <p>Comparison: - Pure Leveled: 40-100x (compact everything frequently) - ATLL: 8-20x (compact hot data frequently, cold data rarely) - Pure Tiered: 6-8x (but high read amplification)</p>"},{"location":"crates/nori-lsm/core-concepts/write-path/#backpressure-and-flow-control","title":"Backpressure and Flow Control","text":""},{"location":"crates/nori-lsm/core-concepts/write-path/#memory-pressure-system","title":"Memory Pressure System","text":"<p>Composite Pressure Score: <pre><code>composite_score = 0.4 \u00d7 l0_pressure + 0.4 \u00d7 memory_pressure + 0.2 \u00d7 memtable_pressure\n\nLevels:\n  None:     &lt; 0.5  (Green zone)\n  Low:      0.5-0.75 (Green zone)\n  Moderate: 0.75-0.9 (Yellow zone)\n  High:     0.9-1.1 (Orange zone)\n  Critical: \u2265 1.1   (Red zone)\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/write-path/#adaptive-backpressure","title":"Adaptive Backpressure","text":"<p>Green Zone (None, Low): <pre><code>// No throttling\nput(key, value).await?;  // ~1-2ms latency\n</code></pre></p> <p>Yellow Zone (Moderate): <pre><code>// Soft throttle\nlet delay = base_delay_ms \u00d7 l0_excess;  // 20ms \u00d7 3 = 60ms\ntokio::time::sleep(Duration::from_millis(delay)).await;\nput(key, value).await?;  // ~60ms total latency\n</code></pre></p> <p>Orange Zone (High): <pre><code>// Heavy throttle\nlet delay = base_delay_ms \u00d7 l0_excess \u00d7 2;  // 20ms \u00d7 5 \u00d7 2 = 200ms\ntokio::time::sleep(Duration::from_millis(delay)).await;\nput(key, value).await?;  // ~200ms total latency\n</code></pre></p> <p>Red Zone (Critical): <pre><code>// Hard stall (reject writes)\nreturn Err(Error::SystemPressure);\n// Caller must retry with exponential backoff\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/write-path/#exponential-backoff-retry","title":"Exponential Backoff Retry","text":"<p>Client-side retry strategy: <pre><code>let mut retries = 0;\nloop {\n    match lsm.put(key, value).await {\n        Ok(()) =&gt; break,\n        Err(Error::SystemPressure) if retries &lt; max_retries =&gt; {\n            let delay = base_delay_ms \u00d7 2u64.pow(retries);\n            tokio::time::sleep(Duration::from_millis(delay)).await;\n            retries += 1;\n        }\n        Err(e) =&gt; return Err(e),\n    }\n}\n</code></pre></p> <p>Example: <pre><code>Retry 0: Wait 5ms\nRetry 1: Wait 10ms\nRetry 2: Wait 20ms\nRetry 3: Wait 40ms\nRetry 4: Wait 80ms\nMax retries: 5 (total ~155ms)\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/write-path/#failure-recovery","title":"Failure Recovery","text":""},{"location":"crates/nori-lsm/core-concepts/write-path/#wal-based-crash-recovery","title":"WAL-Based Crash Recovery","text":"<p>On startup: <pre><code>pub async fn recover(wal_path: &amp;Path) -&gt; Result&lt;Memtable&gt; {\n    let mut memtable = Memtable::new();\n    let entries = WAL::read_all_entries(wal_path).await?;\n\n    for entry in entries {\n        match entry.op_type {\n            OpType::Put =&gt; memtable.insert(entry.key, entry.value),\n            OpType::Delete =&gt; memtable.delete(entry.key),\n        }\n    }\n\n    Ok(memtable)\n}\n</code></pre></p> <p>WAL Truncation Strategy: <pre><code>Scenario 1: Crash during memtable flush\n  \u251c\u2500 Partial SSTable written (incomplete)\n  \u2514\u2500 Recovery: Replay WAL to rebuild memtable, retry flush\n\nScenario 2: Crash after flush, before WAL truncate\n  \u251c\u2500 SSTable complete, WAL still has data\n  \u2514\u2500 Recovery: Detect duplicate data, skip WAL entries already in SSTable\n\nScenario 3: Crash during WAL write\n  \u251c\u2500 Partial WAL entry (corrupt CRC)\n  \u2514\u2500 Recovery: Truncate at last valid entry, discard partial write\n</code></pre></p> <p>Idempotency: <pre><code>// Recovery is idempotent (safe to replay multiple times)\nfor entry in wal_entries {\n    // Last-write-wins semantics\n    memtable.insert(entry.key, entry.value);\n}\n</code></pre></p>"},{"location":"crates/nori-lsm/core-concepts/write-path/#performance-tuning","title":"Performance Tuning","text":""},{"location":"crates/nori-lsm/core-concepts/write-path/#memtable-size","title":"Memtable Size","text":"<p>Trade-off: - Larger (128 MB, 256 MB):   -  Fewer L0 flushes (lower WA)   -  Better sequential write batching   -  Higher memory usage   -  Slower crash recovery (larger WAL replay)</p> <ul> <li>Smaller (32 MB, 64 MB):</li> <li>Lower memory footprint</li> <li>Faster recovery</li> <li>More L0 flushes (higher WA)</li> </ul> <p>Recommendation: 64 MB (default)</p>"},{"location":"crates/nori-lsm/core-concepts/write-path/#l0-thresholds","title":"L0 Thresholds","text":"<p>Trade-off: - Higher max_files (16, 20):   -  Less write throttling   -  Higher sustained write throughput   -  Higher read amplification   -  Longer L0 compaction times</p> <ul> <li>Lower max_files (8, 10):</li> <li>Lower read amplification</li> <li>Faster L0 compactions</li> <li>More frequent write throttling</li> </ul> <p>Recommendation: 12 files (default)</p>"},{"location":"crates/nori-lsm/core-concepts/write-path/#wal-fsync-strategy","title":"WAL Fsync Strategy","text":"<p>Options: <pre><code>// 1. Sync per write (default, most durable)\nwal.append(key, value).await?;\nwal.sync_all().await?;  // Every write\n\n// 2. Sync every N writes (higher throughput)\nwal.append(key, value).await?;\nif write_count % N == 0 {\n    wal.sync_all().await?;\n}\n\n// 3. Group commit (batched sync)\nbatch.push((key, value));\nif batch.len() &gt;= batch_size {\n    wal.append_batch(&amp;batch).await?;\n    wal.sync_all().await?;\n    batch.clear();\n}\n</code></pre></p> <p>Trade-off: - Sync per write: 1-2ms latency, 100% durable - Sync every 100 writes: 50\u00b5s latency, risk losing last 99 writes - Group commit: 200\u00b5s latency, no data loss (batch all synced together)</p> <p>Recommendation: Sync per write (safety first)</p>"},{"location":"crates/nori-lsm/core-concepts/write-path/#summary","title":"Summary","text":"<p>Write Path Stages: 1. WAL append (1-2ms) \u2192 Durability 2. Memtable insert (50ns) \u2192 Fast lookups 3. Memtable flush (50-200ms, async) \u2192 L0 SSTable 4. L0 compaction (200-500ms, async) \u2192 Slot SSTables 5. Slot compaction (500-2000ms, async) \u2192 Maintain K-way fanout</p> <p>Write Amplification: - ATLL: 8-20x (adaptive per slot) - Leveled: 40-100x (global leveling) - Tiered: 6-8x (but high RA)</p> <p>Backpressure: - Green: No throttling - Yellow: Soft delays (60ms) - Orange: Heavy delays (200ms) - Red: Hard stall (reject writes)</p> <p>Durability: - WAL fsync before <code>put()</code> returns - Crash recovery via WAL replay - Idempotent recovery (safe to replay)</p> <p>Next: Read Read Path to understand how queries work.</p> <p>Last Updated: 2025-10-31 See Also: ATLL Architecture, Memory Pressure</p>"},{"location":"crates/nori-lsm/design-decisions/","title":"Design Decisions","text":"<p>Rationale behind ATLL's key architectural choices and trade-offs.</p>"},{"location":"crates/nori-lsm/design-decisions/#overview","title":"Overview","text":"<p>This section explains why nori-lsm's ATLL (Adaptive Tiered-Leveled LSM) is built the way it is. Each design decision represents a conscious trade-off, balancing performance, adaptability, and operational simplicity.</p> <p>Unlike traditional LSMs that force a global choice between leveled (high WA) or tiered (high RA), ATLL makes per-range decisions, adapting to heterogeneous workloads.</p>"},{"location":"crates/nori-lsm/design-decisions/#key-decisions","title":"Key Decisions","text":""},{"location":"crates/nori-lsm/design-decisions/#guard-based-partitioning","title":"Guard-Based Partitioning","text":"<p>Why we use fixed guard keys for range partitioning instead of dynamic splitting: predictable behavior, simple recovery, and stable boundaries for learning.</p>"},{"location":"crates/nori-lsm/design-decisions/#adaptive-k-way-fanout","title":"Adaptive K-Way Fanout","text":"<p>Why each slot chooses its own K (max runs) based on heat: RUM optimization per range, not global compromise.</p>"},{"location":"crates/nori-lsm/design-decisions/#heat-tracking-ewma","title":"Heat Tracking (EWMA)","text":"<p>Why we use exponential weighted moving average (\u03b1=0.1) for access pattern detection: recency bias, convergence properties, low overhead.</p>"},{"location":"crates/nori-lsm/design-decisions/#bandit-scheduler","title":"Bandit Scheduler","text":"<p>Why epsilon-greedy multi-armed bandits with UCB for compaction scheduling: balances exploration vs exploitation with proven regret bounds.</p>"},{"location":"crates/nori-lsm/design-decisions/#memory-pressure-system","title":"Memory Pressure System","text":"<p>Why 4-zone adaptive backpressure (Green/Yellow/Orange/Red) with composite scoring: progressive degradation, not cliff-edge failures.</p>"},{"location":"crates/nori-lsm/design-decisions/#design-philosophy","title":"Design Philosophy","text":"<p>ATLL follows these core principles:</p>"},{"location":"crates/nori-lsm/design-decisions/#1-adapt-dont-compromise","title":"1. Adapt, Don't Compromise","text":"<p>Traditional LSMs force a global trade-off: - Leveled: Fast reads, slow writes - Tiered: Fast writes, slow reads</p> <p>ATLL: Adapt per key range based on actual access patterns.</p>"},{"location":"crates/nori-lsm/design-decisions/#2-learn-online-not-offline","title":"2. Learn Online, Not Offline","text":"<p>Some LSM tuning systems (e.g., Monkey) require offline learning phases.</p> <p>ATLL: Continuous online learning via EWMA heat tracking and bandit scheduler.</p>"},{"location":"crates/nori-lsm/design-decisions/#3-simplicity-through-automation","title":"3. Simplicity Through Automation","text":"<p>Manual LSM tuning requires expertise: - RocksDB: bloom bits, compaction threads, L0 thresholds, compaction style - Cassandra: window sizes, bucket counts, SSTable sizes</p> <p>ATLL: Self-tuning via reinforcement learning.</p>"},{"location":"crates/nori-lsm/design-decisions/#4-theory-guided-measurement-validated","title":"4. Theory-Guided, Measurement-Validated","text":"<p>Decisions backed by: - Theory: RUM conjecture, UCB regret bounds, EWMA convergence - Measurement: Benchmarks with Zipfian workloads, real metrics</p>"},{"location":"crates/nori-lsm/design-decisions/#5-fail-gracefully-not-catastrophically","title":"5. Fail Gracefully, Not Catastrophically","text":"<p>Hard stalls (reject writes) are a last resort.</p> <p>ATLL: Progressive backpressure (soft throttling \u2192 heavy throttling \u2192 hard stall).</p>"},{"location":"crates/nori-lsm/design-decisions/#decision-making-framework","title":"Decision-Making Framework","text":"<p>When designing ATLL, we prioritize:</p> <p>1. Correctness First - Never sacrifice data integrity for performance - Durability via WAL, crash-safe compaction - Last-write-wins semantics (no lost updates)</p> <p>2. Adaptive Over Static - Access patterns change over time - System learns and adapts (not manual re-tuning) - Resilient to workload shifts</p> <p>3. Measurable Trade-offs - Document what we gained and what we gave up - Benchmark claims (not just theory) - Quantify costs (WA, RA, SA)</p> <p>4. Operational Simplicity - Minimal knobs (defaults work for 80% of use cases) - Observable behavior (heat scores, bandit metrics, pressure zones) - Predictable failure modes</p>"},{"location":"crates/nori-lsm/design-decisions/#trade-offs","title":"Trade-offs","text":"<p>Every design decision involves trade-offs. Here's what we gained vs what we gave up:</p> Decision Gained Cost Fixed guard keys Predictable routing, simple recovery Can't rebalance without data migration Per-slot K-way fanout Adaptive WA/RA per range More complex than global strategy EWMA heat tracking Recency bias, low overhead Slower adaptation than counters Bandit scheduler Automatic optimization 10% exploration overhead (\u03b5=0.1) 4-zone backpressure Graceful degradation More complex than hard stall Bloom filters 99% faster negative lookups 125 KB per 100K keys (memory) Slot-local compaction Parallel compaction Must coordinate cross-slot queries <p>Overall: ATLL sacrifices simplicity for adaptability, achieving near-Pareto-optimal performance for heterogeneous workloads.</p>"},{"location":"crates/nori-lsm/design-decisions/#comparison-to-alternatives","title":"Comparison to Alternatives","text":""},{"location":"crates/nori-lsm/design-decisions/#atll-vs-rocksdb-pure-leveled","title":"ATLL vs RocksDB (Pure Leveled)","text":"<p>RocksDB approach: - Global leveled compaction (K=1 everywhere) - Manual tuning (L0 triggers, compaction threads, bloom bits) - Optimized for read-heavy workloads</p> <p>ATLL improvements: - 2-5x lower WA (via adaptive tiering for cold ranges) - Automatic tuning (no manual intervention) - Better for heterogeneous workloads</p>"},{"location":"crates/nori-lsm/design-decisions/#atll-vs-cassandra-pure-tiered","title":"ATLL vs Cassandra (Pure Tiered)","text":"<p>Cassandra approach: - Global size-tiered compaction (K&gt;1 everywhere) - Optimized for write-heavy workloads - High RA for point queries</p> <p>ATLL improvements: - 2x lower RA for hot ranges (K=1 via adaptation) - Maintains low WA for cold ranges (K&gt;1) - Better for mixed workloads</p>"},{"location":"crates/nori-lsm/design-decisions/#atll-vs-scylladb-ics-time-windowed","title":"ATLL vs ScyllaDB ICS (Time-Windowed)","text":"<p>ScyllaDB approach: - Time-window bucketing (recent=leveled, old=tiered) - Assumes time-series workload - Requires manual window configuration</p> <p>ATLL improvements: - Access-pattern-based (not time-based, works for any workload) - Automatic adaptation (no window tuning) - General-purpose key-value store</p>"},{"location":"crates/nori-lsm/design-decisions/#atll-vs-monkey-ml-based-tuning","title":"ATLL vs Monkey (ML-Based Tuning)","text":"<p>Monkey approach: - Offline learning of optimal T (fanout) and bloom bits - Theoretically optimal for static workloads - Academic research project</p> <p>ATLL improvements: - Per-slot adaptation (finer granularity than global T) - Online learning (no offline phase) - Production-ready implementation</p>"},{"location":"crates/nori-lsm/design-decisions/#non-goals","title":"Non-Goals","text":"<p>It's important to document what ATLL is not designed to do:</p>"},{"location":"crates/nori-lsm/design-decisions/#not-a-generic-compaction-strategy","title":"Not a Generic Compaction Strategy","text":"<p>ATLL is optimized for heterogeneous workloads (hot/cold data).</p> <p>Not ideal for: - Uniform access patterns (all keys equally hot) - Pure sequential scans (no point queries) - Tiny datasets (&lt;100 MB, fits in memory)</p>"},{"location":"crates/nori-lsm/design-decisions/#not-a-manual-tuning-framework","title":"Not a Manual Tuning Framework","text":"<p>ATLL is designed to self-tune.</p> <p>We intentionally avoid: - Per-range compaction strategy overrides - Manual K-max configuration - Expert-mode knobs for every parameter</p>"},{"location":"crates/nori-lsm/design-decisions/#not-a-distributed-system","title":"Not a Distributed System","text":"<p>ATLL is a single-node storage engine.</p> <p>Not included: - Replication (use nori-raft on top) - Sharding (use norikv-placement) - Consensus (use nori-raft)</p>"},{"location":"crates/nori-lsm/design-decisions/#evolution-of-design","title":"Evolution of Design","text":"<p>Some decisions were made early and have proven stable. Others evolved based on experience:</p>"},{"location":"crates/nori-lsm/design-decisions/#stable-since-v01","title":"Stable Since v0.1","text":"<ul> <li>Guard-based range partitioning</li> <li>EWMA heat tracking (\u03b1=0.1)</li> <li>Epsilon-greedy bandit (\u03b5=0.1)</li> <li>4-zone memory pressure system</li> </ul>"},{"location":"crates/nori-lsm/design-decisions/#added-based-on-feedback","title":"Added Based on Feedback","text":"<ul> <li>Dynamic K-way fanout (v0.2) - initially K was fixed per slot</li> <li>UCB exploration bonus (v0.3) - initially pure \u03b5-greedy</li> <li>Composite pressure scoring (v0.4) - initially L0-only</li> </ul>"},{"location":"crates/nori-lsm/design-decisions/#future-considerations","title":"Future Considerations","text":"<ul> <li>Dynamic guard key adjustment - Rebalance slots when sizes diverge</li> <li>Multi-dimensional heat - Separate read/write/scan heat scores</li> <li>Contextual bandits - Use system state (L0 count, memory) as context</li> <li>Learned guard keys - ML-based key space partitioning</li> </ul>"},{"location":"crates/nori-lsm/design-decisions/#theoretical-foundations","title":"Theoretical Foundations","text":"<p>ATLL's design is grounded in established theory:</p>"},{"location":"crates/nori-lsm/design-decisions/#rum-conjecture-athanassoulis-et-al-2016","title":"RUM Conjecture (Athanassoulis et al., 2016)","text":"<pre><code>For any data structure:\n  R \u00d7 U \u00d7 M \u2265 Constant\n\nWhere:\n  R = Read cost\n  U = Update (write) cost\n  M = Memory cost\n</code></pre> <p>ATLL insight: Optimize R-U-M per slot, not globally. - Hot slots: Minimize R (accept higher U) - Cold slots: Minimize U (accept higher R)</p>"},{"location":"crates/nori-lsm/design-decisions/#multi-armed-bandit-theory","title":"Multi-Armed Bandit Theory","text":"<pre><code>UCB Regret Bound:\n  Regret \u2264 O(K \u00d7 log(T))\n\nWhere:\n  K = number of arms (slots)\n  T = total selections\n</code></pre> <p>ATLL guarantee: After T compaction decisions, regret (suboptimal choices) is logarithmically bounded.</p>"},{"location":"crates/nori-lsm/design-decisions/#ewma-convergence","title":"EWMA Convergence","text":"<pre><code>For \u03b1=0.1 and stable access pattern:\n  Convergence to steady state: ~20-30 accesses\n\nError after t steps:\n  error_t = (1-\u03b1)^t \u00d7 initial_error\n  error_30 = 0.9^30 \u2248 0.04 (4% error)\n</code></pre> <p>ATLL property: Heat scores converge within 30 accesses to stable patterns.</p>"},{"location":"crates/nori-lsm/design-decisions/#validation-methodology","title":"Validation Methodology","text":"<p>All design decisions were validated through:</p>"},{"location":"crates/nori-lsm/design-decisions/#1-benchmarks","title":"1. Benchmarks","text":"<ul> <li>Zipfian workloads (80/20 hot/cold distribution)</li> <li>Sustained writes (20K writes/sec for 1 hour)</li> <li>Mixed read/write (50/50 split, 10K ops/sec)</li> </ul>"},{"location":"crates/nori-lsm/design-decisions/#2-property-tests","title":"2. Property Tests","text":"<ul> <li>Reward convergence (bandit scheduler)</li> <li>Heat stability (EWMA tracking)</li> <li>Pressure correctness (4-zone backpressure)</li> </ul>"},{"location":"crates/nori-lsm/design-decisions/#3-real-metrics","title":"3. Real Metrics","text":"<ul> <li>Write amplification: 8-20x (vs 40-100x for pure leveled)</li> <li>Read amplification: 5-12 (vs 10-15 for pure tiered)</li> <li>p95 latency: &lt;10ms (hot ranges)</li> </ul>"},{"location":"crates/nori-lsm/design-decisions/#4-code-review","title":"4. Code Review","text":"<ul> <li>Academic paper citations (O'Neil 1996, Dayan 2017)</li> <li>Prior art comparison (RocksDB, Cassandra, ScyllaDB)</li> <li>Peer feedback from storage systems experts</li> </ul>"},{"location":"crates/nori-lsm/design-decisions/#further-reading","title":"Further Reading","text":"<p>Each subsection dives deep into a specific design decision. Read them in order to build understanding, or jump to specific topics:</p> <ol> <li>Guard-Based Partitioning - Foundation of ATLL's range-level adaptation</li> <li>Adaptive K-Way Fanout - How K-max is computed per slot</li> <li>Heat Tracking - EWMA algorithm and convergence analysis</li> <li>Bandit Scheduler - Epsilon-greedy UCB and reward function</li> <li>Memory Pressure - 4-zone backpressure system</li> </ol> <p>Last Updated: 2025-10-31 References: Athanassoulis et al. (RUM, 2016), Dayan et al. (Monkey, 2017), Auer et al. (UCB, 2002)</p>"},{"location":"crates/nori-lsm/design-decisions/adaptive-k-fanout/","title":"Adaptive K-Way Fanout","text":"<p>Why each slot chooses its own K-max (maximum sorted runs) based on heat score instead of using a global strategy.</p>"},{"location":"crates/nori-lsm/design-decisions/adaptive-k-fanout/#decision","title":"Decision","text":"<p>Each slot independently chooses its K-max (maximum sorted runs allowed) based on its heat score using this formula:</p> <pre><code>k_max[slot] = 1 + floor((1 - heat_score) \u00d7 (K_global - 1))\n\nWhere:\n  heat_score \u2208 [0.0, 1.0]  // 0 = cold, 1 = hot\n  K_global = 4             // Maximum runs allowed (configurable)\n</code></pre> <p>Result: - Hot slots (heat_score \u2265 0.8) \u2192 k_max = 1 (leveled, no overlaps) - Warm slots (heat_score \u2248 0.5) \u2192 k_max = 2 (hybrid) - Cold slots (heat_score \u2264 0.2) \u2192 k_max = 3-4 (tiered, bounded overlaps)</p>"},{"location":"crates/nori-lsm/design-decisions/adaptive-k-fanout/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"crates/nori-lsm/design-decisions/adaptive-k-fanout/#1-pure-leveled-global-k1","title":"1. Pure Leveled (Global K=1)","text":"<p>Approach: All slots maintain K=1 (single sorted run, no overlaps)</p> <pre><code>Every slot:\n  Slot 0: K=1 (leveled)\n  Slot 1: K=1 (leveled)\n  ...\n  Slot N: K=1 (leveled)\n</code></pre> <p>Rejected because: - High write amplification: 40-100x WA for all data (even cold) - Constant I/O: Compaction never stops (even for rarely accessed data) - No adaptation: Hot/cold treated identically - Wasted resources: Compact cold data for no benefit</p> <p>Example (cold slot): <pre><code>Cold slot compacted 100 times/day:\n  Each compaction rewrites 10 MB\n  Total I/O: 1 GB/day\n\nBenefit: Fast reads (but rarely read!)\nCost: 1 GB/day wasted I/O\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/adaptive-k-fanout/#2-pure-tiered-global-k1","title":"2. Pure Tiered (Global K&gt;1)","text":"<p>Approach: All slots allow K&gt;1 (multiple runs, bounded overlaps)</p> <pre><code>Every slot:\n  Slot 0: K=4 (tiered)\n  Slot 1: K=4 (tiered)\n  ...\n  Slot N: K=4 (tiered)\n</code></pre> <p>Rejected because: - High read amplification: 10-15 RA for all data (even hot) - Slow point queries: Must check 4 runs per slot - Poor SLO compliance: p95 latency &gt;20ms (unacceptable for hot data) - No adaptation: Hot/cold treated identically</p> <p>Example (hot slot): <pre><code>Hot slot (1000 queries/sec):\n  Each query checks 4 runs\n  Total I/O: 4000 checks/sec\n\nBenefit: Low WA (fast writes)\nCost: 4x slower reads (SLO violation)\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/adaptive-k-fanout/#3-manual-per-slot-configuration","title":"3. Manual Per-Slot Configuration","text":"<p>Approach: Operator configures K per slot</p> <pre><code>ATLLConfig {\n    slot_k_max: vec![\n        1,  // Slot 0: Known hot range\n        4,  // Slot 1: Known cold range\n        2,  // Slot 2: Warm range\n        ...\n    ],\n}\n</code></pre> <p>Rejected because: - Requires workload knowledge: Operator must analyze access patterns - Static configuration: No adaptation to changes - Brittle: Wrong assumptions \u2192 poor performance - Complex: 64 slots \u00d7 manual tuning = 64 knobs</p> <p>Example: <pre><code>Initial config: Slot 0 = K=1 (thought hot)\n\nWorkload shift:\n  Users stop accessing Slot 0\n  Slot 0 becomes cold\n\nProblem: Still compacting to K=1 (wasted I/O)\nSolution: Operator must notice and reconfigure\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/adaptive-k-fanout/#4-time-based-strategy-scylladb-ics","title":"4. Time-Based Strategy (ScyllaDB ICS)","text":"<p>Approach: Recent data = leveled, old data = tiered</p> <pre><code>Slot 0 (last hour):    K=1 (leveled)\nSlot 1 (last 24h):     K=2 (hybrid)\nSlot 2 (last 30d):     K=4 (tiered)\nSlot 3 (older):        K=8 (heavily tiered)\n</code></pre> <p>Rejected because: - Assumes time-series: Not general-purpose - Recent \u2260 hot: Many workloads access old data frequently - Manual window config: Requires tuning - Key format dependency: Must extract timestamp from key</p> <p>Example (counterexample): <pre><code>E-commerce database:\n  Recent orders (last week): 10% of queries (not hot)\n  Historical orders (&gt;1 year): 70% of queries (hot for analytics)\n\nTime-based strategy:\n  Recent \u2192 K=1 (wasted I/O, rarely queried)\n  Old \u2192 K=8 (slow queries, frequently queried)\n\nResult: Backwards from optimal\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/adaptive-k-fanout/#5-fixed-thresholds-no-continuous-mapping","title":"5. Fixed Thresholds (No Continuous Mapping)","text":"<p>Approach: Discrete heat buckets</p> <pre><code>if heat_score &gt; 0.8 {\n    k_max = 1;\n} else if heat_score &gt; 0.5 {\n    k_max = 2;\n} else {\n    k_max = 4;\n}\n</code></pre> <p>Rejected because: - Cliff edges: Small heat change \u2192 large K change - Oscillation: Heat fluctuates around 0.8 \u2192 constant K changes - Inefficient: No gradations (only 3 strategies)</p> <p>Example: <pre><code>Slot heat: 0.79 \u2192 K=2\nWrite burst \u2192 heat: 0.81 \u2192 K=1 (trigger compaction)\nHeat decays \u2192 heat: 0.79 \u2192 K=2 (allow 2nd run)\nWrite burst \u2192 heat: 0.81 \u2192 K=1 (trigger compaction again)\n\nProblem: Thrashing between K=1 and K=2\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/adaptive-k-fanout/#rationale","title":"Rationale","text":""},{"location":"crates/nori-lsm/design-decisions/adaptive-k-fanout/#1-rum-optimization-per-slot","title":"1. RUM Optimization Per Slot","text":"<p>RUM Conjecture: For any data structure, R \u00d7 U \u00d7 M \u2265 Constant</p> <p>ATLL's insight: Optimize per slot on the RUM Pareto frontier</p> <p>Hot slot (heat_score = 0.9): <pre><code>k_max = 1 + floor((1 - 0.9) \u00d7 3) = 1 + floor(0.3) = 1\n\nRUM trade-off:\n  R (read cost):   Low  (RA = L0 + 1 = 7)\n  U (update cost): High (WA = 20x, frequent compaction)\n  M (memory cost): Low  (no overlaps, compact storage)\n\nJustification: Frequent reads benefit from low RA\n</code></pre></p> <p>Cold slot (heat_score = 0.1): <pre><code>k_max = 1 + floor((1 - 0.1) \u00d7 3) = 1 + floor(2.7) = 3\n\nRUM trade-off:\n  R (read cost):   High (RA = L0 + 3 = 9)\n  U (update cost): Low  (WA = 6x, rare compaction)\n  M (memory cost): Medium (some overlaps, 1.2x SA)\n\nJustification: Rare reads tolerate higher RA, save WA\n</code></pre></p> <p>Continuous mapping: Smooth transition from leveled \u2192 tiered</p>"},{"location":"crates/nori-lsm/design-decisions/adaptive-k-fanout/#2-smooth-adaptation-no-cliff-edges","title":"2. Smooth Adaptation (No Cliff Edges)","text":"<p>Formula properties:</p> <pre><code>k_max = 1 + floor((1 - heat_score) \u00d7 (K_global - 1))\n</code></pre> <p>Gradient: <pre><code>heat_score:  1.0   0.9   0.8   0.7   0.6   0.5   0.4   0.3   0.2   0.1   0.0\nk_max:       1     1     1     2     2     2     3     3     3     3     4\n             \u2514\u2500\u2500\u2500leveled\u2500\u2500\u2500\u2518    \u2514\u2500\u2500hybrid\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500tiered\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>Benefit: Gradual transition, no oscillation</p> <p>Example: <pre><code>Slot heat evolves: 0.85 \u2192 0.80 \u2192 0.75 \u2192 0.70\n\nK-max evolution:   1 \u2192 1 \u2192 1 \u2192 2\n\nResult: K stays stable until significant heat drop\nNo thrashing\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/adaptive-k-fanout/#3-mathematical-justification","title":"3. Mathematical Justification","text":"<p>Write Amplification (slot-level): <pre><code>WA_slot = T \u00d7 compaction_frequency\n\nWhere:\n  T = fanout (default 10)\n  compaction_frequency = f(k_max)\n\nFor k_max=1 (leveled):\n  Compact every L0 flush \u2192 high frequency\n  WA \u2248 10 \u00d7 2 = 20x\n\nFor k_max=4 (tiered):\n  Compact every 4 L0 flushes \u2192 low frequency\n  WA \u2248 10 \u00d7 0.5 = 5x\n</code></pre></p> <p>Read Amplification (slot-level): <pre><code>RA_slot = L0_files + k_max\n\nFor k_max=1:\n  RA = 6 + 1 = 7 (fast)\n\nFor k_max=4:\n  RA = 6 + 4 = 10 (slower, but acceptable for cold data)\n</code></pre></p> <p>Space Amplification: <pre><code>SA_slot = 1 + (k_max - 1) / T\n\nFor k_max=1:\n  SA = 1 + 0/10 = 1.0 (no overhead)\n\nFor k_max=4:\n  SA = 1 + 3/10 = 1.3 (30% overhead)\n</code></pre></p> <p>Trade-off: Hot slots pay WA for low RA, cold slots save WA, accept higher RA</p>"},{"location":"crates/nori-lsm/design-decisions/adaptive-k-fanout/#4-workload-driven-not-assumption-driven","title":"4. Workload-Driven (Not Assumption-Driven)","text":"<p>Heat-based K adapts to actual access patterns:</p> <pre><code>Scenario 1: Recent orders hot\n  Orders (last 30d) \u2192 heat=0.9 \u2192 K=1 (fast reads)\n  Orders (&gt;1 year) \u2192 heat=0.1 \u2192 K=4 (low WA)\n\nScenario 2: Historical analytics hot\n  Orders (last 30d) \u2192 heat=0.2 \u2192 K=3 (low WA, few writes)\n  Orders (&gt;1 year) \u2192 heat=0.8 \u2192 K=1 (fast analytics queries)\n\nResult: Adapts to both scenarios without manual tuning\n</code></pre> <p>Contrast with time-based: <pre><code>Time-based assumes recent=hot, old=cold\n  \u2192 Works for Scenario 1\n  \u2192 Fails for Scenario 2\n\nHeat-based measures actual access\n  \u2192 Works for both scenarios\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/adaptive-k-fanout/#trade-offs","title":"Trade-offs","text":""},{"location":"crates/nori-lsm/design-decisions/adaptive-k-fanout/#what-we-gained","title":"What We Gained","text":"<p>1. Per-Range Optimization - Hot ranges: Low RA, fast queries - Cold ranges: Low WA, efficient writes - No global compromise</p> <p>2. Automatic Adaptation - Heat increases \u2192 K decreases (toward leveled) - Heat decreases \u2192 K increases (toward tiered) - No manual intervention</p> <p>3. Smooth Transitions - Continuous mapping (no cliff edges) - Stable K values (no thrashing) - Predictable behavior</p> <p>4. Workload Agnostic - Works for time-series, key-value, analytics - No assumptions about access patterns - Self-tuning</p>"},{"location":"crates/nori-lsm/design-decisions/adaptive-k-fanout/#what-we-gave-up","title":"What We Gave Up","text":"<p>1. Simplicity - More complex than global K=1 or K=4 - Requires heat tracking subsystem - Per-slot state management</p> <p>2. Predictability - K changes over time (not static) - Harder to reason about worst-case - Variable compaction schedules</p> <p>3. Control - Operator can't override K per slot (without code changes) - No manual \"pin this slot to K=1\" mode - Learning period before convergence</p>"},{"location":"crates/nori-lsm/design-decisions/adaptive-k-fanout/#k-max-evolution-examples","title":"K-Max Evolution Examples","text":""},{"location":"crates/nori-lsm/design-decisions/adaptive-k-fanout/#example-1-hot-slot-user-sessions","title":"Example 1: Hot Slot (User Sessions)","text":"<p>Workload: 1000 queries/sec to active user sessions</p> <pre><code>Week 1 (new slot, no history):\n  heat_score = 0.0 (default)\n  k_max = 1 + floor((1 - 0.0) \u00d7 3) = 4 (tiered initially)\n\nDay 2 (after 100K queries):\n  heat_score \u2192 0.85 (EWMA converged)\n  k_max = 1 + floor((1 - 0.85) \u00d7 3) = 1 (leveled)\n\nWeek 2 (stable workload):\n  heat_score = 0.9 (stable)\n  k_max = 1 (stable)\n  RA = 7 (fast queries)\n  WA = 20x (acceptable for hot data)\n</code></pre>"},{"location":"crates/nori-lsm/design-decisions/adaptive-k-fanout/#example-2-cold-slot-archived-data","title":"Example 2: Cold Slot (Archived Data)","text":"<p>Workload: 10 queries/day to archived orders</p> <pre><code>Week 1 (new slot):\n  heat_score = 0.0\n  k_max = 4 (tiered)\n\nWeek 2 (10 queries over 7 days):\n  heat_score \u2192 0.05 (very low)\n  k_max = 1 + floor((1 - 0.05) \u00d7 3) = 3 (tiered)\n\nMonth 1 (stable low access):\n  heat_score = 0.1 (stable)\n  k_max = 3 (stable)\n  RA = 9 (acceptable for rare queries)\n  WA = 6x (low I/O overhead)\n</code></pre>"},{"location":"crates/nori-lsm/design-decisions/adaptive-k-fanout/#example-3-workload-shift","title":"Example 3: Workload Shift","text":"<p>Scenario: Cold slot becomes hot due to analytics job</p> <pre><code>Initial state (cold):\n  heat_score = 0.1\n  k_max = 3 (tiered)\n\nAnalytics job starts (1000 queries/sec):\n  Day 1: heat_score \u2192 0.3, k_max = 3\n  Day 2: heat_score \u2192 0.5, k_max = 2\n  Day 3: heat_score \u2192 0.7, k_max = 2\n  Day 5: heat_score \u2192 0.85, k_max = 1\n\nAnalytics job completes:\n  Week 2: heat_score \u2192 0.6 (decay)\n  Week 3: heat_score \u2192 0.3, k_max = 3\n  Week 4: heat_score \u2192 0.1 (back to cold)\n\nResult: Automatically adapted to temporary workload shift\n</code></pre>"},{"location":"crates/nori-lsm/design-decisions/adaptive-k-fanout/#configuration","title":"Configuration","text":"<p>Default:</p> <pre><code>pub struct ATLLConfig {\n    /// Maximum K allowed for cold slots\n    /// Default: 4\n    /// Recommendation: 4-8 for most workloads\n    pub k_global: usize,\n}\n</code></pre> <p>Tuning guidelines:</p>"},{"location":"crates/nori-lsm/design-decisions/adaptive-k-fanout/#write-heavy-workloads","title":"Write-Heavy Workloads","text":"<pre><code>ATLLConfig {\n    k_global: 8,  // Allow colder slots to tier more aggressively\n    ..Default::default()\n}\n</code></pre> <p>Effect: - Cold slots: k_max up to 8 (very tiered) - Lower WA: 4-6x (vs 6-8x with K=4) - Higher RA: 14 (vs 10, acceptable for cold data)</p>"},{"location":"crates/nori-lsm/design-decisions/adaptive-k-fanout/#read-heavy-workloads","title":"Read-Heavy Workloads","text":"<pre><code>ATLLConfig {\n    k_global: 2,  // Limit tiering, stay closer to leveled\n    ..Default::default()\n}\n</code></pre> <p>Effect: - Cold slots: k_max up to 2 (mild tiering) - Higher WA: 10-12x (vs 6-8x with K=4) - Lower RA: 8 (vs 10, faster cold reads)</p>"},{"location":"crates/nori-lsm/design-decisions/adaptive-k-fanout/#balanced-default","title":"Balanced (Default)","text":"<pre><code>ATLLConfig {\n    k_global: 4,  // Standard balance\n    ..Default::default()\n}\n</code></pre> <p>Effect: - Hot slots: k_max=1 (leveled) - Cold slots: k_max=3-4 (tiered) - WA: 8-20x, RA: 5-12</p>"},{"location":"crates/nori-lsm/design-decisions/adaptive-k-fanout/#validation","title":"Validation","text":"<p>Benchmark results (Zipfian workload, 80/20 hot/cold):</p> <pre><code>Hot slots (20% of data, 80% of queries):\n  k_max converged to: 1\n  RA: 7\n  WA: 18x\n  p95 latency: 8.2ms\n\nCold slots (80% of data, 20% of queries):\n  k_max converged to: 3-4\n  RA: 9-10\n  WA: 6x\n  p95 latency: 15.3ms (acceptable for rare queries)\n\nOverall:\n  Weighted WA: 0.8\u00d718 + 0.2\u00d76 = 15.6x (vs 40-100x for pure leveled)\n  Weighted RA: 0.8\u00d77 + 0.2\u00d79.5 = 7.5 (vs 10-15 for pure tiered)\n</code></pre> <p>Property test: K-max convergence</p> <pre><code>#[test]\nfn test_k_max_convergence() {\n    let mut slot = Slot::new(0, vec![0x00], vec![0x40]);\n\n    // Simulate hot workload (1000 accesses)\n    for _ in 0..1000 {\n        slot.update_heat(1.0);  // Access\n    }\n\n    // After convergence\n    assert!(slot.heat_score &gt; 0.85);\n    assert_eq!(slot.k_max(), 1);  // Leveled\n\n    // Simulate workload shift (no accesses for 1000 iterations)\n    for _ in 0..1000 {\n        slot.update_heat(0.0);  // No access\n    }\n\n    // After decay\n    assert!(slot.heat_score &lt; 0.15);\n    assert!(slot.k_max() &gt;= 3);  // Tiered\n}\n</code></pre>"},{"location":"crates/nori-lsm/design-decisions/adaptive-k-fanout/#summary","title":"Summary","text":"<p>Adaptive K-way fanout per slot is the right choice because:</p> <ol> <li>RUM optimization per range - Hot slots minimize R, cold slots minimize U</li> <li>Automatic adaptation - Heat-driven, not manual configuration</li> <li>Smooth transitions - Continuous formula, no cliff edges</li> <li>Workload agnostic - Measures actual access, no assumptions</li> </ol> <p>We accept these trade-offs: - Complexity (vs global K) - Variable K over time (vs static) - Learning period before convergence</p> <p>For heterogeneous workloads (Zipfian, multi-tenant), adaptive K achieves near-Pareto-optimal performance without manual tuning.</p> <p>Last Updated: 2025-10-31 See Also: Heat Tracking, ATLL Architecture</p>"},{"location":"crates/nori-lsm/design-decisions/bandit-scheduler/","title":"Bandit Scheduler","text":"<p>Why we use epsilon-greedy multi-armed bandits with UCB for compaction scheduling instead of heuristics or round-robin.</p>"},{"location":"crates/nori-lsm/design-decisions/bandit-scheduler/#decision","title":"Decision","text":"<p>Use epsilon-greedy multi-armed bandit with Upper Confidence Bound (UCB) to select which slot to compact:</p> <pre><code>pub struct BanditScheduler {\n    arms: Vec&lt;BanditArm&gt;,  // One arm per slot\n    epsilon: f64,          // Exploration rate (default: 0.1)\n    ucb_c: f64,            // Exploration constant (default: 2.0)\n}\n\npub struct BanditArm {\n    slot_id: u32,\n    avg_reward: f64,        // EMA of historical rewards\n    selection_count: u64,   // Times this slot was selected\n}\n\nimpl BanditScheduler {\n    pub fn select_slot(&amp;mut self) -&gt; u32 {\n        if random() &lt; self.epsilon {\n            // Exploration: random slot\n            random_slot()\n        } else {\n            // Exploitation: best UCB score\n            argmax(|arm| arm.ucb_score(self.total_selections()))\n        }\n    }\n}\n\nimpl BanditArm {\n    pub fn ucb_score(&amp;self, total_selections: u64) -&gt; f64 {\n        self.avg_reward + self.ucb_c * sqrt(ln(total_selections) / self.selection_count)\n        // \u2514\u2500exploitation\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500exploration bonus\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    }\n}\n</code></pre> <p>Reward function: <pre><code>reward = (predicted_latency_reduction \u00d7 heat_score) / bytes_written\n</code></pre></p> <p>Parameters: - \u03b5 (epsilon) = 0.1 (10% exploration, 90% exploitation) - c (UCB constant) = 2.0 (standard value from bandit literature) - \u03b1 (reward EMA) = 0.1 (smoothing factor)</p>"},{"location":"crates/nori-lsm/design-decisions/bandit-scheduler/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"crates/nori-lsm/design-decisions/bandit-scheduler/#1-round-robin","title":"1. Round-Robin","text":"<p>Approach: Compact slots in order (0 \u2192 1 \u2192 2 \u2192 ... \u2192 N \u2192 0)</p> <pre><code>pub fn select_slot(&amp;mut self) -&gt; u32 {\n    let slot = self.current_slot;\n    self.current_slot = (self.current_slot + 1) % self.num_slots;\n    slot\n}\n</code></pre> <p>Rejected because: - Ignores heat: Hot/cold treated equally - Wasteful: Compacts cold slots unnecessarily - Inflexible: No adaptation to workload - High WA: Compact everything regardless of benefit</p> <p>Example problem: <pre><code>Slots:\n  0-3: Hot (1000 queries/sec each)\n  4-63: Cold (1 query/day each)\n\nRound-robin:\n  Compacts all 64 slots equally\n  60/64 = 94% of compactions are wasted (on cold data)\n\nBandit:\n  Learns to compact slots 0-3 frequently, 4-63 rarely\n  &gt;90% of compactions focus on hot slots\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/bandit-scheduler/#2-priority-queue-largest-first","title":"2. Priority Queue (Largest First)","text":"<p>Approach: Compact largest slots first</p> <pre><code>pub fn select_slot(&amp;mut self) -&gt; u32 {\n    self.slots\n        .iter()\n        .max_by_key(|s| s.total_size())\n        .unwrap()\n        .slot_id\n}\n</code></pre> <p>Rejected because: - Size \u2260 benefit: Large cold slot has low read benefit - Ignores heat: Doesn't consider access frequency - Starvation: Small hot slots never compacted - No learning: Static heuristic</p> <p>Example problem: <pre><code>Slot 0: 10 MB, heat=0.9 (hot, small)\nSlot 1: 1 GB, heat=0.1 (cold, large)\n\nPriority queue: Always compacts Slot 1 (large)\n  Benefit: Low (rarely queried)\n  Cost: High (1 GB rewrite)\n\nBandit: Learns to compact Slot 0 (high reward/byte)\n  Benefit: High (frequently queried)\n  Cost: Low (10 MB rewrite)\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/bandit-scheduler/#3-age-based-oldest-runs-first","title":"3. Age-Based (Oldest Runs First)","text":"<p>Approach: Compact slot with oldest run</p> <pre><code>pub fn select_slot(&amp;mut self) -&gt; u32 {\n    self.slots\n        .iter()\n        .max_by_key(|s| s.oldest_run_age())\n        .unwrap()\n        .slot_id\n}\n</code></pre> <p>Rejected because: - Age \u2260 benefit: Old cold data doesn't benefit from compaction - Ignores heat: Doesn't consider query patterns - Predictable: No exploration of new strategies - No optimization: Just a heuristic</p>"},{"location":"crates/nori-lsm/design-decisions/bandit-scheduler/#4-thompson-sampling","title":"4. Thompson Sampling","text":"<p>Approach: Bayesian bandit algorithm</p> <pre><code>pub struct BanditArm {\n    alpha: f64,  // Success count (Beta distribution)\n    beta: f64,   // Failure count\n}\n\npub fn select_slot(&amp;mut self) -&gt; u32 {\n    // Sample from Beta distribution for each arm\n    let samples: Vec&lt;f64&gt; = self.arms\n        .iter()\n        .map(|arm| sample_beta(arm.alpha, arm.beta))\n        .collect();\n\n    argmax(samples)\n}\n</code></pre> <p>Rejected because: - More complex: Beta distributions, sampling - Unclear reward mapping: How to map compaction reward to success/failure? - Implementation overhead: Beta distribution sampling - Epsilon-greedy is sufficient: Proven to work for non-stationary environments</p> <p>Decision: May revisit for future optimization, but epsilon-greedy is simpler and sufficient</p>"},{"location":"crates/nori-lsm/design-decisions/bandit-scheduler/#5-contextual-bandits","title":"5. Contextual Bandits","text":"<p>Approach: Use system state as context</p> <pre><code>pub struct Context {\n    l0_file_count: usize,\n    memory_pressure: f32,\n    recent_query_latency: f64,\n}\n\npub fn select_slot(&amp;mut self, context: &amp;Context) -&gt; u32 {\n    // Learn reward function: f(slot, context) \u2192 reward\n    self.model.predict(slot, context)\n}\n</code></pre> <p>Rejected for now because: - Much more complex: Requires feature engineering, model training - Data requirements: Need large dataset to train model - Unclear benefit: Simple bandits may be sufficient - Future work: Promising direction for optimization</p>"},{"location":"crates/nori-lsm/design-decisions/bandit-scheduler/#rationale","title":"Rationale","text":""},{"location":"crates/nori-lsm/design-decisions/bandit-scheduler/#1-exploration-vs-exploitation","title":"1. Exploration vs Exploitation","text":"<p>Multi-armed bandit problem: Balance trying new actions (exploration) vs using known-good actions (exploitation)</p> <p>Epsilon-greedy solution: <pre><code>With probability \u03b5 (0.1):\n  \u2192 Exploration: Try random slot\n  \u2192 Benefit: Discover better strategies\n  \u2192 Cost: 10% suboptimal compactions\n\nWith probability 1-\u03b5 (0.9):\n  \u2192 Exploitation: Choose best UCB score\n  \u2192 Benefit: Use known-good strategy\n  \u2192 Cost: May miss better strategies\n</code></pre></p> <p>Why 10% exploration? - Standard value in bandit literature - Balances learning vs performance - Non-stationary environments (workloads change) need exploration - Validated through benchmarks</p> <p>Example: <pre><code>1000 compaction decisions:\n  100 are random (exploration)\n  900 use best UCB score (exploitation)\n\nResult:\n  Learn about all slots (avoid starvation)\n  Mostly compact high-reward slots (good performance)\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/bandit-scheduler/#2-ucb-exploration-bonus","title":"2. UCB Exploration Bonus","text":"<p>Upper Confidence Bound formula: <pre><code>ucb_score = avg_reward + c \u00d7 sqrt(ln(total_selections) / arm_selections)\n            \u2514\u2500exploitation\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500exploration bonus\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>Exploration bonus properties: - Large when rarely selected: Encourages trying less-explored slots - Small when frequently selected: Don't over-explore well-known slots - Grows with total_selections: More data \u2192 more confidence in exploration - Theoretical regret bounds: O(K \u00d7 log T) regret over T selections</p> <p>Example: <pre><code>Slot 0 (hot, frequently compacted):\n  avg_reward = 8.5\n  selections = 900\n  total = 1000\n\n  ucb_score = 8.5 + 2.0 \u00d7 sqrt(ln(1000) / 900)\n            = 8.5 + 2.0 \u00d7 sqrt(6.9 / 900)\n            = 8.5 + 2.0 \u00d7 0.088\n            = 8.68\n\nSlot 1 (cold, rarely compacted):\n  avg_reward = 2.0\n  selections = 10\n  total = 1000\n\n  ucb_score = 2.0 + 2.0 \u00d7 sqrt(ln(1000) / 10)\n            = 2.0 + 2.0 \u00d7 sqrt(6.9 / 10)\n            = 2.0 + 2.0 \u00d7 0.831\n            = 3.66\n\nDecision: Compact Slot 0 (higher UCB score)\n  But Slot 1 gets exploration bonus (not starved)\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/bandit-scheduler/#3-reward-function-design","title":"3. Reward Function Design","text":"<p>Formula: <pre><code>reward = (predicted_latency_reduction \u00d7 heat_score) / bytes_written\n</code></pre></p> <p>Components:</p> <p>1. Predicted Latency Reduction: <pre><code>fn predicted_latency_reduction(slot: &amp;Slot) -&gt; f64 {\n    // Assume each run adds 100\u00b5s to query latency\n    let current_latency = slot.runs.len() as f64 * 100.0;\n\n    // After compaction to k_max, latency reduces\n    let target_latency = slot.k_max as f64 * 100.0;\n\n    current_latency - target_latency\n}\n</code></pre></p> <p>2. Heat Score: Weight by access frequency <pre><code>heat_score \u2208 [0.0, 1.0]  // From EWMA tracking\n</code></pre></p> <p>3. Bytes Written: Cost of compaction <pre><code>bytes_written = total_size_of_runs_to_merge\n</code></pre></p> <p>Intuition: - High reward: Hot slots with high RA (good targets for leveling) - Low reward: Cold slots with low RA (avoid unnecessary compaction) - Normalized by cost: Prefer cheap compactions over expensive ones</p> <p>Example: <pre><code>Slot 0 (hot, 4 runs, 10 MB each):\n  latency_reduction = (4 - 1) \u00d7 100\u00b5s = 300\u00b5s\n  heat_score = 0.9\n  bytes_written = 40 MB\n\n  reward = (300 \u00d7 0.9) / 40\n         = 270 / 40\n         = 6.75\n\nSlot 1 (cold, 4 runs, 100 MB each):\n  latency_reduction = (4 - 3) \u00d7 100\u00b5s = 100\u00b5s (k_max=3 for cold)\n  heat_score = 0.1\n  bytes_written = 400 MB\n\n  reward = (100 \u00d7 0.1) / 400\n         = 10 / 400\n         = 0.025\n\nDecision: Compact Slot 0 (270\u00d7 higher reward)\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/bandit-scheduler/#4-non-stationary-environment","title":"4. Non-Stationary Environment","text":"<p>Workloads change over time: <pre><code>Week 1: Slots 0-3 hot (user traffic)\nWeek 2: Slots 10-13 hot (analytics job)\nWeek 3: Slots 0-3 hot again (back to normal)\n</code></pre></p> <p>Epsilon-greedy adapts: - Exploration: Discovers new hot slots (Week 2) - EMA rewards: Recent rewards weigh more (forgets old patterns) - UCB bonus: Encourages trying previously-cold slots</p> <p>Contrast with static heuristics: <pre><code>Priority queue (largest first):\n  Week 1: Compacts same large slots\n  Week 2: Still compacts same large slots (misses new hot slots)\n  Week 3: Still compacts same large slots\n\nBandit:\n  Week 1: Learns Slots 0-3 are best\n  Week 2: Explores, discovers Slots 10-13 are better\n  Week 3: Re-learns Slots 0-3 (EMA forgets Week 2)\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/bandit-scheduler/#mathematical-guarantees","title":"Mathematical Guarantees","text":""},{"location":"crates/nori-lsm/design-decisions/bandit-scheduler/#regret-bound-ucb","title":"Regret Bound (UCB)","text":"<p>Regret: Cumulative difference between optimal and actual rewards</p> <pre><code>Regret_T = \u03a3(reward_optimal - reward_actual)\n\nUCB guarantee:\n  Regret_T \u2264 O(K \u00d7 log T)\n\nWhere:\n  K = number of arms (slots)\n  T = total selections\n</code></pre> <p>Interpretation: <pre><code>For 16 slots, 1000 compactions:\n  Regret \u2264 16 \u00d7 log(1000)\n         \u2248 16 \u00d7 6.9\n         \u2248 110 suboptimal decisions\n\nEfficiency: 890/1000 = 89% optimal (after warmup)\n</code></pre></p> <p>Practical implication: Bandit converges to near-optimal strategy</p>"},{"location":"crates/nori-lsm/design-decisions/bandit-scheduler/#convergence-rate","title":"Convergence Rate","text":"<p>EMA reward tracking: <pre><code>avg_reward_t = \u03b1 \u00d7 reward_t + (1-\u03b1) \u00d7 avg_reward_{t-1}\n\nConvergence: 10-20 selections per slot\n\nExample (\u03b1=0.1):\n  After 10 selections: 65% of steady state\n  After 20 selections: 88% of steady state\n  After 30 selections: 96% of steady state\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/bandit-scheduler/#trade-offs","title":"Trade-offs","text":""},{"location":"crates/nori-lsm/design-decisions/bandit-scheduler/#what-we-gained","title":"What We Gained","text":"<p>1. Automatic Optimization - Learns which slots benefit most from compaction - Adapts to workload changes - No manual tuning required</p> <p>2. Theoretical Guarantees - O(log T) regret bound (UCB) - Converges to near-optimal policy - Proven in bandit literature</p> <p>3. Flexible - Works for any workload (time-series, key-value, analytics) - Adapts to non-stationary environments - Handles heterogeneous slots</p> <p>4. Observable - Emit BanditSelection and BanditReward events - Monitor exploration rate, rewards, UCB scores - Debug suboptimal behavior</p>"},{"location":"crates/nori-lsm/design-decisions/bandit-scheduler/#what-we-gave-up","title":"What We Gave Up","text":"<p>1. Predictability - 10% of compactions are random (exploration) - Slot selection varies over time (not deterministic) - Harder to reason about worst-case</p> <p>2. Simplicity - More complex than round-robin or priority queue - Requires reward function design - Per-slot state management (EMA, counts)</p> <p>3. Warmup Period - First 10-20 compactions per slot are learning - Suboptimal during warmup - Need ~16 \u00d7 20 = 320 compactions to warm up all slots</p>"},{"location":"crates/nori-lsm/design-decisions/bandit-scheduler/#configuration","title":"Configuration","text":"<pre><code>pub struct ATLLConfig {\n    /// Epsilon (exploration rate)\n    /// Default: 0.1 (10% exploration)\n    /// Range: 0.01 - 0.5\n    pub compaction_epsilon: f64,\n\n    /// UCB exploration constant\n    /// Default: 2.0 (standard value)\n    /// Range: 1.0 - 4.0\n    pub compaction_ucb_c: f64,\n\n    /// Reward EMA smoothing factor\n    /// Default: 0.1\n    /// Range: 0.01 - 0.5\n    pub compaction_reward_alpha: f64,\n}\n</code></pre> <p>Tuning guidelines:</p> <p>Rapidly changing workloads: <pre><code>ATLLConfig {\n    compaction_epsilon: 0.15,      // More exploration\n    compaction_ucb_c: 2.5,         // Higher exploration bonus\n    compaction_reward_alpha: 0.2,  // Faster adaptation\n    ..Default::default()\n}\n</code></pre></p> <p>Stable workloads: <pre><code>ATLLConfig {\n    compaction_epsilon: 0.05,      // Less exploration\n    compaction_ucb_c: 1.5,         // Lower exploration bonus\n    compaction_reward_alpha: 0.05, // Slower, smoother adaptation\n    ..Default::default()\n}\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/bandit-scheduler/#observability","title":"Observability","text":"<p>VizEvent emissions:</p> <p>1. BanditSelection (when slot is selected): <pre><code>pub struct BanditSelection {\n    pub slot_id: u32,\n    pub explored: bool,         // true = exploration, false = exploitation\n    pub ucb_score: f64,\n    pub avg_reward: f64,\n    pub selection_count: u64,\n}\n</code></pre></p> <p>2. BanditReward (after compaction completes): <pre><code>pub struct BanditReward {\n    pub slot_id: u32,\n    pub reward: f64,\n    pub bytes_written: u64,\n    pub heat_score: f32,\n}\n</code></pre></p> <p>Dashboard queries: <pre><code>-- Exploration rate (should be ~10%)\nSELECT\n  SUM(CASE WHEN explored THEN 1 ELSE 0 END) / COUNT(*) AS exploration_rate\nFROM bandit_selection;\n\n-- Top slots by reward\nSELECT slot_id, AVG(reward) AS avg_reward, COUNT(*) AS selections\nFROM bandit_reward\nGROUP BY slot_id\nORDER BY avg_reward DESC;\n\n-- UCB score distribution\nSELECT\n  slot_id,\n  AVG(ucb_score) AS avg_ucb,\n  MAX(ucb_score) AS max_ucb\nFROM bandit_selection\nGROUP BY slot_id;\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/bandit-scheduler/#validation","title":"Validation","text":"<p>Benchmark results (Zipfian workload):</p> <pre><code>Slots 0-3 (hot, 80% of queries):\n  Selections: 720/1000 (72%)\n  Avg reward: 8.2\n  Compaction frequency: High\n\nSlots 4-15 (cold, 20% of queries):\n  Selections: 280/1000 (28%)\n  Avg reward: 1.5\n  Compaction frequency: Low\n\nExploration rate: 98/1000 (9.8%)\n  \u2248 10% (as expected)\n\nResult: Bandit correctly learned hot slots\n</code></pre> <p>Property test: Reward convergence <pre><code>#[test]\nfn test_bandit_reward_convergence() {\n    let mut scheduler = BanditScheduler::new(16);\n\n    // Simulate compactions with known rewards\n    for _ in 0..100 {\n        let slot = scheduler.select_slot();\n        let reward = if slot &lt; 4 { 8.0 } else { 2.0 };\n        scheduler.update_reward(slot, reward);\n    }\n\n    // After convergence\n    assert!(scheduler.avg_reward(0) &gt; 7.0);  // Hot slot\n    assert!(scheduler.avg_reward(5) &lt; 3.0);  // Cold slot\n}\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/bandit-scheduler/#future-enhancements","title":"Future Enhancements","text":""},{"location":"crates/nori-lsm/design-decisions/bandit-scheduler/#1-contextual-bandits","title":"1. Contextual Bandits","text":"<p>Idea: Use system state as features</p> <pre><code>pub struct Context {\n    l0_file_count: usize,\n    memory_pressure: f32,\n    recent_p95_latency: f64,\n}\n\npub fn select_slot(&amp;mut self, context: &amp;Context) -&gt; u32 {\n    // Learn: reward = f(slot, l0_count, pressure, latency)\n    self.model.predict_best_slot(context)\n}\n</code></pre> <p>Benefit: More informed decisions based on system state</p>"},{"location":"crates/nori-lsm/design-decisions/bandit-scheduler/#2-thompson-sampling","title":"2. Thompson Sampling","text":"<p>Idea: Bayesian alternative to epsilon-greedy</p> <p>Benefit: More principled exploration (better regret bounds in some scenarios)</p>"},{"location":"crates/nori-lsm/design-decisions/bandit-scheduler/#3-adaptive-epsilon","title":"3. Adaptive Epsilon","text":"<p>Idea: Adjust \u03b5 based on reward variance</p> <pre><code>pub fn adaptive_epsilon(&amp;self) -&gt; f64 {\n    let variance = self.compute_reward_variance();\n\n    if variance &gt; 0.5 {\n        0.2  // High variance \u2192 more exploration\n    } else {\n        0.05  // Low variance \u2192 less exploration\n    }\n}\n</code></pre>"},{"location":"crates/nori-lsm/design-decisions/bandit-scheduler/#summary","title":"Summary","text":"<p>Epsilon-greedy multi-armed bandit with UCB is the right choice because:</p> <ol> <li>Balances exploration vs exploitation (\u03b5=0.1)</li> <li>Theoretical guarantees (O(log T) regret bound)</li> <li>Adapts to workload changes (non-stationary environments)</li> <li>Observable (BanditSelection/BanditReward events)</li> <li>Proven (standard technique in reinforcement learning)</li> </ol> <p>We accept these trade-offs: - 10% exploration overhead (suboptimal compactions) - Warmup period (first ~300 compactions are learning) - Complexity (vs simple round-robin)</p> <p>For heterogeneous workloads with changing access patterns, the bandit scheduler automatically learns to focus compaction effort where it provides the most benefit.</p> <p>Last Updated: 2025-10-31 See Also: Heat Tracking, Adaptive K-Way Fanout References: Auer et al. (UCB, 2002), Sutton &amp; Barto (Reinforcement Learning, 2018)</p>"},{"location":"crates/nori-lsm/design-decisions/guard-based-partitioning/","title":"Guard-Based Partitioning","text":"<p>Why ATLL uses fixed guard keys for range partitioning instead of dynamic splitting.</p>"},{"location":"crates/nori-lsm/design-decisions/guard-based-partitioning/#decision","title":"Decision","text":"<p>Use fixed guard keys to partition the key space into slots (range shards) with stable boundaries.</p> <p>Each slot has: <pre><code>pub struct Slot {\n    slot_id: u32,\n    guard_key_min: Vec&lt;u8&gt;,  // Inclusive lower bound (fixed)\n    guard_key_max: Vec&lt;u8&gt;,  // Exclusive upper bound (fixed)\n    runs: Vec&lt;SortedRun&gt;,    // K-way fanout (adaptive)\n    k_max: usize,            // Dynamic, based on heat\n    heat_score: f32,         // EWMA of access frequency\n}\n</code></pre></p> <p>Invariants: 1. No gaps: Every key falls into exactly one slot 2. No overlaps: <code>slot[i].guard_key_max = slot[i+1].guard_key_min</code> 3. Stable: Guard keys never change (except manual rebalancing)</p>"},{"location":"crates/nori-lsm/design-decisions/guard-based-partitioning/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"crates/nori-lsm/design-decisions/guard-based-partitioning/#1-dynamic-range-splitting-b-tree-style","title":"1. Dynamic Range Splitting (B-Tree Style)","text":"<p>Approach: Split ranges when they grow too large, merge when too small</p> <pre><code>Initial:\n  Slot 0: [0x00, \u221e)\n\nAfter 100K writes to [a..z]:\n  Split into:\n    Slot 0: [0x00, 0x80)  (first half)\n    Slot 1: [0x80, \u221e)     (second half)\n\nAfter more writes:\n  Split Slot 0 into:\n    Slot 0: [0x00, 0x40)\n    Slot 2: [0x40, 0x80)\n</code></pre> <p>Rejected because: - Complex recovery: Manifest must track dynamic splits/merges - Unpredictable routing: Key \u2192 slot mapping changes over time - Cascading updates: Split affects neighboring slots - Learning disruption: Bandit scheduler loses history on split</p> <p>Trade-off: Better load balancing vs stability</p>"},{"location":"crates/nori-lsm/design-decisions/guard-based-partitioning/#2-hash-based-partitioning","title":"2. Hash-Based Partitioning","text":"<p>Approach: Hash key to determine slot</p> <pre><code>fn key_to_slot(key: &amp;[u8], num_slots: u32) -&gt; u32 {\n    let hash = xxhash64(key, seed: 0);\n    (hash % num_slots) as u32\n}\n</code></pre> <p>Rejected because: - No range queries: Cannot efficiently scan [start, end) - Poor locality: Adjacent keys land in different slots - No compaction optimization: Can't compact range subsets - Bloom filter inefficiency: Must check all slots for range scan</p> <p>Trade-off: Perfect load balancing vs range query support</p>"},{"location":"crates/nori-lsm/design-decisions/guard-based-partitioning/#3-time-window-bucketing-scylladb-ics","title":"3. Time-Window Bucketing (ScyllaDB ICS)","text":"<p>Approach: Partition by time, not key</p> <pre><code>Recent data (last 1 hour):   Slot 0 (leveled, K=1)\nLast 24 hours:                Slot 1 (hybrid, K=2)\nLast 30 days:                 Slot 2 (tiered, K=4)\nOlder than 30 days:           Slot 3 (tiered, K=8)\n</code></pre> <p>Rejected because: - Assumes time-series: Not general-purpose - Requires timestamp extraction: Key format dependency - Manual configuration: Window sizes need tuning - Access pattern mismatch: Recent \u2260 hot (many workloads)</p> <p>Trade-off: Optimized for time-series vs general key-value</p>"},{"location":"crates/nori-lsm/design-decisions/guard-based-partitioning/#4-no-partitioning-global-compaction","title":"4. No Partitioning (Global Compaction)","text":"<p>Approach: All data in one level (like traditional LSM)</p> <pre><code>L0: Overlapping files\nL1: Single sorted run (entire key space)\nL2: Single sorted run (entire key space)\n...\n</code></pre> <p>Rejected because: - No per-range adaptation: Hot/cold treated identically - Serial compaction: Can't parallelize across ranges - Large compaction jobs: Merge entire level (slow) - No RUM optimization: Global trade-off (not per-range)</p> <p>Trade-off: Simplicity vs adaptive performance</p>"},{"location":"crates/nori-lsm/design-decisions/guard-based-partitioning/#rationale","title":"Rationale","text":""},{"location":"crates/nori-lsm/design-decisions/guard-based-partitioning/#1-predictable-routing","title":"1. Predictable Routing","text":"<p>Fixed boundaries enable deterministic mapping:</p> <pre><code>fn find_slot_for_key(&amp;self, key: &amp;[u8]) -&gt; u32 {\n    // Binary search on guard keys (O(log num_slots))\n    self.slots\n        .binary_search_by(|slot| {\n            if key &lt; slot.guard_key_min {\n                Ordering::Greater\n            } else if key &gt;= slot.guard_key_max {\n                Ordering::Less\n            } else {\n                Ordering::Equal\n            }\n        })\n        .unwrap()\n}\n</code></pre> <p>Benefits: - Constant-time routing (after binary search) - Same key \u2192 same slot (always) - No routing table (guard keys stored once in manifest) - Cache-friendly (predictable access patterns)</p> <p>Example: <pre><code>Query: get(\"user:12345\")\n\nGuard keys:\n  Slot 0: [0x00, 0x40)\n  Slot 1: [0x40, 0x80)\n  Slot 2: [0x80, 0xC0)\n  Slot 3: [0xC0, \u221e)\n\n\"user:12345\" \u2192 0x75... (hash prefix)\nBinary search: 0x40 \u2264 0x75 &lt; 0x80\nResult: Slot 1 (always)\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/guard-based-partitioning/#2-simple-recovery","title":"2. Simple Recovery","text":"<p>Manifest format: <pre><code>pub struct Manifest {\n    slots: Vec&lt;SlotMetadata&gt;,\n}\n\npub struct SlotMetadata {\n    slot_id: u32,\n    guard_key_min: Vec&lt;u8&gt;,\n    guard_key_max: Vec&lt;u8&gt;,\n    runs: Vec&lt;RunMetadata&gt;,  // SSTable file paths\n}\n</code></pre></p> <p>On crash: 1. Read manifest (guard keys + SSTable list) 2. Reconstruct slots (no dynamic state to rebuild) 3. Resume compaction (bandit state resets, learns quickly)</p> <p>Contrast with dynamic splitting: <pre><code>// Dynamic system would need:\npub struct Manifest {\n    split_history: Vec&lt;SplitEvent&gt;,  // When/how slots split\n    merge_history: Vec&lt;MergeEvent&gt;,  // When/how slots merged\n    current_boundaries: Vec&lt;(Vec&lt;u8&gt;, Vec&lt;u8&gt;)&gt;,  // Rebuild from history\n}\n</code></pre></p> <p>Complexity: Fixed guard keys \u2192 simple manifest format</p>"},{"location":"crates/nori-lsm/design-decisions/guard-based-partitioning/#3-stable-boundaries-for-learning","title":"3. Stable Boundaries for Learning","text":"<p>Bandit scheduler tracks per-slot rewards:</p> <pre><code>pub struct BanditArm {\n    slot_id: u32,\n    avg_reward: f64,         // EMA of historical rewards\n    selection_count: u64,    // Times this slot was compacted\n}\n</code></pre> <p>Fixed boundaries enable: - Cumulative learning: Slot 0 today = Slot 0 tomorrow - Reward convergence: EMA stabilizes over 10-20 selections - UCB score accuracy: Exploration bonus based on selection count</p> <p>Contrast with dynamic splitting: <pre><code>Initial:\n  Slot 0: [a..z], compacted 100 times, avg_reward = 8.5\n\nAfter split:\n  Slot 0: [a..m], compacted 0 times (reset!)\n  Slot 1: [m..z], compacted 0 times (reset!)\n\nProblem: Lost 100 compactions worth of learning\n</code></pre></p> <p>Benefit: Stable boundaries preserve learned behavior</p>"},{"location":"crates/nori-lsm/design-decisions/guard-based-partitioning/#4-range-query-locality","title":"4. Range Query Locality","text":"<p>Range queries benefit from contiguous slots:</p> <pre><code>async fn scan(&amp;self, start: &amp;[u8], end: &amp;[u8]) -&gt; Result&lt;Vec&lt;(Vec&lt;u8&gt;, Vec&lt;u8&gt;)&gt;&gt; {\n    // Find slots overlapping [start, end)\n    let start_slot = self.find_slot_for_key(start);\n    let end_slot = self.find_slot_for_key(end);\n\n    // Scan contiguous slot range\n    for slot_id in start_slot..=end_slot {\n        // Merge iterators from slot's runs\n    }\n}\n</code></pre> <p>Example: <pre><code>Query: scan(\"user:\", \"user:~\")\n\nGuard keys:\n  Slot 0: [0x00, 0x40)  (not users)\n  Slot 1: [0x40, 0x80)  (users a-m)\n  Slot 2: [0x80, 0xC0)  (users n-z)\n  Slot 3: [0xC0, \u221e)     (not users)\n\nResult: Scan slots 1-2 only (skip 0, 3)\n</code></pre></p> <p>Contrast with hash partitioning: <pre><code>With hash:\n  Must scan all 16 slots (no locality)\n  10x more I/O for range queries\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/guard-based-partitioning/#trade-offs","title":"Trade-offs","text":""},{"location":"crates/nori-lsm/design-decisions/guard-based-partitioning/#what-we-gained","title":"What We Gained","text":"<p>1. Predictability - Same key always routes to same slot - No surprise routing changes - Deterministic recovery</p> <p>2. Simplicity - Manifest stores guard keys once - No split/merge history tracking - Binary search for routing</p> <p>3. Learning Stability - Bandit scheduler accumulates knowledge - Reward convergence guaranteed - No learning resets</p> <p>4. Range Query Efficiency - Scan contiguous slots - Skip irrelevant ranges - Locality benefits</p>"},{"location":"crates/nori-lsm/design-decisions/guard-based-partitioning/#what-we-gave-up","title":"What We Gave Up","text":"<p>1. Load Balancing - Skewed writes create imbalanced slots - No automatic rebalancing - Manual intervention needed for severe skew</p> <p>2. Storage Overhead - Small slots waste space (metadata overhead) - Large slots slow compaction (merge entire range) - Fixed granularity (can't adjust dynamically)</p> <p>3. Flexibility - Can't optimize per-workload (time-series, geo, etc.) - Guard keys hardcoded (not configurable at runtime) - Rebalancing requires data migration</p>"},{"location":"crates/nori-lsm/design-decisions/guard-based-partitioning/#guard-key-selection-strategies","title":"Guard Key Selection Strategies","text":""},{"location":"crates/nori-lsm/design-decisions/guard-based-partitioning/#uniform-split-default","title":"Uniform Split (Default)","text":"<p>Approach: Divide key space evenly</p> <pre><code>fn uniform_guard_keys(num_slots: u32) -&gt; Vec&lt;Vec&lt;u8&gt;&gt; {\n    let mut guards = vec![];\n    let step = 256 / num_slots;\n\n    for i in 0..num_slots {\n        guards.push(vec![(i * step) as u8]);\n    }\n\n    guards.push(vec![0xFF]);  // Final boundary\n    guards\n}\n</code></pre> <p>Example (16 slots): <pre><code>Slot 0:  [0x00, 0x10)\nSlot 1:  [0x10, 0x20)\n...\nSlot 15: [0xF0, 0xFF]\n</code></pre></p> <p>Pros: - Simple implementation - Predictable boundaries - No sampling required</p> <p>Cons: - Assumes uniform key distribution - Skewed workloads create imbalance - No adaptation to actual data</p>"},{"location":"crates/nori-lsm/design-decisions/guard-based-partitioning/#data-driven-split-future","title":"Data-Driven Split (Future)","text":"<p>Approach: Sample existing data, split by size</p> <pre><code>async fn data_driven_guard_keys(num_slots: u32) -&gt; Vec&lt;Vec&lt;u8&gt;&gt; {\n    // 1. Sample 10K random keys\n    let samples = self.sample_keys(10_000).await?;\n\n    // 2. Sort samples\n    samples.sort();\n\n    // 3. Choose percentile boundaries\n    let mut guards = vec![];\n    for i in 0..num_slots {\n        let percentile = (i as f64) / (num_slots as f64);\n        let idx = (percentile * samples.len() as f64) as usize;\n        guards.push(samples[idx].clone());\n    }\n\n    guards\n}\n</code></pre> <p>Pros: - Balanced slot sizes - Adapts to actual key distribution - Better for skewed workloads</p> <p>Cons: - Requires sampling (slow on startup) - Changes with data (not stable) - Complex recovery (must resample)</p>"},{"location":"crates/nori-lsm/design-decisions/guard-based-partitioning/#workload-specific-scylladb","title":"Workload-Specific (ScyllaDB)","text":"<p>Approach: Partition by semantic meaning</p> <pre><code>// Time-series workload\nSlot 0: timestamps [0, 3600)        (last hour)\nSlot 1: timestamps [3600, 86400)    (last day)\nSlot 2: timestamps [86400, 2592000) (last 30 days)\nSlot 3: timestamps [2592000, \u221e)     (older)\n\n// Geo workload\nSlot 0: latitude [-90, -45)  (southern hemisphere)\nSlot 1: latitude [-45, 0)    (southern temperate)\nSlot 2: latitude [0, 45)     (northern temperate)\nSlot 3: latitude [45, 90]    (northern hemisphere)\n</code></pre> <p>Pros: - Optimized for specific use case - Aligns with query patterns - Domain knowledge encoded</p> <p>Cons: - Not general-purpose - Requires workload analysis - Brittle (breaks if assumptions change)</p> <p>Decision: Use uniform split by default, allow override via configuration</p>"},{"location":"crates/nori-lsm/design-decisions/guard-based-partitioning/#rebalancing-strategy-future-work","title":"Rebalancing Strategy (Future Work)","text":"<p>Problem: Skewed writes create imbalanced slots</p> <pre><code>After 1M writes to \"user:\" prefix:\n\nSlot 0 [0x00, 0x40):  100 MB   (cold, few writes)\nSlot 1 [0x40, 0x80):  5 GB     (hot, many writes to \"user:\")\nSlot 2 [0x80, 0xC0):  200 MB   (cold)\nSlot 3 [0xC0, \u221e):     150 MB   (cold)\n\nProblem: Slot 1 is 50x larger than others\n</code></pre> <p>Proposed Solution: Periodic rebalancing</p> <pre><code>async fn rebalance_slots(&amp;mut self) -&gt; Result&lt;()&gt; {\n    // 1. Identify imbalanced slots (size &gt; 2\u00d7 median)\n    let median_size = self.median_slot_size();\n    let large_slots: Vec&lt;u32&gt; = self.slots\n        .iter()\n        .filter(|s| s.total_size() &gt; median_size * 2)\n        .map(|s| s.slot_id)\n        .collect();\n\n    // 2. For each large slot, split into two\n    for slot_id in large_slots {\n        let mid_key = self.find_median_key(slot_id).await?;\n        self.split_slot(slot_id, mid_key).await?;\n    }\n\n    // 3. Update manifest with new guard keys\n    self.manifest.update_guard_keys(&amp;self.slots).await?;\n\n    Ok(())\n}\n</code></pre> <p>Trade-off: - Benefit: Balanced slot sizes, better parallelism - Cost: Data migration, learning reset, complex implementation</p> <p>Status: Not implemented (manual rebalancing via configuration)</p>"},{"location":"crates/nori-lsm/design-decisions/guard-based-partitioning/#configuration","title":"Configuration","text":"<p>Default configuration:</p> <pre><code>pub struct ATLLConfig {\n    /// Number of range-partitioned slots\n    /// Default: 16\n    /// Recommendation: 16-64 for most workloads\n    pub num_slots: u32,\n\n    /// Guard key selection strategy\n    /// Default: Uniform split\n    pub guard_key_strategy: GuardKeyStrategy,\n}\n\npub enum GuardKeyStrategy {\n    /// Evenly divide key space (default)\n    Uniform,\n\n    /// Sample existing data, split by size (future)\n    DataDriven,\n\n    /// Manual guard keys (expert mode)\n    Manual(Vec&lt;Vec&lt;u8&gt;&gt;),\n}\n</code></pre> <p>Tuning guidelines:</p> <p>Small datasets (&lt;1 GB): <pre><code>ATLLConfig {\n    num_slots: 8,  // Lower overhead\n    ..Default::default()\n}\n</code></pre></p> <p>Large datasets (&gt;100 GB): <pre><code>ATLLConfig {\n    num_slots: 64,  // Finer granularity\n    ..Default::default()\n}\n</code></pre></p> <p>Skewed workloads: <pre><code>// Option 1: More slots (finer partitioning)\nATLLConfig {\n    num_slots: 128,\n    ..Default::default()\n}\n\n// Option 2: Manual guard keys (expert mode)\nATLLConfig {\n    guard_key_strategy: GuardKeyStrategy::Manual(vec![\n        vec![0x00],\n        vec![0x30],  // Split hot range finer\n        vec![0x40],\n        vec![0x50],\n        vec![0x60],  // Hot range ends\n        vec![0x80],\n        vec![0xC0],\n        vec![0xFF],\n    ]),\n    ..Default::default()\n}\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/guard-based-partitioning/#summary","title":"Summary","text":"<p>Guard-based partitioning with fixed boundaries is the right choice for ATLL because:</p> <ol> <li>Predictable routing - Same key \u2192 same slot (always)</li> <li>Simple recovery - Manifest stores guard keys once</li> <li>Learning stability - Bandit scheduler accumulates knowledge</li> <li>Range query efficiency - Scan contiguous slots</li> </ol> <p>We accept these trade-offs: - No automatic rebalancing (manual intervention for severe skew) - Fixed granularity (can't adjust dynamically) - Storage overhead (metadata per slot)</p> <p>Future improvements: - Data-driven guard key selection (sampling-based) - Periodic rebalancing (split large slots) - Workload-specific strategies (time-series, geo)</p> <p>For most workloads, the defaults (16-64 uniform slots) provide the right balance of adaptability and simplicity.</p> <p>Last Updated: 2025-10-31 See Also: ATLL Architecture, Adaptive K-Way Fanout</p>"},{"location":"crates/nori-lsm/design-decisions/heat-tracking/","title":"Heat Tracking (EWMA)","text":"<p>Why we use Exponential Weighted Moving Average (\u03b1=0.1) for access pattern detection instead of counters or sliding windows.</p>"},{"location":"crates/nori-lsm/design-decisions/heat-tracking/#decision","title":"Decision","text":"<p>Track access frequency per slot using EWMA (Exponential Weighted Moving Average) with \u03b1=0.1:</p> <pre><code>pub struct Slot {\n    heat_score: f32,  // \u2208 [0.0, 1.0], 0 = cold, 1 = hot\n}\n\nimpl Slot {\n    pub fn update_heat(&amp;mut self) {\n        const ALPHA: f32 = 0.1;  // Smoothing factor\n        self.heat_score = ALPHA * 1.0 + (1.0 - ALPHA) * self.heat_score;\n    }\n\n    pub fn decay_heat(&amp;mut self) {\n        const ALPHA: f32 = 0.1;\n        self.heat_score = ALPHA * 0.0 + (1.0 - ALPHA) * self.heat_score;\n    }\n}\n</code></pre> <p>Update trigger: Every read/write to a slot calls <code>update_heat()</code></p> <p>Decay trigger: Periodic background task (every 60 seconds) calls <code>decay_heat()</code> for all slots</p>"},{"location":"crates/nori-lsm/design-decisions/heat-tracking/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"crates/nori-lsm/design-decisions/heat-tracking/#1-simple-access-counters","title":"1. Simple Access Counters","text":"<p>Approach: Count accesses per slot</p> <pre><code>pub struct Slot {\n    access_count: u64,  // Incremented on every access\n}\n\nfn is_hot(slot: &amp;Slot) -&gt; bool {\n    slot.access_count &gt; THRESHOLD  // e.g., 1000\n}\n</code></pre> <p>Rejected because: - No time decay: Old accesses count forever - Unbounded growth: Counter overflows after 2^64 accesses - Threshold tuning: What is \"hot\"? 1000? 10000? 1M? - No recency bias: Access from 1 year ago = access from 1 second ago</p> <p>Example problem: <pre><code>Slot was hot (10M accesses) in 2023\nSlot is cold (0 accesses) in 2024\n\nCounter value: 10,000,000 (still looks hot!)\nReality: Cold (no recent accesses)\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/heat-tracking/#2-sliding-window","title":"2. Sliding Window","text":"<p>Approach: Count accesses in last N seconds</p> <pre><code>pub struct Slot {\n    access_times: VecDeque&lt;Instant&gt;,  // Queue of access timestamps\n}\n\nimpl Slot {\n    pub fn update_heat(&amp;mut self, now: Instant) {\n        // Add current access\n        self.access_times.push_back(now);\n\n        // Remove accesses older than 60 seconds\n        while let Some(t) = self.access_times.front() {\n            if now - *t &gt; Duration::from_secs(60) {\n                self.access_times.pop_front();\n            } else {\n                break;\n            }\n        }\n    }\n\n    pub fn heat_score(&amp;self) -&gt; f32 {\n        self.access_times.len() as f32 / WINDOW_SIZE\n    }\n}\n</code></pre> <p>Rejected because: - Memory overhead: Store timestamp per access (8 bytes \u00d7 accesses/sec \u00d7 window) - Cliff edge: Access from 59.9s ago counts, 60.1s ago doesn't - Expensive cleanup: Must scan queue on every access - Poor cache locality: VecDeque allocations</p> <p>Example overhead: <pre><code>Hot slot: 1000 accesses/sec\nWindow: 60 seconds\n\nMemory per slot:\n  1000 \u00d7 60 \u00d7 8 bytes = 480 KB\n\nFor 64 slots:\n  64 \u00d7 480 KB = 30 MB (just for timestamps!)\n\nvs EWMA:\n  64 slots \u00d7 4 bytes = 256 bytes\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/heat-tracking/#3-lrulfu-tracking","title":"3. LRU/LFU Tracking","text":"<p>Approach: Track least-recently-used or least-frequently-used</p> <pre><code>pub struct Slot {\n    last_access: Instant,   // LRU\n    access_count: u64,      // LFU\n}\n\nfn is_hot_lru(slot: &amp;Slot, now: Instant) -&gt; bool {\n    now - slot.last_access &lt; Duration::from_secs(60)\n}\n\nfn is_hot_lfu(slot: &amp;Slot) -&gt; bool {\n    slot.access_count &gt; THRESHOLD\n}\n</code></pre> <p>Rejected because: - LRU: Binary (accessed recently or not), no gradations - LFU: Same issues as simple counters (no time decay) - Both: Don't capture \"hotness\" over time - Tuning: Requires threshold configuration</p>"},{"location":"crates/nori-lsm/design-decisions/heat-tracking/#4-histogram-bucket-counting","title":"4. Histogram / Bucket Counting","text":"<p>Approach: Track accesses in time buckets</p> <pre><code>pub struct Slot {\n    buckets: [u64; 60],  // 60 buckets (1 per second)\n    current_bucket: usize,\n}\n\nimpl Slot {\n    pub fn update_heat(&amp;mut self, now: Instant) {\n        let bucket = (now.as_secs() % 60) as usize;\n\n        // Rotate to new bucket if needed\n        if bucket != self.current_bucket {\n            self.buckets[bucket] = 0;\n            self.current_bucket = bucket;\n        }\n\n        // Increment current bucket\n        self.buckets[bucket] += 1;\n    }\n\n    pub fn heat_score(&amp;self) -&gt; f32 {\n        let total: u64 = self.buckets.iter().sum();\n        total as f32 / (60 * MAX_ACCESSES_PER_SEC)\n    }\n}\n</code></pre> <p>Rejected because: - Fixed granularity: 1-second buckets (too coarse or too fine) - Cliff edges: Access rotates out after exactly 60 seconds - Memory overhead: 60 \u00d7 8 bytes = 480 bytes per slot - Complexity: Bucket rotation logic</p>"},{"location":"crates/nori-lsm/design-decisions/heat-tracking/#5-multi-dimensional-heat","title":"5. Multi-Dimensional Heat","text":"<p>Approach: Separate heat for reads, writes, scans</p> <pre><code>pub struct Slot {\n    read_heat: f32,   // Read access frequency\n    write_heat: f32,  // Write access frequency\n    scan_heat: f32,   // Range scan frequency\n}\n</code></pre> <p>Rejected because: - Complexity: 3\u00d7 state, 3\u00d7 decay logic - K-max formula: How to combine? <code>k_max = f(read_heat, write_heat, scan_heat)</code>? - Unclear benefit: Hot reads/writes both benefit from K=1 - Future work: May revisit for specialized optimizations</p>"},{"location":"crates/nori-lsm/design-decisions/heat-tracking/#rationale","title":"Rationale","text":""},{"location":"crates/nori-lsm/design-decisions/heat-tracking/#1-recency-bias","title":"1. Recency Bias","text":"<p>EWMA gives more weight to recent accesses:</p> <pre><code>heat_new = 0.1 \u00d7 1.0 + 0.9 \u00d7 heat_old\n           \u2514\u2500recent\u2500\u2518   \u2514\u2500\u2500historical\u2500\u2500\u2518\n</code></pre> <p>Decay over time: <pre><code>No access for t steps:\n  heat_t = 0.9^t \u00d7 heat_0\n\nExamples:\n  After 10 steps: heat = 0.9^10 \u00d7 heat_0 = 0.35 \u00d7 heat_0 (35% remaining)\n  After 20 steps: heat = 0.9^20 \u00d7 heat_0 = 0.12 \u00d7 heat_0 (12% remaining)\n  After 30 steps: heat = 0.9^30 \u00d7 heat_0 = 0.04 \u00d7 heat_0 (4% remaining)\n</code></pre></p> <p>Benefit: Adapts to workload shifts</p> <p>Example: <pre><code>Slot was hot (heat=0.9) last week\nSlot is now cold (no accesses this week)\n\nCounter approach: Still looks hot (10M count)\nEWMA approach: heat decays to 0.04 after 30 intervals\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/heat-tracking/#2-convergence-properties","title":"2. Convergence Properties","text":"<p>EWMA converges to steady state:</p> <pre><code>For stable access pattern (access every step):\n  heat_\u221e = lim(t\u2192\u221e) heat_t\n         = \u03b1 / (1 - (1-\u03b1))\n         = 0.1 / 0.1\n         = 1.0\n\nFor stable non-access (no accesses):\n  heat_\u221e = 0.0\n\nConvergence rate:\n  error_t = (1-\u03b1)^t \u00d7 initial_error\n  error_30 = 0.9^30 \u00d7 1.0 \u2248 0.04 (4% error)\n\nConclusion: Converges within 20-30 steps\n</code></pre> <p>Validation: <pre><code>#[test]\nfn test_ewma_convergence() {\n    let mut slot = Slot::new();\n\n    // Access for 30 steps\n    for _ in 0..30 {\n        slot.update_heat();\n    }\n\n    assert!(slot.heat_score &gt; 0.96);  // 96% of steady state\n\n    // No access for 30 steps\n    for _ in 0..30 {\n        slot.decay_heat();\n    }\n\n    assert!(slot.heat_score &lt; 0.04);  // 4% of previous\n}\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/heat-tracking/#3-low-memory-overhead","title":"3. Low Memory Overhead","text":"<p>EWMA state: <pre><code>pub struct Slot {\n    heat_score: f32,  // 4 bytes\n}\n</code></pre></p> <p>Total memory (64 slots): <pre><code>64 slots \u00d7 4 bytes = 256 bytes\n</code></pre></p> <p>Comparison: <pre><code>EWMA:              256 bytes\nSliding window:    30 MB (1000 accesses/sec \u00d7 60 sec \u00d7 8 bytes \u00d7 64 slots)\nHistogram:         30 KB (60 buckets \u00d7 8 bytes \u00d7 64 slots)\n\nEWMA wins by 100-100,000\u00d7\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/heat-tracking/#4-simple-implementation","title":"4. Simple Implementation","text":"<p>Update logic: <pre><code>pub fn update_heat(&amp;mut self) {\n    self.heat_score = 0.1 * 1.0 + 0.9 * self.heat_score;\n}\n</code></pre></p> <p>Complexity: 2 multiplications, 1 addition (~5 CPU cycles)</p> <p>Contrast with sliding window: <pre><code>pub fn update_heat(&amp;mut self, now: Instant) {\n    self.access_times.push_back(now);  // Allocation\n\n    // Scan and remove old accesses\n    while let Some(t) = self.access_times.front() {\n        if now - *t &gt; Duration::from_secs(60) {\n            self.access_times.pop_front();  // Deallocation\n        } else {\n            break;\n        }\n    }\n}\n</code></pre></p> <p>Complexity: O(N) scan, allocations, pointer chasing</p>"},{"location":"crates/nori-lsm/design-decisions/heat-tracking/#mathematical-analysis","title":"Mathematical Analysis","text":""},{"location":"crates/nori-lsm/design-decisions/heat-tracking/#ewma-formula","title":"EWMA Formula","text":"<p>Recursive form: <pre><code>heat_t = \u03b1 \u00d7 access_t + (1-\u03b1) \u00d7 heat_{t-1}\n\nWhere:\n  heat_t     = heat score at time t\n  \u03b1 = 0.1    = smoothing factor (weight of recent observation)\n  access_t   = 1 if accessed at time t, 0 otherwise\n  heat_{t-1} = previous heat score\n</code></pre></p> <p>Expanded form (n steps of constant access): <pre><code>heat_n = \u03b1 \u00d7 (1 + (1-\u03b1) + (1-\u03b1)^2 + ... + (1-\u03b1)^{n-1})\n\nGeometric series:\n  sum = \u03b1 \u00d7 (1 - (1-\u03b1)^n) / (1 - (1-\u03b1))\n      = \u03b1 \u00d7 (1 - (1-\u03b1)^n) / \u03b1\n      = 1 - (1-\u03b1)^n\n\nAs n \u2192 \u221e:\n  heat_\u221e = 1.0\n</code></pre></p> <p>Decay (n steps of no access): <pre><code>heat_n = (1-\u03b1)^n \u00d7 heat_0\n\nExamples (\u03b1=0.1):\n  n=10: heat = 0.9^10 \u00d7 heat_0 = 0.349 \u00d7 heat_0\n  n=20: heat = 0.9^20 \u00d7 heat_0 = 0.122 \u00d7 heat_0\n  n=30: heat = 0.9^30 \u00d7 heat_0 = 0.042 \u00d7 heat_0\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/heat-tracking/#half-life","title":"Half-Life","text":"<p>Time for heat to decay to 50%: <pre><code>(1-\u03b1)^n = 0.5\n\nn = log(0.5) / log(1-\u03b1)\n  = log(0.5) / log(0.9)\n  = -0.693 / -0.105\n  \u2248 6.6 steps\n\nInterpretation: Heat halves every ~7 accesses\n</code></pre></p> <p>Practical implications: <pre><code>If slot accessed every 1 second:\n  Half-life: 7 seconds\n\nIf slot accessed every 60 seconds:\n  Half-life: 7 minutes\n\nIf slot accessed every 3600 seconds (1 hour):\n  Half-life: 7 hours\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/heat-tracking/#smoothing-effect","title":"Smoothing Effect","text":"<p>Bursty workload: <pre><code>Access pattern: 100 accesses in 1 second, then 59 seconds idle\n\nCounter approach:\n  Count=100 (looks very hot)\n\nEWMA approach:\n  After 100 accesses: heat \u2248 1.0 (hot)\n  After 59 idle steps: heat \u2248 0.002 (cold)\n\nResult: EWMA filters out burst, shows true average\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/heat-tracking/#alpha-tuning","title":"Alpha (\u03b1) Tuning","text":"<p>Trade-off: \u03b1 controls recency bias vs stability</p>"},{"location":"crates/nori-lsm/design-decisions/heat-tracking/#large-03-05","title":"Large \u03b1 (0.3 - 0.5)","text":"<p>Effect: - More responsive: Adapts quickly to changes - Less stable: Fluctuates with short-term noise - Shorter memory: Forgets old accesses faster</p> <p>Use case: Rapidly changing workloads (dev/test environments)</p> <p>Example (\u03b1=0.5): <pre><code>Convergence: 5-10 steps (fast)\nHalf-life: 1 step (very short memory)\nStability: Low (noisy)\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/heat-tracking/#small-001-005","title":"Small \u03b1 (0.01 - 0.05)","text":"<p>Effect: - Less responsive: Slow to adapt - More stable: Filters out noise - Longer memory: Retains old accesses longer</p> <p>Use case: Stable production workloads</p> <p>Example (\u03b1=0.01): <pre><code>Convergence: 300 steps (slow)\nHalf-life: 69 steps (long memory)\nStability: High (smooth)\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/heat-tracking/#default-01","title":"Default \u03b1 = 0.1","text":"<p>Rationale: Balanced trade-off</p> <pre><code>Convergence: 20-30 steps (moderate)\nHalf-life: 7 steps (reasonable memory)\nStability: Good (filters noise, responds to trends)\n</code></pre> <p>Validation: Tested with Zipfian workloads, \u03b1=0.1 converged within 30 accesses</p>"},{"location":"crates/nori-lsm/design-decisions/heat-tracking/#decay-strategy","title":"Decay Strategy","text":"<p>Problem: Slots with no recent accesses should cool down</p> <p>Solution: Periodic background decay</p> <pre><code>pub async fn decay_heat_task(&amp;self) {\n    loop {\n        tokio::time::sleep(Duration::from_secs(60)).await;\n\n        for slot in &amp;mut self.slots {\n            slot.decay_heat();\n        }\n    }\n}\n\nimpl Slot {\n    pub fn decay_heat(&amp;mut self) {\n        const ALPHA: f32 = 0.1;\n        self.heat_score = ALPHA * 0.0 + (1.0 - ALPHA) * self.heat_score;\n        // Equivalent to: self.heat_score *= 0.9\n    }\n}\n</code></pre> <p>Frequency: Every 60 seconds (configurable)</p> <p>Effect: <pre><code>Slot with no accesses for 10 minutes (10 decay cycles):\n  heat_new = 0.9^10 \u00d7 heat_old\n           = 0.349 \u00d7 heat_old\n\nExample:\n  Initial heat: 0.9 (hot)\n  After 10 min: 0.31 (warm)\n  After 20 min: 0.11 (cold)\n  After 30 min: 0.04 (very cold)\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/heat-tracking/#configuration","title":"Configuration","text":"<pre><code>pub struct ATLLConfig {\n    /// EWMA smoothing factor (\u03b1)\n    /// Default: 0.1\n    /// Range: 0.01 - 0.5\n    /// Higher = more responsive, less stable\n    pub heat_alpha: f32,\n\n    /// Heat decay interval (seconds)\n    /// Default: 60\n    /// How often to decay heat for idle slots\n    pub heat_decay_interval_secs: u64,\n}\n</code></pre> <p>Tuning guidelines:</p> <p>Rapidly changing workloads: <pre><code>ATLLConfig {\n    heat_alpha: 0.2,                  // Faster adaptation\n    heat_decay_interval_secs: 30,    // More frequent decay\n    ..Default::default()\n}\n</code></pre></p> <p>Stable workloads: <pre><code>ATLLConfig {\n    heat_alpha: 0.05,                // Smoother, slower adaptation\n    heat_decay_interval_secs: 120,   // Less frequent decay\n    ..Default::default()\n}\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/heat-tracking/#future-enhancements","title":"Future Enhancements","text":""},{"location":"crates/nori-lsm/design-decisions/heat-tracking/#1-adaptive-alpha","title":"1. Adaptive Alpha","text":"<p>Idea: Adjust \u03b1 based on workload variance</p> <pre><code>pub fn adaptive_alpha(&amp;self) -&gt; f32 {\n    let variance = self.compute_heat_variance();\n\n    if variance &gt; 0.5 {\n        0.2  // High variance \u2192 more responsive\n    } else {\n        0.05  // Low variance \u2192 more stable\n    }\n}\n</code></pre>"},{"location":"crates/nori-lsm/design-decisions/heat-tracking/#2-multi-dimensional-heat","title":"2. Multi-Dimensional Heat","text":"<p>Idea: Track read vs write heat separately</p> <pre><code>pub struct Slot {\n    read_heat: f32,   // For query-heavy ranges\n    write_heat: f32,  // For write-heavy ranges\n}\n\npub fn k_max(&amp;self) -&gt; usize {\n    // Prioritize read heat for K-max decision\n    1 + floor((1.0 - self.read_heat) \u00d7 (K_global - 1))\n}\n</code></pre>"},{"location":"crates/nori-lsm/design-decisions/heat-tracking/#3-per-access-type-weighting","title":"3. Per-Access-Type Weighting","text":"<p>Idea: Weight different access types differently</p> <pre><code>pub fn update_heat(&amp;mut self, access_type: AccessType) {\n    let weight = match access_type {\n        AccessType::PointRead =&gt; 1.0,   // Standard weight\n        AccessType::RangeScan =&gt; 0.5,   // Lower weight (less selective)\n        AccessType::Write =&gt; 0.3,       // Even lower (benefits from tiering)\n    };\n\n    self.heat_score = ALPHA * weight + (1.0 - ALPHA) * self.heat_score;\n}\n</code></pre>"},{"location":"crates/nori-lsm/design-decisions/heat-tracking/#summary","title":"Summary","text":"<p>EWMA heat tracking with \u03b1=0.1 is the right choice because:</p> <ol> <li>Recency bias - Recent accesses weigh more than old</li> <li>Convergence - Stabilizes within 20-30 accesses</li> <li>Low overhead - 4 bytes per slot (vs MB for sliding window)</li> <li>Simple - 2 multiplications, 1 addition per update</li> <li>Proven - Standard technique in signal processing, networking</li> </ol> <p>We accept these trade-offs: - Not instant (convergence period) - Fixed \u03b1 (no per-slot tuning without code changes) - Single-dimensional (read/write/scan treated equally)</p> <p>For most workloads, \u03b1=0.1 with 60-second decay provides the right balance of responsiveness and stability.</p> <p>Last Updated: 2025-10-31 See Also: Adaptive K-Way Fanout, Bandit Scheduler</p>"},{"location":"crates/nori-lsm/design-decisions/memory-pressure/","title":"Memory Pressure System","text":"<p>Why ATLL uses 4-zone adaptive backpressure (Green/Yellow/Orange/Red) with composite scoring instead of hard stalls or single thresholds.</p>"},{"location":"crates/nori-lsm/design-decisions/memory-pressure/#decision","title":"Decision","text":"<p>Use a 4-zone adaptive backpressure system with composite scoring to progressively throttle writes before hitting hard limits.</p> <p>Each zone applies different strategies:</p> <pre><code>pub enum PressureZone {\n    Green,   // 0-50%:  No backpressure\n    Yellow,  // 50-75%: Soft throttling (warn, delay small)\n    Orange,  // 75-90%: Heavy throttling (delay exponential)\n    Red,     // 90%+:   Hard stall (reject writes)\n}\n\n// Composite pressure score\npressure_score = 0.4 \u00d7 L0_ratio + 0.4 \u00d7 memory_ratio + 0.2 \u00d7 memtable_ratio\n\nWhere:\n  L0_ratio = L0_count / L0_max\n  memory_ratio = total_memory / memory_limit\n  memtable_ratio = memtable_size / memtable_max\n</code></pre> <p>Result: - Progressive degradation: Gradual slowdown instead of cliff-edge failures - Multi-dimensional awareness: Responds to L0 count, memory usage, and memtable size - Observable behavior: Clear pressure zones with metrics and VizEvent emissions</p>"},{"location":"crates/nori-lsm/design-decisions/memory-pressure/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"crates/nori-lsm/design-decisions/memory-pressure/#1-hard-stall-only-no-backpressure","title":"1. Hard Stall Only (No Backpressure)","text":"<p>Approach: Accept writes until limit, then reject</p> <pre><code>async fn put(&amp;self, key: Vec&lt;u8&gt;, value: Vec&lt;u8&gt;) -&gt; Result&lt;()&gt; {\n    if self.l0_count &gt;= L0_MAX {\n        return Err(Error::MemoryLimitExceeded);\n    }\n\n    // Write normally\n    self.write(key, value).await\n}\n</code></pre> <p>Rejected because: - Cliff-edge failures: 0ms latency \u2192 rejection with no warning - No client adaptation: Clients can't detect pressure and slow down - Burst amplification: All clients retry simultaneously (thundering herd) - Poor UX: Sudden errors instead of gradual slowdown</p> <p>Example: <pre><code>L0 count: 5 (of 6 max)\n  100 concurrent writes arrive\n  \u2192 All succeed (L0 = 6)\n\nL0 count: 6 (at max)\n  Next write arrives\n  \u2192 Rejected (Error::MemoryLimitExceeded)\n  \u2192 Client retries immediately (backoff logic needed)\n  \u2192 Same error (compaction hasn't finished yet)\n\nProblem: No warning, no graceful degradation\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/memory-pressure/#2-single-threshold-binary-backpressure","title":"2. Single Threshold (Binary Backpressure)","text":"<p>Approach: Normal speed until threshold, then fixed delay</p> <pre><code>async fn put(&amp;self, key: Vec&lt;u8&gt;, value: Vec&lt;u8&gt;) -&gt; Result&lt;()&gt; {\n    if self.l0_count &gt; 4 {\n        // Above threshold: delay all writes\n        sleep(Duration::from_millis(100)).await;\n    }\n\n    self.write(key, value).await\n}\n</code></pre> <p>Rejected because: - Cliff edge (smaller): 0ms \u2192 100ms with no gradation - Inefficient: Same delay at 50% and 99% pressure - No severity signal: Clients can't distinguish \"mildly busy\" from \"critically overloaded\" - Fixed delay: Doesn't adapt to pressure severity</p> <p>Example: <pre><code>L0 count: 4 \u2192 0ms write latency\nL0 count: 5 \u2192 100ms write latency (sudden jump)\nL0 count: 6 \u2192 100ms write latency (same as 5, but more critical)\n\nProblem: Binary signal, no proportional response\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/memory-pressure/#3-per-dimension-limits-independent-throttling","title":"3. Per-Dimension Limits (Independent Throttling)","text":"<p>Approach: Separate thresholds for L0, memory, memtable</p> <pre><code>async fn put(&amp;self, key: Vec&lt;u8&gt;, value: Vec&lt;u8&gt;) -&gt; Result&lt;()&gt; {\n    let mut delay_ms = 0;\n\n    if self.l0_count &gt; L0_THRESHOLD {\n        delay_ms += 50;\n    }\n\n    if self.total_memory &gt; MEMORY_THRESHOLD {\n        delay_ms += 50;\n    }\n\n    if self.memtable_size &gt; MEMTABLE_THRESHOLD {\n        delay_ms += 50;\n    }\n\n    sleep(Duration::from_millis(delay_ms)).await;\n    self.write(key, value).await\n}\n</code></pre> <p>Rejected because: - Additive delays: Multiple dimensions \u2192 150ms delay (too harsh) - No global view: Doesn't balance dimensions (e.g., high L0 + low memory = less critical) - Tuning difficulty: 3 independent thresholds to configure - Uneven response: One dimension can dominate</p> <p>Example: <pre><code>Scenario A: L0=high, memory=low, memtable=low\n  \u2192 50ms delay (reasonable)\n\nScenario B: L0=high, memory=high, memtable=high\n  \u2192 150ms delay (too harsh, might trigger timeout)\n\nProblem: Doesn't consider overall system health\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/memory-pressure/#4-fixed-delay-progression","title":"4. Fixed Delay Progression","text":"<p>Approach: Static delays per pressure level</p> <pre><code>fn calculate_delay(&amp;self) -&gt; Duration {\n    match self.pressure_level() {\n        1 =&gt; Duration::from_millis(10),\n        2 =&gt; Duration::from_millis(20),\n        3 =&gt; Duration::from_millis(40),\n        4 =&gt; Duration::from_millis(80),\n        _ =&gt; Duration::ZERO,\n    }\n}\n</code></pre> <p>Rejected because: - Linear progression: Doesn't adapt to rate of change - No exponential backoff: Can't handle transient spikes - Static levels: Requires manual tuning per workload - No smooth transition: Jumps between fixed delays</p> <p>Example: <pre><code>Pressure: 25% \u2192 0ms\nPressure: 50% \u2192 10ms (jump)\nPressure: 75% \u2192 40ms (jump)\nPressure: 90% \u2192 80ms (jump)\n\nProblem: Discrete jumps, no smooth curve\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/memory-pressure/#5-token-bucket-rate-limiting","title":"5. Token Bucket Rate Limiting","text":"<p>Approach: Allow X writes/sec, delay when bucket empty</p> <pre><code>pub struct TokenBucket {\n    tokens: f64,\n    rate: f64,  // Tokens per second\n    max: f64,   // Bucket capacity\n}\n\nasync fn put(&amp;self, key: Vec&lt;u8&gt;, value: Vec&lt;u8&gt;) -&gt; Result&lt;()&gt; {\n    // Wait until token available\n    self.bucket.acquire(1).await;\n\n    self.write(key, value).await\n}\n</code></pre> <p>Rejected because: - Fixed rate: Doesn't adapt to compaction progress - Ignores system state: Tokens refill regardless of L0/memory pressure - No pressure signal: Clients don't know why they're being throttled - Complex tuning: Rate must match write throughput and compaction rate</p> <p>Example: <pre><code>Bucket: 100 tokens/sec\n\nScenario A: Low pressure, 50 writes/sec\n  \u2192 Tokens accumulate (no backpressure)\n\nScenario B: High pressure, 50 writes/sec\n  \u2192 Tokens accumulate (still no backpressure!)\n\nProblem: Doesn't respond to system state\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/memory-pressure/#rationale","title":"Rationale","text":""},{"location":"crates/nori-lsm/design-decisions/memory-pressure/#1-progressive-degradation","title":"1. Progressive Degradation","text":"<p>Composite scoring provides smooth transition:</p> <pre><code>fn pressure_score(&amp;self) -&gt; f64 {\n    let l0_ratio = self.l0_count as f64 / self.config.l0_max as f64;\n    let memory_ratio = self.total_memory as f64 / self.config.memory_limit as f64;\n    let memtable_ratio = self.memtable_size as f64 / self.config.memtable_max as f64;\n\n    // Weighted average (L0 and memory matter most)\n    0.4 * l0_ratio + 0.4 * memory_ratio + 0.2 * memtable_ratio\n}\n</code></pre> <p>Benefits: - Smooth curve: Pressure increases gradually, not in jumps - Balanced view: No single dimension dominates - Tunable weights: Can adjust for workload (e.g., 0.6\u00d7L0 for write-heavy)</p> <p>Example: <pre><code>State A: L0=50%, memory=30%, memtable=20%\n  pressure_score = 0.4\u00d70.5 + 0.4\u00d70.3 + 0.2\u00d70.2 = 0.36 (Green)\n\nState B: L0=70%, memory=60%, memtable=40%\n  pressure_score = 0.4\u00d70.7 + 0.4\u00d70.6 + 0.2\u00d70.4 = 0.60 (Yellow)\n\nState C: L0=90%, memory=85%, memtable=80%\n  pressure_score = 0.4\u00d70.9 + 0.4\u00d70.85 + 0.2\u00d70.8 = 0.86 (Orange)\n\nResult: Smooth progression from Green \u2192 Yellow \u2192 Orange\n</code></pre></p>"},{"location":"crates/nori-lsm/design-decisions/memory-pressure/#2-zone-based-strategies","title":"2. Zone-Based Strategies","text":"<p>Each zone applies different backpressure:</p> <pre><code>pub async fn apply_backpressure(&amp;self, score: f64) -&gt; Result&lt;()&gt; {\n    match Self::zone_for_score(score) {\n        PressureZone::Green =&gt; {\n            // 0-50%: No delay, emit metrics only\n            Ok(())\n        }\n\n        PressureZone::Yellow =&gt; {\n            // 50-75%: Soft throttling (linear delay)\n            let delay_ms = (score - 0.5) / 0.25 * 50.0;  // 0-50ms\n            sleep(Duration::from_millis(delay_ms as u64)).await;\n            Ok(())\n        }\n\n        PressureZone::Orange =&gt; {\n            // 75-90%: Heavy throttling (exponential delay)\n            let factor = (score - 0.75) / 0.15;  // 0-1\n            let delay_ms = 50.0 * (2.0_f64.powf(factor * 4.0));  // 50-800ms\n            sleep(Duration::from_millis(delay_ms as u64)).await;\n            Ok(())\n        }\n\n        PressureZone::Red =&gt; {\n            // 90%+: Hard stall (reject writes)\n            Err(Error::MemoryLimitExceeded)\n        }\n    }\n}\n</code></pre> <p>Delay curves:</p> <pre><code>Green (0-50%):\n  delay = 0ms (always)\n\nYellow (50-75%):\n  50% \u2192 0ms\n  60% \u2192 20ms\n  70% \u2192 40ms\n  75% \u2192 50ms\n  Linear growth\n\nOrange (75-90%):\n  75% \u2192 50ms\n  80% \u2192 100ms\n  85% \u2192 200ms\n  90% \u2192 400ms\n  Exponential growth (2^x curve)\n\nRed (90%+):\n  Reject writes immediately\n</code></pre> <p>Rationale: - Green: No overhead, normal throughput - Yellow: Gentle slowdown, clients notice but not alarmed - Orange: Aggressive backoff, clear \"slow down\" signal - Red: Last resort, system critically overloaded</p>"},{"location":"crates/nori-lsm/design-decisions/memory-pressure/#3-multi-dimensional-awareness","title":"3. Multi-Dimensional Awareness","text":"<p>Why composite scoring beats single metrics:</p> <p>Scenario 1: High L0, low memory <pre><code>L0: 90% (6 files pending compaction)\nMemory: 20% (plenty of RAM available)\nMemtable: 30%\n\nComposite: 0.4\u00d70.9 + 0.4\u00d70.2 + 0.2\u00d70.3 = 0.50 (Yellow, not Orange)\n\nInterpretation: High L0 but plenty of memory, compaction will catch up soon\nStrategy: Soft throttling (20ms delay), not aggressive backoff\n</code></pre></p> <p>Scenario 2: Low L0, high memory <pre><code>L0: 30% (few files)\nMemory: 95% (nearly full)\nMemtable: 80%\n\nComposite: 0.4\u00d70.3 + 0.4\u00d70.95 + 0.2\u00d70.8 = 0.66 (Yellow, approaching Orange)\n\nInterpretation: L0 is fine but memory critical, need flush\nStrategy: Moderate throttling, trigger memtable flush\n</code></pre></p> <p>Scenario 3: All dimensions high <pre><code>L0: 85%\nMemory: 90%\nMemtable: 95%\n\nComposite: 0.4\u00d70.85 + 0.4\u00d70.9 + 0.2\u00d70.95 = 0.89 (Orange, near Red)\n\nInterpretation: System critically overloaded\nStrategy: Heavy throttling (300ms+ delay), aggressive compaction\n</code></pre></p> <p>Benefit: Responds to overall system health, not single bottleneck</p>"},{"location":"crates/nori-lsm/design-decisions/memory-pressure/#4-observable-and-debuggable","title":"4. Observable and Debuggable","text":"<p>VizEvent emissions for monitoring:</p> <pre><code>pub fn emit_pressure_event(&amp;self, zone: PressureZone, score: f64) {\n    self.meter.emit(VizEvent::PressureZone {\n        zone: zone.as_str(),\n        score,\n        l0_count: self.l0_count,\n        memory_bytes: self.total_memory,\n        memtable_bytes: self.memtable_size,\n        timestamp_ns: self.clock.now().as_nanos(),\n    });\n}\n</code></pre> <p>Dashboard visualization:</p> <pre><code>Pressure Timeline:\n\n  100% \u2502                    \u2588\u2588\u2588\u2588 Red\n   90% \u2502               \u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\n   75% \u2502          \u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 Orange\n   50% \u2502     \u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 Yellow\n    0% \u2502\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 Green\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n         Time \u2192\n\nZone transitions visible in real-time\nOperators can see pressure buildup before failures\n</code></pre> <p>Metrics exposed:</p> <pre><code>// Gauge metrics\npressure_score (0.0-1.0)\npressure_zone (0=Green, 1=Yellow, 2=Orange, 3=Red)\nl0_ratio (0.0-1.0)\nmemory_ratio (0.0-1.0)\n\n// Counter metrics\nwrites_delayed_total (by zone)\nwrites_rejected_total\nbackpressure_time_ms_total\n</code></pre>"},{"location":"crates/nori-lsm/design-decisions/memory-pressure/#trade-offs","title":"Trade-offs","text":""},{"location":"crates/nori-lsm/design-decisions/memory-pressure/#what-we-gained","title":"What We Gained","text":"<p>1. Graceful Degradation - Smooth slowdown from 0ms \u2192 50ms \u2192 400ms \u2192 rejection - Clients experience latency increase, not sudden errors - Time to adapt (reduce write rate, batch, defer)</p> <p>2. Multi-Dimensional Health - Composite score balances L0, memory, memtable - Avoids overreacting to single metric spike - Responds to true system stress</p> <p>3. Clear Severity Signals - 4 zones with distinct behaviors - Operators know severity at a glance - Clients can implement zone-aware retry logic</p> <p>4. Configurable Weights - Adjust for workload (write-heavy, read-heavy, balanced) - Tune L0 vs memory importance - Override via config without code changes</p>"},{"location":"crates/nori-lsm/design-decisions/memory-pressure/#what-we-gave-up","title":"What We Gave Up","text":"<p>1. Simplicity - More complex than hard stall or single threshold - Composite formula requires tuning (default works for most) - 4 zones vs binary on/off</p> <p>2. Maximum Throughput - Yellow/Orange zones add latency (by design) - Reduces peak write rate before hitting limits - Trade throughput for stability</p> <p>3. Predictability - Zone transitions depend on multiple metrics - Not a simple \"L0 &gt; 6 \u2192 reject\" rule - Requires monitoring to understand behavior</p>"},{"location":"crates/nori-lsm/design-decisions/memory-pressure/#configuration","title":"Configuration","text":"<p>Default configuration:</p> <pre><code>pub struct PressureConfig {\n    /// L0 file count limit\n    /// Default: 6\n    pub l0_max: usize,\n\n    /// Total memory limit (bytes)\n    /// Default: 512 MB\n    pub memory_limit: usize,\n\n    /// Memtable size limit (bytes)\n    /// Default: 64 MB\n    pub memtable_max: usize,\n\n    /// Composite score weights (must sum to 1.0)\n    /// Default: [0.4, 0.4, 0.2]\n    pub weights: [f64; 3],  // [L0, memory, memtable]\n\n    /// Zone boundaries (pressure score thresholds)\n    /// Default: [0.50, 0.75, 0.90]\n    pub zone_thresholds: [f64; 3],  // [Yellow, Orange, Red]\n}\n</code></pre> <p>Tuning guidelines:</p>"},{"location":"crates/nori-lsm/design-decisions/memory-pressure/#write-heavy-workloads","title":"Write-Heavy Workloads","text":"<pre><code>PressureConfig {\n    l0_max: 8,  // Allow more L0 accumulation\n    memory_limit: 1024 * 1024 * 1024,  // 1 GB\n    weights: [0.6, 0.3, 0.1],  // Prioritize L0 over memory\n    ..Default::default()\n}\n</code></pre> <p>Effect: - Higher L0 tolerance (8 files vs 6) - L0 ratio weighted more heavily (60% vs 40%) - Less backpressure from memory spikes</p>"},{"location":"crates/nori-lsm/design-decisions/memory-pressure/#read-heavy-workloads","title":"Read-Heavy Workloads","text":"<pre><code>PressureConfig {\n    l0_max: 4,  // Keep L0 low (faster reads)\n    memory_limit: 2048 * 1024 * 1024,  // 2 GB (more cache)\n    weights: [0.5, 0.3, 0.2],  // Balanced\n    ..Default::default()\n}\n</code></pre> <p>Effect: - Lower L0 limit (better read performance) - More memory for block cache - Earlier backpressure to maintain low L0</p>"},{"location":"crates/nori-lsm/design-decisions/memory-pressure/#high-pressure-tolerance","title":"High-Pressure Tolerance","text":"<pre><code>PressureConfig {\n    zone_thresholds: [0.60, 0.85, 0.95],  // Shift zones right\n    ..Default::default()\n}\n</code></pre> <p>Effect: - Yellow zone: 60-85% (wider, less sensitive) - Orange zone: 85-95% (narrower, more tolerance) - Red zone: 95%+ (only truly critical) - Less aggressive backpressure overall</p>"},{"location":"crates/nori-lsm/design-decisions/memory-pressure/#low-latency-slos","title":"Low-Latency SLOs","text":"<pre><code>PressureConfig {\n    zone_thresholds: [0.40, 0.65, 0.85],  // Shift zones left\n    ..Default::default()\n}\n</code></pre> <p>Effect: - Yellow zone: 40-65% (earlier warning) - Orange zone: 65-85% (wider, more aggressive) - Red zone: 85%+ (earlier hard stall) - Preemptive backpressure to maintain low latency</p>"},{"location":"crates/nori-lsm/design-decisions/memory-pressure/#zone-evolution-examples","title":"Zone Evolution Examples","text":""},{"location":"crates/nori-lsm/design-decisions/memory-pressure/#example-1-gradual-write-burst","title":"Example 1: Gradual Write Burst","text":"<p>Workload: Steady increase from 1K writes/sec \u2192 10K writes/sec</p> <pre><code>Time  \u2502 L0  \u2502 Mem  \u2502 MT  \u2502 Score \u2502 Zone   \u2502 Delay\n\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\n00:00 \u2502 20% \u2502 30%  \u2502 10% \u2502 0.24  \u2502 Green  \u2502 0ms\n00:10 \u2502 40% \u2502 50%  \u2502 30% \u2502 0.42  \u2502 Green  \u2502 0ms\n00:20 \u2502 60% \u2502 65%  \u2502 50% \u2502 0.60  \u2502 Yellow \u2502 20ms\n00:30 \u2502 75% \u2502 75%  \u2502 70% \u2502 0.74  \u2502 Yellow \u2502 48ms\n00:40 \u2502 85% \u2502 85%  \u2502 85% \u2502 0.85  \u2502 Orange \u2502 178ms\n00:50 \u2502 90% \u2502 90%  \u2502 90% \u2502 0.90  \u2502 Red    \u2502 Reject\n\nCompaction kicks in aggressively at 00:40\nPressure stabilizes at Yellow zone by 01:00\n</code></pre>"},{"location":"crates/nori-lsm/design-decisions/memory-pressure/#example-2-transient-memory-spike","title":"Example 2: Transient Memory Spike","text":"<p>Workload: Sudden 200 MB write batch</p> <pre><code>Time  \u2502 L0  \u2502 Mem  \u2502 MT  \u2502 Score \u2502 Zone   \u2502 Delay\n\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\n00:00 \u2502 30% \u2502 40%  \u2502 20% \u2502 0.32  \u2502 Green  \u2502 0ms\n00:01 \u2502 35% \u2502 85%  \u2502 70% \u2502 0.62  \u2502 Yellow \u2502 24ms  \u2190 Spike\n00:02 \u2502 40% \u2502 50%  \u2502 30% \u2502 0.38  \u2502 Green  \u2502 0ms   \u2190 Recovered\n\nMemtable flushed quickly (200 MB \u2192 SSTable)\nComposite score smooths out spike (85% memory but 35% L0)\nNo Orange zone entered (avoided overreaction)\n</code></pre>"},{"location":"crates/nori-lsm/design-decisions/memory-pressure/#example-3-sustained-high-load","title":"Example 3: Sustained High Load","text":"<p>Workload: 8K writes/sec sustained for 10 minutes</p> <pre><code>Time  \u2502 L0  \u2502 Mem  \u2502 MT  \u2502 Score \u2502 Zone   \u2502 Delay\n\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\n00:00 \u2502 50% \u2502 55%  \u2502 40% \u2502 0.50  \u2502 Yellow \u2502 0ms    \u2190 Enter Yellow\n00:30 \u2502 70% \u2502 70%  \u2502 60% \u2502 0.68  \u2502 Yellow \u2502 36ms\n01:00 \u2502 80% \u2502 78%  \u2502 75% \u2502 0.78  \u2502 Orange \u2502 89ms   \u2190 Enter Orange\n02:00 \u2502 82% \u2502 80%  \u2502 78% \u2502 0.80  \u2502 Orange \u2502 126ms\n05:00 \u2502 78% \u2502 76%  \u2502 74% \u2502 0.76  \u2502 Orange \u2502 63ms   \u2190 Compaction catching up\n10:00 \u2502 65% \u2502 60%  \u2502 55% \u2502 0.61  \u2502 Yellow \u2502 22ms   \u2190 Stabilized\n\nSystem never hits Red zone\nBackpressure + compaction reach equilibrium in Orange zone\nGradual recovery to Yellow after workload completes\n</code></pre>"},{"location":"crates/nori-lsm/design-decisions/memory-pressure/#validation","title":"Validation","text":"<p>Property test: Pressure monotonicity</p> <pre><code>#[test]\nfn test_pressure_increases_with_load() {\n    let mut lsm = LSM::new(PressureConfig::default());\n\n    let mut prev_score = 0.0;\n\n    // Incrementally add L0 files\n    for i in 0..6 {\n        lsm.add_l0_file(1024 * 1024);  // 1 MB each\n\n        let score = lsm.pressure_score();\n        assert!(score &gt;= prev_score);  // Monotonic increase\n        prev_score = score;\n    }\n\n    // Check zone transitions\n    assert_eq!(lsm.zone_for_score(0.30), PressureZone::Green);\n    assert_eq!(lsm.zone_for_score(0.60), PressureZone::Yellow);\n    assert_eq!(lsm.zone_for_score(0.80), PressureZone::Orange);\n    assert_eq!(lsm.zone_for_score(0.95), PressureZone::Red);\n}\n</code></pre> <p>Benchmark: Backpressure overhead</p> <pre><code>Baseline (no pressure):\n  PUT latency: 1.2ms (p50), 2.1ms (p95)\n\nYellow zone (score=0.60):\n  PUT latency: 21.5ms (p50), 32.8ms (p95)\n  Overhead: +20ms delay (expected)\n\nOrange zone (score=0.85):\n  PUT latency: 201.3ms (p50), 285.6ms (p95)\n  Overhead: ~200ms delay (expected)\n\nRed zone (score=0.95):\n  PUT latency: N/A (writes rejected)\n  Error rate: 100% (expected)\n</code></pre> <p>Integration test: Recovery from Red zone</p> <pre><code>#[tokio::test]\nasync fn test_recovery_from_red_zone() {\n    let lsm = LSM::new(PressureConfig::default());\n\n    // Fill L0 to Red zone\n    for _ in 0..10 {\n        let _ = lsm.flush_memtable().await;\n    }\n\n    assert_eq!(lsm.pressure_zone(), PressureZone::Red);\n\n    // Trigger aggressive compaction\n    lsm.compact_all_slots().await.unwrap();\n\n    // After compaction, should return to Green\n    assert_eq!(lsm.pressure_zone(), PressureZone::Green);\n}\n</code></pre>"},{"location":"crates/nori-lsm/design-decisions/memory-pressure/#summary","title":"Summary","text":"<p>4-zone adaptive backpressure is the right choice for ATLL because:</p> <ol> <li>Progressive degradation - Smooth transition from 0ms \u2192 50ms \u2192 400ms \u2192 rejection</li> <li>Multi-dimensional health - Composite score balances L0, memory, memtable</li> <li>Observable behavior - Clear zones with VizEvent emissions and metrics</li> <li>Configurable response - Tune weights and thresholds per workload</li> </ol> <p>We accept these trade-offs: - Complexity (vs hard stall only) - Reduced peak throughput (by design, for stability) - Multiple metrics to monitor (vs single threshold)</p> <p>For heterogeneous workloads with bursty writes, 4-zone backpressure prevents cliff-edge failures while maintaining observable, predictable behavior.</p> <p>Last Updated: 2025-10-31 See Also: ATLL Architecture, Write Path</p>"},{"location":"crates/nori-lsm/how-it-works/","title":"How It Works","text":"<p>Deep dive into nori-lsm's internals: memtable management, flush process, slot routing, compaction lifecycle, and snapshots.</p>"},{"location":"crates/nori-lsm/how-it-works/#what-youll-learn","title":"What You'll Learn","text":"<p>This section explains the technical implementation details of nori-lsm's ATLL architecture. If you want to understand:</p> <ul> <li>How writes flow from memtable \u2192 L0 \u2192 slots</li> <li>How keys are routed to slots using guard-based partitioning</li> <li>How compaction works with the bandit scheduler</li> <li>How memtable rotation and flushing work</li> <li>How consistent snapshots are created for backups</li> <li>How the entire system coordinates write path, read path, and background jobs</li> </ul> <p>...then you're in the right place.</p>"},{"location":"crates/nori-lsm/how-it-works/#navigation","title":"Navigation","text":""},{"location":"crates/nori-lsm/how-it-works/#memtable-management","title":"Memtable Management","text":"<p>The in-memory skiplist: writes, rotation triggers, concurrent access, and memory accounting.</p>"},{"location":"crates/nori-lsm/how-it-works/#flush-process","title":"Flush Process","text":"<p>How memtables are flushed to L0 SSTables. Sorting, serialization, bloom filter generation, and atomic swaps.</p>"},{"location":"crates/nori-lsm/how-it-works/#slot-routing","title":"Slot Routing","text":"<p>How keys are mapped to slots using binary search on guard keys. Range queries and slot overlap detection.</p>"},{"location":"crates/nori-lsm/how-it-works/#compaction-lifecycle","title":"Compaction Lifecycle","text":"<p>The full compaction process: slot selection via bandit scheduler, K-way merge, heat updates, and metrics.</p>"},{"location":"crates/nori-lsm/how-it-works/#snapshot-process","title":"Snapshot Process","text":"<p>Creating consistent point-in-time snapshots for backups, replication, and disaster recovery.</p>"},{"location":"crates/nori-lsm/how-it-works/#who-should-read-this","title":"Who Should Read This","text":"<p>You should read this section if: - You're implementing your own LSM-tree - You're debugging nori-lsm behavior - You're contributing to nori-lsm - You want deep technical understanding of ATLL - You're evaluating LSM implementations</p> <p>You can skip this section if: - You just want to use nori-lsm (see Getting Started - coming soon) - You want high-level concepts (see Core Concepts) - You want design rationale (see Design Decisions)</p>"},{"location":"crates/nori-lsm/how-it-works/#prerequisites","title":"Prerequisites","text":"<p>Before diving in, make sure you understand:</p> <ul> <li>What is LSM - The fundamental concept</li> <li>ATLL Architecture - Guard keys, K-way fanout, heat tracking</li> <li>Write Path - High-level flow: WAL \u2192 memtable \u2192 L0 \u2192 compaction</li> <li>Read Path - High-level flow: memtable \u2192 L0 \u2192 slot</li> </ul> <p>If you haven't read those yet, start there first!</p>"},{"location":"crates/nori-lsm/how-it-works/#architecture-overview","title":"Architecture Overview","text":"<p>Here's how nori-lsm components fit together:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      Application Layer                        \u2502\n\u2502                  put(key, value) / get(key)                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u2502                       \u2502\n             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n             \u2502   Write Path       \u2502   \u2502   Read Path     \u2502\n             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u2502                       \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502\n        \u2502  1. WAL (durability)        \u2502       \u2502\n        \u2502  2. Memtable (in-memory)    \u2502       \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\n                       \u2502                       \u2502\n                   Flush (async)               \u2502\n                       \u2502                       \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502              L0 (unsorted)                        \u2502\n        \u2502  [SST-001] [SST-002] [SST-003] [SST-004] ...     \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u2502\n                 Slot Routing\n                 (guard keys)\n                       \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502         Slot 0 [0x00, 0x40)                 \u2502\n        \u2502   [Run 0] K-max=1 (leveled, hot)            \u2502\n        \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n        \u2502         Slot 1 [0x40, 0x80)                 \u2502\n        \u2502   [Run 0] [Run 1] K-max=2 (hybrid, warm)    \u2502\n        \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n        \u2502         Slot 2 [0x80, 0xC0)                 \u2502\n        \u2502   [Run 0] [Run 1] [Run 2] K-max=3 (cold)    \u2502\n        \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n        \u2502         Slot 3 [0xC0, 0xFF]                 \u2502\n        \u2502   [Run 0] [Run 1] [Run 2] [Run 3] K-max=4   \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u2502\n                 Compaction\n              (bandit scheduler)\n                       \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502     Merged SSTables (sorted, non-overlapping \u2502\n        \u2502              per slot)                       \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Key components: - Memtable: In-memory skiplist, bounded by size (default 64 MB) - L0: Unsorted SSTables from memtable flushes - Slots: Range-partitioned levels with guard keys - Compaction Scheduler: Bandit-based slot selection - Snapshot Manager: Consistent backups via reference counting</p>"},{"location":"crates/nori-lsm/how-it-works/#code-organization","title":"Code Organization","text":"<p>nori-lsm is organized into modules:</p> <pre><code>nori-lsm/\n  src/\n    lib.rs              - Public API (LSM, Config, Storage trait)\n    memtable.rs         - In-memory skiplist with rotation\n    flush.rs            - Memtable \u2192 L0 SSTable conversion\n    slot.rs             - Slot management (guard keys, runs, heat)\n    compaction.rs       - K-way merge algorithm\n    scheduler.rs        - Bandit-based compaction scheduling\n    snapshot.rs         - Snapshot creation and management\n    manifest.rs         - Metadata persistence (slots, runs, versions)\n    pressure.rs         - 4-zone backpressure system\n    observe.rs          - Observability (metrics, VizEvent)\n</code></pre> <p>Each \"How It Works\" page corresponds to one or more of these modules.</p>"},{"location":"crates/nori-lsm/how-it-works/#reading-order","title":"Reading Order","text":"<p>We recommend reading in this order:</p> <ol> <li>Memtable Management - Start here to understand the write buffer</li> <li>Flush Process - How memtables become SSTables</li> <li>Slot Routing - How guard-based partitioning works</li> <li>Compaction Lifecycle - The most complex subsystem</li> <li>Snapshot Process - Backups and consistency</li> </ol> <p>You can read them independently, but they build on each other.</p>"},{"location":"crates/nori-lsm/how-it-works/#operational-flow","title":"Operational Flow","text":"<p>Here's a typical sequence of operations:</p>"},{"location":"crates/nori-lsm/how-it-works/#write-flow","title":"Write Flow","text":"<pre><code>1. Client: put(\"user:12345\", \"data\")\n2. WAL: Append to 000042.wal, fsync\n3. Memtable: Insert into skiplist (50ns)\n4. Check pressure: Green zone, no delay\n5. Return Ok(())\n\n[Background thread, triggered when memtable &gt; 64 MB]\n6. Rotate memtable: Active \u2192 Immutable\n7. Create new active memtable\n8. Flush immutable memtable:\n   - Sort 1M entries\n   - Build SSTable with bloom filter\n   - Write 000015.sst to L0\n9. Update manifest: L0 += 000015.sst\n10. Delete WAL segment (no longer needed)\n</code></pre>"},{"location":"crates/nori-lsm/how-it-works/#compaction-flow","title":"Compaction Flow","text":"<pre><code>1. Scheduler: Select slot via epsilon-greedy + UCB\n2. Slot 1 selected (heat=0.8, k_max=1, 3 L0 files overlap)\n3. Compaction:\n   - Open 3 L0 SSTables + 1 existing run\n   - 4-way merge (K=4 \u2192 K=1 leveled)\n   - Write merged SSTable: 000016.sst\n   - Build bloom filter (10,000 keys, 0.01 FPR)\n4. Update slot:\n   - Remove old run\n   - Add new run: 000016.sst\n   - Update heat score (EWMA decay)\n5. Update manifest atomically\n6. Delete old SSTables (reference counting)\n7. Emit VizEvent::Compaction with metrics\n</code></pre>"},{"location":"crates/nori-lsm/how-it-works/#read-flow","title":"Read Flow","text":"<pre><code>1. Client: get(\"user:12345\")\n2. Memtable: Check active, miss\n3. Memtable: Check immutable (if exists), miss\n4. L0: Check bloom filters (6 files)\n   - 5 negative (bloom says \"no\")\n   - 1 maybe (bloom says \"maybe\")\n   - Read SSTable 000015.sst, found!\n5. Return value (skip slot traversal)\n\n[Alternative: key not in L0]\n6. Slot routing: Binary search guard keys \u2192 Slot 1\n7. Slot 1: Check bloom filter \u2192 maybe\n8. Slot 1: Binary search index, read block\n9. Return value or NotFound\n</code></pre>"},{"location":"crates/nori-lsm/how-it-works/#visual-learning","title":"Visual Learning","text":"<p>Each page includes:</p> <ul> <li>Mermaid diagrams - Flowcharts and sequence diagrams</li> <li>ASCII diagrams - Memory layouts, tree structures</li> <li>Code snippets - Actual implementation from nori-lsm</li> <li>Examples - Concrete scenarios and edge cases</li> <li>Metrics - Performance characteristics and benchmarks</li> </ul> <p>If you're a visual learner, you'll love this section!</p>"},{"location":"crates/nori-lsm/how-it-works/#concurrency-model","title":"Concurrency Model","text":"<p>nori-lsm uses a hybrid concurrency approach:</p> <p>Lock-Free Reads: - Memtable: Lock-free skiplist (crossbeam-skiplist) - SSTables: Immutable files, no locks needed - Manifest: RwLock (many readers, single writer)</p> <p>Synchronized Writes: - WAL append: Mutex (sequential writes for durability) - Memtable rotation: Mutex (rare, &lt;1/min) - Compaction: Per-slot locks (parallel compaction across slots)</p> <p>Example concurrency: <pre><code>Thread 1: put(\"a\", \"1\")  \u2192 WAL mutex \u2192 memtable lock-free\nThread 2: put(\"b\", \"2\")  \u2192 WAL mutex \u2192 memtable lock-free\nThread 3: get(\"c\")       \u2192 memtable lock-free \u2192 L0 lock-free\nThread 4: compaction     \u2192 Slot 0 mutex (doesn't block Slot 1-15)\n</code></pre></p>"},{"location":"crates/nori-lsm/how-it-works/#performance-characteristics","title":"Performance Characteristics","text":"<p>From benchmarks (see Performance for details):</p> <p>Write latency: - Memtable insert: 50ns (in-memory skiplist) - WAL append: 1-2ms (fsync, dominant cost) - p95: 2.1ms (Green zone), 20-40ms (Yellow zone)</p> <p>Flush latency: - 64 MB memtable \u2192 SSTable: ~200ms - Bloom filter generation: ~50ms (100K keys) - Total: ~250ms per flush</p> <p>Compaction latency: - 10 MB 4-way merge: ~100ms - 100 MB 4-way merge: ~800ms - 1 GB 4-way merge: ~8 seconds</p> <p>Throughput: - Sustained writes: 20K ops/sec (single memtable) - Peak writes: 50K ops/sec (before backpressure) - Compaction throughput: 100-150 MB/sec</p>"},{"location":"crates/nori-lsm/how-it-works/#next-steps","title":"Next Steps","text":"<p>Ready to dive in? Start with:</p> <ul> <li>Memtable Management - Learn how the write buffer works</li> <li>Or jump to a specific topic that interests you</li> </ul> <p>If you're looking for something else: - Core Concepts - High-level architecture and theory - Design Decisions - Why ATLL is built this way - Performance - Benchmarks and tuning guides (coming soon)</p>"},{"location":"crates/nori-lsm/how-it-works/compaction-lifecycle/","title":"Compaction Lifecycle","text":"<p>The full compaction process: slot selection via bandit scheduler, K-way merge, heat updates, and metrics.</p>"},{"location":"crates/nori-lsm/how-it-works/compaction-lifecycle/#overview","title":"Overview","text":"<p>Compaction is the process of merging sorted runs within a slot to reduce read amplification and reclaim space.</p> <p>ATLL's innovation: Use multi-armed bandits to select which slot to compact, balancing exploration (try all slots) vs exploitation (compact high-reward slots).</p> <p>Key properties: - Adaptive slot selection: Epsilon-greedy + UCB (Upper Confidence Bound) - K-way merge: Merge up to K runs per slot (K varies by heat) - Heat tracking: Update EWMA scores after each compaction - Parallel execution: Compact multiple slots concurrently - Observable: VizEvent emissions for dashboard</p>"},{"location":"crates/nori-lsm/how-it-works/compaction-lifecycle/#compaction-trigger","title":"Compaction Trigger","text":"<p>Compaction runs continuously in background threads:</p> <pre><code>pub async fn compaction_loop(mut lsm: LSM) -&gt; Result&lt;()&gt; {\n    loop {\n        // 1. Check if compaction needed\n        if !lsm.should_compact().await? {\n            tokio::time::sleep(Duration::from_secs(1)).await;\n            continue;\n        }\n\n        // 2. Select slot via bandit scheduler\n        let slot_id = lsm.scheduler.select_slot();\n\n        // 3. Compact slot\n        lsm.compact_slot(slot_id).await?;\n\n        // 4. Update bandit reward\n        let reward = lsm.calculate_reward(slot_id);\n        lsm.scheduler.update(slot_id, reward);\n    }\n}\n</code></pre> <p>Trigger conditions: - L0 count &gt; 4 (reduce read amplification) - Slot run count &gt; k_max (enforce K-way fanout limit) - Manual trigger via API</p>"},{"location":"crates/nori-lsm/how-it-works/compaction-lifecycle/#bandit-scheduler-slot-selection","title":"Bandit Scheduler: Slot Selection","text":""},{"location":"crates/nori-lsm/how-it-works/compaction-lifecycle/#epsilon-greedy-with-ucb","title":"Epsilon-Greedy with UCB","text":"<pre><code>pub struct BanditScheduler {\n    /// Bandit arms (one per slot)\n    arms: Vec&lt;BanditArm&gt;,\n\n    /// Exploration probability (default 0.1 = 10%)\n    epsilon: f64,\n\n    /// Total selections across all arms\n    total_selections: u64,\n}\n\npub struct BanditArm {\n    slot_id: u32,\n    avg_reward: f64,         // Exponential moving average\n    selection_count: u64,     // Times this arm was selected\n}\n\nimpl BanditScheduler {\n    pub fn select_slot(&amp;mut self) -&gt; u32 {\n        // 1. Epsilon-greedy: explore or exploit?\n        if rand::random::&lt;f64&gt;() &lt; self.epsilon {\n            // Exploration: random slot\n            return rand::random::&lt;u32&gt;() % self.arms.len() as u32;\n        }\n\n        // 2. Exploitation: choose arm with highest UCB score\n        let selected = self.arms\n            .iter()\n            .max_by(|a, b| {\n                self.ucb_score(a).partial_cmp(&amp;self.ucb_score(b)).unwrap()\n            })\n            .unwrap();\n\n        selected.slot_id\n    }\n\n    fn ucb_score(&amp;self, arm: &amp;BanditArm) -&gt; f64 {\n        let avg_reward = arm.avg_reward;\n        let exploration_bonus = if arm.selection_count == 0 {\n            f64::INFINITY  // Force exploration of unselected arms\n        } else {\n            let c = 2.0;  // Exploration constant\n            c * ((self.total_selections as f64).ln() / arm.selection_count as f64).sqrt()\n        };\n\n        avg_reward + exploration_bonus\n    }\n}\n</code></pre> <p>Formula: <pre><code>UCB(arm) = avg_reward + c \u00d7 sqrt(ln(total_selections) / arm_selections)\n\nWhere:\n  c = 2.0 (exploration constant, higher = more exploration)\n  total_selections = sum of all arm selections\n  arm_selections = times this arm was selected\n</code></pre></p> <p>Intuition: - avg_reward: Exploitation (pick best known arm) - exploration_bonus: Exploration (try under-explored arms) - Balance: c controls trade-off (c=0 \u2192 pure exploitation, c=\u221e \u2192 pure exploration)</p>"},{"location":"crates/nori-lsm/how-it-works/compaction-lifecycle/#reward-function","title":"Reward Function","text":"<p>Reward measures \"bang for buck\" of compaction:</p> <pre><code>fn calculate_reward(&amp;self, slot_id: u32) -&gt; f64 {\n    let slot = &amp;self.slots[slot_id as usize];\n\n    // 1. Latency reduction (how much faster are reads now?)\n    let old_ra = slot.old_run_count;  // Before compaction\n    let new_ra = slot.runs.len();     // After compaction\n    let latency_reduction = (old_ra - new_ra) as f64;\n\n    // 2. Heat score (how valuable is this slot?)\n    let heat = slot.heat_score as f64;\n\n    // 3. Bytes written (cost of compaction)\n    let bytes_written = slot.compaction_bytes_written as f64;\n\n    // 4. Reward = (latency reduction \u00d7 heat) / bytes written\n    (latency_reduction * heat) / (bytes_written / 1_000_000.0)  // Normalize to MB\n}\n</code></pre> <p>Example calculation:</p> <pre><code>Slot 5 (hot):\n  old_ra = 4 (4 runs before compaction)\n  new_ra = 1 (1 run after compaction)\n  latency_reduction = 4 - 1 = 3\n  heat_score = 0.9 (very hot)\n  bytes_written = 50 MB\n\n  reward = (3 \u00d7 0.9) / 50 = 0.054\n\nSlot 12 (cold):\n  old_ra = 4\n  new_ra = 3\n  latency_reduction = 1\n  heat_score = 0.1 (cold)\n  bytes_written = 50 MB\n\n  reward = (1 \u00d7 0.1) / 50 = 0.002\n\nConclusion: Slot 5 has 27x higher reward (should be prioritized)\n</code></pre> <p>Interpretation: - High reward: Hot slot with many runs (reduce RA significantly) - Low reward: Cold slot with few runs (little RA reduction, wasted I/O)</p>"},{"location":"crates/nori-lsm/how-it-works/compaction-lifecycle/#compaction-algorithm-k-way-merge","title":"Compaction Algorithm: K-Way Merge","text":""},{"location":"crates/nori-lsm/how-it-works/compaction-lifecycle/#step-1-select-runs-to-merge","title":"Step 1: Select Runs to Merge","text":"<pre><code>async fn select_runs_for_compaction(&amp;self, slot: &amp;Slot) -&gt; Vec&lt;SortedRun&gt; {\n    let mut candidates = vec![];\n\n    // 1. Add all L0 SSTables overlapping this slot\n    for l0_sst in &amp;self.l0_sstables {\n        if self.overlaps_slot(l0_sst, slot) {\n            candidates.push(l0_sst.clone());\n        }\n    }\n\n    // 2. Add all existing runs in this slot\n    candidates.extend(slot.runs.clone());\n\n    // 3. If count &gt; k_max, compact all (reduce to 1 run)\n    if candidates.len() &gt; slot.k_max {\n        return candidates;\n    }\n\n    // 4. Otherwise, skip compaction (not enough runs yet)\n    vec![]\n}\n</code></pre> <p>Example (Slot 3, k_max=2):</p> <pre><code>L0 SSTables:\n  SST-001: [0x00, 0x50) \u2192 Overlaps Slot 0, Slot 1 (not Slot 3)\n  SST-002: [0xC0, 0xE0) \u2192 Overlaps Slot 3 Yes\n  SST-003: [0xD0, 0xF0) \u2192 Overlaps Slot 3 Yes\n\nSlot 3 existing runs:\n  Run-042: [0xC0, 0xFF]\n\nCandidates:\n  [SST-002, SST-003, Run-042]\n  Count = 3\n\n3 &gt; k_max (2) \u2192 Compact all 3 runs into 1\n</code></pre>"},{"location":"crates/nori-lsm/how-it-works/compaction-lifecycle/#step-2-k-way-merge","title":"Step 2: K-Way Merge","text":"<p>Merge K sorted iterators into one sorted output:</p> <pre><code>async fn k_way_merge(&amp;self, runs: Vec&lt;SortedRun&gt;) -&gt; Result&lt;SSTable&gt; {\n    // 1. Open iterators for each run\n    let mut iters: Vec&lt;_&gt; = runs.iter()\n        .map(|run| run.sstable.iter())\n        .collect();\n\n    // 2. Initialize min-heap (priority queue)\n    let mut heap = BinaryHeap::new();\n    for (i, iter) in iters.iter_mut().enumerate() {\n        if let Some((key, value)) = iter.next().await? {\n            heap.push(HeapEntry {\n                key: key.clone(),\n                value: value.clone(),\n                iter_index: i,\n            });\n        }\n    }\n\n    // 3. Build output SSTable\n    let mut builder = SSTableBuilder::new(self.config.block_size, ...);\n\n    while let Some(entry) = heap.pop() {\n        // 4. Add to output\n        builder.add(entry.key.clone(), entry.value.clone())?;\n\n        // 5. Advance iterator\n        if let Some((key, value)) = iters[entry.iter_index].next().await? {\n            heap.push(HeapEntry {\n                key: key.clone(),\n                value: value.clone(),\n                iter_index: entry.iter_index,\n            });\n        }\n    }\n\n    // 6. Finalize SSTable\n    let sst_path = self.slot_path(slot_id).join(format!(\"{:06}.sst\", self.next_id()));\n    builder.finish(sst_path).await\n}\n</code></pre> <p>Complexity: - Time: O(N log K) where N = total entries, K = number of runs - Space: O(K) for heap (one entry per iterator)</p> <p>Example (3-way merge):</p> <pre><code>Run 0: [a:1, c:3, e:5]\nRun 1: [b:2, d:4, f:6]\nRun 2: [a:10, c:30, g:70]  (newer versions of a, c)\n\nInitial heap:\n  [a:1 (run 0), b:2 (run 1), a:10 (run 2)]\n\nIteration 1: Pop a:1\n  Check if newer version exists \u2192 a:10 in heap \u2192 skip a:1\n  Advance run 0 \u2192 push c:3\n  Heap: [b:2 (run 1), a:10 (run 2), c:3 (run 0)]\n\nIteration 2: Pop a:10\n  No newer version \u2192 write a:10\n  Advance run 2 \u2192 push c:30\n  Heap: [b:2 (run 1), c:3 (run 0), c:30 (run 2)]\n\nIteration 3: Pop b:2\n  No newer version \u2192 write b:2\n  Advance run 1 \u2192 push d:4\n  Heap: [c:3 (run 0), d:4 (run 1), c:30 (run 2)]\n\n... (continue until heap empty)\n\nOutput: [a:10, b:2, c:30, d:4, e:5, f:6, g:70]\n</code></pre> <p>Key insight: Newer runs shadow older values (Last-Write-Wins semantics).</p>"},{"location":"crates/nori-lsm/how-it-works/compaction-lifecycle/#step-3-tombstone-handling","title":"Step 3: Tombstone Handling","text":"<p>Deletions are represented as tombstones (sentinel values):</p> <pre><code>const TOMBSTONE: &amp;[u8] = &amp;[0xFF, 0xFF, 0xFF, 0xFF];\n\nasync fn k_way_merge(&amp;self, runs: Vec&lt;SortedRun&gt;) -&gt; Result&lt;SSTable&gt; {\n    // ... (merge logic)\n\n    while let Some(entry) = heap.pop() {\n        // Skip tombstones if no lower levels exist\n        if entry.value == TOMBSTONE &amp;&amp; !self.has_lower_levels(slot_id) {\n            continue;  // Drop tombstone (nothing to shadow)\n        }\n\n        builder.add(entry.key, entry.value)?;\n    }\n\n    // ...\n}\n</code></pre> <p>Tombstone GC rules: - Keep tombstone if lower levels may contain old value - Drop tombstone if this is the bottom-most run (nothing to shadow)</p> <p>Example:</p> <pre><code>Slot 5 (k_max=1, leveled):\n  Run 0: [a:1, b:TOMBSTONE, c:3]\n\nCompaction:\n  b:TOMBSTONE \u2192 No lower runs \u2192 Drop tombstone\n\nOutput: [a:1, c:3]\n</code></pre>"},{"location":"crates/nori-lsm/how-it-works/compaction-lifecycle/#heat-score-updates","title":"Heat Score Updates","text":"<p>After compaction, update heat scores using EWMA:</p> <pre><code>pub fn update_heat_on_compaction(&amp;mut self, slot_id: u32) {\n    let slot = &amp;mut self.slots[slot_id as usize];\n\n    // 1. Decay heat (compaction indicates access, not zero activity)\n    const ALPHA: f32 = 0.1;\n    slot.heat_score = ALPHA * 0.5 + (1.0 - ALPHA) * slot.heat_score;\n\n    // 2. Adjust k_max based on new heat score\n    slot.k_max = self.calculate_k_max(slot.heat_score);\n}\n\nfn calculate_k_max(&amp;self, heat_score: f32) -&gt; usize {\n    let k_global = self.config.k_global;  // Default 4\n    1 + ((1.0 - heat_score) * (k_global - 1) as f32) as usize\n}\n</code></pre> <p>Example:</p> <pre><code>Before compaction:\n  heat_score = 0.8 (hot)\n  k_max = 1 + (1 - 0.8) \u00d7 3 = 1 (leveled)\n\nAfter compaction (no new reads):\n  heat_score = 0.1 \u00d7 0.5 + 0.9 \u00d7 0.8 = 0.77\n  k_max = 1 + (1 - 0.77) \u00d7 3 = 1 (still leveled)\n\nAfter 10 compactions with no reads:\n  heat_score \u2192 0.5 (decayed)\n  k_max = 1 + (1 - 0.5) \u00d7 3 = 2 (hybrid)\n</code></pre> <p>Heat evolution: - Reads \u2192 increase heat (towards 1.0) - Compactions without reads \u2192 decay heat (towards 0.0) - Balanced workload \u2192 stabilize at intermediate heat</p>"},{"location":"crates/nori-lsm/how-it-works/compaction-lifecycle/#manifest-update-atomic-swap","title":"Manifest Update (Atomic Swap)","text":"<p>After compaction completes, update manifest atomically:</p> <pre><code>async fn finalize_compaction(&amp;mut self, slot_id: u32, new_run: SortedRun) -&gt; Result&lt;()&gt; {\n    // 1. Lock slot (prevent concurrent compactions)\n    let _guard = self.slots[slot_id as usize].lock.lock().await;\n\n    // 2. Remove old runs from slot\n    let old_runs = std::mem::take(&amp;mut self.slots[slot_id as usize].runs);\n\n    // 3. Add new run\n    self.slots[slot_id as usize].runs.push(new_run.clone());\n\n    // 4. Update manifest (atomic write)\n    self.manifest.update_slot(slot_id, vec![new_run]).await?;\n\n    // 5. Delete old SSTables (reference counting)\n    for run in old_runs {\n        self.delete_sstable(run.sstable_id).await?;\n    }\n\n    Ok(())\n}\n</code></pre> <p>Atomicity: Manifest update is atomic (write to temp file, fsync, rename).</p> <p>Crash safety: - Crash before manifest update \u2192 old runs still valid, new run invisible - Crash after manifest update \u2192 new run visible, old runs deleted on recovery</p>"},{"location":"crates/nori-lsm/how-it-works/compaction-lifecycle/#write-amplification-calculation","title":"Write Amplification Calculation","text":"<p>Track WA per slot and overall:</p> <pre><code>pub struct CompactionMetrics {\n    /// Total bytes written by compactions\n    bytes_written: u64,\n\n    /// Total bytes written by user (put operations)\n    user_bytes_written: u64,\n}\n\nimpl CompactionMetrics {\n    pub fn write_amplification(&amp;self) -&gt; f64 {\n        if self.user_bytes_written == 0 {\n            return 0.0;\n        }\n\n        (self.bytes_written + self.user_bytes_written) as f64 / self.user_bytes_written as f64\n    }\n}\n</code></pre> <p>Example:</p> <pre><code>User writes: 1 GB (1000 MB)\nCompaction writes:\n  Slot 0 (hot, k_max=1): 500 MB (leveled, high WA)\n  Slot 1 (warm, k_max=2): 200 MB (hybrid)\n  Slot 2 (cold, k_max=4): 50 MB (tiered, low WA)\n  Total: 750 MB\n\nWA = (1000 + 750) / 1000 = 1.75 (1.75x)\n\nInterpretation: Each byte written by user causes 0.75 bytes of compaction I/O\n</code></pre> <p>Comparison: - Pure leveled (K=1 everywhere): WA = 40-100x - Pure tiered (K=8 everywhere): WA = 6-8x - ATLL (adaptive K): WA = 8-20x (balanced)</p>"},{"location":"crates/nori-lsm/how-it-works/compaction-lifecycle/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"crates/nori-lsm/how-it-works/compaction-lifecycle/#compaction-latency","title":"Compaction Latency","text":"<p>Benchmark (10 MB 4-way merge):</p> <pre><code>Phase                  Time      Percentage\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nOpen iterators         10ms      10%\nK-way merge            60ms      60%\nBloom filter rebuild   20ms      20%\nManifest update        10ms      10%\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nTotal                  100ms     100%\n</code></pre> <p>Throughput: 10 MB / 100ms = 100 MB/sec</p>"},{"location":"crates/nori-lsm/how-it-works/compaction-lifecycle/#bandit-scheduler-overhead","title":"Bandit Scheduler Overhead","text":"<p>Benchmark (select_slot call):</p> <pre><code>Operation              Latency (p50)   Latency (p95)\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nUCB score calculation  50ns            80ns\nMax search (16 slots)  200ns           300ns\nTotal                  250ns           380ns\n</code></pre> <p>Negligible overhead: 250ns per compaction (compaction takes 100ms+).</p>"},{"location":"crates/nori-lsm/how-it-works/compaction-lifecycle/#parallel-compaction-throughput","title":"Parallel Compaction Throughput","text":"<p>Benchmark (4 concurrent compactions on 4-core CPU):</p> <pre><code>Single-threaded: 100 MB/sec\n4 threads:       350 MB/sec (3.5x speedup, not 4x due to I/O contention)\n</code></pre> <p>Scalability: Near-linear up to 4 threads, then I/O bound.</p>"},{"location":"crates/nori-lsm/how-it-works/compaction-lifecycle/#observability","title":"Observability","text":"<p>Emit VizEvent for dashboard:</p> <pre><code>self.meter.emit(VizEvent::Compaction {\n    slot_id,\n    old_run_count: 4,\n    new_run_count: 1,\n    bytes_read: 50_000_000,\n    bytes_written: 48_000_000,\n    duration_ms: 100,\n    old_heat_score: 0.8,\n    new_heat_score: 0.77,\n    k_max: 1,\n});\n</code></pre> <p>Dashboard visualization:</p> <pre><code>Compaction Timeline:\n\n  Slot 0: \u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591 (100ms, 4\u21921 runs, heat=0.9)\n  Slot 1:     \u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591 (150ms, 3\u21921 runs, heat=0.7)\n  Slot 2:          \u2588\u2588\u2588\u2588 (80ms, 2\u21921 runs, heat=0.5)\n  Slot 3:              \u2588\u2588\u2588\u2588 (90ms, 4\u21923 runs, heat=0.2)\n          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192\n          Time (0-400ms)\n</code></pre>"},{"location":"crates/nori-lsm/how-it-works/compaction-lifecycle/#code-example-complete-compaction-flow","title":"Code Example: Complete Compaction Flow","text":"<pre><code>pub async fn compact_slot(&amp;mut self, slot_id: u32) -&gt; Result&lt;()&gt; {\n    let slot = &amp;self.slots[slot_id as usize];\n\n    // 1. Select runs to merge\n    let runs = self.select_runs_for_compaction(slot).await?;\n    if runs.is_empty() {\n        return Ok(());  // Nothing to compact\n    }\n\n    // 2. K-way merge\n    let start = Instant::now();\n    let new_sst = self.k_way_merge(runs.clone()).await?;\n    let duration = start.elapsed();\n\n    // 3. Calculate metrics\n    let bytes_read: u64 = runs.iter().map(|r| r.size).sum();\n    let bytes_written = new_sst.size;\n\n    // 4. Update slot\n    let old_run_count = slot.runs.len();\n    self.finalize_compaction(slot_id, new_sst).await?;\n\n    // 5. Update heat\n    self.update_heat_on_compaction(slot_id);\n\n    // 6. Emit observability event\n    self.meter.emit(VizEvent::Compaction {\n        slot_id,\n        old_run_count,\n        new_run_count: 1,\n        bytes_read,\n        bytes_written,\n        duration_ms: duration.as_millis() as u64,\n        old_heat_score: slot.heat_score,\n        new_heat_score: self.slots[slot_id as usize].heat_score,\n        k_max: self.slots[slot_id as usize].k_max,\n    });\n\n    Ok(())\n}\n</code></pre>"},{"location":"crates/nori-lsm/how-it-works/compaction-lifecycle/#summary","title":"Summary","text":"<p>Compaction lifecycle merges runs to reduce read amplification:</p> <ol> <li>Trigger: L0 count &gt; 4 or slot run count &gt; k_max</li> <li>Bandit scheduler: Epsilon-greedy + UCB selects slot</li> <li>K-way merge: Merge K sorted runs into 1 (O(N log K))</li> <li>Manifest update: Atomic swap of old \u2192 new runs</li> <li>Heat update: EWMA decay, adjust k_max</li> <li>Metrics: Track WA, RA, reward</li> </ol> <p>Performance: - Compaction throughput: 100 MB/sec single-threaded - Scheduler overhead: 250ns per selection - Write amplification: 8-20x (vs 40-100x for pure leveled)</p> <p>Next: Snapshot Process - Consistent backups</p> <p>Last Updated: 2025-10-31 See Also: Bandit Scheduler, Adaptive K-Way Fanout</p>"},{"location":"crates/nori-lsm/how-it-works/flush-process/","title":"Flush Process","text":"<p>How memtables are flushed to L0 SSTables: sorting, serialization, bloom filter generation, and atomic swaps.</p>"},{"location":"crates/nori-lsm/how-it-works/flush-process/#overview","title":"Overview","text":"<p>The flush process converts an immutable memtable (in-memory skiplist) into an L0 SSTable (on-disk sorted file).</p> <p>Key properties: - Sorted iteration: Skiplist already sorted, no additional sort needed - Bloom filter: Generated during iteration (0.01 false positive rate) - Atomic swap: New SSTable made visible atomically via manifest update - WAL cleanup: Old WAL segments deleted after successful flush - Async execution: Flush runs in background, doesn't block writes</p>"},{"location":"crates/nori-lsm/how-it-works/flush-process/#flush-lifecycle","title":"Flush Lifecycle","text":"<pre><code>sequenceDiagram\n    participant Write as Write Thread\n    participant Memtable as Active Memtable\n    participant Immutable as Immutable Memtable\n    participant Flush as Flush Task (async)\n    participant Disk as L0 SSTable\n\n    Write-&gt;&gt;Memtable: put(key, value)\n    Memtable-&gt;&gt;Memtable: size &gt; 64 MB?\n    Memtable-&gt;&gt;Immutable: Rotate (make immutable)\n    Memtable-&gt;&gt;Flush: Spawn flush task\n    Flush-&gt;&gt;Immutable: Iterate sorted entries\n    Flush-&gt;&gt;Disk: Write SSTable blocks\n    Flush-&gt;&gt;Disk: Write bloom filter\n    Flush-&gt;&gt;Disk: Write index\n    Flush-&gt;&gt;Disk: fsync\n    Flush-&gt;&gt;Manifest: Add L0 SSTable atomically\n    Flush-&gt;&gt;Immutable: Drop memtable</code></pre> <p>Duration: ~200ms for 64 MB memtable (100K entries)</p>"},{"location":"crates/nori-lsm/how-it-works/flush-process/#step-by-step-algorithm","title":"Step-by-Step Algorithm","text":""},{"location":"crates/nori-lsm/how-it-works/flush-process/#step-1-trigger-flush","title":"Step 1: Trigger Flush","text":"<p>Flush is triggered when memtable size exceeds threshold:</p> <pre><code>async fn check_and_flush(&amp;mut self) -&gt; Result&lt;()&gt; {\n    // 1. Check if any immutable memtables are queued\n    if self.immutable_memtables.is_empty() {\n        return Ok(());\n    }\n\n    // 2. Take oldest immutable memtable\n    let memtable = self.immutable_memtables.remove(0);\n\n    // 3. Spawn flush task (async)\n    let lsm = self.clone();\n    tokio::spawn(async move {\n        lsm.flush_memtable(memtable).await\n    });\n\n    Ok(())\n}\n</code></pre> <p>Timing: - Rotation: ~1\u03bcs (pointer swap) - Spawn task: ~1\u03bcs (tokio overhead) - Total trigger time: ~2\u03bcs (doesn't block writes)</p>"},{"location":"crates/nori-lsm/how-it-works/flush-process/#step-2-sort-already-sorted","title":"Step 2: Sort (Already Sorted!)","text":"<p>Key insight: Skiplist maintains sorted order, so iteration is O(n), not O(n log n).</p> <pre><code>fn iter_sorted(memtable: &amp;Memtable) -&gt; impl Iterator&lt;Item = (Vec&lt;u8&gt;, Vec&lt;u8&gt;)&gt; {\n    // Skiplist iterator already yields sorted entries\n    memtable.skiplist.iter().map(|entry| {\n        (entry.key().clone(), entry.value().clone())\n    })\n}\n</code></pre> <p>Benefit: No additional sort needed, saves CPU time.</p> <p>Comparison to alternatives: - HashMap \u2192 Vec \u2192 sort: O(n log n) + memory allocation - BTreeMap \u2192 iter: O(n) but mutex contention - Skiplist \u2192 iter: O(n), lock-free</p>"},{"location":"crates/nori-lsm/how-it-works/flush-process/#step-3-build-sstable","title":"Step 3: Build SSTable","text":"<p>SSTable format (from nori-sstable):</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Data Blocks (sorted)      \u2502  \u2190 Key-value pairs (4 KB blocks)\n\u2502  [Block 0] [Block 1] ...   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Index (offsets)           \u2502  \u2190 Block offsets + first key\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Bloom Filter              \u2502  \u2190 Bit array (0.01 FPR)\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Footer (metadata)         \u2502  \u2190 Index offset, bloom offset\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Build process:</p> <pre><code>async fn build_sstable(&amp;self, memtable: &amp;Memtable) -&gt; Result&lt;SSTHandle&gt; {\n    // 1. Create SSTable builder\n    let mut builder = SSTableBuilder::new(\n        self.config.block_size,        // 4 KB\n        self.config.compression,       // LZ4\n        self.config.bloom_fpr,         // 0.01\n    );\n\n    // 2. Iterate memtable in sorted order\n    for (key, value) in memtable.iter() {\n        builder.add(key, value)?;\n    }\n\n    // 3. Finalize SSTable (write to disk)\n    let sst_path = self.l0_path.join(format!(\"{:06}.sst\", self.next_sst_id()));\n    let handle = builder.finish(sst_path).await?;\n\n    Ok(handle)\n}\n</code></pre> <p>Timing breakdown (64 MB memtable): - Iteration: 50ms (100K entries \u00d7 500ns each) - Block serialization: 80ms (16K blocks \u00d7 5\u03bcs each) - Bloom filter: 40ms (100K inserts \u00d7 400ns each) - Index build: 10ms - Disk write: 20ms (64 MB / 3 GB/sec SSD) - Total: ~200ms</p>"},{"location":"crates/nori-lsm/how-it-works/flush-process/#step-4-generate-bloom-filter","title":"Step 4: Generate Bloom Filter","text":"<p>Bloom filter is built incrementally during iteration:</p> <pre><code>pub struct BloomFilter {\n    bits: Vec&lt;u64&gt;,         // Bit array\n    num_hashes: usize,      // Number of hash functions (k=7)\n    num_bits: usize,        // Total bits (m = 125 KB for 100K keys)\n}\n\nimpl BloomFilter {\n    pub fn insert(&amp;mut self, key: &amp;[u8]) {\n        let hash1 = xxhash64(key, seed: 0);\n        let hash2 = xxhash64(key, seed: 1);\n\n        // Double hashing: h_i = hash1 + i * hash2 (mod m)\n        for i in 0..self.num_hashes {\n            let bit_index = (hash1.wrapping_add(i as u64 * hash2)) % self.num_bits as u64;\n            self.set_bit(bit_index as usize);\n        }\n    }\n\n    fn set_bit(&amp;mut self, index: usize) {\n        let word = index / 64;\n        let bit = index % 64;\n        self.bits[word] |= 1u64 &lt;&lt; bit;\n    }\n}\n</code></pre> <p>Parameters (for 100K keys, 0.01 FPR): - Bits per key: <code>m/n = -ln(p) / (ln(2)^2) = 9.6 bits/key</code> - Total bits: <code>100K \u00d7 9.6 = 960K bits = 120 KB</code> - Hash functions: <code>k = (m/n) \u00d7 ln(2) = 6.65 \u2248 7</code></p> <p>Performance: - Insert time: 7 hashes \u00d7 50ns/hash = 350ns per key - Total bloom build: 100K \u00d7 350ns = 35ms</p>"},{"location":"crates/nori-lsm/how-it-works/flush-process/#step-5-write-to-disk","title":"Step 5: Write to Disk","text":"<p>Write order (critical for crash safety):</p> <pre><code>async fn write_sstable(&amp;self, builder: SSTableBuilder) -&gt; Result&lt;PathBuf&gt; {\n    let path = self.temp_path();  // /tmp/000042.sst.tmp\n\n    // 1. Write data blocks\n    for block in builder.blocks {\n        file.write_all(&amp;block.data).await?;\n    }\n\n    // 2. Write index\n    file.write_all(&amp;builder.index.serialize()).await?;\n\n    // 3. Write bloom filter\n    file.write_all(&amp;builder.bloom.serialize()).await?;\n\n    // 4. Write footer (points to index and bloom)\n    file.write_all(&amp;builder.footer.serialize()).await?;\n\n    // 5. Fsync (durability)\n    file.sync_all().await?;\n\n    // 6. Atomic rename (make visible)\n    fs::rename(path, self.final_path()).await?;\n\n    Ok(self.final_path())\n}\n</code></pre> <p>Why temp file + rename? - Atomicity: Rename is atomic on POSIX systems - Crash safety: Partial writes to temp file are invisible - No torn reads: Readers never see incomplete SSTables</p>"},{"location":"crates/nori-lsm/how-it-works/flush-process/#step-6-update-manifest","title":"Step 6: Update Manifest","text":"<p>Manifest tracks all SSTables and their metadata:</p> <pre><code>pub struct Manifest {\n    /// L0 SSTables (unsorted, overlapping)\n    l0_sstables: Vec&lt;SSTableMetadata&gt;,\n\n    /// Slot metadata (guard keys, runs)\n    slots: Vec&lt;SlotMetadata&gt;,\n\n    /// Version counter (incremented on each update)\n    version: u64,\n}\n\nasync fn add_l0_sstable(&amp;mut self, sst: SSTableMetadata) -&gt; Result&lt;()&gt; {\n    // 1. Add to in-memory manifest\n    self.l0_sstables.push(sst);\n\n    // 2. Increment version\n    self.version += 1;\n\n    // 3. Write updated manifest to disk\n    self.persist().await?;\n\n    // 4. Emit VizEvent for observability\n    self.meter.emit(VizEvent::L0Flush {\n        sst_id: sst.id,\n        size_bytes: sst.size,\n        entry_count: sst.entry_count,\n        bloom_fpr: sst.bloom_fpr,\n    });\n\n    Ok(())\n}\n</code></pre> <p>Manifest persistence: - Format: JSON (human-readable, easy to debug) - Atomic write: Write to temp file, fsync, rename - Crash recovery: Read manifest on startup, replay if needed</p>"},{"location":"crates/nori-lsm/how-it-works/flush-process/#step-7-delete-old-wal","title":"Step 7: Delete Old WAL","text":"<p>After flush completes, WAL segments are no longer needed:</p> <pre><code>async fn delete_wal_segments(&amp;mut self, memtable_id: u64) -&gt; Result&lt;()&gt; {\n    // 1. Find WAL segments older than this memtable\n    let wal_segments = self.wal.segments_before(memtable_id);\n\n    // 2. Delete each segment\n    for segment in wal_segments {\n        fs::remove_file(segment.path()).await?;\n    }\n\n    // 3. Update WAL metadata\n    self.wal.truncate_before(memtable_id).await?;\n\n    Ok(())\n}\n</code></pre> <p>Safety: Only delete WAL after: 1. SSTable written to disk 2. SSTable fsynced 3. Manifest updated 4. Manifest fsynced</p> <p>Crash scenarios: - Crash before flush completes: WAL replays, memtable rebuilt - Crash after flush, before WAL delete: WAL replays, duplicate entries ignored (idempotent) - Crash after WAL delete: No replay needed, read from SSTable</p>"},{"location":"crates/nori-lsm/how-it-works/flush-process/#concurrency-and-blocking","title":"Concurrency and Blocking","text":""},{"location":"crates/nori-lsm/how-it-works/flush-process/#non-blocking-writes","title":"Non-Blocking Writes","text":"<p>Flush runs in background, doesn't block new writes:</p> <pre><code>Time  \u2502 Write Thread          \u2502 Flush Thread\n\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n0ms   \u2502 put(\"a\", \"1\")         \u2502\n1ms   \u2502 put(\"b\", \"2\")         \u2502\n2ms   \u2502 Memtable size &gt; 64 MB \u2502\n3ms   \u2502 Rotate memtable       \u2502 Spawn flush task\n4ms   \u2502 put(\"c\", \"3\")         \u2502 (new active memtable)\n5ms   \u2502 put(\"d\", \"4\")         \u2502 Iterate immutable memtable\n...   \u2502 ...                   \u2502 ...\n200ms \u2502 put(\"z\", \"100\")       \u2502 Write SSTable to disk\n201ms \u2502 put(\"x\", \"101\")       \u2502 Update manifest\n202ms \u2502 put(\"y\", \"102\")       \u2502 Delete WAL\n203ms \u2502                       \u2502 Flush complete\n</code></pre> <p>Key insight: Rotation is fast (&lt;10\u03bcs), so writes are only blocked briefly.</p>"},{"location":"crates/nori-lsm/how-it-works/flush-process/#backpressure","title":"Backpressure","text":"<p>If flushes are slower than writes, immutable memtables queue up:</p> <pre><code>fn put(&amp;mut self, key: Vec&lt;u8&gt;, value: Vec&lt;u8&gt;) -&gt; Result&lt;()&gt; {\n    // 1. Check backpressure\n    if self.immutable_memtables.len() &gt;= 2 {\n        // Too many immutable memtables, block writes\n        return Err(Error::MemoryPressure);\n    }\n\n    // 2. Proceed with write\n    self.active_memtable.insert(key, value);\n    Ok(())\n}\n</code></pre> <p>Backpressure zones: - Green (0-1 immutable): No delay - Yellow (1 immutable): Warn, no delay yet - Orange (2 immutable): Delay 100ms, give flush time to catch up - Red (2+ immutable): Reject writes</p>"},{"location":"crates/nori-lsm/how-it-works/flush-process/#performance-analysis","title":"Performance Analysis","text":""},{"location":"crates/nori-lsm/how-it-works/flush-process/#flush-throughput","title":"Flush Throughput","text":"<p>Benchmark (64 MB memtable, 100K entries):</p> <pre><code>Phase                  Time      Percentage\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nIteration              50ms      25%\nBlock serialization    80ms      40%\nBloom filter           40ms      20%\nDisk write             20ms      10%\nManifest update        10ms      5%\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nTotal                  200ms     100%\n</code></pre> <p>Throughput: 64 MB / 200ms = 320 MB/sec</p> <p>Bottleneck: Block serialization (40% of time)</p> <p>Optimization opportunity: - Use SIMD for prefix compression - Parallelize block writes (currently sequential) - Pre-allocate buffers to reduce allocation overhead</p>"},{"location":"crates/nori-lsm/how-it-works/flush-process/#flush-vs-compaction","title":"Flush vs Compaction","text":"Metric Flush Compaction Input 1 memtable (sorted) K runs (sorted) Output 1 L0 SSTable 1 merged run Sorting None (already sorted) K-way merge Bloom filter Build from scratch Rebuild (can't merge) Frequency Every 3 sec (at 20K writes/sec) Every 10-60 sec Duration 200ms 500ms - 8 sec (size-dependent) <p>Key difference: Flush is faster because skiplist is already sorted.</p>"},{"location":"crates/nori-lsm/how-it-works/flush-process/#edge-cases","title":"Edge Cases","text":""},{"location":"crates/nori-lsm/how-it-works/flush-process/#1-disk-full-during-flush","title":"1. Disk Full During Flush","text":"<p>Scenario: Disk runs out of space while writing SSTable.</p> <pre><code>async fn flush_memtable(&amp;mut self, memtable: Memtable) -&gt; Result&lt;()&gt; {\n    match self.write_sstable(&amp;memtable).await {\n        Ok(sst_path) =&gt; {\n            self.manifest.add_l0(sst_path).await?;\n            Ok(())\n        }\n        Err(Error::DiskFull) =&gt; {\n            // Keep memtable in immutable list\n            self.immutable_memtables.push(memtable);\n\n            // Enter backpressure mode\n            self.pressure_zone = PressureZone::Red;\n\n            Err(Error::DiskFull)\n        }\n        Err(e) =&gt; Err(e),\n    }\n}\n</code></pre> <p>Recovery: - Memtable kept in memory (not dropped) - Writes rejected until disk space freed - Operator intervention required (delete old SSTables, expand disk)</p>"},{"location":"crates/nori-lsm/how-it-works/flush-process/#2-crash-during-flush","title":"2. Crash During Flush","text":"<p>Scenario: Power loss while SSTable is being written.</p> <pre><code>State before crash:\n  Memtable: In-memory (64 MB)\n  WAL: Contains all entries\n  SSTable: Partially written (32 MB of 64 MB)\n  Manifest: Not updated (old version)\n\nState after recovery:\n  Memtable: Rebuilt from WAL replay\n  WAL: Replayed, memtable reconstructed\n  SSTable: Temp file deleted (incomplete)\n  Manifest: Old version (no reference to incomplete SSTable)\n\nResult: No data loss, flush retried\n</code></pre> <p>Why safe?: - WAL not deleted until flush completes - Temp file not visible to readers - Manifest not updated until fsync completes</p>"},{"location":"crates/nori-lsm/how-it-works/flush-process/#3-empty-memtable-flush","title":"3. Empty Memtable Flush","text":"<p>Scenario: Memtable rotated but contains only tombstones (all deletes).</p> <pre><code>async fn flush_memtable(&amp;mut self, memtable: Memtable) -&gt; Result&lt;()&gt; {\n    if memtable.len() == 0 {\n        // Empty memtable, skip flush\n        return Ok(());\n    }\n\n    // Proceed with flush\n    self.write_sstable(&amp;memtable).await\n}\n</code></pre> <p>Benefit: Skip I/O for empty memtables (e.g., after delete-heavy workload).</p>"},{"location":"crates/nori-lsm/how-it-works/flush-process/#code-example-complete-flush-implementation","title":"Code Example: Complete Flush Implementation","text":"<pre><code>use nori_sstable::SSTableBuilder;\nuse tokio::fs;\n\npub struct FlushTask {\n    memtable: Arc&lt;Memtable&gt;,\n    l0_dir: PathBuf,\n    next_id: u64,\n    config: Config,\n}\n\nimpl FlushTask {\n    pub async fn run(self) -&gt; Result&lt;SSTableMetadata&gt; {\n        // 1. Create SSTable builder\n        let mut builder = SSTableBuilder::new(\n            self.config.block_size,\n            self.config.compression,\n            self.config.bloom_fpr,\n        );\n\n        // 2. Iterate memtable (already sorted)\n        let mut entry_count = 0;\n        for (key, value) in self.memtable.iter() {\n            builder.add(key, value)?;\n            entry_count += 1;\n        }\n\n        // 3. Write to temp file\n        let temp_path = self.l0_dir.join(format!(\"{:06}.sst.tmp\", self.next_id));\n        builder.write(&amp;temp_path).await?;\n\n        // 4. Fsync\n        let file = fs::OpenOptions::new()\n            .write(true)\n            .open(&amp;temp_path)\n            .await?;\n        file.sync_all().await?;\n\n        // 5. Atomic rename\n        let final_path = self.l0_dir.join(format!(\"{:06}.sst\", self.next_id));\n        fs::rename(&amp;temp_path, &amp;final_path).await?;\n\n        // 6. Return metadata\n        Ok(SSTableMetadata {\n            id: self.next_id,\n            path: final_path,\n            size: self.memtable.total_size(),\n            entry_count,\n            min_key: builder.min_key().clone(),\n            max_key: builder.max_key().clone(),\n            bloom_fpr: self.config.bloom_fpr,\n        })\n    }\n}\n</code></pre>"},{"location":"crates/nori-lsm/how-it-works/flush-process/#summary","title":"Summary","text":"<p>Flush process transforms memtables into durable L0 SSTables:</p> <ol> <li>Trigger: Memtable size exceeds 64 MB, rotation + spawn flush task</li> <li>Iteration: Sorted skiplist iteration (O(n), no additional sort)</li> <li>Build: Serialize blocks, generate bloom filter, write index</li> <li>Persist: Write to temp file, fsync, atomic rename</li> <li>Manifest: Update L0 list atomically</li> <li>Cleanup: Delete old WAL segments</li> </ol> <p>Performance: - Flush latency: ~200ms for 64 MB memtable - Throughput: 320 MB/sec - Non-blocking: Writes continue during flush</p> <p>Next: Slot Routing - How keys are mapped to slots</p> <p>Last Updated: 2025-10-31 See Also: Memtable Management, Slot Routing</p>"},{"location":"crates/nori-lsm/how-it-works/memtable-management/","title":"Memtable Management","text":"<p>The in-memory skiplist: writes, rotation triggers, concurrent access, and memory accounting.</p>"},{"location":"crates/nori-lsm/how-it-works/memtable-management/#overview","title":"Overview","text":"<p>The memtable is nori-lsm's write buffer: an in-memory data structure that accepts all writes before they're flushed to disk as SSTables.</p> <p>Key properties: - Data structure: Lock-free skiplist (O(log n) writes, O(log n) reads) - Bounded size: Default 64 MB, configurable - Sorted: Keys maintained in lexicographic order - Concurrent: Lock-free reads, synchronized writes - Two-tier: Active (mutable) + Immutable (flushing)</p>"},{"location":"crates/nori-lsm/how-it-works/memtable-management/#memtable-lifecycle","title":"Memtable Lifecycle","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; Active: New memtable created\n    Active --&gt; Immutable: Size threshold reached\n    Immutable --&gt; Flushing: Flush task started\n    Flushing --&gt; [*]: SSTable written, memtable dropped\n\n    Active: Accepts writes\n    Active: Serves reads\n    Immutable: Read-only\n    Immutable: Waiting for flush\n    Flushing: Sorted iteration\n    Flushing: SSTable serialization</code></pre> <p>States: 1. Active: Current write target, accepts <code>put()</code> and <code>delete()</code> 2. Immutable: Read-only, waiting to be flushed 3. Flushing: Background task serializing to SSTable 4. Dropped: Flushed successfully, memory reclaimed</p>"},{"location":"crates/nori-lsm/how-it-works/memtable-management/#skiplist-data-structure","title":"Skiplist Data Structure","text":"<p>nori-lsm uses <code>crossbeam-skiplist</code>, a lock-free concurrent skiplist.</p>"},{"location":"crates/nori-lsm/how-it-works/memtable-management/#why-skiplist","title":"Why Skiplist?","text":"<p>Alternatives considered:</p> Data Structure Write Complexity Read Complexity Sorted? Concurrent? Chosen? Skiplist O(log n) O(log n) Yes Lock-free Yes HashMap O(1) O(1) No Sharded No BTreeMap O(log n) O(log n) Yes Mutex No RBTree O(log n) O(log n) Yes Mutex No <p>Why skiplist won: -  Lock-free: No contention on reads (critical for LSMs) -  Sorted: Enables efficient range scans -  Fast iteration: O(n) scan for flush (no rebalancing needed) -  Predictable: Probabilistic balancing, no worst-case rotations</p>"},{"location":"crates/nori-lsm/how-it-works/memtable-management/#skiplist-structure","title":"Skiplist Structure","text":"<pre><code>Level 3:  1 -----------------&gt; 20 ------------------------&gt; \u221e\n          \u2193                    \u2193                            \u2193\nLevel 2:  1 --------&gt; 10 ----&gt; 20 --------&gt; 30 ----------&gt; \u221e\n          \u2193           \u2193        \u2193            \u2193              \u2193\nLevel 1:  1 -&gt; 5 ---&gt; 10 ----&gt; 20 -&gt; 25 -&gt; 30 -&gt; 35 -----&gt; \u221e\n          \u2193    \u2193      \u2193        \u2193     \u2193     \u2193     \u2193        \u2193\nLevel 0:  1 -&gt; 5 -&gt; 8 -&gt; 10 -&gt; 20 -&gt; 25 -&gt; 30 -&gt; 35 -&gt; 40 -&gt; \u221e\n\n(Pointers shown as arrows, keys shown as numbers)\n</code></pre> <p>Search for key 25: 1. Start at Level 3, head node (1) 2. 1 \u2192 20 (20 \u2264 25, continue) 3. 20 \u2192 \u221e (\u221e &gt; 25, drop to Level 2) 4. 20 \u2192 30 (30 &gt; 25, drop to Level 1) 5. 20 \u2192 25 (found!)</p> <p>Expected hops: O(log n) = 3 hops for 100 keys, 7 hops for 10K keys</p>"},{"location":"crates/nori-lsm/how-it-works/memtable-management/#write-operations","title":"Write Operations","text":""},{"location":"crates/nori-lsm/how-it-works/memtable-management/#put-insert-or-update","title":"Put (Insert or Update)","text":"<pre><code>pub fn put(&amp;self, key: Vec&lt;u8&gt;, value: Vec&lt;u8&gt;) -&gt; Result&lt;()&gt; {\n    // 1. Calculate entry size\n    let entry_size = key.len() + value.len() + 8;  // 8 bytes overhead\n\n    // 2. Check if rotation needed (before insert)\n    if self.active_size.load(Ordering::Relaxed) + entry_size &gt; self.config.memtable_max {\n        self.rotate_memtable()?;\n    }\n\n    // 3. Insert into skiplist (lock-free)\n    self.active_memtable.insert(key.clone(), value);\n\n    // 4. Update size counter (atomic)\n    self.active_size.fetch_add(entry_size, Ordering::Relaxed);\n\n    // 5. Update write counter for heat tracking\n    self.total_writes.fetch_add(1, Ordering::Relaxed);\n\n    Ok(())\n}\n</code></pre> <p>Concurrency: - Multiple threads can <code>put()</code> concurrently - Skiplist handles lock-free insertion - Only <code>active_size</code> counter needs atomic ops</p>"},{"location":"crates/nori-lsm/how-it-works/memtable-management/#delete-tombstone","title":"Delete (Tombstone)","text":"<pre><code>pub fn delete(&amp;self, key: Vec&lt;u8&gt;) -&gt; Result&lt;()&gt; {\n    // Deletions are just puts with a tombstone marker\n    let tombstone = vec![0xFF, 0xFF, 0xFF, 0xFF];  // Sentinel value\n    self.put(key, tombstone)\n}\n</code></pre> <p>Why tombstones? - LSMs are immutable after flush - Can't delete from already-written SSTables - Tombstones shadow older values during compaction - Eventually garbage collected when no lower levels remain</p>"},{"location":"crates/nori-lsm/how-it-works/memtable-management/#rotation-triggers","title":"Rotation Triggers","text":"<p>Memtable rotation happens when size exceeds threshold:</p>"},{"location":"crates/nori-lsm/how-it-works/memtable-management/#size-based-rotation-primary","title":"Size-Based Rotation (Primary)","text":"<pre><code>fn should_rotate(&amp;self) -&gt; bool {\n    self.active_size.load(Ordering::Relaxed) &gt;= self.config.memtable_max\n}\n</code></pre> <p>Default threshold: 64 MB</p> <p>Rationale: - Not too small: Reduce flush overhead (200ms per flush) - Not too large: Avoid long recovery time (scan 64 MB skiplist in ~100ms) - Power-of-2: Cache-friendly, easier to reason about</p>"},{"location":"crates/nori-lsm/how-it-works/memtable-management/#rotation-process","title":"Rotation Process","text":"<pre><code>fn rotate_memtable(&amp;mut self) -&gt; Result&lt;()&gt; {\n    // 1. Lock rotation mutex (prevents concurrent rotations)\n    let _guard = self.rotation_lock.lock();\n\n    // 2. Swap active memtable\n    let old_active = std::mem::replace(\n        &amp;mut self.active_memtable,\n        SkipList::new(),  // New empty memtable\n    );\n\n    // 3. Move to immutable list\n    self.immutable_memtables.push(old_active);\n\n    // 4. Reset size counter\n    self.active_size.store(0, Ordering::Relaxed);\n\n    // 5. Spawn flush task (async)\n    let immutable = self.immutable_memtables[0].clone();\n    tokio::spawn(async move {\n        self.flush_memtable(immutable).await?;\n    });\n\n    Ok(())\n}\n</code></pre> <p>Key insight: Rotation is fast (&lt;10\u03bcs) because: - No data copying (just pointer swap) - New memtable starts empty - Flush happens asynchronously in background</p>"},{"location":"crates/nori-lsm/how-it-works/memtable-management/#active-vs-immutable-memtables","title":"Active vs Immutable Memtables","text":"<p>nori-lsm maintains two classes of memtables:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     Active Memtable (1 instance)     \u2502\n\u2502  - Accepts writes                    \u2502\n\u2502  - Serves reads                      \u2502\n\u2502  - Bounded by memtable_max           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2193 (rotation)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Immutable Memtables (0-2 instances) \u2502\n\u2502  - Read-only                         \u2502\n\u2502  - Waiting to flush                  \u2502\n\u2502  - Queued for background task        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2193 (flush)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         L0 SSTables (on disk)        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Why allow multiple immutable memtables? - Burst tolerance: If flushes are slow (disk I/O), queue up to 2 immutable memtables - Backpressure: If 2 immutable memtables exist, block writes until flush completes - Memory bound: At most 3\u00d7memtable_max memory usage (1 active + 2 immutable)</p>"},{"location":"crates/nori-lsm/how-it-works/memtable-management/#read-path-across-memtables","title":"Read Path Across Memtables","text":"<pre><code>pub fn get(&amp;self, key: &amp;[u8]) -&gt; Option&lt;Vec&lt;u8&gt;&gt; {\n    // 1. Check active memtable first (most recent)\n    if let Some(value) = self.active_memtable.get(key) {\n        return Some(value.clone());\n    }\n\n    // 2. Check immutable memtables (newest to oldest)\n    for memtable in self.immutable_memtables.iter().rev() {\n        if let Some(value) = memtable.get(key) {\n            return Some(value.clone());\n        }\n    }\n\n    // 3. Not in memtables, check L0 and slots\n    None\n}\n</code></pre> <p>Time complexity: - Active memtable: O(log n) - Immutable memtables: O(k \u00d7 log n) where k = 0-2 - Total: O(log n) in common case</p>"},{"location":"crates/nori-lsm/how-it-works/memtable-management/#memory-accounting","title":"Memory Accounting","text":"<p>Accurate memory tracking is critical for rotation triggers and backpressure.</p>"},{"location":"crates/nori-lsm/how-it-works/memtable-management/#entry-size-calculation","title":"Entry Size Calculation","text":"<pre><code>fn entry_size(key: &amp;[u8], value: &amp;[u8]) -&gt; usize {\n    // Key size\n    key.len() +\n    // Value size\n    value.len() +\n    // Skiplist node overhead (pointer + level array)\n    std::mem::size_of::&lt;usize&gt;() * 4  // 4 pointers average (levels 0-3)\n}\n</code></pre> <p>Why 4 pointers? - Skiplist levels are probabilistic: \u00bd chance of level 1, \u00bc for level 2, etc. - Expected value: 1 + 0.5 + 0.25 + 0.125 + ... \u2248 2 - Conservative estimate: 4 pointers (32 bytes on 64-bit)</p>"},{"location":"crates/nori-lsm/how-it-works/memtable-management/#size-tracking","title":"Size Tracking","text":"<pre><code>pub struct Memtable {\n    skiplist: SkipList&lt;Vec&lt;u8&gt;, Vec&lt;u8&gt;&gt;,\n\n    /// Atomic counter of total bytes (keys + values + overhead)\n    size: AtomicUsize,\n\n    /// Number of entries (for metrics)\n    entry_count: AtomicU64,\n}\n\nimpl Memtable {\n    pub fn insert(&amp;self, key: Vec&lt;u8&gt;, value: Vec&lt;u8&gt;) {\n        let entry_size = Self::entry_size(&amp;key, &amp;value);\n\n        self.skiplist.insert(key, value);\n\n        // Update counters atomically\n        self.size.fetch_add(entry_size, Ordering::Relaxed);\n        self.entry_count.fetch_add(1, Ordering::Relaxed);\n    }\n\n    pub fn total_size(&amp;self) -&gt; usize {\n        self.size.load(Ordering::Relaxed)\n    }\n}\n</code></pre> <p>Why <code>Ordering::Relaxed</code>? - Size counter doesn't need strict ordering (approximate is fine) - Rotation check happens with mutex (sequential consistency guaranteed there) - Relaxed atomics are faster (no memory fence overhead)</p>"},{"location":"crates/nori-lsm/how-it-works/memtable-management/#concurrent-access-patterns","title":"Concurrent Access Patterns","text":""},{"location":"crates/nori-lsm/how-it-works/memtable-management/#single-writer-multiple-readers-swmr","title":"Single Writer, Multiple Readers (SWMR)","text":"<p>Write path: <pre><code>// Thread 1: put(\"a\", \"1\")\nself.active_memtable.insert(\"a\", \"1\");  // Lock-free\n\n// Thread 2: put(\"b\", \"2\") (concurrent)\nself.active_memtable.insert(\"b\", \"2\");  // Lock-free, no contention\n</code></pre></p> <p>Read path: <pre><code>// Thread 3: get(\"a\")\nself.active_memtable.get(\"a\");  // Lock-free, concurrent with writes\n\n// Thread 4: get(\"c\")\nself.active_memtable.get(\"c\");  // Lock-free, concurrent with everything\n</code></pre></p> <p>Rotation (rare): <pre><code>// Thread 1: Rotation triggered\nlet _guard = self.rotation_lock.lock();  // Mutex (blocks other rotations)\nself.active_memtable = new_memtable;     // Atomic pointer swap\ndrop(_guard);                            // Release lock\n</code></pre></p>"},{"location":"crates/nori-lsm/how-it-works/memtable-management/#linearizability","title":"Linearizability","text":"<p>Guarantee: All operations appear to execute atomically in some sequential order.</p> <p>Example: <pre><code>Thread 1: put(\"x\", \"1\")  [starts at t=0, completes at t=5]\nThread 2: get(\"x\")       [starts at t=3, completes at t=7]\n\nLinearization point for put: t=2 (insert into skiplist)\nLinearization point for get: t=4 (skiplist search)\n\nBecause t=4 &gt; t=2, get MUST see \"1\" (not None)\n</code></pre></p> <p>Crossbeam-skiplist guarantees: - Inserts are linearizable at the moment the node is visible - Reads are linearizable at the moment the search completes - No torn reads (always see consistent key-value pairs)</p>"},{"location":"crates/nori-lsm/how-it-works/memtable-management/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"crates/nori-lsm/how-it-works/memtable-management/#write-performance","title":"Write Performance","text":"<p>Benchmark (64 MB memtable, 1 KB entries):</p> <pre><code>Operation        Latency (p50)   Latency (p95)   Throughput\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nput (no flush)   50ns            120ns           20M ops/sec\nput (with flush) 1.2ms           2.1ms           800 ops/sec\ndelete           50ns            120ns           20M ops/sec\n</code></pre> <p>Interpretation: - Memtable inserts are extremely fast (50ns = 20M ops/sec) - Flush dominates latency (1-2ms due to WAL fsync) - No performance difference between put and delete (both skiplist inserts)</p>"},{"location":"crates/nori-lsm/how-it-works/memtable-management/#memory-overhead","title":"Memory Overhead","text":"<p>Per-entry overhead:</p> <pre><code>Key: 16 bytes (e.g., \"user:12345678\")\nValue: 1 KB\nSkiplist overhead: 32 bytes (4 pointers \u00d7 8 bytes)\n\nTotal: 16 + 1024 + 32 = 1072 bytes\nOverhead: 32/1072 = 3%\n</code></pre> <p>Total memtable overhead: - 64 MB memtable with 1 KB entries: ~60K entries - Skiplist overhead: 60K \u00d7 32 bytes = 1.92 MB - Percentage: 1.92 / 64 = 3% overhead</p>"},{"location":"crates/nori-lsm/how-it-works/memtable-management/#rotation-overhead","title":"Rotation Overhead","text":"<p>Rotation time breakdown:</p> <pre><code>Lock acquisition:     50ns\nPointer swap:         10ns\nSize counter reset:   5ns\nSpawn flush task:     1\u03bcs\nTotal rotation time:  ~1.1\u03bcs\n</code></pre> <p>Rotation frequency: - 64 MB memtable at 20K writes/sec (1 KB entries) - Time to fill: 64 MB / (20K \u00d7 1 KB) = 3.2 seconds - Rotations per hour: 3600 / 3.2 = 1,125 rotations/hour</p> <p>Impact: 1.1\u03bcs \u00d7 1,125 = 1.2ms overhead per hour (negligible)</p>"},{"location":"crates/nori-lsm/how-it-works/memtable-management/#edge-cases-and-error-handling","title":"Edge Cases and Error Handling","text":""},{"location":"crates/nori-lsm/how-it-works/memtable-management/#1-rotation-during-concurrent-writes","title":"1. Rotation During Concurrent Writes","text":"<p>Scenario: Thread A triggers rotation while Thread B is writing.</p> <pre><code>// Thread A\nif self.active_size &gt;= THRESHOLD {\n    self.rotate_memtable();  // Acquires rotation_lock\n}\n\n// Thread B (concurrent)\nself.active_memtable.insert(key, value);  // Which memtable?\n</code></pre> <p>Solution: Rotation lock ensures atomic swap.</p> <pre><code>fn put(&amp;self, key: Vec&lt;u8&gt;, value: Vec&lt;u8&gt;) -&gt; Result&lt;()&gt; {\n    loop {\n        let memtable = self.active_memtable.load(Ordering::Acquire);\n\n        if memtable.insert_if_active(key.clone(), value.clone()) {\n            return Ok(());\n        }\n\n        // Memtable rotated, retry with new active memtable\n    }\n}\n</code></pre>"},{"location":"crates/nori-lsm/how-it-works/memtable-management/#2-out-of-memory-during-rotation","title":"2. Out of Memory During Rotation","text":"<p>Scenario: 2 immutable memtables already queued, new rotation would exceed memory limit.</p> <pre><code>fn rotate_memtable(&amp;mut self) -&gt; Result&lt;()&gt; {\n    if self.immutable_memtables.len() &gt;= 2 {\n        // Block writes until flush completes\n        return Err(Error::MemoryLimitExceeded);\n    }\n\n    // Proceed with rotation\n}\n</code></pre> <p>Backpressure: - Red zone (memory pressure &gt; 90%): Reject writes - Orange zone (75-90%): Delay writes exponentially - Yellow zone (50-75%): Warn, continue</p>"},{"location":"crates/nori-lsm/how-it-works/memtable-management/#3-flush-failure","title":"3. Flush Failure","text":"<p>Scenario: Disk I/O error during flush.</p> <pre><code>async fn flush_memtable(&amp;mut self, memtable: Memtable) -&gt; Result&lt;()&gt; {\n    match self.write_sstable(memtable).await {\n        Ok(sst_path) =&gt; {\n            // Remove flushed memtable from immutable list\n            self.immutable_memtables.remove(0);\n            Ok(())\n        }\n        Err(e) =&gt; {\n            // Keep memtable in immutable list, retry later\n            log::error!(\"Flush failed: {}\", e);\n            Err(e)\n        }\n    }\n}\n</code></pre> <p>Retry policy: - Exponential backoff: 1s, 2s, 4s, 8s, ... - Max retries: 10 - After 10 failures: Shut down LSM (prevent data loss)</p>"},{"location":"crates/nori-lsm/how-it-works/memtable-management/#code-example-complete-memtable-implementation","title":"Code Example: Complete Memtable Implementation","text":"<pre><code>use crossbeam_skiplist::SkipMap;\nuse std::sync::atomic::{AtomicUsize, AtomicU64, Ordering};\nuse std::sync::{Arc, Mutex};\n\npub struct MemtableManager {\n    /// Currently active memtable (accepts writes)\n    active: Arc&lt;Memtable&gt;,\n\n    /// Immutable memtables (flushing or queued)\n    immutable: Vec&lt;Arc&lt;Memtable&gt;&gt;,\n\n    /// Rotation lock (prevents concurrent rotations)\n    rotation_lock: Mutex&lt;()&gt;,\n\n    /// Configuration\n    config: Config,\n}\n\npub struct Memtable {\n    /// Lock-free skiplist\n    skiplist: SkipMap&lt;Vec&lt;u8&gt;, Vec&lt;u8&gt;&gt;,\n\n    /// Total bytes (keys + values + overhead)\n    size: AtomicUsize,\n\n    /// Entry count\n    count: AtomicU64,\n}\n\nimpl Memtable {\n    pub fn new() -&gt; Self {\n        Self {\n            skiplist: SkipMap::new(),\n            size: AtomicUsize::new(0),\n            count: AtomicU64::new(0),\n        }\n    }\n\n    pub fn insert(&amp;self, key: Vec&lt;u8&gt;, value: Vec&lt;u8&gt;) {\n        let entry_size = key.len() + value.len() + 32;\n\n        self.skiplist.insert(key, value);\n        self.size.fetch_add(entry_size, Ordering::Relaxed);\n        self.count.fetch_add(1, Ordering::Relaxed);\n    }\n\n    pub fn get(&amp;self, key: &amp;[u8]) -&gt; Option&lt;Vec&lt;u8&gt;&gt; {\n        self.skiplist.get(key).map(|entry| entry.value().clone())\n    }\n\n    pub fn total_size(&amp;self) -&gt; usize {\n        self.size.load(Ordering::Relaxed)\n    }\n\n    pub fn len(&amp;self) -&gt; u64 {\n        self.count.load(Ordering::Relaxed)\n    }\n\n    /// Iterate in sorted order (for flush)\n    pub fn iter(&amp;self) -&gt; impl Iterator&lt;Item = (Vec&lt;u8&gt;, Vec&lt;u8&gt;)&gt; + '_ {\n        self.skiplist.iter().map(|entry| {\n            (entry.key().clone(), entry.value().clone())\n        })\n    }\n}\n</code></pre>"},{"location":"crates/nori-lsm/how-it-works/memtable-management/#summary","title":"Summary","text":"<p>Memtable management is critical for LSM write performance:</p> <ol> <li>Lock-free skiplist - 20M ops/sec throughput, O(log n) complexity</li> <li>Size-based rotation - 64 MB threshold balances flush overhead and recovery time</li> <li>Active + Immutable - Allows async flushing without blocking writes</li> <li>Atomic counters - Accurate memory tracking with minimal overhead</li> <li>Backpressure - Prevents OOM by rejecting writes when memory exhausted</li> </ol> <p>Next: Flush Process - How memtables become SSTables</p> <p>Last Updated: 2025-10-31 See Also: Write Path, Flush Process</p>"},{"location":"crates/nori-lsm/how-it-works/slot-routing/","title":"Slot Routing","text":"<p>How keys are mapped to slots using binary search on guard keys. Range queries and slot overlap detection.</p>"},{"location":"crates/nori-lsm/how-it-works/slot-routing/#overview","title":"Overview","text":"<p>Slot routing maps keys to slots (range shards) using fixed guard keys. This enables: - Per-range adaptation: Each slot chooses its own compaction strategy (K-max) - Parallel compaction: Compact multiple slots concurrently - Efficient range queries: Scan only slots overlapping [start, end)</p> <p>Key properties: - Deterministic: Same key always maps to same slot - Fast: Binary search O(log num_slots) = ~4 hops for 16 slots - Stable: Guard keys never change (unless manual rebalancing) - Range-preserving: Adjacent keys often in same slot (locality)</p>"},{"location":"crates/nori-lsm/how-it-works/slot-routing/#guard-key-structure","title":"Guard Key Structure","text":"<p>Slots are defined by <code>[guard_key_min, guard_key_max)</code> boundaries:</p> <pre><code>Slot 0:  [0x00, 0x40)  \u2190 Handles keys 0x00..=0x3F\nSlot 1:  [0x40, 0x80)  \u2190 Handles keys 0x40..=0x7F\nSlot 2:  [0x80, 0xC0)  \u2190 Handles keys 0x80..=0xBF\nSlot 3:  [0xC0, \u221e)     \u2190 Handles keys 0xC0..=0xFF\n</code></pre> <p>Invariants: 1. No gaps: Every key falls into exactly one slot 2. No overlaps: <code>slot[i].max = slot[i+1].min</code> 3. Sorted: <code>slot[i].min &lt; slot[i+1].min</code> for all i</p>"},{"location":"crates/nori-lsm/how-it-works/slot-routing/#point-query-routing","title":"Point Query Routing","text":""},{"location":"crates/nori-lsm/how-it-works/slot-routing/#binary-search-algorithm","title":"Binary Search Algorithm","text":"<pre><code>pub fn find_slot_for_key(&amp;self, key: &amp;[u8]) -&gt; u32 {\n    let mut left = 0;\n    let mut right = self.slots.len();\n\n    while left &lt; right {\n        let mid = (left + right) / 2;\n        let slot = &amp;self.slots[mid];\n\n        if key &lt; slot.guard_key_min.as_slice() {\n            right = mid;\n        } else if key &gt;= slot.guard_key_max.as_slice() {\n            left = mid + 1;\n        } else {\n            // Found: slot.min &lt;= key &lt; slot.max\n            return mid as u32;\n        }\n    }\n\n    panic!(\"No slot found for key (guard key invariant violated)\");\n}\n</code></pre> <p>Time complexity: O(log n) where n = number of slots</p> <p>Example (16 slots, searching for <code>key = 0x75</code>):</p> <pre><code>Iteration 1: left=0, right=16, mid=8\n  Slot 8: [0x80, 0x90)\n  0x75 &lt; 0x80 \u2192 right=8\n\nIteration 2: left=0, right=8, mid=4\n  Slot 4: [0x40, 0x50)\n  0x75 &gt;= 0x50 \u2192 left=5\n\nIteration 3: left=5, right=8, mid=6\n  Slot 6: [0x60, 0x70)\n  0x75 &gt;= 0x70 \u2192 left=7\n\nIteration 4: left=7, right=8, mid=7\n  Slot 7: [0x70, 0x80)\n  0x70 &lt;= 0x75 &lt; 0x80 \u2192 Found!\n\nResult: Slot 7 (4 iterations)\n</code></pre>"},{"location":"crates/nori-lsm/how-it-works/slot-routing/#comparison-to-alternatives","title":"Comparison to Alternatives","text":"Routing Strategy Time Complexity Pros Cons Binary search O(log n) Fast, simple, range-preserving Requires sorted guards Hash table O(1) Fastest point queries No range queries, no locality Linear scan O(n) Simple Too slow (n iterations) Trie O(k) k=key length Prefix compression Complex, high memory <p>Binary search wins: Balance of speed, simplicity, and range query support.</p>"},{"location":"crates/nori-lsm/how-it-works/slot-routing/#range-query-routing","title":"Range Query Routing","text":"<p>Range queries scan multiple slots:</p>"},{"location":"crates/nori-lsm/how-it-works/slot-routing/#find-overlapping-slots","title":"Find Overlapping Slots","text":"<pre><code>pub fn find_slots_for_range(&amp;self, start: &amp;[u8], end: &amp;[u8]) -&gt; Vec&lt;u32&gt; {\n    // 1. Find first slot containing start\n    let start_slot = self.find_slot_for_key(start);\n\n    // 2. Find last slot containing end\n    let end_slot = self.find_slot_for_key(end);\n\n    // 3. Return all slots in range [start_slot, end_slot]\n    (start_slot..=end_slot).collect()\n}\n</code></pre> <p>Example (range query <code>[\"user:1000\", \"user:9999\"]</code>):</p> <pre><code>Guard keys (16 slots, uniform split):\n  Slot 0: [0x00, 0x10)\n  Slot 1: [0x10, 0x20)\n  ...\n  Slot 7: [0x70, 0x80)  \u2190 \"user:1000\" (0x75...) falls here\n  Slot 8: [0x80, 0x90)\n  ...\n  Slot 11: [0xB0, 0xC0) \u2190 \"user:9999\" (0x75...) falls here (same slot!)\n\nResult: Only scan Slot 7 (start and end in same slot)\n</code></pre>"},{"location":"crates/nori-lsm/how-it-works/slot-routing/#range-scan-implementation","title":"Range Scan Implementation","text":"<pre><code>pub async fn scan(&amp;self, start: &amp;[u8], end: &amp;[u8]) -&gt; Result&lt;Vec&lt;(Vec&lt;u8&gt;, Vec&lt;u8&gt;)&gt;&gt; {\n    let slots = self.find_slots_for_range(start, end);\n    let mut results = Vec::new();\n\n    for slot_id in slots {\n        let slot = &amp;self.slots[slot_id as usize];\n\n        // Scan all runs in this slot\n        for run in &amp;slot.runs {\n            // 1. Check bloom filter (skip if key range doesn't overlap)\n            if !run.bloom.may_contain_range(start, end) {\n                continue;\n            }\n\n            // 2. Scan SSTable\n            let mut iter = run.sstable.range(start, end).await?;\n            while let Some((key, value)) = iter.next().await? {\n                results.push((key, value));\n            }\n        }\n    }\n\n    // 3. Merge results (keys may be duplicated across runs)\n    results.sort_by(|a, b| a.0.cmp(&amp;b.0));\n    results.dedup_by(|a, b| a.0 == b.0);  // Keep latest version\n\n    Ok(results)\n}\n</code></pre> <p>Optimization: Bloom filter range check skips SSTables that definitely don't contain keys in [start, end).</p>"},{"location":"crates/nori-lsm/how-it-works/slot-routing/#guard-key-selection-strategies","title":"Guard Key Selection Strategies","text":""},{"location":"crates/nori-lsm/how-it-works/slot-routing/#uniform-split-default","title":"Uniform Split (Default)","text":"<p>Divide key space evenly:</p> <pre><code>pub fn uniform_guard_keys(num_slots: u32) -&gt; Vec&lt;Vec&lt;u8&gt;&gt; {\n    let mut guards = vec![];\n    let step = 256 / num_slots;\n\n    for i in 0..num_slots {\n        guards.push(vec![(i * step) as u8]);\n    }\n\n    guards.push(vec![0xFF]);  // Final boundary\n    guards\n}\n</code></pre> <p>Example (4 slots): <pre><code>Step = 256 / 4 = 64\nSlot 0: [0x00, 0x40)\nSlot 1: [0x40, 0x80)\nSlot 2: [0x80, 0xC0)\nSlot 3: [0xC0, 0xFF]\n</code></pre></p> <p>Pros: - Simple, predictable - No sampling required - Works for any workload</p> <p>Cons: - Assumes uniform key distribution - Skewed workloads create imbalanced slots</p>"},{"location":"crates/nori-lsm/how-it-works/slot-routing/#data-driven-split-future","title":"Data-Driven Split (Future)","text":"<p>Sample existing keys, split by percentiles:</p> <pre><code>pub async fn data_driven_guard_keys(num_slots: u32) -&gt; Vec&lt;Vec&lt;u8&gt;&gt; {\n    // 1. Sample 10K random keys from L0 and slots\n    let samples = self.sample_keys(10_000).await?;\n\n    // 2. Sort samples\n    samples.sort();\n\n    // 3. Choose percentile boundaries\n    let mut guards = vec![];\n    for i in 0..num_slots {\n        let percentile = (i as f64) / (num_slots as f64);\n        let idx = (percentile * samples.len() as f64) as usize;\n        guards.push(samples[idx].clone());\n    }\n\n    guards\n}\n</code></pre> <p>Pros: - Balanced slot sizes - Adapts to actual key distribution</p> <p>Cons: - Requires sampling (slow) - Changes over time (not stable)</p>"},{"location":"crates/nori-lsm/how-it-works/slot-routing/#slot-metadata","title":"Slot Metadata","text":"<p>Each slot tracks its own state:</p> <pre><code>pub struct Slot {\n    /// Slot ID (0-indexed)\n    pub slot_id: u32,\n\n    /// Inclusive lower bound\n    pub guard_key_min: Vec&lt;u8&gt;,\n\n    /// Exclusive upper bound\n    pub guard_key_max: Vec&lt;u8&gt;,\n\n    /// Sorted runs in this slot (K-way fanout)\n    pub runs: Vec&lt;SortedRun&gt;,\n\n    /// Maximum K allowed (adaptive based on heat)\n    pub k_max: usize,\n\n    /// Heat score (EWMA of access frequency)\n    pub heat_score: f32,\n\n    /// Total size of all runs (bytes)\n    pub total_size: u64,\n\n    /// Entry count (approximate)\n    pub entry_count: u64,\n}\n</code></pre> <p>Example (Slot 1 in a hot workload):</p> <pre><code>Slot {\n    slot_id: 1,\n    guard_key_min: vec![0x40],\n    guard_key_max: vec![0x80],\n    runs: vec![\n        SortedRun { id: 42, size: 128 MB, entries: 1M },\n    ],\n    k_max: 1,  // Leveled (hot slot)\n    heat_score: 0.85,\n    total_size: 134_217_728,\n    entry_count: 1_048_576,\n}\n</code></pre>"},{"location":"crates/nori-lsm/how-it-works/slot-routing/#parallel-compaction","title":"Parallel Compaction","text":"<p>Slots enable parallel compaction:</p> <pre><code>pub async fn compact_parallel(&amp;mut self) -&gt; Result&lt;()&gt; {\n    // 1. Select N slots via bandit scheduler\n    let selected_slots = self.scheduler.select_slots(num_workers: 4);\n\n    // 2. Spawn compaction tasks\n    let tasks: Vec&lt;_&gt; = selected_slots.iter().map(|slot_id| {\n        let slot = self.slots[*slot_id as usize].clone();\n        tokio::spawn(async move {\n            compact_slot(slot).await\n        })\n    }).collect();\n\n    // 3. Await all tasks\n    for task in tasks {\n        task.await??;\n    }\n\n    Ok(())\n}\n</code></pre> <p>Benefit: 4x throughput (compact 4 slots in parallel on 4-core CPU).</p> <p>Synchronization: Each slot has its own lock, no contention between slots.</p>"},{"location":"crates/nori-lsm/how-it-works/slot-routing/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"crates/nori-lsm/how-it-works/slot-routing/#routing-latency","title":"Routing Latency","text":"<p>Benchmark (16 slots):</p> <pre><code>Operation              Latency (p50)   Latency (p95)\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nfind_slot_for_key      40ns            60ns\nfind_slots_for_range   80ns            120ns\n</code></pre> <p>Breakdown (find_slot_for_key): - Binary search: 4 iterations \u00d7 8ns/iteration = 32ns - Guard key comparison: 8ns - Total: ~40ns</p>"},{"location":"crates/nori-lsm/how-it-works/slot-routing/#routing-throughput","title":"Routing Throughput","text":"<p>25M lookups/sec on single thread (40ns per lookup).</p> <p>Comparison to hash routing: - Hash routing: 20ns (faster, but no range queries) - Binary search: 40ns (2x slower, but supports ranges)</p> <p>Trade-off: Accept 2x slower point queries for range query support.</p>"},{"location":"crates/nori-lsm/how-it-works/slot-routing/#range-query-performance","title":"Range Query Performance","text":"<p>Benchmark (scan 10K keys across 3 slots):</p> <pre><code>Phase                  Time      Percentage\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nFind overlapping slots 80ns      &lt;0.01%\nBloom filter checks    300ns     0.02%\nSSTable range scans    1.2ms     99.98%\nMerge and dedup        5ms       &lt;0.01%\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nTotal                  6.5ms     100%\n</code></pre> <p>Key insight: Routing overhead is negligible (&lt;0.01%), SSTable I/O dominates.</p>"},{"location":"crates/nori-lsm/how-it-works/slot-routing/#edge-cases","title":"Edge Cases","text":""},{"location":"crates/nori-lsm/how-it-works/slot-routing/#1-key-exactly-at-boundary","title":"1. Key Exactly at Boundary","text":"<p>Scenario: Key equals guard_key_max of slot.</p> <pre><code>// Slot 0: [0x00, 0x40)\n// Slot 1: [0x40, 0x80)\n\nfind_slot_for_key(&amp;[0x40])  // Which slot?\n</code></pre> <p>Answer: Slot 1 (boundaries are [inclusive, exclusive))</p> <p>Invariant: <code>slot.min &lt;= key &lt; slot.max</code></p>"},{"location":"crates/nori-lsm/how-it-works/slot-routing/#2-empty-range-query","title":"2. Empty Range Query","text":"<p>Scenario: start &gt; end (invalid range).</p> <pre><code>find_slots_for_range(&amp;[0x80], &amp;[0x40])  // start &gt; end\n</code></pre> <p>Handling: <pre><code>pub fn find_slots_for_range(&amp;self, start: &amp;[u8], end: &amp;[u8]) -&gt; Vec&lt;u32&gt; {\n    if start &gt;= end {\n        return vec![];  // Empty range, no slots\n    }\n\n    // Normal logic\n}\n</code></pre></p>"},{"location":"crates/nori-lsm/how-it-works/slot-routing/#3-single-byte-keys-vs-multi-byte-keys","title":"3. Single-Byte Keys vs Multi-Byte Keys","text":"<p>Scenario: Mix of short and long keys.</p> <pre><code>// Short key\nfind_slot_for_key(&amp;[0x75])  \u2192 Slot 7\n\n// Long key (same prefix)\nfind_slot_for_key(&amp;[0x75, 0x01, 0x02, 0x03])  \u2192 Slot 7 (same slot!)\n</code></pre> <p>Comparison: Lexicographic byte-by-byte.</p> <pre><code>0x75 vs 0x70: 0x75 &gt; 0x70 \u2192 Continue\n0x75 vs 0x80: 0x75 &lt; 0x80 \u2192 In range [0x70, 0x80)\n\n0x75 0x01 0x02 0x03 vs 0x70: First byte 0x75 &gt; 0x70 \u2192 Continue\n0x75 0x01 0x02 0x03 vs 0x80: First byte 0x75 &lt; 0x80 \u2192 In range\n</code></pre> <p>Locality: Keys with same prefix often in same slot (good for range queries).</p>"},{"location":"crates/nori-lsm/how-it-works/slot-routing/#code-example-complete-routing-implementation","title":"Code Example: Complete Routing Implementation","text":"<pre><code>pub struct SlotRouter {\n    slots: Vec&lt;Slot&gt;,\n}\n\nimpl SlotRouter {\n    pub fn new(num_slots: u32) -&gt; Self {\n        let guard_keys = Self::uniform_guard_keys(num_slots);\n        let mut slots = Vec::new();\n\n        for i in 0..num_slots as usize {\n            slots.push(Slot {\n                slot_id: i as u32,\n                guard_key_min: guard_keys[i].clone(),\n                guard_key_max: guard_keys[i + 1].clone(),\n                runs: vec![],\n                k_max: 4,  // Default K_global\n                heat_score: 0.0,\n                total_size: 0,\n                entry_count: 0,\n            });\n        }\n\n        Self { slots }\n    }\n\n    pub fn find_slot_for_key(&amp;self, key: &amp;[u8]) -&gt; u32 {\n        self.slots\n            .binary_search_by(|slot| {\n                if key &lt; slot.guard_key_min.as_slice() {\n                    std::cmp::Ordering::Greater\n                } else if key &gt;= slot.guard_key_max.as_slice() {\n                    std::cmp::Ordering::Less\n                } else {\n                    std::cmp::Ordering::Equal\n                }\n            })\n            .unwrap() as u32\n    }\n\n    pub fn find_slots_for_range(&amp;self, start: &amp;[u8], end: &amp;[u8]) -&gt; Vec&lt;u32&gt; {\n        if start &gt;= end {\n            return vec![];\n        }\n\n        let start_slot = self.find_slot_for_key(start);\n        let end_slot = self.find_slot_for_key(end);\n\n        (start_slot..=end_slot).collect()\n    }\n\n    fn uniform_guard_keys(num_slots: u32) -&gt; Vec&lt;Vec&lt;u8&gt;&gt; {\n        let mut guards = vec![];\n        let step = 256 / num_slots;\n\n        for i in 0..num_slots {\n            guards.push(vec![(i * step) as u8]);\n        }\n\n        guards.push(vec![0xFF]);\n        guards\n    }\n}\n</code></pre>"},{"location":"crates/nori-lsm/how-it-works/slot-routing/#summary","title":"Summary","text":"<p>Slot routing maps keys to range-partitioned slots:</p> <ol> <li>Binary search - O(log n) routing, 40ns latency for 16 slots</li> <li>Guard keys - Fixed boundaries, stable, predictable</li> <li>Range queries - Scan contiguous slots, skip non-overlapping</li> <li>Parallel compaction - Independent per-slot locks, no contention</li> </ol> <p>Performance: - Point query routing: 40ns - Range query routing: 80ns - Throughput: 25M lookups/sec</p> <p>Next: Compaction Lifecycle - The most complex subsystem</p> <p>Last Updated: 2025-10-31 See Also: ATLL Architecture, Guard-Based Partitioning</p>"},{"location":"crates/nori-lsm/how-it-works/snapshot-process/","title":"Snapshot Process","text":"<p>Creating consistent point-in-time snapshots for backups, replication, and disaster recovery.</p>"},{"location":"crates/nori-lsm/how-it-works/snapshot-process/#overview","title":"Overview","text":"<p>A snapshot is a consistent point-in-time view of the LSM tree. Snapshots enable: - Backups: Copy data to remote storage without blocking writes - Replication: Send initial state to replicas - Disaster recovery: Restore from known-good state - Long-running queries: Prevent compaction from deleting files mid-query</p> <p>Key properties: - Consistent: All data visible as of snapshot time (no torn reads) - Non-blocking: Writes continue during snapshot creation - Reference counting: SSTables kept alive until snapshot released - Efficient: No data copying, just metadata</p>"},{"location":"crates/nori-lsm/how-it-works/snapshot-process/#snapshot-lifecycle","title":"Snapshot Lifecycle","text":"<pre><code>sequenceDiagram\n    participant App as Application\n    participant LSM as LSM Engine\n    participant Snap as Snapshot\n    participant Files as SSTables\n\n    App-&gt;&gt;LSM: create_snapshot()\n    LSM-&gt;&gt;LSM: Flush active memtable\n    LSM-&gt;&gt;Snap: Capture manifest version\n    LSM-&gt;&gt;Files: Increment refcounts\n    LSM--&gt;&gt;App: Return SnapshotHandle\n\n    App-&gt;&gt;Snap: read(key)\n    Snap-&gt;&gt;Files: Read from frozen SSTables\n    Files--&gt;&gt;Snap: Return value\n    Snap--&gt;&gt;App: Return value\n\n    App-&gt;&gt;LSM: release_snapshot()\n    LSM-&gt;&gt;Files: Decrement refcounts\n    LSM-&gt;&gt;Files: Delete unreferenced SSTables</code></pre> <p>Duration: ~200ms to create snapshot (dominated by memtable flush).</p>"},{"location":"crates/nori-lsm/how-it-works/snapshot-process/#snapshot-creation-algorithm","title":"Snapshot Creation Algorithm","text":""},{"location":"crates/nori-lsm/how-it-works/snapshot-process/#step-1-flush-active-memtable","title":"Step 1: Flush Active Memtable","text":"<p>Ensure all in-memory data is persisted:</p> <pre><code>pub async fn create_snapshot(&amp;mut self) -&gt; Result&lt;SnapshotHandle&gt; {\n    // 1. Flush active memtable to L0 (make durable)\n    self.flush_memtable().await?;\n\n    // 2. Capture current manifest version\n    let manifest_version = self.manifest.version();\n\n    // 3. Increment refcounts for all SSTables\n    let sstable_ids = self.collect_all_sstables();\n    for id in &amp;sstable_ids {\n        self.refcount.increment(*id);\n    }\n\n    // 4. Return snapshot handle\n    Ok(SnapshotHandle {\n        id: self.next_snapshot_id(),\n        version: manifest_version,\n        sstables: sstable_ids,\n        created_at: Instant::now(),\n    })\n}\n</code></pre> <p>Why flush first? - Snapshots only reference on-disk SSTables (not in-memory memtables) - Flushing ensures no data is lost if snapshot is used for backup - Snapshot is durable (survives crash)</p>"},{"location":"crates/nori-lsm/how-it-works/snapshot-process/#step-2-capture-manifest-version","title":"Step 2: Capture Manifest Version","text":"<p>Manifest tracks all SSTables and their metadata:</p> <pre><code>pub struct Manifest {\n    /// Version counter (incremented on every update)\n    version: u64,\n\n    /// L0 SSTables\n    l0_sstables: Vec&lt;SSTableMetadata&gt;,\n\n    /// Slot metadata (runs per slot)\n    slots: Vec&lt;SlotMetadata&gt;,\n}\n\npub struct SnapshotHandle {\n    /// Snapshot ID\n    id: u64,\n\n    /// Manifest version at snapshot time\n    version: u64,\n\n    /// All SSTable IDs referenced by this snapshot\n    sstables: Vec&lt;u64&gt;,\n\n    /// Creation timestamp\n    created_at: Instant,\n}\n</code></pre> <p>Example:</p> <pre><code>Manifest version 42:\n  L0: [SST-001, SST-002, SST-003]\n  Slot 0: [SST-010]\n  Slot 1: [SST-011, SST-012]\n  Slot 2: [SST-013]\n\nSnapshot captures version 42:\n  sstables: [001, 002, 003, 010, 011, 012, 013]\n\nAfter snapshot:\n  Compaction merges SST-001, SST-002 \u2192 SST-020\n  Manifest version 43:\n    L0: [SST-003]\n    Slot 0: [SST-020]  (new merged run)\n    Slot 1: [SST-011, SST-012]\n\nSnapshot still references version 42:\n  SST-001, SST-002 kept alive (refcount &gt; 0)\n  SST-020 not visible to snapshot\n</code></pre>"},{"location":"crates/nori-lsm/how-it-works/snapshot-process/#step-3-reference-counting","title":"Step 3: Reference Counting","text":"<p>Prevent deletion of SSTables referenced by snapshots:</p> <pre><code>pub struct ReferenceCounter {\n    /// Refcount per SSTable\n    refcounts: HashMap&lt;u64, Arc&lt;AtomicU32&gt;&gt;,\n}\n\nimpl ReferenceCounter {\n    pub fn increment(&amp;mut self, sstable_id: u64) {\n        let refcount = self.refcounts.entry(sstable_id)\n            .or_insert_with(|| Arc::new(AtomicU32::new(0)));\n\n        refcount.fetch_add(1, Ordering::Relaxed);\n    }\n\n    pub fn decrement(&amp;mut self, sstable_id: u64) {\n        if let Some(refcount) = self.refcounts.get(&amp;sstable_id) {\n            refcount.fetch_sub(1, Ordering::Relaxed);\n        }\n    }\n\n    pub fn can_delete(&amp;self, sstable_id: u64) -&gt; bool {\n        self.refcounts.get(&amp;sstable_id)\n            .map(|rc| rc.load(Ordering::Relaxed) == 0)\n            .unwrap_or(true)  // No refcount \u2192 safe to delete\n    }\n}\n</code></pre> <p>Example:</p> <pre><code>Initial state:\n  SST-001: refcount=1 (active in L0)\n  SST-002: refcount=1 (active in Slot 0)\n\nSnapshot created:\n  SST-001: refcount=2 (active + snapshot)\n  SST-002: refcount=2 (active + snapshot)\n\nCompaction merges SST-001, SST-002 \u2192 SST-020:\n  SST-001: refcount=1 (removed from L0, still in snapshot)\n  SST-002: refcount=1 (removed from Slot 0, still in snapshot)\n  SST-020: refcount=1 (new run in Slot 0)\n\nSnapshot released:\n  SST-001: refcount=0 \u2192 DELETE\n  SST-002: refcount=0 \u2192 DELETE\n</code></pre>"},{"location":"crates/nori-lsm/how-it-works/snapshot-process/#snapshot-reads","title":"Snapshot Reads","text":"<p>Reads from snapshot use frozen manifest version:</p> <pre><code>pub async fn get(&amp;self, snapshot: &amp;SnapshotHandle, key: &amp;[u8]) -&gt; Option&lt;Vec&lt;u8&gt;&gt; {\n    // 1. Load manifest version at snapshot time\n    let manifest = self.manifest_at_version(snapshot.version).await?;\n\n    // 2. Check L0 SSTables (from snapshot time)\n    for sst_id in &amp;manifest.l0_sstables {\n        if snapshot.sstables.contains(sst_id) {\n            if let Some(value) = self.read_sstable(*sst_id, key).await? {\n                return Some(value);\n            }\n        }\n    }\n\n    // 3. Check slots (from snapshot time)\n    for slot in &amp;manifest.slots {\n        for run_id in &amp;slot.runs {\n            if snapshot.sstables.contains(run_id) {\n                if let Some(value) = self.read_sstable(*run_id, key).await? {\n                    return Some(value);\n                }\n            }\n        }\n    }\n\n    // 4. Not found\n    None\n}\n</code></pre> <p>Isolation: Snapshot sees only SSTables from its version, not newer compaction results.</p> <p>Example:</p> <pre><code>Snapshot at version 42:\n  Sees: SST-001, SST-002 (old L0 files)\n\nCurrent state at version 45:\n  SST-001, SST-002 deleted (compacted to SST-020)\n  New data: SST-021, SST-022\n\nget(snapshot, \"key\") \u2192 Only searches SST-001, SST-002 (not SST-020, SST-021, SST-022)\n</code></pre>"},{"location":"crates/nori-lsm/how-it-works/snapshot-process/#snapshot-release","title":"Snapshot Release","text":"<p>Release snapshot and decrement refcounts:</p> <pre><code>pub async fn release_snapshot(&amp;mut self, snapshot: SnapshotHandle) -&gt; Result&lt;()&gt; {\n    // 1. Decrement refcounts for all SSTables\n    for sstable_id in &amp;snapshot.sstables {\n        self.refcount.decrement(*sstable_id);\n    }\n\n    // 2. Delete SSTables with refcount=0\n    for sstable_id in &amp;snapshot.sstables {\n        if self.refcount.can_delete(*sstable_id) {\n            self.delete_sstable(*sstable_id).await?;\n        }\n    }\n\n    // 3. Remove snapshot from registry\n    self.snapshots.remove(&amp;snapshot.id);\n\n    Ok(())\n}\n</code></pre> <p>Garbage collection: SSTables deleted only when: 1. Removed from active manifest (compacted away) 2. Refcount = 0 (no snapshots reference them)</p>"},{"location":"crates/nori-lsm/how-it-works/snapshot-process/#use-cases","title":"Use Cases","text":""},{"location":"crates/nori-lsm/how-it-works/snapshot-process/#use-case-1-backup-to-s3","title":"Use Case 1: Backup to S3","text":"<pre><code>pub async fn backup_to_s3(&amp;mut self, bucket: &amp;str) -&gt; Result&lt;()&gt; {\n    // 1. Create snapshot\n    let snapshot = self.lsm.create_snapshot().await?;\n\n    // 2. Upload SSTables to S3\n    for sstable_id in &amp;snapshot.sstables {\n        let local_path = self.lsm.sstable_path(*sstable_id);\n        let s3_key = format!(\"backups/{}/{:06}.sst\", snapshot.id, sstable_id);\n\n        upload_file_to_s3(&amp;local_path, bucket, &amp;s3_key).await?;\n    }\n\n    // 3. Upload manifest\n    let manifest = self.lsm.manifest_at_version(snapshot.version).await?;\n    let manifest_json = serde_json::to_string(&amp;manifest)?;\n    upload_to_s3(&amp;manifest_json, bucket, &amp;format!(\"backups/{}/manifest.json\", snapshot.id)).await?;\n\n    // 4. Release snapshot\n    self.lsm.release_snapshot(snapshot).await?;\n\n    Ok(())\n}\n</code></pre> <p>Duration: Minutes to hours (dominated by S3 upload, not snapshot creation).</p>"},{"location":"crates/nori-lsm/how-it-works/snapshot-process/#use-case-2-replication-initial-sync","title":"Use Case 2: Replication Initial Sync","text":"<pre><code>pub async fn replicate_snapshot(&amp;mut self, replica_addr: &amp;str) -&gt; Result&lt;()&gt; {\n    // 1. Create snapshot\n    let snapshot = self.lsm.create_snapshot().await?;\n\n    // 2. Stream SSTables to replica\n    for sstable_id in &amp;snapshot.sstables {\n        let data = self.lsm.read_sstable_data(*sstable_id).await?;\n        send_to_replica(replica_addr, *sstable_id, data).await?;\n    }\n\n    // 3. Send manifest\n    let manifest = self.lsm.manifest_at_version(snapshot.version).await?;\n    send_manifest_to_replica(replica_addr, manifest).await?;\n\n    // 4. Release snapshot\n    self.lsm.release_snapshot(snapshot).await?;\n\n    Ok(())\n}\n</code></pre> <p>Benefit: Replica receives consistent snapshot while primary continues serving writes.</p>"},{"location":"crates/nori-lsm/how-it-works/snapshot-process/#use-case-3-long-running-analytics-query","title":"Use Case 3: Long-Running Analytics Query","text":"<pre><code>pub async fn run_analytics(&amp;mut self, query: &amp;str) -&gt; Result&lt;Vec&lt;Row&gt;&gt; {\n    // 1. Create snapshot (isolate from compaction)\n    let snapshot = self.lsm.create_snapshot().await?;\n\n    // 2. Run query (may take minutes)\n    let results = self.execute_query_on_snapshot(&amp;snapshot, query).await?;\n\n    // 3. Release snapshot\n    self.lsm.release_snapshot(snapshot).await?;\n\n    Ok(results)\n}\n</code></pre> <p>Isolation: Compaction can't delete SSTables mid-query, preventing \"file not found\" errors.</p>"},{"location":"crates/nori-lsm/how-it-works/snapshot-process/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"crates/nori-lsm/how-it-works/snapshot-process/#snapshot-creation-latency","title":"Snapshot Creation Latency","text":"<p>Benchmark (64 MB memtable, 100 SSTables):</p> <pre><code>Phase                  Time      Percentage\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nFlush memtable         200ms     99%\nCapture manifest       100\u03bcs     &lt;0.1%\nIncrement refcounts    50\u03bcs      &lt;0.1%\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nTotal                  200ms     100%\n</code></pre> <p>Key insight: Memtable flush dominates (99% of time).</p>"},{"location":"crates/nori-lsm/how-it-works/snapshot-process/#snapshot-read-performance","title":"Snapshot Read Performance","text":"<p>Benchmark (snapshot with 50 SSTables):</p> <pre><code>Operation              Latency (p50)   Latency (p95)\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nget (in memory cache)  500ns           1\u03bcs\nget (SSD read)         50\u03bcs            100\u03bcs\nscan (1K keys)         5ms             10ms\n</code></pre> <p>Same as regular reads: Snapshot reads use same SSTables, same bloom filters, same block cache.</p>"},{"location":"crates/nori-lsm/how-it-works/snapshot-process/#snapshot-overhead","title":"Snapshot Overhead","text":"<p>Memory overhead: - SnapshotHandle: 128 bytes (ID, version, SSTable list) - Refcount per SSTable: 4 bytes (AtomicU32) - Total for 100 SSTables: 128 + 400 = 528 bytes per snapshot</p> <p>Disk overhead: - No additional disk space (SSTables shared) - Only overhead: Delayed deletion (until snapshot released)</p>"},{"location":"crates/nori-lsm/how-it-works/snapshot-process/#edge-cases","title":"Edge Cases","text":""},{"location":"crates/nori-lsm/how-it-works/snapshot-process/#1-snapshot-during-compaction","title":"1. Snapshot During Compaction","text":"<p>Scenario: Compaction starts, then snapshot created.</p> <pre><code>Timeline:\n  t=0:   Compaction starts (merging SST-001, SST-002)\n  t=50:  Snapshot created\n  t=100: Compaction completes (SST-020 created)\n\nSnapshot sees:\n  SST-001, SST-002 (refcount incremented at t=50)\n\nCompaction result:\n  SST-001, SST-002 refcount decremented (removed from manifest)\n  But refcount still &gt; 0 (snapshot holds reference)\n  SST-001, SST-002 not deleted (kept until snapshot released)\n</code></pre> <p>Outcome: Snapshot sees pre-compaction state (isolated).</p>"},{"location":"crates/nori-lsm/how-it-works/snapshot-process/#2-multiple-concurrent-snapshots","title":"2. Multiple Concurrent Snapshots","text":"<p>Scenario: 3 snapshots created at different times.</p> <pre><code>t=0:   Snapshot A created (version 42)\nt=10:  Compaction (version 43)\nt=20:  Snapshot B created (version 43)\nt=30:  Compaction (version 44)\nt=40:  Snapshot C created (version 44)\n\nRefcounts:\n  SST-001: refcount=2 (Snapshot A + B)\n  SST-020: refcount=2 (Snapshot B + C)\n  SST-030: refcount=1 (Snapshot C)\n\nRelease Snapshot A:\n  SST-001: refcount=1 (still in Snapshot B)\n\nRelease Snapshot B:\n  SST-001: refcount=0 \u2192 DELETE\n  SST-020: refcount=1 (still in Snapshot C)\n</code></pre> <p>Garbage collection: SSTables deleted only when no snapshot references them.</p>"},{"location":"crates/nori-lsm/how-it-works/snapshot-process/#3-snapshot-of-empty-lsm","title":"3. Snapshot of Empty LSM","text":"<p>Scenario: No data written yet, snapshot created.</p> <pre><code>pub async fn create_snapshot(&amp;mut self) -&gt; Result&lt;SnapshotHandle&gt; {\n    // Memtable is empty, no flush needed\n    if self.active_memtable.is_empty() {\n        return Ok(SnapshotHandle {\n            id: self.next_snapshot_id(),\n            version: self.manifest.version(),\n            sstables: vec![],  // Empty snapshot\n            created_at: Instant::now(),\n        });\n    }\n\n    // Normal flush logic\n}\n</code></pre> <p>Benefit: Fast snapshot creation (no flush overhead).</p>"},{"location":"crates/nori-lsm/how-it-works/snapshot-process/#code-example-complete-snapshot-implementation","title":"Code Example: Complete Snapshot Implementation","text":"<pre><code>use std::sync::Arc;\nuse std::sync::atomic::{AtomicU32, Ordering};\nuse tokio::time::Instant;\n\npub struct SnapshotManager {\n    snapshots: HashMap&lt;u64, SnapshotHandle&gt;,\n    refcounts: HashMap&lt;u64, Arc&lt;AtomicU32&gt;&gt;,\n    next_id: AtomicU64,\n}\n\npub struct SnapshotHandle {\n    pub id: u64,\n    pub version: u64,\n    pub sstables: Vec&lt;u64&gt;,\n    pub created_at: Instant,\n}\n\nimpl SnapshotManager {\n    pub async fn create_snapshot(&amp;mut self, lsm: &amp;mut LSM) -&gt; Result&lt;SnapshotHandle&gt; {\n        // 1. Flush memtable\n        lsm.flush_memtable().await?;\n\n        // 2. Capture manifest version\n        let version = lsm.manifest.version();\n        let sstables = lsm.collect_all_sstables();\n\n        // 3. Increment refcounts\n        for id in &amp;sstables {\n            let refcount = self.refcounts.entry(*id)\n                .or_insert_with(|| Arc::new(AtomicU32::new(0)));\n            refcount.fetch_add(1, Ordering::Relaxed);\n        }\n\n        // 4. Create snapshot handle\n        let snapshot = SnapshotHandle {\n            id: self.next_id.fetch_add(1, Ordering::Relaxed),\n            version,\n            sstables,\n            created_at: Instant::now(),\n        };\n\n        self.snapshots.insert(snapshot.id, snapshot.clone());\n\n        Ok(snapshot)\n    }\n\n    pub async fn release_snapshot(&amp;mut self, snapshot: SnapshotHandle, lsm: &amp;mut LSM) -&gt; Result&lt;()&gt; {\n        // 1. Decrement refcounts\n        for id in &amp;snapshot.sstables {\n            if let Some(refcount) = self.refcounts.get(id) {\n                refcount.fetch_sub(1, Ordering::Relaxed);\n            }\n        }\n\n        // 2. Delete unreferenced SSTables\n        for id in &amp;snapshot.sstables {\n            if self.can_delete(*id) {\n                lsm.delete_sstable(*id).await?;\n            }\n        }\n\n        // 3. Remove snapshot\n        self.snapshots.remove(&amp;snapshot.id);\n\n        Ok(())\n    }\n\n    fn can_delete(&amp;self, sstable_id: u64) -&gt; bool {\n        self.refcounts.get(&amp;sstable_id)\n            .map(|rc| rc.load(Ordering::Relaxed) == 0)\n            .unwrap_or(true)\n    }\n}\n</code></pre>"},{"location":"crates/nori-lsm/how-it-works/snapshot-process/#summary","title":"Summary","text":"<p>Snapshot process creates consistent point-in-time views:</p> <ol> <li>Flush memtable - Ensure all data durable</li> <li>Capture manifest version - Freeze SSTable list</li> <li>Reference counting - Prevent deletion during snapshot lifetime</li> <li>Isolated reads - Snapshot sees frozen manifest version</li> <li>Garbage collection - Delete SSTables when refcount=0</li> </ol> <p>Performance: - Creation latency: ~200ms (dominated by flush) - Read latency: Same as regular reads (shared SSTables) - Memory overhead: ~500 bytes per snapshot</p> <p>Use cases: Backups, replication, long-running queries, disaster recovery</p> <p>Last Updated: 2025-10-31 See Also: Flush Process, Compaction Lifecycle</p>"},{"location":"crates/nori-sstable/","title":"nori-sstable","text":"<p>Immutable sorted string tables with blocks, index, bloom filters, and compression.</p> <p>Get Started API Reference View on GitHub</p>"},{"location":"crates/nori-sstable/#what-is-nori-sstable","title":"What is nori-sstable?","text":"<p>nori-sstable provides a production-ready implementation of SSTables (Sorted String Tables) for building LSM-tree storage engines. SSTables are immutable, on-disk data structures that store sorted key-value pairs with efficient lookups and range scans.</p> <p>This crate is a core building block of the NoriKV distributed key-value store, but can be used standalone in any Rust project that needs persistent sorted storage.</p>"},{"location":"crates/nori-sstable/#key-features","title":"Key Features","text":""},{"location":"crates/nori-sstable/#storage-format","title":"Storage &amp; Format","text":"<ul> <li>Block-based storage: 4KB blocks with prefix compression for space efficiency</li> <li>Two-level index: Sparse block index for fast key lookups with minimal I/O</li> <li>Bloom filters: Probabilistic membership testing (~0.9% false positive rate) to avoid unnecessary disk reads</li> <li>CRC32C checksums: Data integrity validation at block level</li> </ul>"},{"location":"crates/nori-sstable/#performance-optimization","title":"Performance &amp; Optimization","text":"<ul> <li>Block compression: Optional LZ4 (fast, 3.9 GB/s decompress) or Zstd (higher ratio) compression \ud83c\udd95</li> <li>LRU block cache: Configurable in-memory cache for hot data blocks (default 64MB) \ud83c\udd95</li> <li>Async I/O: Built on Tokio for high-performance asynchronous operations</li> <li>~67ns bloom filter checks: Ultra-fast negative lookups</li> </ul>"},{"location":"crates/nori-sstable/#developer-experience","title":"Developer Experience","text":"<ul> <li>Tombstones: Explicit delete markers preserved through the storage layer</li> <li>Observability: Vendor-neutral metrics via <code>nori-observe::Meter</code> trait</li> <li>Thread-safe: Concurrent reads supported via <code>Arc&lt;SSTableReader&gt;</code></li> <li>100% Safe Rust: No unsafe code in the public API</li> <li>108 tests passing: Comprehensive test suite including compression and property tests</li> </ul> <p>{: .new }</p> <p>Recent Updates: nori-sstable now includes production-ready LZ4/Zstd compression and an LRU block cache that delivers 18x performance improvements for hot key workloads!</p>"},{"location":"crates/nori-sstable/#quick-example","title":"Quick Example","text":"<pre><code>use nori_sstable::{Compression, Entry, SSTableBuilder, SSTableConfig, SSTableReader};\nuse std::path::PathBuf;\nuse std::sync::Arc;\n\n#[tokio::main]\nasync fn main() -&gt; nori_sstable::Result&lt;()&gt; {\n    // Build an SSTable with LZ4 compression\n    let config = SSTableConfig {\n        path: PathBuf::from(\"data.sst\"),\n        estimated_entries: 1000,\n        compression: Compression::Lz4,  // Enable compression\n        block_cache_mb: 64,              // 64MB cache (default)\n        ..Default::default()\n    };\n\n    let mut builder = SSTableBuilder::new(config).await?;\n\n    // Add entries in sorted order\n    builder.add(&amp;Entry::put(\"key1\", \"value1\")).await?;\n    builder.add(&amp;Entry::put(\"key2\", \"value2\")).await?;\n    builder.add(&amp;Entry::delete(\"key3\")).await?; // Tombstone\n\n    let metadata = builder.finish().await?;\n    println!(\"Created SSTable with {} entries\", metadata.entry_count);\n\n    // Read data back\n    let reader = Arc::new(SSTableReader::open(PathBuf::from(\"data.sst\")).await?);\n\n    // Point lookup (uses bloom filter + index + cache)\n    if let Some(entry) = reader.get(b\"key1\").await? {\n        println!(\"Found: {:?}\", String::from_utf8_lossy(&amp;entry.value));\n    }\n\n    // Range scan\n    let mut iter = reader.iter();\n    while let Some(entry) = iter.try_next().await? {\n        println!(\"{:?} = {:?}\", entry.key, entry.value);\n    }\n\n    Ok(())\n}\n</code></pre>"},{"location":"crates/nori-sstable/#performance-highlights","title":"Performance Highlights","text":"<p>Benchmarked on Apple M1 (release build):</p> Operation Performance Notes Bloom filter check ~67ns In-memory, ultra-fast Point lookup (hit) ~5\u00b5s With cache enabled Point lookup (miss) &lt;20\u00b5s Bloom filter skip Sequential scan ~1M entries/sec Streaming iteration Hot key workload 18x faster (14ms \u2192 777\u00b5s) With 64MB cache Compression ratio (LZ4) 2-3x typical 14x on highly compressible data <p>See detailed benchmarks \u2192</p>"},{"location":"crates/nori-sstable/#architecture-overview","title":"Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        Write Path                            \u2502\n\u2502  User \u2192 SSTableBuilder \u2192 BlockBuilder \u2192 Compress \u2192 Writer   \u2502\n\u2502           \u2502                  \u2502              \u2502          \u2502     \u2502\n\u2502           \u251c\u2500 BloomFilter     \u251c\u2500 Prefix      \u2502          \u2514\u2500 File I/O\n\u2502           \u2502  (add keys)      \u2502   Compression\u2502                \u2502\n\u2502           \u2502                  \u2502   (shared len)                \u2502\n\u2502           \u2514\u2500 Index           \u2514\u2500 Restart                      \u2502\n\u2502              (track blocks)     Points                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         Read Path                            \u2502\n\u2502  User \u2192 SSTableReader \u2192 [Cache?] \u2192 [Bloom?] \u2192 Index \u2192 Block \u2502\n\u2502                             \u2193          \u2193         \u2193        \u2193  \u2502\n\u2502                          Hit/Miss  Contains?  Find    Binary \u2502\n\u2502                          (~18x)    (~67ns)    Block   Search \u2502\n\u2502                                                (log B)  (log E)\u2502\n\u2502         SSTableIterator \u2192 load blocks on demand              \u2502\n\u2502                            \u2193                                 \u2502\n\u2502                         BlockIterator                        \u2502\n\u2502                          (decompress + decode)               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"crates/nori-sstable/#file-layout","title":"File Layout","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Data Block 0   \u2502 \u2190 4KB blocks (compressed with LZ4/Zstd)\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Data Block 1   \u2502   Entry: shared_len | unshared_len |\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524          value_len | key | value\n\u2502     ...        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524   Restart points every 16 entries\n\u2502 Data Block N   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Index          \u2502 first_key | block_offset | block_size (per block)\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Bloom Filter   \u2502 xxhash64 with double hashing\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 10 bits/key \u2192 ~0.9% FP rate\n\u2502 Footer (64B)   \u2502 Magic | Index offset/size | Bloom offset/size |\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Compression type | CRC32C checksum\n</code></pre> <p>Learn more about the architecture \u2192</p>"},{"location":"crates/nori-sstable/#when-to-use-nori-sstable","title":"When to Use nori-sstable","text":""},{"location":"crates/nori-sstable/#great-fit","title":"Great Fit","text":"<ul> <li>Building LSM-tree storage engines (like RocksDB, LevelDB)</li> <li>Time-series databases with immutable time-ordered data</li> <li>Log storage with sorted logs and range queries</li> <li>Snapshot storage for point-in-time database snapshots</li> <li>Need fast reads with bloom filter optimization</li> <li>Hot key workloads where caching provides 10x+ speedups</li> <li>Workloads where compression saves significant storage costs</li> </ul>"},{"location":"crates/nori-sstable/#not-the-right-tool","title":"Not the Right Tool","text":"<ul> <li>Need mutable data structures (use in-memory B-trees instead)</li> <li>Random writes (SSTables are write-once, immutable)</li> <li>Ultra-low latency &lt; 1\u00b5s (use in-memory stores)</li> <li>Very small datasets &lt; 1MB (overhead not worth it)</li> </ul>"},{"location":"crates/nori-sstable/#documentation-sections","title":"Documentation Sections","text":""},{"location":"crates/nori-sstable/#getting-started","title":"Getting Started","text":"<p>Learn how to install and use nori-sstable in your project.</p> <p>Getting Started \u2192</p>"},{"location":"crates/nori-sstable/#core-concepts","title":"Core Concepts","text":"<p>Understand the fundamental concepts behind SSTables: immutability, block-based storage, bloom filters, and when to use them.</p> <p>Core Concepts \u2192</p>"},{"location":"crates/nori-sstable/#compression","title":"Compression \ud83c\udd95","text":"<p>Deep dive into LZ4 and Zstd compression: when to use each, performance tradeoffs, and configuration.</p> <p>Compression Guide \u2192</p>"},{"location":"crates/nori-sstable/#caching","title":"Caching \ud83c\udd95","text":"<p>Learn how the LRU block cache works, how to tune it for hot workloads, and achieve 18x speedups.</p> <p>Caching Guide \u2192</p>"},{"location":"crates/nori-sstable/#how-it-works","title":"How It Works","text":"<p>Detailed internals: file format, block format, bloom filters, index structure, compression, and cache implementation.</p> <p>How It Works \u2192</p>"},{"location":"crates/nori-sstable/#api-reference","title":"API Reference","text":"<p>Complete API documentation for builders, readers, configuration, and iterators.</p> <p>API Reference \u2192</p>"},{"location":"crates/nori-sstable/#performance","title":"Performance","text":"<p>Benchmarks, tuning guides, compression ratio analysis, and profiling.</p> <p>Performance \u2192</p>"},{"location":"crates/nori-sstable/#design-decisions","title":"Design Decisions","text":"<p>Rationale behind key design choices: block-based organization, immutability, compression strategy, and more.</p> <p>Design Decisions \u2192</p>"},{"location":"crates/nori-sstable/#recipes","title":"Recipes","text":"<p>Common patterns and use cases with code examples.</p> <p>Recipes \u2192</p>"},{"location":"crates/nori-sstable/#internals","title":"Internals","text":"<p>Deep implementation details for contributors and advanced users.</p> <p>Internals \u2192</p>"},{"location":"crates/nori-sstable/#installation","title":"Installation","text":"<p>Add to your <code>Cargo.toml</code>:</p> <pre><code>[dependencies]\nnori-sstable = \"0.1\"\ntokio = { version = \"1\", features = [\"full\"] }\n</code></pre> <p>Then import in your code:</p> <pre><code>use nori_sstable::{\n    SSTableBuilder, SSTableReader, SSTableConfig,\n    Entry, Compression,\n};\n</code></pre>"},{"location":"crates/nori-sstable/#project-status","title":"Project Status","text":"Aspect Status Core functionality Production-ready Tests 108 tests passing Compression LZ4 + Zstd supported Caching LRU cache implemented Documentation Complete Benchmarks Comprehensive Published \ud83d\udea7 Preparing for crates.io"},{"location":"crates/nori-sstable/#contributing","title":"Contributing","text":"<p>nori-sstable is part of the NoriKV project and welcomes contributions!</p> <ul> <li>Found a bug? Open an issue</li> <li>Have a question? Start a discussion</li> <li>Want to contribute? Check the Contributing Guide</li> </ul>"},{"location":"crates/nori-sstable/#license","title":"License","text":"<p>MIT License - see LICENSE for details.</p>"},{"location":"crates/nori-sstable/#next-steps","title":"Next Steps","text":"<p>New to SSTables? Start with Getting Started to build your first SSTable in 5 minutes.</p> <p>Want to optimize performance? Check out Compression and Caching to learn about our newest performance features.</p> <p>Need the API? Jump to API Reference for complete method documentation.</p> <p>Curious about internals? Dive into How It Works for implementation details.</p>"},{"location":"crates/nori-sstable/caching/","title":"LRU Block Cache","text":"<p>Deep dive into the LRU block cache and achieving 18x performance improvements.</p>"},{"location":"crates/nori-sstable/caching/#overview","title":"Overview","text":"<p>nori-sstable includes a built-in LRU (Least Recently Used) block cache that dramatically improves read performance for hot key workloads. The cache stores decompressed blocks in memory, eliminating repeated disk I/O and decompression overhead.</p> <p>{: .highlight }</p> <p>NEW Feature: The LRU block cache was added in version 0.1 and delivers 18x performance improvements for hot key workloads (14ms \u2192 777\u00b5s for 1000 operations).</p>"},{"location":"crates/nori-sstable/caching/#why-cache","title":"Why Cache?","text":"<p>The Problem: - Every SSTable read requires disk I/O (~100-1000\u00b5s latency) - With compression, every read also requires decompression (~10\u00b5s) - Hot keys (frequently accessed) pay this cost repeatedly - 80/20 workloads (80% of requests hit 20% of keys) suffer most</p> <p>The Solution: - Cache decompressed blocks in memory (one-time cost) - Serve subsequent reads from RAM (~100ns access time) - Result: 10-100x faster reads for hot data</p>"},{"location":"crates/nori-sstable/caching/#performance-impact","title":"Performance Impact","text":""},{"location":"crates/nori-sstable/caching/#benchmark-results","title":"Benchmark Results","text":"<p>From <code>benches/read_sstable.rs</code> hot key pattern:</p> Configuration Time (1000 ops) Improvement No cache 14.0 ms Baseline 64MB cache 777 \u00b5s 18x faster! 256MB cache 650 \u00b5s 21.5x faster <p>Point lookup improvements:</p> Entry Count No Cache With Cache Improvement 100 entries 13.3 \u00b5s 486 ns 27x faster 1K entries 14.2 \u00b5s 609 ns 23x faster 10K entries 15.1 \u00b5s 877 ns 17x faster <p>{: .note }</p> <p>Why the improvement? Cache hits avoid two expensive operations: (1) Disk I/O (~100-1000\u00b5s), and (2) Decompression (~10\u00b5s). RAM access is ~100ns, giving 10-100x speedups.</p>"},{"location":"crates/nori-sstable/caching/#how-it-works","title":"How It Works","text":""},{"location":"crates/nori-sstable/caching/#cache-architecture","title":"Cache Architecture","text":"<pre><code>User Request (key)\n    \u2193\nBloom filter check (key might exist?)\n    \u2193\nIndex lookup (which block contains key?)\n    \u2193\nread_block(offset, size)\n    \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Check LRU Cache                \u2502\n\u2502  Key: block offset (u64)        \u2502\n\u2502  Value: decompressed Block      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2193                      \u2193\nCache HIT           Cache MISS\n    \u2193                      \u2193\nReturn cached       Read from disk\nblock (~100ns)          \u2193\n                   Decompress block\n                        \u2193\n                   Add to cache (evict LRU if full)\n                        \u2193\n                   Return block\n</code></pre> <p>Key insights: 1. Cache key = block offset: Each 4KB block is cached by its file offset 2. Cache value = decompressed block: Avoid repeated decompression 3. Thread-safe: Uses <code>Mutex&lt;LruCache&gt;</code> for concurrent access 4. LRU eviction: Automatically evicts least recently used blocks when full</p>"},{"location":"crates/nori-sstable/caching/#data-flow","title":"Data Flow","text":"<pre><code>// In SSTableReader::read_block()\npub(crate) async fn read_block(&amp;self, offset: u64, size: u32) -&gt; Result&lt;Block&gt; {\n    // 1. Check cache first\n    if let Some(ref cache) = self.block_cache {\n        let mut cache_lock = cache.lock().await;\n        if let Some(block) = cache_lock.get(&amp;offset) {\n            // Cache hit! Return cloned block\n            self.meter.counter(\"sstable_block_cache_hits\", &amp;[]).inc(1);\n            return Ok(block.clone());\n        }\n        // Cache miss\n        self.meter.counter(\"sstable_block_cache_misses\", &amp;[]).inc(1);\n    }\n\n    // 2. Read compressed block from disk\n    let mut file = self.file.lock().await;\n    file.seek(SeekFrom::Start(offset)).await?;\n    let mut compressed_bytes = vec![0u8; size as usize];\n    file.read_exact(&amp;mut compressed_bytes).await?;\n\n    // 3. Decompress block\n    let decompressed_bytes = compress::decompress(&amp;compressed_bytes, self.footer.compression)?;\n\n    // 4. Decode block structure\n    let block = Block::decode(Bytes::from(decompressed_bytes))?;\n\n    // 5. Cache the decompressed block\n    if let Some(ref cache) = self.block_cache {\n        let mut cache_lock = cache.lock().await;\n        cache_lock.put(offset, block.clone());  // LRU eviction happens here\n    }\n\n    Ok(block)\n}\n</code></pre>"},{"location":"crates/nori-sstable/caching/#configuration","title":"Configuration","text":""},{"location":"crates/nori-sstable/caching/#default-configuration-64mb","title":"Default Configuration (64MB)","text":"<pre><code>use nori_sstable::{SSTableConfig, SSTableReader};\n\n// Option 1: Use default (64MB cache)\nlet reader = SSTableReader::open(\"data.sst\".into()).await?;\n\n// Option 2: Explicit default in config\nlet config = SSTableConfig {\n    path: \"data.sst\".into(),\n    block_cache_mb: 64,  // Default\n    ..Default::default()\n};\n</code></pre> <p>Memory usage: 64MB \u2248 16,384 blocks (at 4KB per block)</p>"},{"location":"crates/nori-sstable/caching/#custom-cache-size","title":"Custom Cache Size","text":"<pre><code>use nori_sstable::SSTableReader;\nuse nori_observe::NoopMeter;\nuse std::sync::Arc;\n\n// Hot workload: Increase cache to 256MB\nlet reader = SSTableReader::open_with_config(\n    \"hot_data.sst\".into(),\n    Arc::new(NoopMeter),\n    256  // 256MB cache\n).await?;\n</code></pre> <p>Memory usage: 256MB \u2248 65,536 blocks</p>"},{"location":"crates/nori-sstable/caching/#disable-cache-cold-storage","title":"Disable Cache (Cold Storage)","text":"<pre><code>let config = SSTableConfig {\n    path: \"archive.sst\".into(),\n    block_cache_mb: 0,  // Disable caching\n    ..Default::default()\n};\n</code></pre> <p>Use case: Cold storage where reads are infrequent and memory is limited</p>"},{"location":"crates/nori-sstable/caching/#cache-sizing-guide","title":"Cache Sizing Guide","text":""},{"location":"crates/nori-sstable/caching/#how-much-memory-does-the-cache-use","title":"How Much Memory Does the Cache Use?","text":"<p>Formula: <pre><code>Cache Memory = block_cache_mb * 1024 * 1024 bytes\nNumber of Blocks = Cache Memory / block_size (default 4KB)\n</code></pre></p> <p>Examples:</p> Config Memory Blocks Cached Use Case <code>block_cache_mb: 16</code> 16 MB ~4,096 Development, testing <code>block_cache_mb: 64</code> 64 MB ~16,384 Default (good balance) <code>block_cache_mb: 256</code> 256 MB ~65,536 Hot workloads <code>block_cache_mb: 1024</code> 1 GB ~262,144 Very large hot datasets <code>block_cache_mb: 0</code> 0 0 Cold storage"},{"location":"crates/nori-sstable/caching/#sizing-for-your-workload","title":"Sizing for Your Workload","text":""},{"location":"crates/nori-sstable/caching/#8020-hot-key-pattern-common","title":"80/20 Hot Key Pattern (Common)","text":"<p>Scenario: 80% of requests hit 20% of your data</p> <p>Calculation: 1. Total SSTable size: 1 GB 2. Hot data (20%): 200 MB 3. Number of blocks: 200 MB / 4 KB = 51,200 blocks 4. Recommended cache: 256 MB (to fit all hot blocks)</p> <p>Expected hit rate: 80-90%</p>"},{"location":"crates/nori-sstable/caching/#uniform-access-pattern-rare","title":"Uniform Access Pattern (Rare)","text":"<p>Scenario: All keys accessed equally (cache less effective)</p> <p>Calculation: 1. Total SSTable size: 10 GB 2. Cache can only hold fraction of data 3. Recommended: 64-128 MB (default is fine)</p> <p>Expected hit rate: 1-5% (proportional to cache/data ratio)</p>"},{"location":"crates/nori-sstable/caching/#very-hot-keys-eg-metadata-counters","title":"Very Hot Keys (e.g., Metadata, Counters)","text":"<p>Scenario: 95% of requests hit 5% of data</p> <p>Calculation: 1. Total SSTable size: 500 MB 2. Hot data (5%): 25 MB 3. Number of blocks: 25 MB / 4 KB = 6,400 blocks 4. Recommended cache: 64 MB (default is sufficient!)</p> <p>Expected hit rate: 95%+</p>"},{"location":"crates/nori-sstable/caching/#monitoring-cache-performance","title":"Monitoring Cache Performance","text":""},{"location":"crates/nori-sstable/caching/#key-metrics","title":"Key Metrics","text":"<p>nori-sstable emits metrics via the <code>Meter</code> trait:</p> <pre><code>// Cache hits (good!)\nsstable_block_cache_hits{} = 8500\n\n// Cache misses (first-time reads or evictions)\nsstable_block_cache_misses{} = 1500\n\n// Calculate hit rate\nhit_rate = hits / (hits + misses) = 8500 / 10000 = 85%\n</code></pre>"},{"location":"crates/nori-sstable/caching/#interpreting-metrics","title":"Interpreting Metrics","text":"Hit Rate Status Action &gt;80% Excellent Cache is sized well 50-80% Good Consider increasing cache 20-50% \ud83d\udfe0 Fair Increase cache or optimize access pattern &lt;20% Poor Cache too small or uniform access pattern"},{"location":"crates/nori-sstable/caching/#example-monitoring-in-production","title":"Example: Monitoring in Production","text":"<pre><code>use nori_sstable::{SSTableBuilder, SSTableConfig};\nuse nori_observe_prom::PrometheusMeter;  // Prometheus exporter\n\n// Create custom meter\nlet meter = Box::new(PrometheusMeter::new());\n\nlet config = SSTableConfig {\n    path: \"data.sst\".into(),\n    block_cache_mb: 256,\n    ..Default::default()\n};\n\nlet mut builder = SSTableBuilder::new_with_meter(config, meter).await?;\n\n// Metrics are now exported to Prometheus:\n// sstable_block_cache_hits\n// sstable_block_cache_misses\n// sstable_block_reads (total disk reads)\n</code></pre> <p>Query in Prometheus: <pre><code># Cache hit rate\nrate(sstable_block_cache_hits[5m]) /\n(rate(sstable_block_cache_hits[5m]) + rate(sstable_block_cache_misses[5m]))\n</code></pre></p>"},{"location":"crates/nori-sstable/caching/#cache-compression-synergy","title":"Cache + Compression Synergy","text":""},{"location":"crates/nori-sstable/caching/#the-winning-combination","title":"The Winning Combination","text":"<p>Configuration: <pre><code>let config = SSTableConfig {\n    compression: Compression::Lz4,  // 2-3x storage savings\n    block_cache_mb: 64,              // Cache decompressed blocks\n    ..Default::default()\n};\n</code></pre></p> <p>What happens:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Disk: Compressed blocks (2-3x smaller)     \u2502\n\u2502 [...LZ4 compressed data...]                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2193 Read compressed (fast due to smaller size)\n            \u2193 Decompress (one-time cost: ~10\u00b5s)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Cache: Decompressed blocks (fast access)   \u2502\n\u2502 [Block1][Block2][Block3]...[BlockN]       \u2502\n\u2502 (RAM: ~100ns access)                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2193 Serve from cache (no decompression!)\n         User Request (~5\u00b5s total)\n</code></pre> <p>Benefits: 1. Storage: Save 50-70% disk space (LZ4 compression) 2. First read: Pay decompression cost once (~10\u00b5s) 3. Cached reads: Zero decompression cost (cached = decompressed) 4. Network: Faster backups/replication (smaller files)</p> <p>Result: Best of both worlds! \ud83c\udf89</p>"},{"location":"crates/nori-sstable/caching/#implementation-details","title":"Implementation Details","text":""},{"location":"crates/nori-sstable/caching/#lru-algorithm","title":"LRU Algorithm","text":"<p>nori-sstable uses the <code>lru</code> crate for O(1) cache operations:</p> <pre><code>use lru::LruCache;\nuse std::num::NonZeroUsize;\n\n// In SSTableReader\npub struct SSTableReader {\n    // ...\n    block_cache: Option&lt;Mutex&lt;LruCache&lt;u64, Block&gt;&gt;&gt;,\n    // ...\n}\n\n// Cache initialization\nlet blocks_in_cache = (block_cache_mb * 1024 * 1024) / 4096;\nlet cache = LruCache::new(\n    NonZeroUsize::new(blocks_in_cache.max(1)).unwrap()\n);\n</code></pre> <p>Operations: - <code>get(&amp;key)</code> - O(1) - Returns value and marks as recently used - <code>put(key, value)</code> - O(1) - Inserts and evicts LRU if full - Thread-safe with <code>Mutex</code></p>"},{"location":"crates/nori-sstable/caching/#memory-management","title":"Memory Management","text":"<p>Block structure: <pre><code>pub struct Block {\n    data: Bytes,              // Block data (4KB typical)\n    restart_offsets: Vec&lt;u32&gt;, // Restart point offsets\n    // ...\n}\n</code></pre></p> <p>Memory per cached block: ~4KB + ~64 bytes overhead = ~4100 bytes</p> <p>Total cache memory: <pre><code>Memory = (blocks_in_cache * 4100 bytes) \u2248 block_cache_mb * 1024 * 1024\n</code></pre></p>"},{"location":"crates/nori-sstable/caching/#thread-safety","title":"Thread Safety","text":"<p>The cache is protected by a Tokio async <code>Mutex</code>:</p> <pre><code>// Multiple readers can safely access cache concurrently\nlet reader = Arc::new(SSTableReader::open(\"data.sst\").await?);\n\nfor _ in 0..4 {\n    let reader_clone = reader.clone();\n    tokio::spawn(async move {\n        // Each task safely accesses shared cache\n        reader_clone.get(b\"key\").await?;\n    });\n}\n</code></pre> <p>Lock contention: - Cache locks are held briefly (&lt;1\u00b5s typically) - Read-heavy workloads scale well (cache hits don't modify LRU state) - Multiple readers can queue on cache lock (fair scheduling)</p>"},{"location":"crates/nori-sstable/caching/#best-practices","title":"Best Practices","text":""},{"location":"crates/nori-sstable/caching/#do","title":"Do","text":"<ul> <li>Enable caching by default (64MB is reasonable for most workloads)</li> <li>Monitor hit rates to validate cache effectiveness</li> <li>Increase cache for hot workloads (80/20 patterns benefit most)</li> <li>Combine with compression (store compressed, cache decompressed)</li> <li>Use <code>Arc&lt;SSTableReader&gt;</code> to share cache across threads</li> <li>Size based on hot data (not total data size)</li> </ul>"},{"location":"crates/nori-sstable/caching/#dont","title":"Don't","text":"<ul> <li>Don't disable cache unless memory is extremely limited</li> <li>Don't over-provision cache (diminishing returns beyond hot set size)</li> <li>Don't forget to monitor <code>sstable_block_cache_*</code> metrics</li> <li>Don't use tiny caches (&lt;16MB) - overhead not worth it</li> <li>Don't expect miracles on uniform access patterns (cache helps less)</li> </ul>"},{"location":"crates/nori-sstable/caching/#troubleshooting","title":"Troubleshooting","text":""},{"location":"crates/nori-sstable/caching/#cache-hit-rate-is-low-20","title":"\"Cache hit rate is low (&lt;20%)\"","text":"<p>Possible causes: 1. Cache too small for working set 2. Uniform access pattern (all keys accessed equally) 3. Working set larger than total data (shouldn't happen)</p> <p>Solutions: - Increase <code>block_cache_mb</code> to 256 or 512 MB - Check access pattern (is data actually hot?) - Monitor <code>sstable_block_reads</code> to see if disk I/O is high</p>"},{"location":"crates/nori-sstable/caching/#high-memory-usage","title":"\"High memory usage\"","text":"<p>Possible causes: 1. Cache configured too large 2. Multiple SSTableReaders with separate caches</p> <p>Solutions: - Reduce <code>block_cache_mb</code> to 64 or 32 MB - Share <code>SSTableReader</code> instances via <code>Arc</code> (shares cache) - Use <code>block_cache_mb: 0</code> for cold data SSTables</p>"},{"location":"crates/nori-sstable/caching/#cache-not-improving-performance","title":"\"Cache not improving performance\"","text":"<p>Possible causes: 1. Data access is write-heavy (cache only helps reads) 2. First-time reads (cache miss is expected) 3. Access pattern is sequential scan (cache less helpful)</p> <p>Solutions: - Verify workload is read-heavy - Allow warm-up period (first reads populate cache) - For sequential scans, cache is less beneficial (still helps for iterators)</p>"},{"location":"crates/nori-sstable/caching/#advanced-topics","title":"Advanced Topics","text":""},{"location":"crates/nori-sstable/caching/#cache-warming","title":"Cache Warming","text":"<p>For predictable workloads, pre-warm the cache:</p> <pre><code>// Pre-load hot keys into cache\nlet hot_keys = vec![b\"key1\", b\"key2\", b\"key3\"];\n\nfor key in hot_keys {\n    let _ = reader.get(key).await?;  // Populate cache\n}\n\n// Now subsequent reads are fast\nlet value = reader.get(b\"key1\").await?;  // Cache hit!\n</code></pre>"},{"location":"crates/nori-sstable/caching/#multiple-readers-shared-cache","title":"Multiple Readers, Shared Cache","text":"<pre><code>// Share reader (and cache) across threads\nlet reader = Arc::new(SSTableReader::open(\"data.sst\").await?);\n\nlet mut handles = vec![];\nfor i in 0..10 {\n    let reader_clone = reader.clone();  // Shares cache!\n    let handle = tokio::spawn(async move {\n        reader_clone.get(format!(\"key{}\", i).as_bytes()).await\n    });\n    handles.push(handle);\n}\n\n// All tasks share the same cache\nfor handle in handles {\n    handle.await??;\n}\n</code></pre>"},{"location":"crates/nori-sstable/caching/#separate-caches-for-different-sstables","title":"Separate Caches for Different SSTables","text":"<pre><code>// Each reader gets its own cache\nlet reader1 = Arc::new(SSTableReader::open(\"hot.sst\").await?);\nlet reader2 = Arc::new(SSTableReader::open(\"cold.sst\").await?);\n\n// hot.sst has 256MB cache\n// cold.sst has 16MB cache (or 0 to disable)\n</code></pre> <p>Use case: Allocate more cache to hot SSTables, less to cold ones.</p>"},{"location":"crates/nori-sstable/caching/#performance-tuning-workflow","title":"Performance Tuning Workflow","text":"<ol> <li>Start with defaults: <code>block_cache_mb: 64</code></li> <li>Deploy and monitor: <pre><code>sstable_block_cache_hits / (sstable_block_cache_hits + sstable_block_cache_misses)\n</code></pre></li> <li>Analyze hit rate:</li> <li>&gt;80%: Cache is sized well </li> <li>50-80%: Consider increasing cache</li> <li>&lt;50%: Increase cache or investigate access pattern</li> <li>Tune cache size:</li> <li>Increase by 2x increments (64 \u2192 128 \u2192 256)</li> <li>Monitor hit rate improvement</li> <li>Stop when hit rate plateaus (diminishing returns)</li> <li>Balance memory: Ensure total cache usage across all readers fits in RAM</li> </ol>"},{"location":"crates/nori-sstable/caching/#related-documentation","title":"Related Documentation","text":"<ul> <li>Compression Guide - Learn how compression works with caching</li> <li>Performance Benchmarks - See cache benchmark results</li> <li>API Reference - SSTableReader cache methods</li> <li>Tuning Guide - General performance tuning</li> </ul>"},{"location":"crates/nori-sstable/caching/#summary","title":"Summary","text":"<p>LRU Block Cache in nori-sstable: -  18x faster reads for hot key workloads -  Caches decompressed blocks (avoid repeated decompression) -  LRU eviction - automatic management -  Thread-safe - share via <code>Arc</code> -  Configurable - default 64MB, tune to workload -  Works with compression - best of both worlds</p> <p>Recommended configuration: <pre><code>SSTableConfig {\n    compression: Compression::Lz4,  // Storage savings\n    block_cache_mb: 64,              // Good default (tune as needed)\n    ..Default::default()\n}\n</code></pre></p> <p>Monitor this metric: <pre><code>cache_hit_rate = sstable_block_cache_hits / (hits + misses)\n</code></pre></p> <p>Result: Dramatically faster reads for hot data + storage savings!</p>"},{"location":"crates/nori-sstable/compression/","title":"Block Compression","text":"<p>Deep dive into LZ4 and Zstd compression in nori-sstable.</p>"},{"location":"crates/nori-sstable/compression/#overview","title":"Overview","text":"<p>nori-sstable supports block-level compression using industry-standard algorithms: LZ4 (fast compression with excellent decompression speed) and Zstd (higher compression ratios with moderate speed). Compression is applied at the block level (default 4KB blocks), balancing memory usage and compression effectiveness.</p> <p>{: .highlight }</p> <p>NEW Feature: Compression support was added in version 0.1 with full LZ4 and Zstd integration, comprehensive testing, and production-ready performance.</p>"},{"location":"crates/nori-sstable/compression/#why-compress","title":"Why Compress?","text":"<p>Storage Cost Savings: - Typical workloads: 2-3x size reduction with LZ4 - Highly compressible data: 14x+ size reduction - Zstd: 3-5x reduction for archival use cases</p> <p>Performance Tradeoffs: - Write overhead: Minimal (&lt;10% CPU increase with LZ4) - Read overhead: Mitigated by caching (decompress once, cache decompressed blocks) - Network savings: Smaller files mean faster backups and replication</p>"},{"location":"crates/nori-sstable/compression/#compression-algorithms","title":"Compression Algorithms","text":""},{"location":"crates/nori-sstable/compression/#compressionnone-no-compression","title":"Compression::None (No Compression)","text":"<p>When to use: - Ultra-low latency requirements (&lt;5\u00b5s reads) - Already compressed data (images, videos, encrypted data) - Very fast CPUs with slow storage (rare edge case) - Debugging or benchmarking raw SSTable performance</p> <p>Configuration: <pre><code>use nori_sstable::{SSTableConfig, Compression};\n\nlet config = SSTableConfig {\n    compression: Compression::None,\n    ..Default::default()\n};\n</code></pre></p> <p>Characteristics: - Zero CPU overhead - Largest file sizes - Simplest read/write path - Best for testing and development</p>"},{"location":"crates/nori-sstable/compression/#compressionlz4-recommended-default","title":"Compression::Lz4 (Recommended Default) \ud83c\udf1f","text":"<p>When to use: - Most production workloads (balanced speed and compression) - Hot data with frequent reads (combine with caching) - Real-time applications - Text data, JSON, logs, structured data</p> <p>Performance: - Compression speed: ~750 MB/s - Decompression speed: ~3,900 MB/s (blazingly fast!) - Compression ratio: 2-3x typical, up to 14x for highly compressible data - CPU overhead: Minimal (&lt;10% on writes)</p> <p>Configuration: <pre><code>use nori_sstable::{SSTableConfig, Compression};\n\nlet config = SSTableConfig {\n    compression: Compression::Lz4,  // Recommended!\n    ..Default::default()\n};\n</code></pre></p> <p>Why LZ4? 1. Fast decompression: 3.9 GB/s means negligible read overhead 2. Good compression: 2-3x savings for typical key-value data 3. Widely used: Industry standard (Kafka, RocksDB, Cassandra) 4. Cache-friendly: Decompress once, cache hot blocks</p> <p>{: .note }</p> <p>LZ4 + Cache = Best Performance: With the LRU cache enabled (default), hot blocks are decompressed once and served from memory. This means you get the storage savings of compression with zero decompression cost on cache hits.</p>"},{"location":"crates/nori-sstable/compression/#compressionzstd-higher-compression","title":"Compression::Zstd (Higher Compression)","text":"<p>When to use: - Cold storage or archival data - Infrequently accessed data - Storage cost is critical - Backup systems - Historical data retention</p> <p>Performance: - Compression speed: ~400 MB/s (slower than LZ4) - Decompression speed: ~1,200 MB/s (still fast!) - Compression ratio: 3-5x typical, better than LZ4 - CPU overhead: Moderate (~20% on writes)</p> <p>Configuration: <pre><code>use nori_sstable::{SSTableConfig, Compression};\n\nlet config = SSTableConfig {\n    compression: Compression::Zstd,  // For cold storage\n    block_cache_mb: 0,               // Disable cache for cold data\n    ..Default::default()\n};\n</code></pre></p> <p>Why Zstd? 1. Best compression ratio: 3-5x savings, sometimes higher 2. Still fast: 1.2 GB/s decompression is acceptable for cold data 3. Facebook-backed: Used in production at scale 4. Configurable: Can tune compression level (nori-sstable uses level 3)</p>"},{"location":"crates/nori-sstable/compression/#how-compression-works","title":"How Compression Works","text":""},{"location":"crates/nori-sstable/compression/#block-level-compression","title":"Block-Level Compression","text":"<p>nori-sstable compresses individual blocks (not the entire file):</p> <pre><code>Uncompressed Block (4KB):\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Entry 1 | Entry 2 | ... | Entry N  \u2502\n\u2502 (prefix compressed, ~4096 bytes)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2193 Compress with LZ4\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Compressed Block (~1.5KB)\u2502\n\u2502 (stored on disk)        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Benefits of block-level compression: - Random access: Can decompress single block without reading entire file - Memory efficient: Only decompress blocks you need - Balanced compression: 4KB blocks compress well without excessive overhead - Prefix compression + LZ4: Double compression benefit (prefix within block, LZ4 across block)</p>"},{"location":"crates/nori-sstable/compression/#write-path-compression","title":"Write Path (Compression)","text":"<pre><code>Builder.add(entry)\n    \u2193\nBlockBuilder (prefix compression)\n    \u2193 Block fills up (4KB)\nBlockBuilder.finish()\n    \u2193 Returns uncompressed block\ncompress::compress(block, Compression::Lz4)\n    \u2193 Compress entire block\nWriter.write_block(compressed_data)\n    \u2193 Write to disk\nFile: [...compressed blocks...][index][bloom][footer]\n</code></pre> <p>Code snippet from builder.rs: <pre><code>// Finish the block (uncompressed, with prefix compression)\nlet block_data = self.block_builder.finish();\nlet uncompressed_size = block_data.len();\n\n// Compress the entire block\nlet compressed_data = compress::compress(&amp;block_data, self.config.compression)?;\nlet compressed_size = compressed_data.len();\n\n// Write compressed block to disk\nlet block_offset = self.writer.write_block(&amp;compressed_data).await?;\n\n// Track compression ratio\nlet ratio = uncompressed_size as f64 / compressed_size.max(1) as f64;\nself.meter.histo(\"sstable_compression_ratio\", ...).observe(ratio);\n</code></pre></p>"},{"location":"crates/nori-sstable/compression/#read-path-decompression","title":"Read Path (Decompression)","text":"<pre><code>Reader.get(key)\n    \u2193\nCheck bloom filter \u2192 Check cache \u2192 Find block via index\n    \u2193\nread_block(offset, size)\n    \u2193\nCheck cache (decompressed blocks cached)\n    \u2193 Cache miss\nRead compressed bytes from disk\n    \u2193\ncompress::decompress(bytes, footer.compression)\n    \u2193 Decompress entire block\nBlock::decode(decompressed_bytes)\n    \u2193 Decode entries (prefix decompression)\nCache decompressed block (for future hits)\n    \u2193\nReturn entry to user\n</code></pre> <p>Key insight: Decompressed blocks are cached, so hot data only pays decompression cost once!</p>"},{"location":"crates/nori-sstable/compression/#configuration-examples","title":"Configuration Examples","text":""},{"location":"crates/nori-sstable/compression/#default-lz4-with-cache","title":"Default (LZ4 with Cache)","text":"<pre><code>use nori_sstable::{SSTableBuilder, SSTableConfig, Compression};\n\nlet config = SSTableConfig {\n    path: \"data.sst\".into(),\n    estimated_entries: 10_000,\n    compression: Compression::Lz4,  // Fast compression\n    block_cache_mb: 64,              // Cache decompressed blocks\n    ..Default::default()\n};\n\nlet mut builder = SSTableBuilder::new(config).await?;\n</code></pre> <p>Use case: Production workloads with balanced read/write performance</p>"},{"location":"crates/nori-sstable/compression/#maximum-compression-zstd-for-cold-storage","title":"Maximum Compression (Zstd for Cold Storage)","text":"<pre><code>let config = SSTableConfig {\n    path: \"archive.sst\".into(),\n    estimated_entries: 100_000,\n    compression: Compression::Zstd,  // Higher compression ratio\n    block_cache_mb: 0,               // Disable cache (cold data)\n    ..Default::default()\n};\n</code></pre> <p>Use case: Archival, backups, infrequently accessed data</p>"},{"location":"crates/nori-sstable/compression/#no-compression-maximum-speed","title":"No Compression (Maximum Speed)","text":"<pre><code>let config = SSTableConfig {\n    path: \"hot.sst\".into(),\n    estimated_entries: 1_000,\n    compression: Compression::None,  // No compression overhead\n    block_cache_mb: 256,             // Large cache for speed\n    ..Default::default()\n};\n</code></pre> <p>Use case: Ultra-low latency requirements, testing, or already-compressed data</p>"},{"location":"crates/nori-sstable/compression/#compression-ratios","title":"Compression Ratios","text":""},{"location":"crates/nori-sstable/compression/#real-world-test-results","title":"Real-World Test Results","text":"<p>From <code>tests/compression_tests.rs</code>:</p> <pre><code>// Test: Repetitive text data (highly compressible)\nlet value = \"test_value_that_should_compress_well_\".repeat(10);\n\n// Result: 14.38x compression ratio!\n// Uncompressed: 11,777 bytes\n// Compressed:      819 bytes\n</code></pre> <p>Expected ratios by data type:</p> Data Type LZ4 Ratio Zstd Ratio Notes Repeated values 10-20x 15-30x Highly compressible JSON/Text 2-4x 3-6x Structured data compresses well Binary data 1.5-2.5x 2-4x Moderate compression Random data ~1x ~1x May expand slightly Pre-compressed ~1x ~1x Already compressed (images, videos)"},{"location":"crates/nori-sstable/compression/#compression-vs-block-size","title":"Compression vs Block Size","text":"<p>Larger blocks generally compress better, but increase memory usage:</p> Block Size Compression Ratio Memory per Block Random Access 1 KB ~1.8x Low Excellent 4 KB ~2.5x Balanced Good 16 KB ~3.2x High Fair 64 KB ~3.8x Very high Poor <p>Recommendation: Stick with the default 4KB block size for balanced performance.</p>"},{"location":"crates/nori-sstable/compression/#performance-analysis","title":"Performance Analysis","text":""},{"location":"crates/nori-sstable/compression/#write-performance","title":"Write Performance","text":"<p>LZ4 overhead on build (10K entries): - No compression: 100K entries/sec - LZ4 compression: 95K entries/sec (~5% slower) - Zstd compression: 85K entries/sec (~15% slower)</p> <p>Bottleneck: Disk I/O, not compression (SSDs write slower than LZ4 compresses)</p>"},{"location":"crates/nori-sstable/compression/#read-performance","title":"Read Performance","text":"<p>Point lookup with cache: - Cache hit: ~5\u00b5s (no decompression needed) - Cache miss + decompress: ~15\u00b5s (one-time cost) - Subsequent reads: ~5\u00b5s (cached)</p> <p>Impact: Negligible with caching enabled (default).</p>"},{"location":"crates/nori-sstable/compression/#storage-savings","title":"Storage Savings","text":"<p>Example: 1GB of JSON data - Uncompressed: 1,000 MB - LZ4 compressed: ~350 MB (2.9x savings) - Zstd compressed: ~220 MB (4.5x savings)</p> <p>Cost-benefit: - LZ4: 650MB saved, &lt;5% write overhead, &lt;1% read overhead with cache - Zstd: 780MB saved, ~15% write overhead, ~3% read overhead with cache</p>"},{"location":"crates/nori-sstable/compression/#compression-caching-synergy","title":"Compression + Caching Synergy","text":"<p>The killer combination: LZ4 compression + LRU block cache</p> <pre><code>let config = SSTableConfig {\n    compression: Compression::Lz4,  // 2-3x storage savings\n    block_cache_mb: 64,              // Cache decompressed blocks\n    ..Default::default()\n};\n</code></pre> <p>What happens: 1. Write: Data is compressed before writing (save storage) 2. First read (cache miss): Decompress block once (~10\u00b5s overhead) 3. Cache: Store decompressed block in memory 4. Subsequent reads (cache hit): Serve from cache (no decompression!)</p> <p>Result: Storage savings of compression + speed of uncompressed reads!</p> <p>Metrics to monitor: <pre><code>// Cache effectiveness\nsstable_block_cache_hits     // High = good caching\nsstable_block_cache_misses   // Low = good caching\n\n// Compression effectiveness\nsstable_compression_ratio    // Higher = better compression\n</code></pre></p>"},{"location":"crates/nori-sstable/compression/#migration-guide","title":"Migration Guide","text":""},{"location":"crates/nori-sstable/compression/#changing-compression-on-existing-data","title":"Changing Compression on Existing Data","text":"<p>Important: You cannot change compression on existing SSTable files. Compression is set at build time and stored in the footer.</p> <p>To change compression: 1. Build new SSTables with desired compression setting 2. Read from old SSTables, write to new SSTables 3. Delete old SSTables once migrated</p> <p>Example migration: <pre><code>// Read from old uncompressed SSTable\nlet old_reader = Arc::new(SSTableReader::open(\"old.sst\").await?);\n\n// Create new compressed SSTable\nlet config = SSTableConfig {\n    path: \"new.sst\".into(),\n    compression: Compression::Lz4,  // Enable compression\n    ..Default::default()\n};\nlet mut builder = SSTableBuilder::new(config).await?;\n\n// Copy all entries\nlet mut iter = old_reader.iter();\nwhile let Some(entry) = iter.try_next().await? {\n    builder.add(&amp;entry).await?;\n}\n\nbuilder.finish().await?;\n</code></pre></p>"},{"location":"crates/nori-sstable/compression/#best-practices","title":"Best Practices","text":""},{"location":"crates/nori-sstable/compression/#do","title":"Do","text":"<ul> <li>Use LZ4 by default for production workloads</li> <li>Enable caching with compression (64MB+ cache)</li> <li>Monitor compression ratios via metrics</li> <li>Use Zstd for cold storage where reads are infrequent</li> <li>Keep default 4KB blocks unless you have specific needs</li> <li>Test with your data to measure actual compression ratios</li> </ul>"},{"location":"crates/nori-sstable/compression/#dont","title":"Don't","text":"<ul> <li>Don't compress already-compressed data (images, videos)</li> <li>Don't use Zstd for hot, latency-sensitive workloads</li> <li>Don't disable caching with compression (loses performance benefit)</li> <li>Don't change block size unless benchmarks show improvement</li> <li>Don't expect compression on random or encrypted data</li> </ul>"},{"location":"crates/nori-sstable/compression/#troubleshooting","title":"Troubleshooting","text":""},{"location":"crates/nori-sstable/compression/#compression-ratio-is-only-11x","title":"\"Compression ratio is only 1.1x\"","text":"<p>Possible causes: - Data is already compressed (check data type) - Data is random/encrypted (not compressible) - Very small values (compression overhead dominates)</p> <p>Solution: Consider <code>Compression::None</code> if ratio &lt; 1.5x</p>"},{"location":"crates/nori-sstable/compression/#reads-are-slower-with-compression","title":"\"Reads are slower with compression\"","text":"<p>Possible causes: - Cache disabled (decompressing every read) - Cache too small (frequent evictions) - Using Zstd on hot data</p> <p>Solution: - Enable cache: <code>block_cache_mb: 64</code> or higher - Switch to LZ4 for hot data - Monitor <code>sstable_block_cache_hits</code> metric</p>"},{"location":"crates/nori-sstable/compression/#write-performance-degraded","title":"\"Write performance degraded\"","text":"<p>Possible causes: - Using Zstd (slower compression) - Very large blocks (compression overhead)</p> <p>Solution: - Use LZ4 instead of Zstd - Keep default 4KB block size - Write overhead should be &lt;10% with LZ4</p>"},{"location":"crates/nori-sstable/compression/#implementation-details","title":"Implementation Details","text":""},{"location":"crates/nori-sstable/compression/#compression-module","title":"Compression Module","text":"<p>Location: <code>crates/nori-sstable/src/compress.rs</code></p> <pre><code>pub fn compress(data: &amp;[u8], algo: Compression) -&gt; Result&lt;Vec&lt;u8&gt;&gt; {\n    match algo {\n        Compression::None =&gt; Ok(data.to_vec()),\n        Compression::Lz4 =&gt; compress_lz4(data),\n        Compression::Zstd =&gt; compress_zstd(data),\n    }\n}\n\npub fn decompress(data: &amp;[u8], algo: Compression) -&gt; Result&lt;Vec&lt;u8&gt;&gt; {\n    match algo {\n        Compression::None =&gt; Ok(data.to_vec()),\n        Compression::Lz4 =&gt; decompress_lz4(data),\n        Compression::Zstd =&gt; decompress_zstd(data),\n    }\n}\n</code></pre> <p>Safety: Conservative decompression limits prevent decompression bombs: - LZ4: Max 256KB decompressed output - Zstd: Bounded by input size heuristics</p>"},{"location":"crates/nori-sstable/compression/#footer-storage","title":"Footer Storage","text":"<p>Compression type is stored in the SSTable footer:</p> <pre><code>pub struct Footer {\n    // ... other fields\n    pub compression: Compression,  // Enum: None, Lz4, or Zstd\n    // ...\n}\n</code></pre> <p>On open: Reader reads footer and uses compression type for all block decompression.</p>"},{"location":"crates/nori-sstable/compression/#related-documentation","title":"Related Documentation","text":"<ul> <li>Caching Guide - Learn how caching works with compression</li> <li>Performance Benchmarks - See compression benchmark results</li> <li>API Reference - SSTableConfig compression field</li> <li>Compression Ratios - Detailed ratio analysis</li> </ul>"},{"location":"crates/nori-sstable/compression/#summary","title":"Summary","text":"<p>Compression in nori-sstable: -  Block-level compression (4KB blocks) -  LZ4 (fast, 2-3x) and Zstd (higher, 3-5x) support -  Production-ready with 108 tests passing -  Works seamlessly with LRU cache (decompress once, cache decompressed) -  Minimal performance overhead (&lt;10% writes, ~0% reads with cache) -  2-14x storage savings on typical workloads</p> <p>Recommended configuration: <pre><code>SSTableConfig {\n    compression: Compression::Lz4,  // Fast + good ratio\n    block_cache_mb: 64,              // Cache decompressed blocks\n    ..Default::default()\n}\n</code></pre></p> <p>Result: Storage savings + fast reads = production-ready performance!</p>"},{"location":"crates/nori-sstable/getting-started/","title":"Getting Started with nori-sstable","text":"<p>Build your first SSTable in 5 minutes.</p>"},{"location":"crates/nori-sstable/getting-started/#installation","title":"Installation","text":"<p>Add <code>nori-sstable</code> to your <code>Cargo.toml</code>:</p> <pre><code>[dependencies]\nnori-sstable = \"0.1\"\ntokio = { version = \"1\", features = [\"full\"] }\n</code></pre> <p>{: .note }</p> <p>nori-sstable requires <code>tokio</code> for async I/O. Make sure to include the <code>full</code> feature set or at minimum <code>fs</code>, <code>io-util</code>, and <code>rt</code>.</p>"},{"location":"crates/nori-sstable/getting-started/#your-first-sstable","title":"Your First SSTable","text":""},{"location":"crates/nori-sstable/getting-started/#step-1-create-a-builder","title":"Step 1: Create a Builder","text":"<pre><code>use nori_sstable::{SSTableBuilder, SSTableConfig};\nuse std::path::PathBuf;\n\n#[tokio::main]\nasync fn main() -&gt; nori_sstable::Result&lt;()&gt; {\n    // Configure the SSTable\n    let config = SSTableConfig {\n        path: PathBuf::from(\"my_first.sst\"),\n        estimated_entries: 1000,\n        ..Default::default()\n    };\n\n    // Create the builder\n    let mut builder = SSTableBuilder::new(config).await?;\n\n    Ok(())\n}\n</code></pre>"},{"location":"crates/nori-sstable/getting-started/#step-2-add-entries","title":"Step 2: Add Entries","text":"<p>Entries must be added in sorted order by key:</p> <pre><code>use nori_sstable::Entry;\n\n// Add key-value pairs\nbuilder.add(&amp;Entry::put(\"apple\", \"red fruit\")).await?;\nbuilder.add(&amp;Entry::put(\"banana\", \"yellow fruit\")).await?;\nbuilder.add(&amp;Entry::put(\"cherry\", \"red fruit\")).await?;\n\n// Add a tombstone (deletion marker)\nbuilder.add(&amp;Entry::delete(\"durian\")).await?;\n</code></pre> <p>{: .warning }</p> <p>Important: Keys must be added in sorted order. If you try to add keys out of order, you'll get a <code>KeysNotSorted</code> error.</p>"},{"location":"crates/nori-sstable/getting-started/#step-3-finish-building","title":"Step 3: Finish Building","text":"<pre><code>// Finalize the SSTable (writes index, bloom filter, footer)\nlet metadata = builder.finish().await?;\n\nprintln!(\" Created SSTable:\");\nprintln!(\"   Path: {:?}\", metadata.path);\nprintln!(\"   Entries: {}\", metadata.entry_count);\nprintln!(\"   Size: {} bytes\", metadata.file_size);\nprintln!(\"   Blocks: {}\", metadata.block_count);\n</code></pre>"},{"location":"crates/nori-sstable/getting-started/#complete-example","title":"Complete Example","text":"<pre><code>use nori_sstable::{Entry, SSTableBuilder, SSTableConfig};\nuse std::path::PathBuf;\n\n#[tokio::main]\nasync fn main() -&gt; nori_sstable::Result&lt;()&gt; {\n    // Create builder\n    let config = SSTableConfig {\n        path: PathBuf::from(\"my_first.sst\"),\n        estimated_entries: 1000,\n        ..Default::default()\n    };\n    let mut builder = SSTableBuilder::new(config).await?;\n\n    // Add entries (sorted order!)\n    builder.add(&amp;Entry::put(\"apple\", \"red fruit\")).await?;\n    builder.add(&amp;Entry::put(\"banana\", \"yellow fruit\")).await?;\n    builder.add(&amp;Entry::put(\"cherry\", \"red fruit\")).await?;\n\n    // Finish\n    let metadata = builder.finish().await?;\n    println!(\" Created SSTable with {} entries\", metadata.entry_count);\n\n    Ok(())\n}\n</code></pre>"},{"location":"crates/nori-sstable/getting-started/#reading-from-an-sstable","title":"Reading from an SSTable","text":""},{"location":"crates/nori-sstable/getting-started/#step-1-open-a-reader","title":"Step 1: Open a Reader","text":"<pre><code>use nori_sstable::SSTableReader;\nuse std::sync::Arc;\n\n#[tokio::main]\nasync fn main() -&gt; nori_sstable::Result&lt;()&gt; {\n    // Open the SSTable file\n    let reader = Arc::new(\n        SSTableReader::open(PathBuf::from(\"my_first.sst\")).await?\n    );\n\n    Ok(())\n}\n</code></pre> <p>{: .note }</p> <p>We wrap the reader in <code>Arc</code> because it's designed to be shared across threads. The reader is immutable and thread-safe.</p>"},{"location":"crates/nori-sstable/getting-started/#step-2-point-lookups","title":"Step 2: Point Lookups","text":"<pre><code>// Look up a single key\nif let Some(entry) = reader.get(b\"banana\").await? {\n    println!(\"Found: key={:?}, value={:?}\",\n        String::from_utf8_lossy(&amp;entry.key),\n        String::from_utf8_lossy(&amp;entry.value)\n    );\n} else {\n    println!(\"Key not found\");\n}\n</code></pre> <p>What happens: 1. Bloom filter check (~67ns) - might the key exist? 2. Index lookup (O(log B)) - which block contains the key? 3. Block read (cache or disk) - read the 4KB block 4. Binary search within block - find the exact entry</p>"},{"location":"crates/nori-sstable/getting-started/#step-3-range-scans","title":"Step 3: Range Scans","text":"<pre><code>// Iterate over all entries\nlet mut iter = reader.clone().iter();\n\nwhile let Some(entry) = iter.try_next().await? {\n    println!(\"{:?} = {:?}\",\n        String::from_utf8_lossy(&amp;entry.key),\n        String::from_utf8_lossy(&amp;entry.value)\n    );\n}\n</code></pre>"},{"location":"crates/nori-sstable/getting-started/#step-4-range-with-bounds","title":"Step 4: Range with Bounds","text":"<pre><code>// Scan from \"apple\" to \"cherry\" (exclusive end)\nlet mut range_iter = reader.iter_range(\n    Bytes::from(\"apple\"),\n    Bytes::from(\"cherry\")\n);\n\nwhile let Some(entry) = range_iter.try_next().await? {\n    // Only entries with apple &lt;= key &lt; cherry\n    println!(\"{:?}\", String::from_utf8_lossy(&amp;entry.key));\n}\n</code></pre>"},{"location":"crates/nori-sstable/getting-started/#complete-read-example","title":"Complete Read Example","text":"<pre><code>use nori_sstable::SSTableReader;\nuse std::sync::Arc;\nuse std::path::PathBuf;\n\n#[tokio::main]\nasync fn main() -&gt; nori_sstable::Result&lt;()&gt; {\n    // Open reader\n    let reader = Arc::new(SSTableReader::open(PathBuf::from(\"my_first.sst\")).await?);\n\n    // Point lookup\n    if let Some(entry) = reader.get(b\"banana\").await? {\n        println!(\"Found banana: {:?}\", String::from_utf8_lossy(&amp;entry.value));\n    }\n\n    // Full scan\n    let mut iter = reader.iter();\n    while let Some(entry) = iter.try_next().await? {\n        println!(\"{:?} = {:?}\",\n            String::from_utf8_lossy(&amp;entry.key),\n            String::from_utf8_lossy(&amp;entry.value)\n        );\n    }\n\n    Ok(())\n}\n</code></pre>"},{"location":"crates/nori-sstable/getting-started/#enabling-compression","title":"Enabling Compression","text":""},{"location":"crates/nori-sstable/getting-started/#why-compress","title":"Why Compress?","text":"<ul> <li>Save storage: 2-3x size reduction (LZ4) or 3-5x (Zstd)</li> <li>Fast decompression: LZ4 decompresses at 3.9 GB/s</li> <li>Cache-friendly: Decompressed blocks are cached</li> </ul>"},{"location":"crates/nori-sstable/getting-started/#using-lz4-compression-recommended","title":"Using LZ4 Compression (Recommended)","text":"<pre><code>use nori_sstable::{SSTableConfig, Compression};\n\nlet config = SSTableConfig {\n    path: PathBuf::from(\"compressed.sst\"),\n    estimated_entries: 1000,\n    compression: Compression::Lz4,  // \u2728 Enable compression\n    ..Default::default()\n};\n\nlet mut builder = SSTableBuilder::new(config).await?;\n</code></pre> <p>Reading is automatic: <pre><code>// Reader automatically detects compression from footer\nlet reader = Arc::new(SSTableReader::open(\"compressed.sst\".into()).await?);\n\n// Reads work exactly the same - compression is transparent!\nlet entry = reader.get(b\"key\").await?;\n</code></pre></p> <p>{: .highlight }</p> <p>Pro tip: Combine compression with caching for best results. The default 64MB cache will store decompressed blocks, giving you storage savings + fast reads!</p>"},{"location":"crates/nori-sstable/getting-started/#using-zstd-compression-higher-ratio","title":"Using Zstd Compression (Higher Ratio)","text":"<p>For cold storage or archival data:</p> <pre><code>let config = SSTableConfig {\n    path: PathBuf::from(\"archive.sst\"),\n    estimated_entries: 10_000,\n    compression: Compression::Zstd,  // Higher compression ratio\n    block_cache_mb: 0,               // Disable cache for cold data\n    ..Default::default()\n};\n</code></pre> <p>Learn more about compression \u2192</p>"},{"location":"crates/nori-sstable/getting-started/#configuring-the-cache","title":"Configuring the Cache","text":""},{"location":"crates/nori-sstable/getting-started/#default-cache-64mb","title":"Default Cache (64MB)","text":"<p>The default configuration includes a 64MB LRU cache:</p> <pre><code>// This automatically includes 64MB cache\nlet reader = SSTableReader::open(\"data.sst\".into()).await?;\n</code></pre>"},{"location":"crates/nori-sstable/getting-started/#custom-cache-size","title":"Custom Cache Size","text":"<p>For hot workloads, increase the cache:</p> <pre><code>use nori_observe::NoopMeter;\n\n// 256MB cache for hot data\nlet reader = SSTableReader::open_with_config(\n    \"hot_data.sst\".into(),\n    Arc::new(NoopMeter),\n    256  // MB\n).await?;\n</code></pre>"},{"location":"crates/nori-sstable/getting-started/#disable-cache-cold-storage","title":"Disable Cache (Cold Storage)","text":"<p>For infrequently accessed data:</p> <pre><code>let config = SSTableConfig {\n    block_cache_mb: 0,  // Disable caching\n    ..Default::default()\n};\n</code></pre> <p>Learn more about caching \u2192</p>"},{"location":"crates/nori-sstable/getting-started/#error-handling","title":"Error Handling","text":""},{"location":"crates/nori-sstable/getting-started/#common-errors","title":"Common Errors","text":"<pre><code>use nori_sstable::{SSTableError, Result};\n\nmatch builder.add(&amp;Entry::put(\"key\", \"value\")).await {\n    Ok(_) =&gt; println!(\"Added successfully\"),\n\n    Err(SSTableError::KeysNotSorted(prev, current)) =&gt; {\n        eprintln!(\"Error: Keys must be sorted!\");\n        eprintln!(\"Previous: {:?}, Current: {:?}\", prev, current);\n    }\n\n    Err(SSTableError::Io(e)) =&gt; {\n        eprintln!(\"I/O error: {}\", e);\n    }\n\n    Err(e) =&gt; {\n        eprintln!(\"Other error: {}\", e);\n    }\n}\n</code></pre>"},{"location":"crates/nori-sstable/getting-started/#using-the-operator","title":"Using the ? Operator","text":"<p>Most examples use <code>?</code> for error propagation:</p> <pre><code>async fn build_sstable() -&gt; Result&lt;()&gt; {\n    let mut builder = SSTableBuilder::new(config).await?;\n    builder.add(&amp;Entry::put(\"key\", \"value\")).await?;\n    builder.finish().await?;\n    Ok(())\n}\n</code></pre>"},{"location":"crates/nori-sstable/getting-started/#working-with-entries","title":"Working with Entries","text":""},{"location":"crates/nori-sstable/getting-started/#put-entries","title":"PUT Entries","text":"<pre><code>// From string slices\nlet entry = Entry::put(\"key\", \"value\");\n\n// From byte slices\nlet entry = Entry::put(b\"key\", b\"value\");\n\n// From byte vectors\nlet entry = Entry::put(vec![1, 2, 3], vec![4, 5, 6]);\n\n// From Bytes (zero-copy)\nuse bytes::Bytes;\nlet entry = Entry::put(Bytes::from(\"key\"), Bytes::from(\"value\"));\n</code></pre>"},{"location":"crates/nori-sstable/getting-started/#delete-entries-tombstones","title":"DELETE Entries (Tombstones)","text":"<pre><code>// Mark a key as deleted\nlet entry = Entry::delete(\"key_to_delete\");\n\n// When reading, tombstones are still returned\nif let Some(entry) = reader.get(b\"key_to_delete\").await? {\n    if entry.tombstone {\n        println!(\"Key was deleted\");\n    }\n}\n</code></pre>"},{"location":"crates/nori-sstable/getting-started/#checking-for-tombstones","title":"Checking for Tombstones","text":"<pre><code>let entry = reader.get(b\"key\").await?;\n\nmatch entry {\n    Some(e) if e.tombstone =&gt; println!(\"Key deleted\"),\n    Some(e) =&gt; println!(\"Value: {:?}\", e.value),\n    None =&gt; println!(\"Key not found\"),\n}\n</code></pre>"},{"location":"crates/nori-sstable/getting-started/#configuration-options","title":"Configuration Options","text":""},{"location":"crates/nori-sstable/getting-started/#sstableconfig","title":"SSTableConfig","text":"<pre><code>use nori_sstable::{SSTableConfig, Compression};\n\nlet config = SSTableConfig {\n    // Required\n    path: PathBuf::from(\"data.sst\"),           // Output file path\n    estimated_entries: 10_000,                 // For bloom filter sizing\n\n    // Optional (with defaults)\n    block_size: 4096,                          // 4KB blocks (default)\n    restart_interval: 16,                      // Prefix compression restarts\n    compression: Compression::Lz4,             // None, Lz4, or Zstd\n    bloom_bits_per_key: 10,                    // ~0.9% false positive rate\n    block_cache_mb: 64,                        // LRU cache size in MB\n};\n</code></pre>"},{"location":"crates/nori-sstable/getting-started/#common-configurations","title":"Common Configurations","text":"<p>Development (no compression, small cache): <pre><code>let config = SSTableConfig {\n    path: \"dev.sst\".into(),\n    estimated_entries: 100,\n    compression: Compression::None,\n    block_cache_mb: 16,\n    ..Default::default()\n};\n</code></pre></p> <p>Production (LZ4 + cache): <pre><code>let config = SSTableConfig {\n    path: \"prod.sst\".into(),\n    estimated_entries: 100_000,\n    compression: Compression::Lz4,\n    block_cache_mb: 256,\n    ..Default::default()\n};\n</code></pre></p> <p>Archival (Zstd, no cache): <pre><code>let config = SSTableConfig {\n    path: \"archive.sst\".into(),\n    estimated_entries: 1_000_000,\n    compression: Compression::Zstd,\n    block_cache_mb: 0,\n    ..Default::default()\n};\n</code></pre></p>"},{"location":"crates/nori-sstable/getting-started/#thread-safety","title":"Thread Safety","text":""},{"location":"crates/nori-sstable/getting-started/#sharing-readers","title":"Sharing Readers","text":"<p>Readers are designed to be shared via <code>Arc</code>:</p> <pre><code>let reader = Arc::new(SSTableReader::open(\"data.sst\".into()).await?);\n\n// Spawn multiple tasks sharing the same reader\nfor i in 0..4 {\n    let reader_clone = reader.clone();\n    tokio::spawn(async move {\n        let key = format!(\"key{}\", i);\n        reader_clone.get(key.as_bytes()).await\n    });\n}\n</code></pre> <p>Benefits: - Cache is shared across all tasks - No duplication of index/bloom filter in memory - Thread-safe concurrent reads</p>"},{"location":"crates/nori-sstable/getting-started/#builders-are-not-thread-safe","title":"Builders are NOT Thread-Safe","text":"<pre><code>//  Wrong - don't share builders\nlet builder = Arc::new(Mutex::new(builder));\n\n//  Correct - one builder per SSTable\nlet mut builder = SSTableBuilder::new(config).await?;\n</code></pre>"},{"location":"crates/nori-sstable/getting-started/#best-practices","title":"Best Practices","text":""},{"location":"crates/nori-sstable/getting-started/#do","title":"Do","text":"<ul> <li>Sort keys before adding - use a BTreeMap or sort your data first</li> <li>Estimate entries accurately - improves bloom filter sizing</li> <li>Use compression - LZ4 is nearly free with caching</li> <li>Enable caching - 64MB default is reasonable</li> <li>Wrap readers in Arc - share across threads</li> <li>Use <code>?</code> for error handling - simplifies code</li> </ul>"},{"location":"crates/nori-sstable/getting-started/#dont","title":"Don't","text":"<ul> <li>Don't add keys out of order (will error)</li> <li>Don't forget to call <code>finish()</code> on builder</li> <li>Don't share builders across threads</li> <li>Don't open multiple readers for the same file (share one)</li> <li>Don't disable cache unless memory is very limited</li> </ul>"},{"location":"crates/nori-sstable/getting-started/#next-steps","title":"Next Steps","text":""},{"location":"crates/nori-sstable/getting-started/#learn-more","title":"Learn More","text":"<ul> <li>Compression Guide - Deep dive into LZ4/Zstd</li> <li>Caching Guide - Optimize for hot workloads</li> <li>Architecture - Understand the file format</li> <li>API Reference - Complete API documentation</li> </ul>"},{"location":"crates/nori-sstable/getting-started/#examples","title":"Examples","text":"<ul> <li>Basic Usage - More complete examples</li> <li>Hot Workloads - Cache tuning</li> <li>Cold Storage - Archival patterns</li> </ul>"},{"location":"crates/nori-sstable/getting-started/#performance","title":"Performance","text":"<ul> <li>Benchmarks - See performance numbers</li> <li>Tuning Guide - Optimize for your workload</li> </ul>"},{"location":"crates/nori-sstable/getting-started/#complete-example-build-and-read","title":"Complete Example: Build and Read","text":"<p>Here's a complete program that builds and reads an SSTable:</p> <pre><code>use nori_sstable::{\n    Entry, SSTableBuilder, SSTableReader, SSTableConfig, Compression\n};\nuse std::path::PathBuf;\nuse std::sync::Arc;\n\n#[tokio::main]\nasync fn main() -&gt; nori_sstable::Result&lt;()&gt; {\n    // Build SSTable\n    let config = SSTableConfig {\n        path: PathBuf::from(\"example.sst\"),\n        estimated_entries: 100,\n        compression: Compression::Lz4,\n        block_cache_mb: 64,\n        ..Default::default()\n    };\n\n    let mut builder = SSTableBuilder::new(config).await?;\n\n    // Add sorted entries\n    for i in 0..100 {\n        let key = format!(\"key_{:04}\", i);\n        let value = format!(\"value_{:04}\", i);\n        builder.add(&amp;Entry::put(key, value)).await?;\n    }\n\n    let metadata = builder.finish().await?;\n    println!(\" Built SSTable: {} entries, {} bytes\",\n        metadata.entry_count, metadata.file_size);\n\n    // Read SSTable\n    let reader = Arc::new(SSTableReader::open(PathBuf::from(\"example.sst\")).await?);\n\n    // Point lookup\n    if let Some(entry) = reader.get(b\"key_0042\").await? {\n        println!(\"Found key_0042: {:?}\", String::from_utf8_lossy(&amp;entry.value));\n    }\n\n    // Range scan (first 10 keys)\n    let mut iter = reader.iter();\n    let mut count = 0;\n    while let Some(entry) = iter.try_next().await? {\n        println!(\"{:?} = {:?}\",\n            String::from_utf8_lossy(&amp;entry.key),\n            String::from_utf8_lossy(&amp;entry.value)\n        );\n        count += 1;\n        if count &gt;= 10 {\n            break;\n        }\n    }\n\n    Ok(())\n}\n</code></pre> <p>Run this with: <pre><code>cargo run --example build_and_read\n</code></pre></p>"},{"location":"crates/nori-sstable/getting-started/#summary","title":"Summary","text":"<p>You've learned how to:</p> <ul> <li>Install nori-sstable</li> <li>Build an SSTable with sorted entries</li> <li>Read data with point lookups and range scans</li> <li>Enable LZ4/Zstd compression</li> <li>Configure the LRU cache</li> <li>Handle errors properly</li> <li>Share readers across threads</li> </ul> <p>Next: Explore compression and caching to optimize performance, or dive into the API reference for complete documentation.</p> <p>Happy coding! </p>"},{"location":"crates/nori-sstable/api-reference/","title":"API Reference","text":"<p>Complete API documentation for nori-sstable.</p>"},{"location":"crates/nori-sstable/api-reference/#overview","title":"Overview","text":"<p>This section provides complete API documentation for all public types, methods, and traits in nori-sstable. For usage examples and guides, see Getting Started.</p> <p>{: .note }</p> <p>Auto-generated API docs: For exhaustive rustdoc documentation with all method signatures and examples, see the rustdoc \u2192</p>"},{"location":"crates/nori-sstable/api-reference/#quick-reference","title":"Quick Reference","text":""},{"location":"crates/nori-sstable/api-reference/#core-types","title":"Core Types","text":"Type Purpose Page <code>SSTableBuilder</code> Builds immutable SSTables Builder API \u2192 <code>SSTableReader</code> Reads from SSTables Reader API \u2192 <code>SSTableConfig</code> Configuration for building Config API \u2192 <code>Entry</code> Key-value entry with tombstone Entry API \u2192 <code>SSTableIterator</code> Sequential iteration Iterator API \u2192"},{"location":"crates/nori-sstable/api-reference/#enums","title":"Enums","text":"Type Purpose Values <code>Compression</code> Block compression algorithm <code>None</code>, <code>Lz4</code>, <code>Zstd</code>"},{"location":"crates/nori-sstable/api-reference/#metadata-types","title":"Metadata Types","text":"Type Purpose Page <code>SSTableMetadata</code> Build result information Builder API \u2192 <code>Footer</code> SSTable file footer [Internal] <code>Index</code> Block index [Internal] <code>BloomFilter</code> Bloom filter [Internal]"},{"location":"crates/nori-sstable/api-reference/#import-paths","title":"Import Paths","text":"<pre><code>// Main types\nuse nori_sstable::{\n    SSTableBuilder,\n    SSTableReader,\n    SSTableConfig,\n    SSTableMetadata,\n    Entry,\n    SSTableIterator,\n};\n\n// Enums\nuse nori_sstable::Compression;\n\n// Errors\nuse nori_sstable::{Result, SSTableError};\n\n// Re-exported for convenience\nuse nori_sstable::Bytes;  // From bytes crate\n</code></pre>"},{"location":"crates/nori-sstable/api-reference/#api-conventions","title":"API Conventions","text":""},{"location":"crates/nori-sstable/api-reference/#async-methods","title":"Async Methods","text":"<p>All I/O methods are async and require a Tokio runtime:</p> <pre><code>#[tokio::main]\nasync fn main() {\n    builder.add(&amp;entry).await?;  // Async!\n    reader.get(b\"key\").await?;   // Async!\n}\n</code></pre>"},{"location":"crates/nori-sstable/api-reference/#error-handling","title":"Error Handling","text":"<p>All fallible operations return <code>Result&lt;T, SSTableError&gt;</code>:</p> <pre><code>// Propagate errors with ?\nlet position = builder.add(&amp;entry).await?;\n\n// Or match explicitly\nmatch reader.get(b\"key\").await {\n    Ok(Some(entry)) =&gt; println!(\"Found: {:?}\", entry.value),\n    Ok(None) =&gt; println!(\"Not found\"),\n    Err(e) =&gt; eprintln!(\"Error: {}\", e),\n}\n</code></pre>"},{"location":"crates/nori-sstable/api-reference/#thread-safety","title":"Thread Safety","text":"<p>All types are <code>Send + Sync</code> and can be shared:</p> <pre><code>// Readers are designed to be shared\nlet reader = Arc::new(SSTableReader::open(path).await?);\n\nfor _ in 0..4 {\n    let reader_clone = reader.clone();\n    tokio::spawn(async move {\n        reader_clone.get(b\"key\").await\n    });\n}\n</code></pre>"},{"location":"crates/nori-sstable/api-reference/#sstablebuilder","title":"SSTableBuilder","text":"<p>Purpose: Builds immutable SSTables from sorted key-value entries.</p>"},{"location":"crates/nori-sstable/api-reference/#methods","title":"Methods","text":""},{"location":"crates/nori-sstable/api-reference/#new","title":"<code>new</code>","text":"<p>Creates a new builder with default metrics (NoopMeter).</p> <pre><code>pub async fn new(config: SSTableConfig) -&gt; Result&lt;Self&gt;\n</code></pre> <p>Example: <pre><code>let config = SSTableConfig {\n    path: \"data.sst\".into(),\n    estimated_entries: 1000,\n    ..Default::default()\n};\nlet mut builder = SSTableBuilder::new(config).await?;\n</code></pre></p>"},{"location":"crates/nori-sstable/api-reference/#new_with_meter","title":"<code>new_with_meter</code>","text":"<p>Creates a new builder with custom metrics.</p> <pre><code>pub async fn new_with_meter(\n    config: SSTableConfig,\n    meter: Box&lt;dyn Meter&gt;\n) -&gt; Result&lt;Self&gt;\n</code></pre> <p>Example: <pre><code>use nori_observe_prom::PrometheusMeter;\n\nlet meter = Box::new(PrometheusMeter::new());\nlet mut builder = SSTableBuilder::new_with_meter(config, meter).await?;\n</code></pre></p>"},{"location":"crates/nori-sstable/api-reference/#add","title":"<code>add</code>","text":"<p>Adds an entry to the SSTable. Entries must be added in sorted order.</p> <pre><code>pub async fn add(&amp;mut self, entry: &amp;Entry) -&gt; Result&lt;()&gt;\n</code></pre> <p>Errors: - <code>SSTableError::KeysNotSorted</code> - If entry key \u2264 previous key</p> <p>Example: <pre><code>builder.add(&amp;Entry::put(\"key1\", \"value1\")).await?;\nbuilder.add(&amp;Entry::put(\"key2\", \"value2\")).await?;  // Must be sorted!\n</code></pre></p>"},{"location":"crates/nori-sstable/api-reference/#finish","title":"<code>finish</code>","text":"<p>Finishes building the SSTable and writes all metadata.</p> <pre><code>pub async fn finish(self) -&gt; Result&lt;SSTableMetadata&gt;\n</code></pre> <p>Returns: Metadata about the completed SSTable</p> <p>Example: <pre><code>let metadata = builder.finish().await?;\nprintln!(\"Created {} entries in {} bytes\",\n    metadata.entry_count, metadata.file_size);\n</code></pre></p>"},{"location":"crates/nori-sstable/api-reference/#entry_count","title":"<code>entry_count</code>","text":"<p>Returns the number of entries added so far.</p> <pre><code>pub fn entry_count(&amp;self) -&gt; u64\n</code></pre>"},{"location":"crates/nori-sstable/api-reference/#file_size","title":"<code>file_size</code>","text":"<p>Returns the current file size in bytes.</p> <pre><code>pub fn file_size(&amp;self) -&gt; u64\n</code></pre>"},{"location":"crates/nori-sstable/api-reference/#sstablemetadata","title":"SSTableMetadata","text":"<p>Metadata returned by <code>finish()</code>:</p> <pre><code>pub struct SSTableMetadata {\n    pub path: PathBuf,           // Path to SSTable file\n    pub entry_count: u64,        // Total entries written\n    pub file_size: u64,          // Total file size in bytes\n    pub block_count: usize,      // Number of data blocks\n    pub compression: Compression, // Compression used\n}\n</code></pre>"},{"location":"crates/nori-sstable/api-reference/#sstablereader","title":"SSTableReader","text":"<p>Purpose: Reads data from immutable SSTables with bloom filter and cache optimization.</p>"},{"location":"crates/nori-sstable/api-reference/#methods_1","title":"Methods","text":""},{"location":"crates/nori-sstable/api-reference/#open","title":"<code>open</code>","text":"<p>Opens an SSTable with default configuration (64MB cache).</p> <pre><code>pub async fn open(path: PathBuf) -&gt; Result&lt;Self&gt;\n</code></pre> <p>Example: <pre><code>let reader = Arc::new(SSTableReader::open(\"data.sst\".into()).await?);\n</code></pre></p>"},{"location":"crates/nori-sstable/api-reference/#open_with_meter","title":"<code>open_with_meter</code>","text":"<p>Opens an SSTable with custom metrics (64MB cache).</p> <pre><code>pub async fn open_with_meter(\n    path: PathBuf,\n    meter: Arc&lt;dyn Meter&gt;\n) -&gt; Result&lt;Self&gt;\n</code></pre>"},{"location":"crates/nori-sstable/api-reference/#open_with_config","title":"<code>open_with_config</code>","text":"<p>Opens an SSTable with custom cache size and metrics.</p> <pre><code>pub async fn open_with_config(\n    path: PathBuf,\n    meter: Arc&lt;dyn Meter&gt;,\n    block_cache_mb: usize\n) -&gt; Result&lt;Self&gt;\n</code></pre> <p>Example: <pre><code>use nori_observe::NoopMeter;\n\n// 256MB cache for hot data\nlet reader = SSTableReader::open_with_config(\n    \"hot.sst\".into(),\n    Arc::new(NoopMeter),\n    256\n).await?;\n</code></pre></p>"},{"location":"crates/nori-sstable/api-reference/#get","title":"<code>get</code>","text":"<p>Performs a point lookup for a key.</p> <pre><code>pub async fn get(&amp;self, key: &amp;[u8]) -&gt; Result&lt;Option&lt;Entry&gt;&gt;\n</code></pre> <p>Returns: - <code>Some(entry)</code> - Key found (check <code>entry.tombstone</code> for deletes) - <code>None</code> - Key not found (bloom filter rejected or not in index)</p> <p>Example: <pre><code>if let Some(entry) = reader.get(b\"key\").await? {\n    if entry.tombstone {\n        println!(\"Key was deleted\");\n    } else {\n        println!(\"Value: {:?}\", entry.value);\n    }\n}\n</code></pre></p> <p>Performance: - Bloom filter check: ~67ns - Cache hit: ~5\u00b5s - Cache miss: ~15\u00b5s (includes decompression)</p>"},{"location":"crates/nori-sstable/api-reference/#iter","title":"<code>iter</code>","text":"<p>Returns an iterator over all entries in the SSTable.</p> <pre><code>pub fn iter(self: Arc&lt;Self&gt;) -&gt; SSTableIterator\n</code></pre> <p>Example: <pre><code>let mut iter = reader.clone().iter();\nwhile let Some(entry) = iter.try_next().await? {\n    println!(\"{:?} = {:?}\", entry.key, entry.value);\n}\n</code></pre></p>"},{"location":"crates/nori-sstable/api-reference/#iter_range","title":"<code>iter_range</code>","text":"<p>Returns an iterator over entries in a specific range.</p> <pre><code>pub fn iter_range(\n    self: Arc&lt;Self&gt;,\n    start_key: Bytes,\n    end_key: Bytes\n) -&gt; SSTableIterator\n</code></pre> <p>Range: <code>[start_key, end_key)</code> - inclusive start, exclusive end</p> <p>Example: <pre><code>let mut iter = reader.iter_range(\n    Bytes::from(\"key_0000\"),\n    Bytes::from(\"key_1000\")\n);\nwhile let Some(entry) = iter.try_next().await? {\n    // Only entries where key_0000 &lt;= key &lt; key_1000\n}\n</code></pre></p>"},{"location":"crates/nori-sstable/api-reference/#block_count","title":"<code>block_count</code>","text":"<p>Returns the number of data blocks in the SSTable.</p> <pre><code>pub fn block_count(&amp;self) -&gt; usize\n</code></pre>"},{"location":"crates/nori-sstable/api-reference/#sstableconfig","title":"SSTableConfig","text":"<p>Purpose: Configuration for building SSTables.</p>"},{"location":"crates/nori-sstable/api-reference/#fields","title":"Fields","text":"<pre><code>pub struct SSTableConfig {\n    /// Path where the SSTable file will be written\n    pub path: PathBuf,\n\n    /// Estimated number of entries (for bloom filter sizing)\n    pub estimated_entries: usize,\n\n    /// Target block size in bytes (default: 4096)\n    pub block_size: u32,\n\n    /// Restart interval for prefix compression (default: 16)\n    pub restart_interval: usize,\n\n    /// Compression algorithm (default: None)\n    pub compression: Compression,\n\n    /// Bits per key for bloom filter (default: 10)\n    pub bloom_bits_per_key: usize,\n\n    /// Block cache size in MB for readers (default: 64)\n    /// Set to 0 to disable caching\n    pub block_cache_mb: usize,\n}\n</code></pre>"},{"location":"crates/nori-sstable/api-reference/#default-configuration","title":"Default Configuration","text":"<pre><code>impl Default for SSTableConfig {\n    fn default() -&gt; Self {\n        Self {\n            path: PathBuf::from(\"sstable.sst\"),\n            estimated_entries: 1000,\n            block_size: 4096,              // 4KB\n            restart_interval: 16,\n            compression: Compression::None,\n            bloom_bits_per_key: 10,        // ~0.9% FP rate\n            block_cache_mb: 64,            // 64MB cache\n        }\n    }\n}\n</code></pre>"},{"location":"crates/nori-sstable/api-reference/#configuration-examples","title":"Configuration Examples","text":"<p>Balanced (Production): <pre><code>SSTableConfig {\n    path: \"prod.sst\".into(),\n    estimated_entries: 100_000,\n    compression: Compression::Lz4,\n    block_cache_mb: 128,\n    ..Default::default()\n}\n</code></pre></p> <p>High Compression (Archival): <pre><code>SSTableConfig {\n    path: \"archive.sst\".into(),\n    estimated_entries: 1_000_000,\n    compression: Compression::Zstd,\n    block_cache_mb: 0,  // Disable cache\n    ..Default::default()\n}\n</code></pre></p> <p>See full configuration guide \u2192</p>"},{"location":"crates/nori-sstable/api-reference/#entry","title":"Entry","text":"<p>Purpose: Represents a key-value entry with optional tombstone marker.</p>"},{"location":"crates/nori-sstable/api-reference/#structure","title":"Structure","text":"<pre><code>pub struct Entry {\n    pub key: Bytes,        // Entry key\n    pub value: Bytes,      // Entry value (empty for tombstones)\n    pub tombstone: bool,   // true = deletion marker\n}\n</code></pre>"},{"location":"crates/nori-sstable/api-reference/#methods_2","title":"Methods","text":""},{"location":"crates/nori-sstable/api-reference/#put","title":"<code>put</code>","text":"<p>Creates a PUT entry (normal key-value pair).</p> <pre><code>pub fn put&lt;K, V&gt;(key: K, value: V) -&gt; Self\nwhere\n    K: Into&lt;Bytes&gt;,\n    V: Into&lt;Bytes&gt;,\n</code></pre> <p>Example: <pre><code>let entry = Entry::put(\"key\", \"value\");\nlet entry = Entry::put(b\"key\", b\"value\");\nlet entry = Entry::put(vec![1, 2], vec![3, 4]);\n</code></pre></p>"},{"location":"crates/nori-sstable/api-reference/#delete","title":"<code>delete</code>","text":"<p>Creates a DELETE entry (tombstone).</p> <pre><code>pub fn delete&lt;K&gt;(key: K) -&gt; Self\nwhere\n    K: Into&lt;Bytes&gt;,\n</code></pre> <p>Example: <pre><code>let entry = Entry::delete(\"key_to_delete\");\n</code></pre></p> <p>See full entry API \u2192</p>"},{"location":"crates/nori-sstable/api-reference/#sstableiterator","title":"SSTableIterator","text":"<p>Purpose: Sequential iteration over SSTable entries.</p>"},{"location":"crates/nori-sstable/api-reference/#methods_3","title":"Methods","text":""},{"location":"crates/nori-sstable/api-reference/#try_next","title":"<code>try_next</code>","text":"<p>Returns the next entry in the SSTable.</p> <pre><code>pub async fn try_next(&amp;mut self) -&gt; Result&lt;Option&lt;Entry&gt;&gt;\n</code></pre> <p>Returns: - <code>Some(entry)</code> - Next entry - <code>None</code> - End of iteration</p> <p>Example: <pre><code>while let Some(entry) = iter.try_next().await? {\n    println!(\"{:?}\", entry.key);\n}\n</code></pre></p>"},{"location":"crates/nori-sstable/api-reference/#seek","title":"<code>seek</code>","text":"<p>Seeks to the first key &gt;= target.</p> <pre><code>pub async fn seek(&amp;mut self, target: &amp;[u8]) -&gt; Result&lt;()&gt;\n</code></pre> <p>Example: <pre><code>let mut iter = reader.iter();\niter.seek(b\"key_0500\").await?;\n\n// Next entry will be &gt;= \"key_0500\"\nwhile let Some(entry) = iter.try_next().await? {\n    println!(\"{:?}\", entry.key);\n}\n</code></pre></p> <p>See full iterator API \u2192</p>"},{"location":"crates/nori-sstable/api-reference/#compression","title":"Compression","text":"<p>Purpose: Block compression algorithm selection.</p>"},{"location":"crates/nori-sstable/api-reference/#variants","title":"Variants","text":"<pre><code>pub enum Compression {\n    None = 0,   // No compression\n    Lz4 = 1,    // LZ4 compression (fast, 3.9 GB/s decompress)\n    Zstd = 2,   // Zstd compression (higher ratio, 1.2 GB/s decompress)\n}\n</code></pre>"},{"location":"crates/nori-sstable/api-reference/#comparison","title":"Comparison","text":"Algorithm Compression Decompression Ratio Use Case None Instant Instant 1x Testing, already compressed Lz4 750 MB/s 3,900 MB/s 2-3x Production (recommended) Zstd 400 MB/s 1,200 MB/s 3-5x Archival, cold storage <p>See compression guide \u2192</p>"},{"location":"crates/nori-sstable/api-reference/#error-types","title":"Error Types","text":""},{"location":"crates/nori-sstable/api-reference/#sstableerror","title":"SSTableError","text":"<pre><code>pub enum SSTableError {\n    /// I/O error from filesystem operations\n    Io(io::Error),\n\n    /// CRC checksum mismatch (data corruption)\n    CrcMismatch { expected: u32, actual: u32 },\n\n    /// Keys not inserted in sorted order\n    KeysNotSorted(Vec&lt;u8&gt;, Vec&lt;u8&gt;),\n\n    /// Compression operation failed\n    CompressionFailed(String),\n\n    /// Decompression operation failed\n    DecompressionFailed(String),\n\n    /// Invalid SSTable format or magic number\n    InvalidFormat(String),\n\n    /// SSTable file not found\n    NotFound(String),\n\n    /// Invalid configuration parameter\n    InvalidConfig(String),\n\n    /// Key not found in SSTable\n    KeyNotFound,\n\n    /// Incomplete data structure\n    Incomplete,\n}\n</code></pre>"},{"location":"crates/nori-sstable/api-reference/#result-type","title":"Result Type","text":"<pre><code>pub type Result&lt;T&gt; = std::result::Result&lt;T, SSTableError&gt;;\n</code></pre>"},{"location":"crates/nori-sstable/api-reference/#observability","title":"Observability","text":""},{"location":"crates/nori-sstable/api-reference/#metrics-via-meter-trait","title":"Metrics via Meter Trait","text":"<p>nori-sstable emits metrics via the vendor-neutral <code>Meter</code> trait from <code>nori-observe</code>:</p> <pre><code>pub trait Meter: Send + Sync {\n    fn counter(&amp;self, name: &amp;str, labels: &amp;[(&amp;str, &amp;str)]) -&gt; Box&lt;dyn Counter&gt;;\n    fn histo(&amp;self, name: &amp;str, buckets: &amp;[f64], labels: &amp;[(&amp;str, &amp;str)]) -&gt; Box&lt;dyn Histogram&gt;;\n}\n</code></pre>"},{"location":"crates/nori-sstable/api-reference/#tracked-metrics","title":"Tracked Metrics","text":"<p>Builder: - <code>sstable_build_duration_ms</code> - Build time histogram - <code>sstable_entries_written</code> - Entry counter - <code>sstable_blocks_flushed</code> - Block counter - <code>sstable_bytes_written</code> - Byte counter - <code>sstable_compression_ratio</code> - Compression ratio histogram (when enabled)</p> <p>Reader: - <code>sstable_open_duration_ms</code> - Open time histogram - <code>sstable_get_duration_ms</code> - Lookup duration with <code>outcome</code> label - <code>sstable_bloom_checks</code> - Bloom filter checks with <code>outcome</code> label - <code>sstable_block_reads</code> - Disk I/O counter - <code>sstable_block_cache_hits</code> - Cache hit counter \ud83c\udd95 - <code>sstable_block_cache_misses</code> - Cache miss counter \ud83c\udd95</p>"},{"location":"crates/nori-sstable/api-reference/#type-categories","title":"Type Categories","text":""},{"location":"crates/nori-sstable/api-reference/#primary-api-start-here","title":"Primary API (Start Here)","text":"<p>Most use cases only need these types:</p> <ul> <li><code>SSTableBuilder</code> - Build SSTables</li> <li><code>SSTableReader</code> - Read SSTables</li> <li><code>SSTableConfig</code> - Configure behavior</li> <li><code>Entry</code> - Create entries</li> </ul>"},{"location":"crates/nori-sstable/api-reference/#advanced-api","title":"Advanced API","text":"<p>For fine-grained control:</p> <ul> <li><code>SSTableIterator</code> - Custom iteration</li> <li><code>Compression</code> - Algorithm selection</li> <li><code>SSTableMetadata</code> - Build results</li> </ul>"},{"location":"crates/nori-sstable/api-reference/#internal-types","title":"Internal Types","text":"<p>Not typically used directly:</p> <ul> <li><code>Block</code> - Internal block structure</li> <li><code>Index</code> - Block index</li> <li><code>BloomFilter</code> - Bloom filter</li> <li><code>Footer</code> - File footer</li> </ul>"},{"location":"crates/nori-sstable/api-reference/#usage-patterns","title":"Usage Patterns","text":""},{"location":"crates/nori-sstable/api-reference/#basic-write-read-cycle","title":"Basic Write-Read Cycle","text":"<pre><code>// Write\nlet mut builder = SSTableBuilder::new(config).await?;\nbuilder.add(&amp;Entry::put(\"key\", \"value\")).await?;\nlet metadata = builder.finish().await?;\n\n// Read\nlet reader = Arc::new(SSTableReader::open(metadata.path).await?);\nlet entry = reader.get(b\"key\").await?;\n</code></pre>"},{"location":"crates/nori-sstable/api-reference/#batch-writes","title":"Batch Writes","text":"<pre><code>let mut builder = SSTableBuilder::new(config).await?;\n\n// Sort your data first!\nlet mut entries: Vec&lt;_&gt; = data.into_iter().collect();\nentries.sort_by(|a, b| a.0.cmp(&amp;b.0));\n\nfor (key, value) in entries {\n    builder.add(&amp;Entry::put(key, value)).await?;\n}\n\nbuilder.finish().await?;\n</code></pre>"},{"location":"crates/nori-sstable/api-reference/#concurrent-reads","title":"Concurrent Reads","text":"<pre><code>let reader = Arc::new(SSTableReader::open(path).await?);\n\nlet mut handles = vec![];\nfor key in keys {\n    let reader_clone = reader.clone();\n    let handle = tokio::spawn(async move {\n        reader_clone.get(&amp;key).await\n    });\n    handles.push(handle);\n}\n\n// All tasks share the same cache\nfor handle in handles {\n    handle.await??;\n}\n</code></pre>"},{"location":"crates/nori-sstable/api-reference/#related-documentation","title":"Related Documentation","text":"<ul> <li>Getting Started - Quick tutorial</li> <li>Compression - Compression deep dive</li> <li>Caching - Cache tuning guide</li> <li>Architecture - File format details</li> <li>Performance - Benchmark results</li> </ul>"},{"location":"crates/nori-sstable/api-reference/#summary","title":"Summary","text":"<p>nori-sstable API: -  Simple: 5 core types cover 95% of use cases -  Async: All I/O is async via Tokio -  Type-safe: No unsafe code in public API -  Thread-safe: Share readers via <code>Arc</code> -  Documented: 108 tests + comprehensive docs</p> <p>Most common API: <pre><code>// Build\nlet mut builder = SSTableBuilder::new(config).await?;\nbuilder.add(&amp;Entry::put(\"key\", \"value\")).await?;\nbuilder.finish().await?;\n\n// Read\nlet reader = Arc::new(SSTableReader::open(path).await?);\nlet entry = reader.get(b\"key\").await?;\n</code></pre></p> <p>For detailed method documentation, see the individual API pages or rustdoc \u2192</p>"},{"location":"crates/nori-sstable/core-concepts/","title":"Core Concepts","text":"<p>Fundamental concepts behind SSTables and how they enable fast, scalable storage.</p>"},{"location":"crates/nori-sstable/core-concepts/#overview","title":"Overview","text":"<p>SSTables (Sorted String Tables) are a foundational data structure in modern storage systems. Understanding the core concepts behind SSTables helps you use them effectively and understand the tradeoffs they make.</p>"},{"location":"crates/nori-sstable/core-concepts/#key-concepts","title":"Key Concepts","text":""},{"location":"crates/nori-sstable/core-concepts/#what-is-an-sstable","title":"What is an SSTable?","text":"<p>Learn what SSTables are, why they exist, how they work, and how they fit into LSM-tree storage engines.</p>"},{"location":"crates/nori-sstable/core-concepts/#immutability","title":"Immutability","text":"<p>Why SSTables are write-once, immutable files and the profound benefits this provides: lock-free reads, simple caching, crash safety, and zero-cost snapshots.</p>"},{"location":"crates/nori-sstable/core-concepts/#block-based-storage","title":"Block-Based Storage","text":"<p>How data is organized into fixed-size 4KB blocks for efficient I/O, caching, and compression. Understand why blocks are the quantum of I/O in SSTables.</p>"},{"location":"crates/nori-sstable/core-concepts/#bloom-filters","title":"Bloom Filters","text":"<p>Probabilistic data structures that prevent unnecessary disk reads. Learn how ~67ns checks save 100\u00b5s disk I/O and why false positives are acceptable.</p>"},{"location":"crates/nori-sstable/core-concepts/#compression-fundamentals","title":"Compression Fundamentals","text":"<p>How block-level compression reduces storage costs 2-5x with minimal performance impact. Understand LZ4 vs Zstd trade-offs and when compression actually speeds up reads.</p>"},{"location":"crates/nori-sstable/core-concepts/#when-to-use-sstables","title":"When to Use SSTables","text":"<p>Understand the use cases where SSTables excel (write-heavy, time-series, hot keys) and where they don't (ultra-low latency, heavy updates, tiny datasets).</p>"},{"location":"crates/nori-sstable/core-concepts/#learning-path","title":"Learning Path","text":"<p>New to SSTables? Start with What is an SSTable? to understand the basics.</p> <p>Want to understand the design? Read about Immutability and Block-Based Storage.</p> <p>Need performance insights? Check out Bloom Filters and Compression.</p> <p>Ready to use them? Jump to When to Use SSTables for practical guidance.</p>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/","title":"Block-Based Storage","text":"<p>Why SSTables organize data into fixed-size blocks and how this design enables efficient I/O and caching.</p>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#the-core-design","title":"The Core Design","text":"<p>SSTables divide data into fixed-size blocks (typically 4KB). Each block contains multiple key-value entries, compressed independently, and serves as the atomic unit of I/O and caching.</p> <pre><code>SSTable File:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Block 0     \u2502 \u2190 4KB (compressed)\n\u2502  Block 1     \u2502 \u2190 4KB (compressed)\n\u2502  Block 2     \u2502 \u2190 4KB (compressed)\n\u2502     ...      \u2502\n\u2502  Block N     \u2502 \u2190 4KB (compressed)\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Index       \u2502 \u2190 Maps keys \u2192 block numbers\n\u2502  Bloom       \u2502\n\u2502  Footer      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#why-blocks","title":"Why Blocks?","text":""},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#alternative-1-variable-length-entries-no-blocks","title":"Alternative 1: Variable-Length Entries (No Blocks)","text":"<pre><code>File: [entry1][entry2][entry3]...[entryN]\n</code></pre> <p>Problems: - Read key 1000 \u2192 Must scan from beginning - Random access requires full file index (memory overhead) - Cache entire file or nothing (no granularity)</p>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#alternative-2-one-block-per-entry","title":"Alternative 2: One Block Per Entry","text":"<pre><code>File: [block:entry1][block:entry2]...[block:entryN]\n</code></pre> <p>Problems: - Massive overhead (footer per entry) - Poor compression (can't compress across entries) - Index size explodes (one entry per key)</p>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#solution-fixed-size-blocks","title":"Solution: Fixed-Size Blocks","text":"<pre><code>Block: [entry1][entry2]...[entryK] \u2190 ~4KB total\n</code></pre> <p>Benefits: - Random access via block index (log B lookups) - Cache at block granularity (balance memory vs I/O) - Good compression (compress ~100 entries together) - Reasonable index size (one entry per block)</p>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#block-size-trade-offs","title":"Block Size Trade-Offs","text":""},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#small-blocks-1kb-2kb","title":"Small Blocks (1KB-2KB)","text":"<p>Advantages: - Fine-grained caching (less wasted memory) - Lower read amplification per key - Faster decompression per block</p> <p>Disadvantages: - More index entries (larger index) - Poor compression ratio (less data to compress together) - More overhead (footer, checksum per block)</p>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#large-blocks-16kb-64kb","title":"Large Blocks (16KB-64KB)","text":"<p>Advantages: - Better compression ratio (more context) - Smaller index (fewer blocks) - Less overhead per byte</p> <p>Disadvantages: - Coarse-grained caching (waste memory on unused entries) - Higher read amplification (read 64KB to get 1 key) - Slower decompression (more data to decompress)</p>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#the-sweet-spot-4kb","title":"The Sweet Spot: 4KB","text":"<p>nori-sstable uses 4KB blocks by default:</p> <pre><code>pub const DEFAULT_BLOCK_SIZE: usize = 4096;\n</code></pre> <p>Why 4KB? - Matches OS page size (aligned I/O) - Contains ~50-200 entries (good compression) - Small enough for efficient caching - Large enough to amortize overhead</p> <p>Performance: - Compression ratio: 2-3x (LZ4) - Decompress time: &lt; 1\u00b5s (4KB @ 3.9 GB/s) - Cache overhead: Acceptable for 64MB cache (~16K blocks)</p>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#block-internal-structure","title":"Block Internal Structure","text":""},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#entry-layout-within-block","title":"Entry Layout Within Block","text":"<pre><code>Block (4KB):\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Restart Points Array                   \u2502\n\u2502   restart[0] = offset 0                \u2502\n\u2502   restart[1] = offset 512              \u2502\n\u2502   restart[2] = offset 1024             \u2502\n\u2502   ...                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Entries (prefix-compressed)            \u2502\n\u2502                                        \u2502\n\u2502  Entry 0: shared=0, unshared=10, val=5 \u2502\n\u2502           key=\"user:alice\", val=\"...\"  \u2502\n\u2502                                        \u2502\n\u2502  Entry 1: shared=5, unshared=3, val=5  \u2502\n\u2502           key=\"bob\" (\u2192 \"user:bob\")     \u2502\n\u2502                                        \u2502\n\u2502  Entry 2: shared=5, unshared=7, val=5  \u2502\n\u2502           key=\"charlie\" (\u2192 \"user:charlie\")\u2502\n\u2502  ...                                   \u2502\n\u2502                                        \u2502\n\u2502  Entry 16: shared=0, unshared=11, val=5\u2502 \u2190 Restart point\n\u2502            key=\"user:david\", val=\"...\" \u2502\n\u2502  ...                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#restart-points","title":"Restart Points","text":"<p>Purpose: Enable binary search within compressed blocks.</p> <pre><code>// Every 16 entries = restart point (full key)\npub const RESTART_INTERVAL: usize = 16;\n</code></pre> <p>Why needed? - Entries are prefix-compressed - To decode entry N, need entry N-1 - Restart points have full keys (no dependency) - Binary search jumps to restart points</p> <p>Trade-off: - More restarts = faster search, worse compression - Fewer restarts = better compression, slower search - Default 16 = good balance</p>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#block-level-io","title":"Block-Level I/O","text":""},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#reading-a-single-key","title":"Reading a Single Key","text":"<pre><code>1. User: sst.get(b\"user:bob\")\n2. Check bloom filter (~67ns)\n3. Search index \u2192 Block 5 contains range [\"user:alice\" ... \"user:david\"]\n4. Read block 5 (4KB)\n   - Check cache first\n   - If miss: read from disk\n5. Decompress block 5 (&lt;1\u00b5s)\n6. Binary search within block\n7. Return value\n</code></pre> <p>Key insight: Block is the atomic unit of I/O. Even if you need 1 entry, you read the whole 4KB block.</p>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#read-amplification","title":"Read Amplification","text":"<pre><code>Key size: 20 bytes\nValue size: 100 bytes\nEntry size: ~120 bytes\n\nUseful data: 120 bytes\nActual read: 4096 bytes\n\nRead amplification: 4096 / 120 = 34x\n</code></pre> <p>Mitigation: Caching amortizes this over multiple reads.</p>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#block-level-caching","title":"Block-Level Caching","text":""},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#why-cache-blocks-not-entries","title":"Why Cache Blocks (Not Entries)?","text":"<pre><code>// Good: Cache at block granularity\ncache.insert(block_id, decompressed_block);\n\n// Bad: Cache individual entries\ncache.insert(key, value);  // \n</code></pre> <p>Reasons:</p> <ol> <li>Spatial locality: If you read \"user:bob\", likely to read \"user:alice\" next</li> <li>Decompression cost: Decompress once, use many times</li> <li>Memory efficiency: 4KB block contains ~50-200 entries</li> <li>Simpler eviction: LRU at block level</li> </ol>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#cache-hit-patterns","title":"Cache Hit Patterns","text":"<pre><code>Cold cache:\n  get(\"key1\") \u2192 cache miss \u2192 read block 0 \u2192 decompress\n  get(\"key2\") \u2192 cache miss \u2192 read block 0 again \u2192 decompress\n\nWarm cache:\n  get(\"key1\") \u2192 cache miss \u2192 read block 0 \u2192 decompress \u2192 cache\n  get(\"key2\") \u2192 cache HIT \u2192 return from cache (~100ns)\n  get(\"key3\") \u2192 cache HIT (if in same block)\n</code></pre> <p>80/20 rule: 20% of blocks contain 80% of keys accessed.</p>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#block-level-compression","title":"Block-Level Compression","text":""},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#why-compress-per-block","title":"Why Compress Per-Block?","text":"<pre><code>Alternative 1: Compress whole file\n  - Read 1 key \u2192 decompress entire file (slow!)\n\nAlternative 2: Compress per-entry\n  - Poor ratio (no cross-entry patterns)\n  - More overhead\n\nBlock-level:\n  - Read 1 key \u2192 decompress 4KB (fast)\n  - Good ratio (compress ~100 entries together)\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#compression-caching-synergy","title":"Compression + Caching Synergy","text":"<pre><code>Disk: Block 5 (compressed, 1.2KB LZ4)\n        \u2193 read from disk\nRAM: Block 5 (decompressed, 4KB in cache)\n        \u2193 many reads\nUsers get 4KB of decompressed data at &lt;100ns latency\n</code></pre> <p>Key insight: Cache stores decompressed blocks. Decompress once, serve many times.</p>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#example-lz4-on-4kb-block","title":"Example: LZ4 on 4KB Block","text":"<pre><code>Uncompressed block: 4096 bytes\n  Entry 1: \"user:alice\" \u2192 \"data...\"\n  Entry 2: \"user:bob\"   \u2192 \"data...\"\n  ...\n  Entry 50: \"user:zach\" \u2192 \"data...\"\n\nLZ4 compressed: ~1400 bytes (2.9x ratio)\n  - Common prefix \"user:\" compressed\n  - Repeated value patterns compressed\n  - Dictionary built across all entries\n\nDecompress time: ~1\u00b5s (4KB @ 3.9 GB/s)\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#index-structure","title":"Index Structure","text":""},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#block-index","title":"Block Index","text":"<pre><code>Index (in SSTable footer region):\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Block 0: first_key=\"aaa\", offset=0    \u2502\n\u2502 Block 1: first_key=\"bbb\", offset=4096 \u2502\n\u2502 Block 2: first_key=\"ccc\", offset=8192 \u2502\n\u2502 ...                                \u2502\n\u2502 Block N: first_key=\"zzz\", offset=...  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Search algorithm: <pre><code>fn find_block(key: &amp;[u8]) -&gt; BlockId {\n    // Binary search in index\n    index.binary_search(|block| block.first_key.cmp(key))\n}\n</code></pre></p> <p>Complexity: O(log B) where B = number of blocks</p> <p>Example: - 1MB SSTable / 4KB blocks = 256 blocks - Binary search: log2(256) = 8 comparisons</p>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#comparison-entry-level-index","title":"Comparison: Entry-Level Index","text":"<pre><code>Alternative: Index every key\n  - 100K entries \u2192 100K index entries\n  - Index size: ~10MB (key + offset per entry)\n  - Memory overhead: 10x data size!\n\nBlock-level index:\n  - 100K entries / 50 per block = 2000 blocks\n  - Index size: ~200KB\n  - Memory overhead: 2% of data size Yes\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#real-world-example","title":"Real-World Example","text":""},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#scenario-1gb-sstable","title":"Scenario: 1GB SSTable","text":"<pre><code>Configuration:\n  - Block size: 4KB\n  - Average entry: 120 bytes\n  - Entries per block: ~34\n  - Compression (LZ4): 2.5x\n\nMath:\n  - Uncompressed blocks: 1GB / 4KB = 256K blocks\n  - Compressed on disk: 1GB / 2.5 = 400MB\n  - Index size: 256K * 32 bytes = 8MB\n  - Total file size: 400MB + 8MB = 408MB\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#read-performance","title":"Read Performance","text":"<pre><code>Point lookup (cache miss):\n  1. Bloom filter check: ~67ns\n  2. Index binary search: log2(256K) = 18 comparisons (~500ns)\n  3. Read compressed block from SSD: ~100\u00b5s\n  4. Decompress 4KB block: ~1\u00b5s\n  5. Binary search in block: ~200ns\n  Total: ~102\u00b5s\n\nPoint lookup (cache hit):\n  1. Bloom filter: ~67ns\n  2. Index search: ~500ns\n  3. Cache lookup: ~100ns\n  4. Binary search in cached block: ~200ns\n  Total: ~900ns (100x faster!)\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#design-alternatives-considered","title":"Design Alternatives Considered","text":""},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#1-variable-size-blocks","title":"1. Variable-Size Blocks","text":"<p>Idea: Pack blocks until ~4KB, but allow variance.</p> <p>Pros: - No entry splitting across blocks - Potentially better compression</p> <p>Cons: - Complex index (size per block) - Unpredictable cache sizing - Harder to align with OS pages</p> <p>Decision: Fixed 4KB for simplicity and predictability.</p>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#2-nested-blocks-2-level","title":"2. Nested Blocks (2-Level)","text":"<p>Idea: 64KB \"mega-blocks\" containing 16x 4KB sub-blocks.</p> <p>Pros: - Even better compression (more context) - Smaller index (fewer mega-blocks)</p> <p>Cons: - Higher read amplification - More complex implementation - 64KB cache entries wasteful</p> <p>Decision: Single-level 4KB blocks for simplicity.</p>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#3-adaptive-block-sizing","title":"3. Adaptive Block Sizing","text":"<p>Idea: Small blocks for hot data, large for cold.</p> <p>Pros: - Optimize for access patterns</p> <p>Cons: - Very complex - Unknown access patterns at write time - Index becomes complex</p> <p>Decision: Fixed 4KB, let caching handle hot/cold.</p>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#performance-impact","title":"Performance Impact","text":""},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#benchmark-block-size-comparison","title":"Benchmark: Block Size Comparison","text":"Block Size Index Size Compression Ratio Cache Hit Latency Miss Latency 1KB 32MB 2.0x 400ns 80\u00b5s 4KB 8MB 2.5x 900ns 102\u00b5s 16KB 2MB 3.0x 2.5\u00b5s 150\u00b5s 64KB 512KB 3.5x 8\u00b5s 280\u00b5s <p>Optimal: 4KB balances all factors.</p>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#implementation-details","title":"Implementation Details","text":""},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#block-building","title":"Block Building","text":"<pre><code>pub struct BlockBuilder {\n    buffer: Vec&lt;u8&gt;,\n    restarts: Vec&lt;u32&gt;,\n    counter: usize,\n    last_key: Bytes,\n}\n\nimpl BlockBuilder {\n    pub fn add(&amp;mut self, entry: &amp;Entry) {\n        if self.counter % RESTART_INTERVAL == 0 {\n            // Restart point: full key\n            self.restarts.push(self.buffer.len() as u32);\n            self.write_entry(entry, 0); // shared_len = 0\n        } else {\n            // Compressed entry\n            let shared = common_prefix_len(&amp;self.last_key, &amp;entry.key);\n            self.write_entry(entry, shared);\n        }\n        self.counter += 1;\n        self.last_key = entry.key.clone();\n    }\n\n    pub fn finish(self) -&gt; Vec&lt;u8&gt; {\n        let mut block = self.buffer;\n        // Append restart points\n        for offset in self.restarts {\n            block.extend_from_slice(&amp;offset.to_le_bytes());\n        }\n        block.extend_from_slice(&amp;(self.restarts.len() as u32).to_le_bytes());\n        block\n    }\n}\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#best-practices","title":"Best Practices","text":""},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#1-use-default-4kb","title":"1. Use Default 4KB","text":"<pre><code>// Recommended\nSSTableConfig {\n    block_size: 4096,  // Default\n    ..Default::default()\n}\n\n// Only change if:\n// - Ultra-small keys/values (try 2KB)\n// - Ultra-large values (try 8KB)\n// - Profiling shows bottleneck\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#2-size-cache-based-on-working-set","title":"2. Size Cache Based on Working Set","text":"<pre><code>Working set = hot blocks * 4KB\nCache size \u2248 1.5x working set\n\nExample:\n  10K hot keys / 50 per block = 200 hot blocks\n  200 blocks * 4KB = 800KB working set\n  Cache size: 1-2MB sufficient\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#3-monitor-block-cache-hit-rate","title":"3. Monitor Block Cache Hit Rate","text":"<pre><code>let hit_rate = cache_hits / (cache_hits + cache_misses);\n\n// Target: &gt;80% for hot workloads\nif hit_rate &lt; 0.8 {\n    // Increase cache size\n}\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#summary","title":"Summary","text":"<p>Block-based storage is fundamental to SSTable design:</p> <p>Efficient I/O - 4KB aligned with OS pages  Good compression - Compress ~50-200 entries together  Practical caching - Cache at block granularity  Fast lookups - Small block index (O(log B))  Simple design - Fixed size, no complex logic</p> <p>Key insight: Blocks are the quantum of I/O. Choose block size to balance compression ratio, cache efficiency, and read amplification.</p>"},{"location":"crates/nori-sstable/core-concepts/block-based-storage/#next-steps","title":"Next Steps","text":"<p>Understand prefix compression: See How It Works: Block Format for entry encoding details.</p> <p>Learn about caching: Check Caching for how the LRU cache works with blocks.</p> <p>Optimize compression: Read Compression for how blocks are compressed.</p> <p>See the index: Explore How It Works: Index Structure for block indexing details.</p>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/","title":"Bloom Filters","text":"<p>How probabilistic data structures prevent unnecessary disk reads in SSTables.</p>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#the-problem","title":"The Problem","text":"<pre><code>User: get(\"user:99999\")  // Key doesn't exist\n\nWithout bloom filter:\n1. Check index \u2192 might be in Block 42\n2. Read Block 42 from disk (100\u00b5s)\n3. Decompress block (~1\u00b5s)\n4. Binary search \u2192 not found\nTotal: ~101\u00b5s wasted on disk I/O\n</code></pre> <p>With 1000 non-existent keys: 1000 * 100\u00b5s = 100ms wasted!</p>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#the-solution-bloom-filters","title":"The Solution: Bloom Filters","text":"<p>A bloom filter is a probabilistic data structure that answers: \"Is key X definitely not in the set?\"</p> <pre><code>User: get(\"user:99999\")\n\nWith bloom filter:\n1. Check bloom filter (67ns): NOT PRESENT \u2192 return None\nTotal: 67ns (1500x faster!)\n</code></pre> <p>Key properties: - No false negatives: If bloom says \"not present\", key is definitely absent - Possible false positives: If bloom says \"maybe present\", key might not be there - Space-efficient: 10 bits per key for ~0.9% false positive rate</p>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#how-bloom-filters-work","title":"How Bloom Filters Work","text":""},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#basic-concept","title":"Basic Concept","text":"<p>A bloom filter is a bit array with hash functions:</p> <pre><code>Bit array (128 bits):\n[0][0][0][0]...[0][0][0]\n\nAdd key \"alice\":\n  hash1(\"alice\") = 5  \u2192 set bit 5\n  hash2(\"alice\") = 89 \u2192 set bit 89\n  hash3(\"alice\") = 120 \u2192 set bit 120\n\nBit array after adding \"alice\":\n[0][0][0][0][0][1]...[1]...[1][0][0]\n      bit5      bit89    bit120\n\nQuery \"alice\":\n  hash1(\"alice\") = 5   \u2192 check bit 5: SET Yes\n  hash2(\"alice\") = 89  \u2192 check bit 89: SET Yes\n  hash3(\"alice\") = 120 \u2192 check bit 120: SET Yes\n  Result: MAYBE PRESENT (all bits set)\n\nQuery \"bob\":\n  hash1(\"bob\") = 12 \u2192 check bit 12: NOT SET No\n  Result: DEFINITELY NOT PRESENT (stop here!)\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#bloom-filter-in-sstables","title":"Bloom Filter in SSTables","text":""},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#file-layout","title":"File Layout","text":"<pre><code>SSTable:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Blocks     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Index      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Bloom      \u2502 \u2190 Bloom filter here\n\u2502  Filter     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Footer     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#read-path-with-bloom","title":"Read Path with Bloom","text":"<pre><code>impl SSTableReader {\n    pub async fn get(&amp;self, key: &amp;[u8]) -&gt; Result&lt;Option&lt;Entry&gt;&gt; {\n        // 1. Check bloom filter (67ns)\n        if !self.bloom.contains(key) {\n            return Ok(None);  // Definitely not present\n        }\n\n        // 2. Might be present, check index\n        let block_id = self.index.find_block(key)?;\n\n        // 3. Read block\n        let block = self.read_block(block_id).await?;\n\n        // 4. Search in block\n        block.get(key)\n    }\n}\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#false-positive-rate","title":"False Positive Rate","text":""},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#what-is-a-false-positive","title":"What is a False Positive?","text":"<pre><code>Key \"charlie\" NOT in SSTable\n\nBloom filter checks:\n  hash1(\"charlie\") = 5   \u2192 bit 5 SET (from \"alice\")\n  hash2(\"charlie\") = 89  \u2192 bit 89 SET (from \"alice\")\n  hash3(\"charlie\") = 120 \u2192 bit 120 SET (from \"alice\")\n\nResult: MAYBE PRESENT (false positive!)\n\nThen:\n  1. Check index\n  2. Read block from disk (wasted!)\n  3. Binary search \u2192 not found\n</code></pre> <p>False positive = wasted disk read.</p>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#controlling-false-positive-rate","title":"Controlling False Positive Rate","text":"<p>Formula:</p> <pre><code>FP rate \u2248 (1 - e^(-kn/m))^k\n\nwhere:\n  k = number of hash functions\n  n = number of keys\n  m = number of bits\n</code></pre> <p>Simplified:</p> <pre><code>m/n = bits per key\n\nFor k=3 hash functions:\n  10 bits/key \u2192 ~0.9% FP rate\n  12 bits/key \u2192 ~0.3% FP rate\n  16 bits/key \u2192 ~0.05% FP rate\n</code></pre> <p>nori-sstable default:</p> <pre><code>pub const DEFAULT_BLOOM_BITS_PER_KEY: usize = 10;\n</code></pre> <p>Result: 0.9% false positive rate</p>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#trade-off-analysis","title":"Trade-Off Analysis","text":"Bits/Key FP Rate Bloom Size (100K keys) Wasted Reads (per 100K queries) 5 ~10% 62KB 10,000 10 ~0.9% 125KB 900 12 ~0.3% 150KB 300 16 ~0.05% 200KB 50 <p>Optimal: 10 bits/key balances bloom size vs false positives.</p>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#hash-functions","title":"Hash Functions","text":""},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#why-multiple-hashes","title":"Why Multiple Hashes?","text":"<p>Single hash function:</p> <pre><code>Only 1 bit set per key \u2192 collision likely\n  \"alice\" \u2192 bit 42\n  \"bob\"   \u2192 bit 42 (collision!)\n</code></pre> <p>Multiple hash functions:</p> <pre><code>k bits set per key \u2192 lower collision probability\n  \"alice\" \u2192 bits {5, 89, 120}\n  \"bob\"   \u2192 bits {12, 67, 104}\n</code></pre> <p>Optimal k:</p> <pre><code>k = (m/n) * ln(2) \u2248 0.693 * (m/n)\n\nFor m/n = 10:\n  k = 0.693 * 10 \u2248 7 hash functions\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#double-hashing-trick","title":"Double Hashing Trick","text":"<p>Problem: Computing k independent hash functions is expensive.</p> <p>Solution: Use double hashing with only 2 hash functions:</p> <pre><code>fn bloom_hash(key: &amp;[u8], i: usize, m: usize) -&gt; usize {\n    let h1 = xxhash64(key, seed=0);\n    let h2 = xxhash64(key, seed=1);\n    ((h1 + i * h2) % m) as usize\n}\n</code></pre> <p>Generate k hashes from 2:</p> <pre><code>hash_0 = h1\nhash_1 = h1 + h2\nhash_2 = h1 + 2*h2\n...\nhash_k = h1 + k*h2\n</code></pre> <p>Benefit: Compute 2 hashes, derive k positions (fast!).</p>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#why-xxhash64","title":"Why xxHash64?","text":"<pre><code>use xxhash_rust::xxh64;\n\nlet hash = xxh64::xxh64(key, seed);\n</code></pre> <p>Properties: - Fast: ~10 GB/s throughput - Good distribution: Low collision rate - Deterministic: Same input \u2192 same output - Non-cryptographic: Don't need security, just speed</p> <p>Alternatives considered: - CRC32: Faster but worse distribution - SipHash: Cryptographic (overkill, slower) - MurmurHash3: Similar speed, less Rust support</p>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#building-a-bloom-filter","title":"Building a Bloom Filter","text":""},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#during-sstable-creation","title":"During SSTable Creation","text":"<pre><code>impl SSTableBuilder {\n    pub async fn finish(self) -&gt; Result&lt;SSTableMetadata&gt; {\n        // 1. Write data blocks\n        for block in self.blocks {\n            write_block(&amp;block).await?;\n        }\n\n        // 2. Write index\n        write_index(&amp;self.index).await?;\n\n        // 3. Build bloom filter\n        let bloom = BloomFilter::new(\n            self.entry_count,\n            BLOOM_BITS_PER_KEY\n        );\n        for key in self.all_keys {\n            bloom.insert(&amp;key);\n        }\n\n        // 4. Write bloom filter\n        write_bloom(&amp;bloom).await?;\n\n        // 5. Write footer\n        write_footer(...).await?;\n    }\n}\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#memory-usage","title":"Memory Usage","text":"<pre><code>100,000 keys * 10 bits/key = 1,000,000 bits = 125 KB\n\nBloom filter in memory during build: ~125KB\nBloom filter in file: ~125KB\nBloom filter loaded on read: ~125KB\n</code></pre> <p>Small overhead for huge performance gain.</p>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#bloom-filter-performance","title":"Bloom Filter Performance","text":""},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#benchmark-results","title":"Benchmark Results","text":"<pre><code>Bloom filter operations on M1 Pro:\n\nInsert: ~20ns per key\nQuery:  ~67ns per key\n\nFor 100K key SSTable:\n  Build time: 100K * 20ns = 2ms\n  Query time: 67ns per lookup\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#savings-calculation","title":"Savings Calculation","text":"<pre><code>Scenario: 100K queries on SSTable with 100K keys\n  50% keys present, 50% absent\n\nWithout bloom filter:\n  50K absent keys * 100\u00b5s disk read = 5 seconds wasted\n\nWith bloom filter (0.9% FP rate):\n  50K absent * 67ns = 3.35ms (bloom checks)\n  450 false positives * 100\u00b5s = 45ms (wasted disk)\n  Total: ~48ms\n\nSpeedup: 5000ms / 48ms \u2248 100x faster!\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#advanced-topics","title":"Advanced Topics","text":""},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#partitioned-bloom-filters","title":"Partitioned Bloom Filters","text":"<p>Idea: Split bloom into multiple small filters (one per block).</p> <p>Pros: - Only load bloom for needed blocks - Better cache locality</p> <p>Cons: - Higher false positive rate (smaller filters) - More complex implementation</p> <p>Decision: nori-sstable uses single whole-file bloom for simplicity.</p>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#blocked-bloom-filters","title":"Blocked Bloom Filters","text":"<p>Idea: Organize bits into cache-line-sized blocks (64 bytes).</p> <pre><code>Traditional: bits[0..1000000]\nBlocked: blocks[0..15625] where each block = 64 bytes\n</code></pre> <p>Benefit: All k hash probes hit same cache line (faster).</p> <p>Implementation complexity: Medium</p> <p>Future work: Consider for v2.</p>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#counting-bloom-filters","title":"Counting Bloom Filters","text":"<p>Idea: Store counts instead of bits (supports deletion).</p> <p>Benefit: Can remove keys from bloom filter.</p> <p>Cost: 4x memory (32-bit counters vs 1-bit flags).</p> <p>Use case: Compaction could update bloom (remove deleted keys).</p> <p>Decision: Not needed (bloom rebuilt during compaction anyway).</p>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#bloom-filter-vs-alternatives","title":"Bloom Filter vs Alternatives","text":""},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#cuckoo-filters","title":"Cuckoo Filters","text":"<p>Idea: Hash table with relocation for collisions.</p> <p>Pros: - Supports deletion - Better FP rate for same space</p> <p>Cons: - More complex - Slightly slower queries</p> <p>Decision: Bloom simpler, fast enough for SSTables.</p>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#xor-filters","title":"XOR Filters","text":"<p>Idea: Use XOR operations for compact representation.</p> <p>Pros: - 10-20% smaller than bloom - Faster construction</p> <p>Cons: - Immutable (can't add keys incrementally) - More complex implementation</p> <p>Future: Consider for v2 if bloom filter size becomes bottleneck.</p>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#perfect-hashing","title":"Perfect Hashing","text":"<p>Idea: Build minimal perfect hash function.</p> <p>Pros: - No false positives - Compact</p> <p>Cons: - Expensive to build - Read-only (can't add keys)</p> <p>Decision: Overkill for SSTables (false positives acceptable).</p>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#practical-guidelines","title":"Practical Guidelines","text":""},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#1-use-default-settings","title":"1. Use Default Settings","text":"<pre><code>// Recommended for most workloads\nSSTableConfig {\n    bloom_bits_per_key: 10,  // ~0.9% FP rate\n    ..Default::default()\n}\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#2-increase-for-large-sstables","title":"2. Increase for Large SSTables","text":"<pre><code>// For &gt;1GB SSTables, reduce FP rate\nSSTableConfig {\n    bloom_bits_per_key: 12,  // ~0.3% FP rate\n    // Cost: +20% bloom size (acceptable for large files)\n    ..Default::default()\n}\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#3-decrease-for-tiny-sstables","title":"3. Decrease for Tiny SSTables","text":"<pre><code>// For &lt;1MB SSTables, bloom overhead not worth it\nSSTableConfig {\n    bloom_bits_per_key: 0,  // Disable bloom\n    // Rationale: Index lookup is already fast\n    ..Default::default()\n}\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#4-monitor-false-positive-rate","title":"4. Monitor False Positive Rate","text":"<pre><code>let fp_rate = false_positives / total_queries;\n\n// If FP rate &gt; 2%:\n//   - Increase bloom_bits_per_key\n//   - Check for hash collisions\n//   - Verify bloom filter wasn't corrupted\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#bloom-filter-in-compaction","title":"Bloom Filter in Compaction","text":""},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#problem-stale-bloom-filters","title":"Problem: Stale Bloom Filters","text":"<pre><code>Original SSTable: {alice, bob, charlie}\nAfter compaction: {alice, bob}  // charlie deleted\n\nOld bloom filter still contains \"charlie\" hash\n  \u2192 False positive on \"charlie\" queries\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#solution-rebuild-bloom","title":"Solution: Rebuild Bloom","text":"<pre><code>async fn compact(inputs: Vec&lt;SSTable&gt;) -&gt; SSTable {\n    let mut builder = SSTableBuilder::new(config).await?;\n\n    // Merge all entries\n    for entry in merge_iterator(inputs) {\n        if !entry.tombstone {  // Skip deleted\n            builder.add(&amp;entry).await?;\n        }\n    }\n\n    // Bloom automatically rebuilt with only live keys\n    builder.finish().await?\n}\n</code></pre> <p>Result: Compacted SSTable has fresh, accurate bloom filter.</p>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#real-world-impact","title":"Real-World Impact","text":""},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#case-study-1gb-sstable-with-10m-keys","title":"Case Study: 1GB SSTable with 10M Keys","text":"<pre><code>Configuration:\n  Keys: 10M\n  Bloom bits/key: 10\n  False positive rate: 0.9%\n\nBloom filter size: 10M * 10 bits = 12.5 MB (1.25% of SSTable size)\n\nQuery workload: 1M queries (50% hits, 50% misses)\n\nWithout bloom:\n  500K misses * 100\u00b5s disk = 50 seconds\n\nWith bloom:\n  500K misses * 67ns bloom = 33.5ms\n  4.5K false positives * 100\u00b5s = 450ms\n  Total: ~483ms\n\nSpeedup: 50s / 0.48s \u2248 100x faster!\n\nCost: 12.5 MB memory (negligible)\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#summary","title":"Summary","text":"<p>Bloom filters are essential for SSTables:</p> <p>Fast negative lookups - 67ns to confirm absence  Massive I/O savings - Skip 99%+ of unnecessary disk reads  Space-efficient - 10 bits per key for 0.9% FP rate  Simple - Single global bloom, no complex logic  Battle-tested - Used in LevelDB, RocksDB, Cassandra</p> <p>Key insight: Trading ~1% false positives for 100x speedup on absent keys is an excellent trade-off.</p>"},{"location":"crates/nori-sstable/core-concepts/bloom-filters/#next-steps","title":"Next Steps","text":"<p>Understand the implementation: See How It Works: Bloom Filter for implementation details.</p> <p>Learn about indexing: Read How It Works: Index Structure for how bloom works with block index.</p> <p>Optimize reads: Check Performance: Tuning for bloom filter configuration guidance.</p> <p>See the full read path: Explore What is an SSTable? for how bloom fits into lookups.</p>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/","title":"Compression Fundamentals","text":"<p>Why and how nori-sstable compresses data at block granularity.</p>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#why-compress","title":"Why Compress?","text":""},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#the-storage-cost-problem","title":"The Storage Cost Problem","text":"<pre><code>1 million entries * 1KB/entry = 1GB uncompressed\n\nStorage costs:\n  SSD: $0.10/GB/month = $0.10/month\n  S3: $0.023/GB/month = $0.023/month\n\nOver 1 year: $1.20 (SSD) or $0.28 (S3)\n\nWith 2.5x compression \u2192 400MB:\nOver 1 year: $0.48 (SSD) or $0.11 (S3)\n\nSavings: 60% storage cost\n</code></pre> <p>For large datasets (TB scale), compression saves thousands of dollars/year.</p>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#the-io-speed-benefit","title":"The I/O Speed Benefit","text":"<pre><code>Read 1GB from SSD:\n  Uncompressed: 1GB / 3 GB/s = 333ms\n\n  Compressed (2.5x):\n    Read: 400MB / 3 GB/s = 133ms\n    Decompress: 400MB / 3.9 GB/s = 102ms\n    Total: 235ms\n\nSpeedup: 333ms / 235ms = 1.4x faster!\n</code></pre> <p>Key insight: If decompression is faster than disk, compression actually speeds up reads!</p>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#block-level-compression","title":"Block-Level Compression","text":""},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#why-not-compress-the-whole-file","title":"Why Not Compress the Whole File?","text":"<pre><code>Whole-file compression:\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502 Compressed SSTable      \u2502\n  \u2502 (entire 1GB compressed) \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nTo read 1 key:\n  1. Decompress entire 1GB \u2192 RAM\n  2. Find key\n  Problem: Need to decompress everything!\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#why-not-compress-per-entry","title":"Why Not Compress Per-Entry?","text":"<pre><code>Per-entry compression:\n  Entry 1: compress(\"user:alice\", \"data...\") \u2192 50 bytes\n  Entry 2: compress(\"user:bob\", \"data...\")   \u2192 48 bytes\n  ...\n\nProblems:\n  - Poor ratio (no cross-entry patterns)\n  - Overhead per entry (header, dictionary)\n  - More complex\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#block-level-the-sweet-spot","title":"Block-Level: The Sweet Spot","text":"<pre><code>Block-level compression:\n  Block 0 (4KB):\n    Entry 1: \"user:alice\" \u2192 \"data...\"\n    Entry 2: \"user:bob\"   \u2192 \"data...\"\n    ...\n    Entry 50: \"user:zach\" \u2192 \"data...\"\n\n  Compress entire block \u2192 ~1.6KB\n\nTo read 1 key:\n  1. Read compressed block (1.6KB from disk)\n  2. Decompress block (4KB \u2192 RAM in 1\u00b5s)\n  3. Find key\n\nBenefits:\n  - Good ratio (compress ~50 entries together)\n  - Fast (decompress only needed block)\n  - Simple (block = unit of compression)\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#compression-algorithms","title":"Compression Algorithms","text":""},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#lz4-recommended-default","title":"LZ4 (Recommended Default)","text":"<p>Properties: - Compression: 2-3x typical - Compression speed: ~750 MB/s - Decompression speed: ~3,900 MB/s (blazingly fast!) - CPU cost: Minimal (&lt;10% on reads)</p> <p>Use case: General purpose, hot data, real-time systems</p> <pre><code>SSTableConfig {\n    compression: Compression::Lz4,\n    ..Default::default()\n}\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#zstd-higher-ratio","title":"Zstd (Higher Ratio)","text":"<p>Properties: - Compression: 3-5x typical - Compression speed: ~450 MB/s - Decompression speed: ~1,200 MB/s - CPU cost: Medium (~20-30% on reads)</p> <p>Use case: Cold storage, archival data, when storage cost &gt;&gt; CPU cost</p> <pre><code>SSTableConfig {\n    compression: Compression::Zstd,\n    ..Default::default()\n}\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#none-no-compression","title":"None (No Compression)","text":"<p>Properties: - Compression: 1x (no savings) - Speed: Zero CPU overhead - Best for: Already-compressed data (images, videos)</p> <p>Use case: Development, benchmarking, pre-compressed data</p> <pre><code>SSTableConfig {\n    compression: Compression::None,\n    ..Default::default()\n}\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#compression-ratio-analysis","title":"Compression Ratio Analysis","text":""},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#text-data","title":"Text Data","text":"<pre><code>Block contents (4KB):\n  \"user:alice\" \u2192 \"{'name':'Alice','age':25,'city':'NY'}\"\n  \"user:bob\"   \u2192 \"{'name':'Bob','age':30,'city':'SF'}\"\n  ...\n\nPatterns:\n  - Repeated strings: \"user:\", \"name\", \"age\", \"city\"\n  - JSON structure: \"{'\" \"':'\", \"'}\"\n  - Common values: city names\n\nLZ4 compression: 4096 bytes \u2192 1400 bytes (2.9x)\nZstd compression: 4096 bytes \u2192 1100 bytes (3.7x)\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#time-series-data","title":"Time-Series Data","text":"<pre><code>Block contents (4KB):\n  \"metric:cpu.usage:1678900000\" \u2192 \"45.2\"\n  \"metric:cpu.usage:1678900001\" \u2192 \"45.3\"\n  \"metric:cpu.usage:1678900002\" \u2192 \"45.1\"\n  ...\n\nPatterns:\n  - Highly repeated prefixes: \"metric:cpu.usage:\"\n  - Sequential timestamps: 1678900000, 1678900001, ...\n  - Similar float values: 45.x\n\nLZ4 compression: 4096 bytes \u2192 500 bytes (8.2x!)\nZstd compression: 4096 bytes \u2192 350 bytes (11.7x!)\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#random-binary-data","title":"Random Binary Data","text":"<pre><code>Block contents (4KB):\n  Random bytes: [0xA3, 0x2F, 0x91, ...]\n\nPatterns: None (random)\n\nLZ4 compression: 4096 bytes \u2192 4100 bytes (no compression, added header)\nZstd compression: 4096 bytes \u2192 4120 bytes (no compression)\n\nAuto-detect: Skip compression for incompressible blocks\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#decompression-performance","title":"Decompression Performance","text":""},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#lz4-benchmark","title":"LZ4 Benchmark","text":"<pre><code>Decompress 4KB block:\n  Time: ~1\u00b5s\n  Throughput: 4KB / 1\u00b5s = 3.9 GB/s\n\nCPU cycles: ~4,000 cycles @ 4GHz\n  - Tiny fraction of CPU time\n  - L3 cache miss costs more (200ns = 800 cycles)\n\nConclusion: LZ4 decompression is essentially free!\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#zstd-benchmark","title":"Zstd Benchmark","text":"<pre><code>Decompress 4KB block:\n  Time: ~3.3\u00b5s\n  Throughput: 4KB / 3.3\u00b5s = 1.2 GB/s\n\nCPU cycles: ~13,000 cycles @ 4GHz\n  - Still fast, but 3x slower than LZ4\n  - Noticeable at high request rates\n\nTrade-off: 30% better compression, 3x slower decompression\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#compression-caching-synergy","title":"Compression + Caching Synergy","text":""},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#without-caching","title":"Without Caching","text":"<pre><code>Read same key 100 times:\n  1. Read compressed block from disk (100\u00b5s)\n  2. Decompress (1\u00b5s)\n  3. Find key in block\n  4. Repeat 100 times\n\nTotal: 100 * 101\u00b5s = 10.1ms\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#with-caching-decompressed-blocks","title":"With Caching (Decompressed Blocks)","text":"<pre><code>Read same key 100 times:\n  First read:\n    1. Read compressed block (100\u00b5s)\n    2. Decompress (1\u00b5s)\n    3. Cache decompressed block\n    4. Find key\n\n  Next 99 reads:\n    1. Lookup in cache (100ns)\n    2. Find key in cached block\n    Total: 99 * 100ns = 9.9\u00b5s\n\nTotal: 101\u00b5s + 9.9\u00b5s = 111\u00b5s (90x faster!)\n</code></pre> <p>Key insight: Compress on disk, cache decompressed in RAM. Best of both worlds!</p>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#implementation-details","title":"Implementation Details","text":""},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#compression-during-write","title":"Compression During Write","text":"<pre><code>impl BlockBuilder {\n    pub fn finish(self, compression: Compression) -&gt; Vec&lt;u8&gt; {\n        let uncompressed = self.buffer;\n\n        match compression {\n            Compression::None =&gt; uncompressed,\n\n            Compression::Lz4 =&gt; {\n                lz4::compress(&amp;uncompressed)\n            },\n\n            Compression::Zstd =&gt; {\n                zstd::compress(&amp;uncompressed, level=3)\n            },\n        }\n    }\n}\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#decompression-during-read","title":"Decompression During Read","text":"<pre><code>impl SSTableReader {\n    async fn read_block(&amp;self, block_id: usize) -&gt; Result&lt;Block&gt; {\n        // 1. Check cache (stores decompressed blocks)\n        if let Some(block) = self.cache.get(block_id) {\n            return Ok(block);\n        }\n\n        // 2. Read compressed block from disk\n        let compressed = self.read_compressed_block(block_id).await?;\n\n        // 3. Decompress\n        let decompressed = match self.compression {\n            Compression::None =&gt; compressed,\n            Compression::Lz4 =&gt; lz4::decompress(&amp;compressed)?,\n            Compression::Zstd =&gt; zstd::decompress(&amp;compressed)?,\n        };\n\n        // 4. Cache decompressed block\n        let block = Block::parse(decompressed)?;\n        self.cache.insert(block_id, block.clone());\n\n        Ok(block)\n    }\n}\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#choosing-a-compression-algorithm","title":"Choosing a Compression Algorithm","text":""},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#decision-tree","title":"Decision Tree","text":"<pre><code>Is data hot (frequently accessed)?\n\u251c\u2500 Yes \u2192 Use LZ4\n\u2502   - Fast decompression (3.9 GB/s)\n\u2502   - Cache hit rate high anyway\n\u2502   - Want minimal CPU overhead\n\u2502\n\u2514\u2500 No \u2192 Use Zstd\n    - Better compression (3-5x vs 2-3x)\n    - Slower decompression acceptable for cold data\n    - Storage cost matters more than CPU\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#workload-specific-recommendations","title":"Workload-Specific Recommendations","text":"Workload Algorithm Rationale Real-time queries LZ4 Ultra-fast decompression Hot key-value LZ4 Cache hit rate high, speed matters Cold storage Zstd Maximize storage savings Archival Zstd (level 9) Best compression, slow reads OK Pre-compressed None Already compressed (images, video) Development None Fast iteration, no compression overhead"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#advanced-compression-levels","title":"Advanced: Compression Levels","text":""},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#zstd-levels","title":"Zstd Levels","text":"<pre><code>// Default\nzstd::compress(data, level=3)  // Fast, good ratio\n\n// Higher compression (slower)\nzstd::compress(data, level=9)  // Better ratio, 2x slower\nzstd::compress(data, level=19) // Best ratio, 10x slower\n\nComparison:\n  Level 3:  3.5x ratio, 450 MB/s compress, 1.2 GB/s decompress\n  Level 9:  4.0x ratio, 180 MB/s compress, 1.2 GB/s decompress\n  Level 19: 4.5x ratio, 50 MB/s compress, 1.2 GB/s decompress\n</code></pre> <p>Note: Decompression speed is same regardless of level! Higher level only affects write-time compression.</p>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#lz4-levels","title":"LZ4 Levels","text":"<p>LZ4 has only one level (fast mode). For better ratio, use LZ4HC:</p> <pre><code>lz4_hc::compress(data, level=9)  // 2.5-3x ratio, slower compression\n</code></pre> <p>Trade-off: LZ4HC compresses slower (200 MB/s vs 750 MB/s) but decompresses at same speed (3.9 GB/s).</p>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#storage-savings-calculation","title":"Storage Savings Calculation","text":""},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#example-100gb-sstable","title":"Example: 100GB SSTable","text":"<pre><code>Uncompressed: 100GB\n\nWith LZ4 (2.5x):\n  Disk: 40GB\n  Savings: 60GB\n  At $0.10/GB/month: $6/month saved\n\nWith Zstd (3.5x):\n  Disk: 28.6GB\n  Savings: 71.4GB\n  At $0.10/GB/month: $7.14/month saved\n\nExtra savings with Zstd: $1.14/month\nCPU cost: 3x slower decompression (acceptable for cold data)\n</code></pre> <p>Decision: For cold storage, Zstd's extra 1.4x compression justifies the CPU cost.</p>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#compression-and-prefix-compression","title":"Compression and Prefix Compression","text":""},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#two-types-of-compression","title":"Two Types of Compression","text":"<pre><code>1. Prefix compression (within block):\n   \"user:alice\" \u2192 store full key\n   \"user:bob\"   \u2192 store \"bob\" (shares \"user:\")\n   \"user:carol\" \u2192 store \"carol\"\n\n2. Block compression (entire block):\n   Take prefix-compressed block \u2192 compress with LZ4/Zstd\n</code></pre> <p>Combined effect:</p> <pre><code>Original block: 4KB (no prefix compression, no block compression)\nWith prefix compression: 2.8KB (1.4x from prefix compression)\nWith prefix + LZ4: 1.1KB (2.5x from LZ4 on top)\n\nTotal: 4KB \u2192 1.1KB (3.6x combined!)\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#monitoring-compression","title":"Monitoring Compression","text":""},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#metrics-to-track","title":"Metrics to Track","text":"<pre><code>pub struct CompressionStats {\n    pub blocks_compressed: u64,\n    pub bytes_uncompressed: u64,\n    pub bytes_compressed: u64,\n    pub compression_ratio: f64,\n    pub decompression_time_ns: u64,\n}\n\n// Example values\nCompressionStats {\n    blocks_compressed: 10_000,\n    bytes_uncompressed: 40_960_000,  // 10K * 4KB\n    bytes_compressed: 16_384_000,    // Compressed size\n    compression_ratio: 2.5,\n    decompression_time_ns: 10_000_000, // 10ms total (1\u00b5s avg)\n}\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#red-flags","title":"Red Flags","text":"<pre><code>compression_ratio &lt; 1.2\n  \u2192 Data is incompressible (already compressed?)\n  \u2192 Consider Compression::None\n\ndecompression_time &gt; 5\u00b5s per block\n  \u2192 CPU bottleneck\n  \u2192 Consider switching Zstd \u2192 LZ4\n\nbytes_compressed &gt; bytes_uncompressed\n  \u2192 Compression adding overhead\n  \u2192 Disable compression\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#best-practices","title":"Best Practices","text":""},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#1-use-lz4-by-default","title":"1. Use LZ4 by Default","text":"<pre><code>// For most workloads\nSSTableConfig {\n    compression: Compression::Lz4,\n    ..Default::default()\n}\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#2-use-zstd-for-cold-storage","title":"2. Use Zstd for Cold Storage","text":"<pre><code>// For archival data\nSSTableConfig {\n    compression: Compression::Zstd,\n    block_cache_mb: 0,  // Disable cache (cold data)\n    ..Default::default()\n}\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#3-disable-for-pre-compressed-data","title":"3. Disable for Pre-Compressed Data","text":"<pre><code>// For images, videos, already-compressed files\nSSTableConfig {\n    compression: Compression::None,\n    ..Default::default()\n}\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#4-monitor-compression-ratio","title":"4. Monitor Compression Ratio","text":"<pre><code>let ratio = bytes_uncompressed / bytes_compressed;\n\nif ratio &lt; 1.5 {\n    // Compression not effective, consider disabling\n    log::warn!(\"Low compression ratio: {}\", ratio);\n}\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#summary","title":"Summary","text":"<p>Compression is essential for SSTables:</p> <p>Storage savings - 2-5x reduction in disk usage  Faster I/O - Read less from disk (if decompression faster than disk)  Block-granular - Decompress only needed blocks  Cache-friendly - Cache decompressed blocks for speed  Configurable - LZ4 for hot, Zstd for cold, None for development</p> <p>Key insight: Modern compression (especially LZ4) is so fast that it often speeds up reads by reducing I/O, not just saving storage.</p>"},{"location":"crates/nori-sstable/core-concepts/compression-fundamentals/#next-steps","title":"Next Steps","text":"<p>Deep dive on algorithms: See Compression Guide for detailed LZ4/Zstd comparison and configuration.</p> <p>Understand implementation: Check How It Works: Compression for implementation details.</p> <p>Learn caching interaction: Read Caching for how compression + cache work together.</p> <p>Optimize for your workload: Explore Performance: Tuning for compression configuration guidance.</p>"},{"location":"crates/nori-sstable/core-concepts/immutability/","title":"Immutability","text":"<p>Why SSTables are write-once, immutable files and the profound benefits this provides.</p>"},{"location":"crates/nori-sstable/core-concepts/immutability/#the-core-principle","title":"The Core Principle","text":"<p>Once an SSTable is written, it never changes.</p> <p>This single design decision cascades into numerous benefits: - Lock-free concurrent reads - Simple caching semantics - Crash-safe by design - Perfect snapshot isolation - Zero write amplification on reads</p>"},{"location":"crates/nori-sstable/core-concepts/immutability/#why-immutability","title":"Why Immutability?","text":""},{"location":"crates/nori-sstable/core-concepts/immutability/#problem-mutable-files-require-coordination","title":"Problem: Mutable Files Require Coordination","text":"<p>In a traditional B-tree database:</p> <pre><code>Writer updates page 42\n    \u2193\n1. Read page 42 from disk\n2. Modify in memory\n3. Write back to disk\n4. Flush to ensure durability\n</code></pre> <p>Issues: - Readers need locks (can't read page being written) - Cache invalidation (did page change?) - Crash during write = corrupted page - Write amplification (read-modify-write)</p>"},{"location":"crates/nori-sstable/core-concepts/immutability/#solution-write-new-never-modify","title":"Solution: Write New, Never Modify","text":"<p>In an SSTable-based system:</p> <pre><code>New data arrives\n    \u2193\n1. Accumulate in memtable (RAM)\n2. When full, write NEW SSTable\n3. Old SSTables unchanged\n4. Background: merge old SSTables \u2192 new SSTable\n</code></pre> <p>Benefits: - Readers never block (old files still valid) - Cache forever (data never changes) - Crash = incomplete file, just delete it - Pure sequential writes</p>"},{"location":"crates/nori-sstable/core-concepts/immutability/#concurrency-benefits","title":"Concurrency Benefits","text":""},{"location":"crates/nori-sstable/core-concepts/immutability/#lock-free-reads","title":"Lock-Free Reads","text":"<pre><code>// Thread 1\nlet reader1 = Arc::new(SSTableReader::open(\"v1.sst\").await?);\nreader1.get(b\"key\").await?;\n\n// Thread 2\nlet reader2 = reader1.clone();  // Just clone Arc\nreader2.get(b\"other_key\").await?;  // No locks!\n\n// Thread 3\nlet reader3 = reader1.clone();\nreader3.iter().await?;  // Still no locks!\n</code></pre> <p>No mutexes, no RwLocks, no coordination overhead.</p>"},{"location":"crates/nori-sstable/core-concepts/immutability/#simple-atomic-updates","title":"Simple Atomic Updates","text":"<pre><code>// Update \"database\" by atomically swapping file list\nstruct DB {\n    sstables: Arc&lt;RwLock&lt;Vec&lt;Arc&lt;SSTableReader&gt;&gt;&gt;&gt;,\n}\n\nimpl DB {\n    async fn compact(&amp;self) {\n        // 1. Create new merged SSTable\n        let new_sst = compact([old1, old2, old3]).await?;\n\n        // 2. Atomically update list\n        let mut tables = self.sstables.write();\n        tables.retain(|sst| sst.path != old1.path &amp;&amp; ...);\n        tables.push(Arc::new(new_sst));\n\n        // 3. Old readers still see old files (Arc keeps them alive)\n        // 4. New readers see new files\n    }\n}\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/immutability/#caching-benefits","title":"Caching Benefits","text":""},{"location":"crates/nori-sstable/core-concepts/immutability/#forever-caching","title":"Forever Caching","text":"<pre><code>// Cache a block from SSTable\ncache.insert(\n    key: (sst_id, block_index),\n    value: decompressed_block,\n    ttl: FOREVER  // Block will NEVER change!\n);\n</code></pre> <p>No cache invalidation logic needed. Block 15 from <code>file_42.sst</code> will always contain the same data.</p>"},{"location":"crates/nori-sstable/core-concepts/immutability/#multi-level-caching","title":"Multi-Level Caching","text":"<pre><code>L1: Process-local LRU cache (64MB)\n    \u2193 miss\nL2: Shared mmap cache (OS page cache)\n    \u2193 miss\nL3: Disk\n</code></pre> <p>All levels can cache aggressively because data never changes.</p>"},{"location":"crates/nori-sstable/core-concepts/immutability/#crash-safety","title":"Crash Safety","text":""},{"location":"crates/nori-sstable/core-concepts/immutability/#atomic-file-creation","title":"Atomic File Creation","text":"<pre><code>Write SSTable:\n1. Write data blocks    \u2192 temp_file.sst.tmp\n2. Write index          \u2192 temp_file.sst.tmp\n3. Write bloom filter   \u2192 temp_file.sst.tmp\n4. Write footer + CRC   \u2192 temp_file.sst.tmp\n5. fsync()\n6. rename() to final.sst  \u2190 Atomic!\n</code></pre> <p>If crash occurs: - Before rename: temp file deleted, no corruption - After rename: file complete and valid</p>"},{"location":"crates/nori-sstable/core-concepts/immutability/#validation-on-open","title":"Validation on Open","text":"<pre><code>impl SSTableReader {\n    pub async fn open(path: PathBuf) -&gt; Result&lt;Self&gt; {\n        let file = File::open(path).await?;\n\n        // Read footer\n        let footer = read_footer(&amp;file).await?;\n\n        // Validate CRC\n        if !footer.validate_crc() {\n            return Err(Error::CorruptedFile);\n        }\n\n        // File is valid!\n        Ok(Self { file, footer, ... })\n    }\n}\n</code></pre> <p>If corruption detected, just delete the file. No recovery needed.</p>"},{"location":"crates/nori-sstable/core-concepts/immutability/#snapshot-isolation-mvcc","title":"Snapshot Isolation (MVCC)","text":""},{"location":"crates/nori-sstable/core-concepts/immutability/#perfect-snapshots","title":"Perfect Snapshots","text":"<pre><code>struct Snapshot {\n    sstables: Vec&lt;Arc&lt;SSTableReader&gt;&gt;,  // Immutable!\n    timestamp: u64,\n}\n\n// Create snapshot\nlet snap = db.snapshot();\n\n// Later... database changed, but snapshot unchanged\nsnap.get(b\"key\").await?;  // Sees data as of snapshot time\n</code></pre> <p>SSTables are immutable \u2192 snapshot is just a list of Arc references.</p>"},{"location":"crates/nori-sstable/core-concepts/immutability/#time-travel-queries","title":"Time-Travel Queries","text":"<pre><code>// Read data as of 1 hour ago\nlet snapshot = db.snapshot_at(now - 3600);\nsnapshot.scan(b\"user:\", b\"user:~\").await?;\n</code></pre> <p>Possible because old SSTables are kept until no longer referenced.</p>"},{"location":"crates/nori-sstable/core-concepts/immutability/#deletion-handling-tombstones","title":"Deletion Handling: Tombstones","text":""},{"location":"crates/nori-sstable/core-concepts/immutability/#problem-how-to-delete-if-immutable","title":"Problem: How to Delete if Immutable?","text":"<p>Solution: Write a tombstone (delete marker)</p> <pre><code>// Delete \"user:42\"\nmemtable.insert(b\"user:42\", Entry::tombstone());\n\n// When memtable flushes\nsstable.write(Entry {\n    key: b\"user:42\",\n    value: b\"\",\n    tombstone: true,  // \u2190 Marker\n});\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/immutability/#tombstone-lifecycle","title":"Tombstone Lifecycle","text":"<pre><code>1. Delete request \u2192 Tombstone in memtable\n2. Flush \u2192 Tombstone in L0 SSTable\n3. Read \"user:42\" \u2192 Sees tombstone first (newest) \u2192 Return None\n4. Compaction \u2192 Merges tombstone with older live value \u2192 Removed\n</code></pre> <p>Tombstone shadows all older versions during reads.</p>"},{"location":"crates/nori-sstable/core-concepts/immutability/#compaction-making-immutability-practical","title":"Compaction: Making Immutability Practical","text":""},{"location":"crates/nori-sstable/core-concepts/immutability/#the-accumulation-problem","title":"The Accumulation Problem","text":"<pre><code>Day 1: SST1 (1MB)\nDay 2: SST1, SST2 (2MB total)\nDay 3: SST1, SST2, SST3 (3MB total)\n...\nDay 100: SST1...SST100 (100MB total)\n</code></pre> <p>Problem: Reads must check 100 files!</p>"},{"location":"crates/nori-sstable/core-concepts/immutability/#solution-background-compaction","title":"Solution: Background Compaction","text":"<pre><code>// Merge multiple SSTables into one\nasync fn compact(inputs: Vec&lt;SSTableReader&gt;) -&gt; SSTable {\n    let mut builder = SSTableBuilder::new(config).await?;\n\n    // Merge-sort all inputs\n    let mut heap = MergeHeap::new();\n    for sst in inputs {\n        heap.push(sst.iter());\n    }\n\n    while let Some((key, value, tombstone)) = heap.pop() {\n        // Take newest version of each key\n        if !already_seen(key) {\n            builder.add(&amp;Entry { key, value, tombstone }).await?;\n        }\n    }\n\n    builder.finish().await\n}\n</code></pre> <p>Creates new SSTable with merged data. Old SSTables deleted once unreferenced.</p>"},{"location":"crates/nori-sstable/core-concepts/immutability/#update-handling","title":"Update Handling","text":""},{"location":"crates/nori-sstable/core-concepts/immutability/#problem-how-to-update-a-key","title":"Problem: How to Update a Key?","text":"<p>Solution: Write the new value. Newest version wins.</p> <pre><code>Time 0: Write \"user:42\" = \"alice\" \u2192 SST1\nTime 1: Write \"user:42\" = \"bob\"   \u2192 SST2\n\nRead \"user:42\":\n  Check SST2 (newer) \u2192 \"bob\" Yes (return this)\n  Check SST1 (older) \u2192 \"alice\" (ignored)\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/immutability/#space-amplification","title":"Space Amplification","text":"<pre><code>Same key updated N times = N copies on disk\n    \u2193\nCompaction merges \u2192 Keep only newest\n    \u2193\nSpace amplification = (data_on_disk / live_data)\n  Typical: 1.1-1.5x with regular compaction\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/immutability/#comparison-mutable-vs-immutable","title":"Comparison: Mutable vs Immutable","text":"Aspect Mutable (B-tree) Immutable (SSTable) Concurrency Locks required Lock-free reads Caching Invalidation logic Cache forever Crash recovery Complex (WAL replay) Simple (validate CRC) Snapshots Copy-on-write Free (just Arc refs) Write pattern Random (slow) Sequential (fast) Space overhead Low Medium (until compaction) Compaction Not needed Required"},{"location":"crates/nori-sstable/core-concepts/immutability/#trade-offs","title":"Trade-Offs","text":""},{"location":"crates/nori-sstable/core-concepts/immutability/#advantages","title":"Advantages","text":"<ul> <li>Write throughput: 10-100x faster than random writes</li> <li>Concurrency: Lock-free, scales to many readers</li> <li>Crash safety: Atomic, no corruption possible</li> <li>Snapshots: Zero-cost MVCC</li> <li>Caching: Aggressive caching with no invalidation</li> </ul>"},{"location":"crates/nori-sstable/core-concepts/immutability/#disadvantages","title":"Disadvantages","text":"<ul> <li>Space amplification: Old versions accumulate until compaction</li> <li>Read amplification: Must check multiple files</li> <li>Compaction cost: Background I/O and CPU</li> <li>Latency spikes: During compaction (can be rate-limited)</li> </ul>"},{"location":"crates/nori-sstable/core-concepts/immutability/#best-practices","title":"Best Practices","text":""},{"location":"crates/nori-sstable/core-concepts/immutability/#1-regular-compaction","title":"1. Regular Compaction","text":"<pre><code>// Schedule compaction to keep read amplification low\ntokio::spawn(async {\n    loop {\n        tokio::time::sleep(Duration::from_secs(3600)).await;\n        db.compact().await?;\n    }\n});\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/immutability/#2-reference-counting-for-deletion","title":"2. Reference Counting for Deletion","text":"<pre><code>// Only delete SSTables when all readers done\nstruct SSTable {\n    reader: Arc&lt;SSTableReader&gt;,  // Ref-counted\n}\n\n// When compaction creates new file:\n// 1. Add new SSTable to list\n// 2. Remove old SSTables from list\n// 3. Old files deleted when Arc count \u2192 0\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/immutability/#3-bounded-retention","title":"3. Bounded Retention","text":"<pre><code>// Don't keep infinite history\ndb.compact_with_policy(CompactionPolicy {\n    max_versions: 1,  // Keep only latest version\n    tombstone_ttl: Duration::from_days(7),  // Drop old tombstones\n});\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/immutability/#real-world-analogy","title":"Real-World Analogy","text":"<p>Think of version control (like Git):</p> <ul> <li>Each commit is immutable</li> <li>New changes = new commit (don't modify old ones)</li> <li>To see current state, merge all commits</li> <li>Periodically, you rebase/squash to clean up history</li> <li>Old commits stay around until unreferenced</li> </ul> <p>SSTables are like commits for your database.</p>"},{"location":"crates/nori-sstable/core-concepts/immutability/#next-steps","title":"Next Steps","text":"<p>Learn about organization: See Block-Based Storage for how immutable data is structured.</p> <p>Understand deletion: Read about Tombstones in the design decisions.</p> <p>See compaction details: Check out Compaction Strategy for how we manage immutability at scale.</p> <p>Explore implementation: Jump to File Format to see how immutability is enforced.</p>"},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/","title":"What is an SSTable?","text":"<p>Understanding the fundamental concept behind Sorted String Tables.</p>"},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#definition","title":"Definition","text":"<p>An SSTable (Sorted String Table) is an immutable, on-disk data structure that stores a sorted collection of key-value pairs. SSTables are a core component of LSM-tree (Log-Structured Merge-tree) storage engines, used in databases like LevelDB, RocksDB, Cassandra, and now NoriKV.</p>"},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#key-properties","title":"Key Properties","text":"<ol> <li>Sorted: Keys are stored in lexicographic order</li> <li>Immutable: Once written, the file never changes</li> <li>Self-contained: Includes data, index, bloom filter, and metadata</li> <li>Block-based: Data organized into fixed-size blocks (typically 4KB)</li> </ol>"},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#why-sstables-exist","title":"Why SSTables Exist","text":""},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#the-problem-random-writes-are-slow","title":"The Problem: Random Writes are Slow","text":"<p>Traditional B-tree databases perform random writes directly to disk: - Each write requires reading a page, modifying it, writing it back - Causes disk head seeks (slow on HDDs) - Even on SSDs, random writes have higher write amplification</p>"},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#the-solution-sequential-writes","title":"The Solution: Sequential Writes","text":"<p>SSTables enable a write-optimized storage approach:</p> <ol> <li>Writes go to memory first (memtable)</li> <li>When memory fills, flush sorted data to a new SSTable</li> <li>All writes to an SSTable are sequential (fast!)</li> <li>Reads check multiple SSTables and merge results</li> </ol> <p>Result: 10-100x faster write throughput</p>"},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#how-sstables-work","title":"How SSTables Work","text":""},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#write-path","title":"Write Path","text":"<pre><code>User writes \u2192 Memtable (in-memory sorted tree)\n                  \u2193 (when full)\n              SSTableBuilder\n                  \u2193\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  1. Sort all entries      \u2502\n    \u2502  2. Build blocks (4KB)    \u2502\n    \u2502  3. Build bloom filter    \u2502\n    \u2502  4. Build index           \u2502\n    \u2502  5. Write footer          \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                  \u2193\n         Immutable SSTable file\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#read-path","title":"Read Path","text":"<pre><code>User reads key \"user:42\"\n    \u2193\nCheck bloom filter (67ns)\n    \u2193 (probably exists)\nSearch index (binary search)\n    \u2193 (find block 15)\nRead block 15 from disk or cache\n    \u2193 (decompress if needed)\nBinary search within block\n    \u2193\nReturn value\n</code></pre> <p>Typical read latency: ~5-10\u00b5s (cache hit), ~100\u00b5s-1ms (disk read)</p>"},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#sstable-file-structure","title":"SSTable File Structure","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Data Blocks (sorted key-value)    \u2502\n\u2502                                    \u2502\n\u2502  Block 0: [aaa...azz] (4KB)       \u2502\n\u2502  Block 1: [baa...bzz] (4KB)       \u2502\n\u2502  Block 2: [caa...czz] (4KB)       \u2502\n\u2502  ...                               \u2502\n\u2502  Block N: [yaa...zzz] (4KB)       \u2502\n\u2502                                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Index (points to blocks)           \u2502\n\u2502  \"aaa\" \u2192 Block 0, offset 0         \u2502\n\u2502  \"baa\" \u2192 Block 1, offset 4096      \u2502\n\u2502  \"caa\" \u2192 Block 2, offset 8192      \u2502\n\u2502  ...                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Bloom Filter                       \u2502\n\u2502  (probabilistic set membership)    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Footer (64 bytes)                  \u2502\n\u2502  - Magic number (validation)       \u2502\n\u2502  - Index offset/size               \u2502\n\u2502  - Bloom filter offset/size        \u2502\n\u2502  - Compression type                \u2502\n\u2502  - CRC32C checksum                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Size: Typically 1MB-256MB per SSTable</p>"},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#sstables-in-lsm-trees","title":"SSTables in LSM-Trees","text":"<p>SSTables power LSM-tree storage engines by enabling:</p>"},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#leveled-compaction","title":"Leveled Compaction","text":"<pre><code>Level 0: [SST1] [SST2] [SST3]  \u2190 Recent, may overlap\n            \u2193 compact\nLevel 1: [SST4 \u2500\u2500\u2500\u2500\u2500] [SST5 \u2500\u2500\u2500\u2500\u2500]  \u2190 No overlaps, 10x size\n            \u2193 compact\nLevel 2: [SST6 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500]  \u2190 No overlaps, 100x size\n</code></pre> <ul> <li>Level 0: Fresh SSTables from memtable flushes</li> <li>Level 1+: Merged, non-overlapping SSTables</li> <li>Compaction: Background process that merges SSTables</li> </ul>"},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#point-reads","title":"Point Reads","text":"<pre><code>// Check newest to oldest\nif let Some(val) = memtable.get(key) { return val; }\nfor sst in level_0.iter() {\n    if sst.bloom_contains(key) &amp;&amp; sst.get(key).is_some() {\n        return val;\n    }\n}\nfor sst in level_1.iter() { /* ... */ }\n// ...\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#range-scans","title":"Range Scans","text":"<pre><code>// Merge iterators from all levels\nlet mut heap = MergeHeap::new();\nheap.push(memtable.iter());\nfor sst in all_sstables {\n    heap.push(sst.iter_range(start, end));\n}\n\nwhile let Some((key, value)) = heap.pop() {\n    // Return newest version of each key\n    yield (key, value);\n}\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#comparison-to-b-trees","title":"Comparison to B-Trees","text":"Aspect SSTable (LSM) B-Tree Write pattern Sequential Random Write throughput High (10-100K/sec) Medium (1-10K/sec) Read throughput Medium (need to check multiple files) High (single lookup) Space amplification Medium (1.1-1.5x) Low (1.0-1.1x) Compaction Background cost None Use case Write-heavy, append-mostly Read-heavy, updates <p>Key insight: SSTables trade read complexity for write performance.</p>"},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#real-world-analogies","title":"Real-World Analogies","text":""},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#library-card-catalog","title":"Library Card Catalog","text":"<p>Think of each SSTable as a card catalog drawer:</p> <ul> <li>Each drawer contains cards (key-value pairs) in alphabetical order</li> <li>When you add new books, you create a new drawer (don't modify old ones)</li> <li>Periodically, you merge drawers to consolidate and remove duplicates</li> <li>To find a book, you check drawers newest to oldest</li> </ul>"},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#git-commits","title":"Git Commits","text":"<p>SSTables are like git commits:</p> <ul> <li>Each commit (SSTable) is immutable</li> <li>New commits don't change old ones</li> <li>Occasionally, you rebase/compact to clean up history</li> <li>To get current state, you merge all commits</li> </ul>"},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#benefits-of-immutability","title":"Benefits of Immutability","text":"<p>SSTables are write-once, never modified. This provides:</p>"},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#1-simple-concurrency","title":"1. Simple Concurrency","text":"<pre><code>// Multiple readers, no locks needed!\nlet reader = Arc::new(SSTableReader::open(\"data.sst\").await?);\n\ntokio::spawn({\n    let r = reader.clone();\n    async move { r.get(b\"key1\").await }\n});\ntokio::spawn({\n    let r = reader.clone();\n    async move { r.get(b\"key2\").await }\n});\n</code></pre> <p>No locks, no coordination, no reader-writer conflicts.</p>"},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#2-easy-caching","title":"2. Easy Caching","text":"<pre><code>Block 15 in cache? Yes\n\u251c\u2500 It will NEVER change\n\u2514\u2500 Cache it forever (until evicted)\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#3-simple-crash-recovery","title":"3. Simple Crash Recovery","text":"<pre><code>SSTable file exists?\n\u251c\u2500 Yes Footer checksum valid \u2192 File is good\n\u2514\u2500 No Checksum invalid \u2192 Discard (write failed mid-creation)\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#4-snapshot-isolation","title":"4. Snapshot Isolation","text":"<pre><code>Snapshot = \"Read from SSTable set at time T\"\n\u251c\u2500 SSTables never change\n\u251c\u2500 Just keep references alive\n\u2514\u2500 Perfect MVCC (multi-version concurrency control)\n</code></pre>"},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#common-misconceptions","title":"Common Misconceptions","text":""},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#sstables-are-slow-for-reads","title":"\"SSTables are slow for reads\"","text":"<p>Reality: With bloom filters and caching, SSTables can achieve &lt; 10\u00b5s reads for hot data. Bloom filters skip 99%+ of unnecessary disk reads.</p>"},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#sstables-waste-space-with-duplicates","title":"\"SSTables waste space with duplicates\"","text":"<p>Reality: Compaction merges SSTables and removes old versions. Space amplification is typically only 1.1-1.5x.</p>"},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#compaction-causes-unpredictable-latency","title":"\"Compaction causes unpredictable latency\"","text":"<p>Reality: Modern LSM engines use rate limiting and tiered compaction to keep p99 latency under SLO.</p>"},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#when-to-use-sstables","title":"When to Use SSTables","text":""},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#great-fit","title":"Great Fit","text":"<ul> <li>Write-heavy workloads (logging, time-series, events)</li> <li>Append-mostly data (few updates/deletes)</li> <li>Range scans (sequential iteration)</li> <li>Hot key patterns (caching helps a lot)</li> <li>Large datasets that don't fit in memory</li> </ul>"},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#not-the-right-tool","title":"Not the Right Tool","text":"<ul> <li>Ultra-low latency (&lt; 1\u00b5s) requirements</li> <li>Random updates to same keys (causes many tombstones)</li> <li>Tiny datasets (&lt; 1MB) where overhead dominates</li> <li>No compaction budget (need background I/O for merges)</li> </ul>"},{"location":"crates/nori-sstable/core-concepts/what-is-sstable/#next-steps","title":"Next Steps","text":"<p>Understand immutability: Read about Immutability and why it's central to SSTable design.</p> <p>Learn about organization: See Block-Based Storage for how data is structured.</p> <p>Optimize reads: Check out Bloom Filters to understand how we avoid disk I/O.</p> <p>Dive into implementation: Jump to How It Works for file format details.</p>"},{"location":"crates/nori-sstable/core-concepts/when-to-use/","title":"When to Use SSTables","text":"<p>Practical guidance on when SSTables are the right choice for your storage needs.</p>"},{"location":"crates/nori-sstable/core-concepts/when-to-use/#decision-matrix","title":"Decision Matrix","text":""},{"location":"crates/nori-sstable/core-concepts/when-to-use/#great-fit","title":"Great Fit","text":"Use Case Why SSTables Excel Write-heavy workloads Sequential writes 10-100x faster than B-trees Time-series data Append-only, natural sort order, range scans Event logging Immutability = perfect audit trail LSM storage engines Core building block (LevelDB, RocksDB pattern) Hot key patterns Bloom filters + cache = &lt;10\u00b5s reads Batch writes Amortize flush cost over many entries Large datasets Scales to TB without in-memory index"},{"location":"crates/nori-sstable/core-concepts/when-to-use/#not-the-right-tool","title":"Not the Right Tool","text":"Use Case Why Not Ultra-low latency (&lt;1\u00b5s) Disk I/O inherently slower Heavy random updates Creates many versions, space amplification Tiny datasets (&lt;1MB) Fixed overhead dominates No compaction budget Read amplification grows unbounded In-memory only Better to use HashMap/BTreeMap"},{"location":"crates/nori-sstable/core-concepts/when-to-use/#workload-patterns","title":"Workload Patterns","text":""},{"location":"crates/nori-sstable/core-concepts/when-to-use/#append-mostly-perfect-fit","title":"Append-Mostly (Perfect Fit)","text":"<pre><code>// Event sourcing, logs, time-series\nfor event in events {\n    sst_builder.add(&amp;Entry::put(\n        format!(\"event:{}\", event.timestamp).as_bytes(),\n        event.data\n    )).await?;\n}\n</code></pre> <p>Why it works: - Natural sort order (timestamps) - Rare updates/deletes - Sequential writes = maximum throughput - Range scans over time windows</p> <p>Performance: 100K+ writes/sec</p>"},{"location":"crates/nori-sstable/core-concepts/when-to-use/#read-heavy-with-hot-keys-good-fit","title":"Read-Heavy with Hot Keys (Good Fit)","text":"<pre><code>// User profiles, product catalog\ncache_hit_rate: 80%+\n    \u2193\np95 latency: &lt;1ms (cache)\np99 latency: ~5ms (disk)\n</code></pre> <p>Why it works: - Bloom filters skip most disk reads - LRU cache caches hot blocks - 80/20 rule: 20% of keys = 80% of reads</p> <p>Performance: 100K+ reads/sec (cached), 10K/sec (disk)</p>"},{"location":"crates/nori-sstable/core-concepts/when-to-use/#update-heavy-on-same-keys-poor-fit","title":"Update-Heavy on Same Keys (Poor Fit)","text":"<pre><code>// Counter updates, session state\nkey \"counter\" updated 1000 times/sec\n    \u2193\n1000 versions on disk (until compaction)\n    \u2193\nSpace amplification: 1000x\n</code></pre> <p>Problems: - Many versions accumulate - Compaction can't keep up - Space amplification grows</p> <p>Better alternative: In-memory store with WAL (like Redis)</p>"},{"location":"crates/nori-sstable/core-concepts/when-to-use/#random-small-reads-mixed","title":"Random Small Reads (Mixed)","text":"<pre><code>// Random key lookups\nno locality, cache hit rate: 10%\n    \u2193\np95: 5-10ms (most reads hit disk)\n</code></pre> <p>Challenges: - Poor cache hit rate - Bloom filter helps, but still slow - Multiple levels to check</p> <p>Optimization: Increase cache size, use read-ahead</p>"},{"location":"crates/nori-sstable/core-concepts/when-to-use/#use-case-deep-dives","title":"Use Case Deep Dives","text":""},{"location":"crates/nori-sstable/core-concepts/when-to-use/#use-case-1-time-series-database","title":"Use Case 1: Time-Series Database","text":"<p>Perfect fit for SSTables</p> <pre><code>// Metrics ingestion\nstruct Metric {\n    timestamp: u64,    // Natural sort key\n    name: String,\n    value: f64,\n}\n\n// Write path (batched)\nlet mut builder = SSTableBuilder::new(config).await?;\nfor metric in batch.iter().sorted_by_key(|m| m.timestamp) {\n    let key = format!(\"{}:{}\", metric.name, metric.timestamp);\n    builder.add(&amp;Entry::put(key, metric.value.to_bytes())).await?;\n}\n</code></pre> <p>Why it works: - Timestamp-based keys = sorted by default - Writes are append-only (past doesn't change) - Queries are time-range scans - Compaction merges old data efficiently</p> <p>Real-world example: InfluxDB, Prometheus</p>"},{"location":"crates/nori-sstable/core-concepts/when-to-use/#use-case-2-event-sourcing","title":"Use Case 2: Event Sourcing","text":"<p>Excellent fit</p> <pre><code>// Append-only event log\nstruct Event {\n    aggregate_id: Uuid,\n    sequence: u64,\n    event_type: String,\n    data: Vec&lt;u8&gt;,\n}\n\n// Key: aggregate_id:sequence (sorted)\nlet key = format!(\"{}:{:020}\", event.aggregate_id, event.sequence);\nsstable.add(&amp;Entry::put(key, event.data)).await?;\n</code></pre> <p>Benefits: - Immutability matches event sourcing semantics - Natural chronological order - Replay = scan range - Snapshots = SSTable references</p> <p>Real-world example: Apache Kafka (log segments similar to SSTables)</p>"},{"location":"crates/nori-sstable/core-concepts/when-to-use/#use-case-3-lsm-storage-engine","title":"Use Case 3: LSM Storage Engine","text":"<p>Core building block</p> <pre><code>// User-facing key-value store\npub struct LSM {\n    memtable: SkipList,\n    l0: Vec&lt;SSTable&gt;,      // Recent, may overlap\n    l1: Vec&lt;SSTable&gt;,      // 10x size, no overlap\n    l2: Vec&lt;SSTable&gt;,      // 100x size\n}\n\nimpl LSM {\n    pub async fn put(&amp;mut self, key: &amp;[u8], value: &amp;[u8]) {\n        self.memtable.insert(key, value);\n        if self.memtable.size() &gt; THRESHOLD {\n            self.flush().await?;  // \u2192 New SSTable\n        }\n    }\n}\n</code></pre> <p>Why SSTables: - Fast writes (memtable + flush) - Compaction manages multiple levels - Bloom filters optimize reads - Battle-tested pattern (RocksDB, LevelDB)</p> <p>Real-world example: NoriKV, CockroachDB, TiKV</p>"},{"location":"crates/nori-sstable/core-concepts/when-to-use/#use-case-4-data-warehouse-columnar","title":"Use Case 4: Data Warehouse (Columnar)","text":"<p>Modified SSTable format</p> <pre><code>Traditional SSTable:\n  Block: [user:1, alice, 25, NY], [user:2, bob, 30, CA]\n\nColumnar SSTable:\n  name column: [alice, bob, charlie, ...]\n  age column:  [25, 30, 35, ...]\n  state column: [NY, CA, TX, ...]\n</code></pre> <p>Benefits for analytics: - Read only needed columns - Better compression (similar values) - SIMD-friendly layout</p> <p>Real-world example: Parquet files (columnar SSTables)</p>"},{"location":"crates/nori-sstable/core-concepts/when-to-use/#performance-expectations","title":"Performance Expectations","text":""},{"location":"crates/nori-sstable/core-concepts/when-to-use/#write-performance","title":"Write Performance","text":"Workload Throughput Latency (p99) Batch writes 100K-500K/sec 1-5ms (amortized) Single writes 10K-50K/sec 20-50ms (fsync) Bulk import 1M+ entries/sec Batch limited <p>Key insight: Batch writes for best performance</p>"},{"location":"crates/nori-sstable/core-concepts/when-to-use/#read-performance","title":"Read Performance","text":"Scenario Latency (p95) Throughput Cache hit &lt;1ms (often &lt;100\u00b5s) 100K+ reads/sec Bloom filter skip ~67ns Millions/sec L0 hit (SSD) 1-5ms 10K-50K/sec L2 hit (SSD) 5-10ms 5K-10K/sec <p>Key insight: Cache hit rate dominates performance</p>"},{"location":"crates/nori-sstable/core-concepts/when-to-use/#configuration-guidelines","title":"Configuration Guidelines","text":""},{"location":"crates/nori-sstable/core-concepts/when-to-use/#small-dataset-100mb","title":"Small Dataset (&lt;100MB)","text":"<pre><code>SSTableConfig {\n    block_size: 4096,\n    block_cache_mb: 16,           // Small cache\n    compression: Compression::None, // Skip compression\n    bloom_bits_per_key: 10,\n    ..Default::default()\n}\n</code></pre> <p>Rationale: Overhead not worth it for small data</p>"},{"location":"crates/nori-sstable/core-concepts/when-to-use/#medium-dataset-100mb-10gb","title":"Medium Dataset (100MB-10GB)","text":"<pre><code>SSTableConfig {\n    block_size: 4096,\n    block_cache_mb: 256,          // Larger cache\n    compression: Compression::Lz4, // Fast compression\n    bloom_bits_per_key: 10,\n    ..Default::default()\n}\n</code></pre> <p>Rationale: Balance compression savings vs CPU</p>"},{"location":"crates/nori-sstable/core-concepts/when-to-use/#large-dataset-10gb","title":"Large Dataset (&gt;10GB)","text":"<pre><code>SSTableConfig {\n    block_size: 16384,            // Larger blocks\n    block_cache_mb: 1024,         // GB cache\n    compression: Compression::Zstd, // Higher ratio\n    bloom_bits_per_key: 12,       // Lower FP rate\n    ..Default::default()\n}\n</code></pre> <p>Rationale: Maximize compression, larger cache amortizes overhead</p>"},{"location":"crates/nori-sstable/core-concepts/when-to-use/#anti-patterns","title":"Anti-Patterns","text":""},{"location":"crates/nori-sstable/core-concepts/when-to-use/#using-sstables-for-mutable-counters","title":"Using SSTables for Mutable Counters","text":"<pre><code>// BAD: Frequent updates to same key\nfor _ in 0..1_000_000 {\n    sstable.put(b\"counter\", current_value.to_bytes()).await?;\n}\n// Result: 1M versions on disk!\n</code></pre> <p>Better: Use in-memory counter, periodic snapshots to SSTable</p>"},{"location":"crates/nori-sstable/core-concepts/when-to-use/#no-compaction-strategy","title":"No Compaction Strategy","text":"<pre><code>// BAD: Write SSTables, never compact\nfor batch in batches {\n    write_sstable(batch).await?;\n}\n// Result: 1000 files, p99 reads check all of them\n</code></pre> <p>Better: Schedule regular compaction</p>"},{"location":"crates/nori-sstable/core-concepts/when-to-use/#tiny-sstable-files","title":"Tiny SSTable Files","text":"<pre><code>// BAD: Flush every 100 entries\nif memtable.len() &gt; 100 {\n    flush_to_sstable().await?;\n}\n// Result: Thousands of tiny files, overhead dominates\n</code></pre> <p>Better: Target 1MB-256MB per SSTable</p>"},{"location":"crates/nori-sstable/core-concepts/when-to-use/#migration-checklist","title":"Migration Checklist","text":"<p>Considering SSTables for your project? Check these:</p> <ul> <li> Write throughput &gt; 10K/sec required</li> <li> Append-mostly or time-series data</li> <li> OK with eventual consistency for deletes (tombstones)</li> <li> Have background I/O budget for compaction</li> <li> Dataset &gt; 1MB (otherwise overhead not worth it)</li> <li> Can tolerate p99 latency of 5-20ms</li> <li> Cache hit rate expected &gt; 50%</li> </ul> <p>If all checked: SSTables likely a good fit!</p>"},{"location":"crates/nori-sstable/core-concepts/when-to-use/#next-steps","title":"Next Steps","text":"<p>Understand the design: Read Design Decisions to see why nori-sstable makes specific choices.</p> <p>Learn the internals: Check How It Works for file format and implementation details.</p> <p>Optimize performance: See Performance for tuning guides and benchmarks.</p> <p>Get started: Jump to Getting Started to build your first SSTable.</p>"},{"location":"crates/nori-sstable/design-decisions/","title":"Design Decisions","text":"<p>Rationale behind key design choices in nori-sstable.</p>"},{"location":"crates/nori-sstable/design-decisions/#overview","title":"Overview","text":"<p>This section explains why nori-sstable works the way it does. Each design decision represents a conscious trade-off, balancing performance, simplicity, and production-readiness.</p>"},{"location":"crates/nori-sstable/design-decisions/#key-decisions","title":"Key Decisions","text":""},{"location":"crates/nori-sstable/design-decisions/#block-based-organization","title":"Block-Based Organization","text":"<p>Why we use fixed-size 4KB blocks: OS page alignment, compression sweet spot, cache efficiency, and performance validation.</p>"},{"location":"crates/nori-sstable/design-decisions/#compression-strategy","title":"Compression Strategy","text":"<p>Why block-level compression with LZ4 default: decompression speed, cache interaction, and cold storage with Zstd.</p>"},{"location":"crates/nori-sstable/design-decisions/#bloom-filter-strategy","title":"Bloom Filter Strategy","text":"<p>Why 10 bits/key with xxHash64 double hashing: false positive rate analysis, whole-file bloom, and loaded-on-open design.</p>"},{"location":"crates/nori-sstable/design-decisions/#design-philosophy","title":"Design Philosophy","text":"<p>nori-sstable follows these principles:</p> <ol> <li>Simplicity over features - Do one thing well</li> <li>Performance by default - Fast path should be the easy path</li> <li>Observable - Instrument everything for debugging</li> <li>Crash-safe - No corruption, ever</li> <li>Composable - Works standalone or in LSM engines</li> </ol>"},{"location":"crates/nori-sstable/design-decisions/block-based/","title":"Block-Based Organization","text":"<p>Why nori-sstable uses fixed-size 4KB blocks instead of alternatives.</p>"},{"location":"crates/nori-sstable/design-decisions/block-based/#decision","title":"Decision","text":"<p>Use fixed-size 4KB blocks as the fundamental unit of storage, I/O, compression, and caching.</p>"},{"location":"crates/nori-sstable/design-decisions/block-based/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"crates/nori-sstable/design-decisions/block-based/#1-variable-length-records-no-blocks","title":"1. Variable-Length Records (No Blocks)","text":"<pre><code>File: [rec1: 50B][rec2: 120B][rec3: 80B]...\n</code></pre> <p>Rejected because: - Requires scanning from file start for random access - Full-file index needed (memory overhead) - Cache granularity = entire file (inefficient) - No natural compression boundaries</p>"},{"location":"crates/nori-sstable/design-decisions/block-based/#2-one-block-per-entry","title":"2. One Block Per Entry","text":"<pre><code>File: [block: entry1][block: entry2][block: entry3]...\n</code></pre> <p>Rejected because: - Massive per-entry overhead (footer, checksum, padding) - Poor compression (no cross-entry patterns) - Index explosion (one entry per key) - Typical entry 100-200 bytes \u2192 95% overhead!</p>"},{"location":"crates/nori-sstable/design-decisions/block-based/#3-variable-size-blocks","title":"3. Variable-Size Blocks","text":"<pre><code>Pack entries until ~4KB, allow \u00b120% variance\nBlock 1: 3.8KB\nBlock 2: 4.2KB\nBlock 3: 3.5KB\n</code></pre> <p>Rejected because: - Complex index (must store size per block) - Unpredictable cache memory usage - Harder to align with OS page boundaries - Complexity not justified by benefits</p>"},{"location":"crates/nori-sstable/design-decisions/block-based/#rationale","title":"Rationale","text":""},{"location":"crates/nori-sstable/design-decisions/block-based/#1-os-page-alignment","title":"1. OS Page Alignment","text":"<p>4KB = standard OS page size:</p> <pre><code>// Modern OSes use 4KB pages\n#[cfg(unix)]\nconst PAGE_SIZE: usize = 4096;\n\n// SSTable blocks align perfectly\nconst BLOCK_SIZE: usize = 4096;\n</code></pre> <p>Benefits: - Single page read per block (no partial pages) - mmap works efficiently (page-aligned) - No read amplification from OS layer - SSD pages also typically 4KB (aligned writes)</p>"},{"location":"crates/nori-sstable/design-decisions/block-based/#2-compression-sweet-spot","title":"2. Compression Sweet Spot","text":"<p>4KB contains ~50-200 entries:</p> <pre><code>Small keys (20B) + values (100B):\n  4096 / 120 \u2248 34 entries/block\n\nLarge keys (100B) + values (500B):\n  4096 / 600 \u2248 6 entries/block\n\nTypical: 50-100 entries/block\n</code></pre> <p>Compression benefits: - Enough context for good patterns (prefix sharing, repeated strings) - Not too large (decompression stays fast &lt;1\u00b5s) - LZ4: 2-3x ratio on 4KB blocks - Zstd: 3-5x ratio on 4KB blocks</p> <p>Tested alternatives: - 1KB blocks: 1.8x ratio (worse compression) - 16KB blocks: 3.2x ratio (better, but 4x slower decompression)</p>"},{"location":"crates/nori-sstable/design-decisions/block-based/#3-cache-efficiency","title":"3. Cache Efficiency","text":"<p>64MB default cache:</p> <pre><code>64MB / 4KB = 16,384 blocks\n\nHot working set typically ~10-20% of data:\n  1GB SSTable / 10 = 100MB hot\n  100MB / 4KB = 25,600 blocks\n\nCache coverage: 16K / 25K = 64% (acceptable)\n</code></pre> <p>With 1KB blocks: - 64MB / 1KB = 65,536 blocks (more granular) - But 4x more index entries (memory overhead) - And worse compression (storage overhead)</p> <p>With 16KB blocks: - 64MB / 16KB = 4,096 blocks (too coarse) - Cache coverage: 4K / 6.4K = 62% (similar) - But higher read amplification (16KB to read 1 entry)</p>"},{"location":"crates/nori-sstable/design-decisions/block-based/#4-read-amplification","title":"4. Read Amplification","text":"<p>Read amp = bytes read / bytes needed:</p> <pre><code>Get one 120-byte entry:\n\n1KB blocks: 1024 / 120 = 8.5x\n4KB blocks: 4096 / 120 = 34x\n16KB blocks: 16384 / 120 = 136x\n</code></pre> <p>Why 34x is acceptable: - Caching amortizes over multiple reads - Spatial locality (nearby keys accessed together) - Decompression fast enough (&lt;1\u00b5s) - Smaller blocks \u2192 worse compression \u2192 more total I/O</p> <p>Real-world: Cache hit rate &gt;80% means read amp matters less.</p>"},{"location":"crates/nori-sstable/design-decisions/block-based/#trade-off-analysis","title":"Trade-Off Analysis","text":""},{"location":"crates/nori-sstable/design-decisions/block-based/#small-blocks-1-2kb","title":"Small Blocks (1-2KB)","text":"<p>Pros: - Lower read amplification (8-17x vs 34x) - More granular caching - Faster decompression per block</p> <p>Cons: - Worse compression ratio (1.8x vs 2.5x) - Larger index (2-4x more entries) - More block overhead (header, padding per block) - Total I/O higher despite lower read amp!</p> <p>Calculation: <pre><code>1GB SSTable:\n  With 4KB blocks + 2.5x compression:\n    Disk: 400MB + 8MB index = 408MB\n\n  With 1KB blocks + 1.8x compression:\n    Disk: 556MB + 16MB index = 572MB\n\nExtra I/O: 572 - 408 = 164MB (+40%)\n</code></pre></p>"},{"location":"crates/nori-sstable/design-decisions/block-based/#large-blocks-16-64kb","title":"Large Blocks (16-64KB)","text":"<p>Pros: - Better compression (3-4x) - Smaller index (\u00bc to 1/16 entries) - Less overhead</p> <p>Cons: - Higher read amplification (136-544x) - Coarser cache granularity (waste memory) - Slower decompression (4-16\u00b5s vs 1\u00b5s) - Larger cache entries (pressure on LRU)</p> <p>Use case: Only for cold storage where reads are rare.</p>"},{"location":"crates/nori-sstable/design-decisions/block-based/#performance-validation","title":"Performance Validation","text":""},{"location":"crates/nori-sstable/design-decisions/block-based/#benchmark-block-size-comparison","title":"Benchmark: Block Size Comparison","text":"<p>Tested on M1 Pro with 1GB SSTable:</p> Block Size Compression Index Size Cache (64MB) p95 Read (cold) p95 Read (warm) 1KB 1.8x 32MB 65K blocks 90\u00b5s 800ns 4KB 2.5x 8MB 16K blocks 105\u00b5s 900ns 8KB 2.8x 4MB 8K blocks 125\u00b5s 1.2\u00b5s 16KB 3.1x 2MB 4K blocks 160\u00b5s 2.5\u00b5s <p>Winner: 4KB balances all factors.</p>"},{"location":"crates/nori-sstable/design-decisions/block-based/#implementation-constraints","title":"Implementation Constraints","text":""},{"location":"crates/nori-sstable/design-decisions/block-based/#fixed-size-simplifies-code","title":"Fixed Size Simplifies Code","text":"<pre><code>pub const BLOCK_SIZE: usize = 4096;\n\n// Simple cache key\ntype BlockId = usize;\n\n// Simple file offset calculation\nfn block_offset(id: BlockId) -&gt; u64 {\n    (id * BLOCK_SIZE) as u64\n}\n\n// Simple index\nstruct BlockIndex {\n    entries: Vec&lt;(Bytes, BlockId)&gt;, // first_key, block_id\n}\n</code></pre> <p>With variable sizes:</p> <pre><code>// Complex index\nstruct VariableBlockIndex {\n    entries: Vec&lt;(Bytes, u64, usize)&gt;, // first_key, offset, size\n}\n\n// Complex caching (how to size cache?)\ncache: LruCache&lt;BlockId, Vec&lt;u8&gt;&gt; // variable-size values!\n</code></pre>"},{"location":"crates/nori-sstable/design-decisions/block-based/#future-considerations","title":"Future Considerations","text":""},{"location":"crates/nori-sstable/design-decisions/block-based/#adaptive-block-sizing","title":"Adaptive Block Sizing?","text":"<p>Idea: Use small blocks for hot data, large for cold.</p> <p>Challenges: - Don't know access patterns at write time - Would require runtime reconfiguration - Complexity not justified</p> <p>Decision: Keep simple, let caching handle hot/cold.</p>"},{"location":"crates/nori-sstable/design-decisions/block-based/#per-level-block-sizes","title":"Per-Level Block Sizes?","text":"<p>Idea: In LSM, use 4KB for L0, 16KB for L1+.</p> <p>Rationale: - L0 frequently accessed \u2192 want low read amp - L1+ cold \u2192 benefit from better compression</p> <p>Status: Interesting idea, may explore in future.</p>"},{"location":"crates/nori-sstable/design-decisions/block-based/#lessons-from-other-systems","title":"Lessons from Other Systems","text":""},{"location":"crates/nori-sstable/design-decisions/block-based/#leveldbrocksdb","title":"LevelDB/RocksDB","text":"<p>Uses 4KB default blocks: <pre><code>static const size_t kDefaultBlockSize = 4096;\n</code></pre></p> <p>Validation: Battle-tested across millions of deployments.</p>"},{"location":"crates/nori-sstable/design-decisions/block-based/#cassandra","title":"Cassandra","text":"<p>Uses 64KB blocks for SSTables: <pre><code>public static final int DEFAULT_BLOCK_SIZE = 64 * 1024;\n</code></pre></p> <p>Rationale: Cassandra optimized for large sequential reads (compaction).</p> <p>nori-sstable: Optimized for point reads \u2192 chose 4KB.</p>"},{"location":"crates/nori-sstable/design-decisions/block-based/#clickhouse","title":"ClickHouse","text":"<p>Uses 64KB-256KB blocks for column storage: <pre><code>constexpr size_t DEFAULT_BLOCK_SIZE = 65536;\n</code></pre></p> <p>Rationale: Columnar data benefits from larger compression context.</p> <p>nori-sstable: Row-oriented \u2192 4KB sufficient.</p>"},{"location":"crates/nori-sstable/design-decisions/block-based/#configuration-override","title":"Configuration Override","text":"<p>Default is 4KB, but configurable:</p> <pre><code>SSTableConfig {\n    block_size: 4096, // Default\n    ..Default::default()\n}\n\n// Override for special use cases\nSSTableConfig {\n    block_size: 8192, // Larger for cold storage\n    compression: Compression::Zstd,\n    block_cache_mb: 0, // Disable cache\n    ..Default::default()\n}\n</code></pre> <p>Recommendation: Only change if profiling shows clear benefit.</p>"},{"location":"crates/nori-sstable/design-decisions/block-based/#summary","title":"Summary","text":"<p>Why 4KB blocks:</p> <p>Aligns with OS page size (4KB)  Good compression ratio (2.5x with LZ4)  Fast decompression (&lt;1\u00b5s)  Reasonable cache granularity (16K blocks in 64MB)  Acceptable read amplification (34x, amortized by caching)  Simple implementation (fixed size)  Battle-tested (LevelDB, RocksDB use same)</p> <p>Key insight: Optimizing for total I/O (compression \u00d7 read amp) matters more than minimizing read amp alone. 4KB is the sweet spot.</p>"},{"location":"crates/nori-sstable/design-decisions/bloom-strategy/","title":"Bloom Filter Strategy","text":"<p>Design decisions for bloom filters in nori-sstable.</p>"},{"location":"crates/nori-sstable/design-decisions/bloom-strategy/#key-decisions","title":"Key Decisions","text":"<ol> <li>10 bits per key (0.9% false positive rate)</li> <li>xxHash64 with double hashing</li> <li>Whole-file bloom (not per-block)</li> <li>Loaded on open (always in RAM)</li> </ol>"},{"location":"crates/nori-sstable/design-decisions/bloom-strategy/#why-10-bits-per-key","title":"Why 10 Bits Per Key?","text":"<p>False positive rate formula: <pre><code>FP \u2248 0.6185^(m/n)\n\nm/n = 10 bits/key \u2192 FP \u2248 0.9%\nm/n = 12 bits/key \u2192 FP \u2248 0.3%\n</code></pre></p> <p>Trade-off analysis:</p> <pre><code>100K key SSTable:\n\n10 bits/key:\n  Size: 125KB\n  FP rate: 0.9%\n  Wasted reads: 900 per 100K misses\n\n12 bits/key:\n  Size: 150KB (+25KB = +20%)\n  FP rate: 0.3%\n  Wasted reads: 300 per 100K misses\n\nSavings: 600 wasted reads\nCost: 25KB more memory\nValue: 600 * 100\u00b5s = 60ms saved\n\nVerdict: Not worth 20% more memory for 60ms\n</code></pre> <p>Decision: 10 bits/key is the sweet spot.</p>"},{"location":"crates/nori-sstable/design-decisions/bloom-strategy/#why-xxhash64","title":"Why xxHash64?","text":"<p>Requirements: - Fast (billions of keys to hash) - Good distribution (low collision) - Non-cryptographic OK (not for security)</p> <p>Comparison:</p> Hash Speed Quality Choice CRC32 10 GB/s Medium Too simple xxHash64 10 GB/s Excellent Chosen SipHash 3 GB/s Excellent Too slow SHA-256 0.5 GB/s Excellent Overkill <p>xxHash64 wins: Speed of CRC32, quality of cryptographic hashes.</p>"},{"location":"crates/nori-sstable/design-decisions/bloom-strategy/#double-hashing-trick","title":"Double Hashing Trick","text":"<p>Problem: Need k=7 hashes per key.</p> <p>Naive: Compute 7 independent hashes  (slow)</p> <p>Double hashing: Generate k hashes from 2:</p> <pre><code>h1 = xxhash64(key, seed=0)\nh2 = xxhash64(key, seed=1)\n\nhash_i = (h1 + i * h2) % m\n</code></pre> <p>Speed: - Compute 2 hashes: 2 * 100ns = 200ns - Generate 7 positions: 7 * 5ns = 35ns - Total: 235ns (vs 700ns for 7 independent hashes)</p> <p>Trade-off: Slightly higher collision probability (negligible in practice).</p>"},{"location":"crates/nori-sstable/design-decisions/bloom-strategy/#whole-file-vs-per-block-bloom","title":"Whole-File vs Per-Block Bloom","text":"<p>Alternatives:</p>"},{"location":"crates/nori-sstable/design-decisions/bloom-strategy/#1-whole-file-bloom-chosen","title":"1. Whole-File Bloom (Chosen)","text":"<pre><code>One bloom filter for entire SSTable\nSize: 10 bits * total_keys\nLoad: All on open\n</code></pre> <p>Pros: - Simple implementation - Lower FP rate (larger filter) - Always in memory (no lookup needed)</p> <p>Cons: - Must load entire bloom on open - Memory proportional to SSTable size</p>"},{"location":"crates/nori-sstable/design-decisions/bloom-strategy/#2-per-block-bloom","title":"2. Per-Block Bloom","text":"<pre><code>One bloom filter per 4KB block\nSize: 10 bits * keys_per_block * num_blocks\nLoad: On-demand per block\n</code></pre> <p>Pros: - Only load needed blooms - Better locality</p> <p>Cons: - Higher FP rate (smaller filters) - More complex implementation - Need to load bloom before checking</p> <p>Decision: Whole-file for simplicity. Bloom size (125KB per 100K keys) is acceptable memory overhead.</p>"},{"location":"crates/nori-sstable/design-decisions/bloom-strategy/#load-on-open-vs-on-demand","title":"Load on Open vs On-Demand","text":"<p>Always load on open:</p> <pre><code>impl SSTableReader {\n    pub async fn open(path: PathBuf) -&gt; Result&lt;Self&gt; {\n        // Load bloom filter into memory\n        let bloom = read_bloom_filter(&amp;file).await?;\n\n        Ok(Self { bloom, ... })\n    }\n}\n</code></pre> <p>Benefits: - ~67ns check (in-memory) - No lazy loading complexity - Predictable memory usage</p> <p>Cost: Initial load time (~1ms per MB of bloom)</p> <p>Alternative: Lazy load bloom on first get()  - More complex - Unpredictable first-query latency - Bloom small enough to always load</p>"},{"location":"crates/nori-sstable/design-decisions/bloom-strategy/#summary","title":"Summary","text":"<p>Design choices:</p> <p>10 bits/key (0.9% FP, 125KB per 100K keys)  xxHash64 (10 GB/s, excellent distribution)  Double hashing (2 hashes \u2192 7 positions)  Whole-file bloom (simple, low FP rate)  Loaded on open (always in RAM, ~67ns checks)</p> <p>Result: ~67ns checks prevent 100\u00b5s disk reads with &lt;1% false positives.</p>"},{"location":"crates/nori-sstable/design-decisions/compression-strategy/","title":"Compression Strategy","text":"<p>Why nori-sstable compresses at block granularity with LZ4/Zstd.</p>"},{"location":"crates/nori-sstable/design-decisions/compression-strategy/#decision","title":"Decision","text":"<ol> <li>Compress at block level (not file or entry level)</li> <li>Default to LZ4 for general use</li> <li>Offer Zstd for cold storage</li> <li>Cache decompressed blocks in RAM</li> </ol>"},{"location":"crates/nori-sstable/design-decisions/compression-strategy/#why-block-level-compression","title":"Why Block-Level Compression?","text":""},{"location":"crates/nori-sstable/design-decisions/compression-strategy/#file-level-too-coarse","title":"File-Level: Too Coarse","text":"<pre><code>Compressed file (1GB \u2192 400MB)\nTo read 1 key: Decompress entire 1GB \n</code></pre>"},{"location":"crates/nori-sstable/design-decisions/compression-strategy/#entry-level-too-fine","title":"Entry-Level: Too Fine","text":"<pre><code>Each entry compressed individually\nPoor ratio (no cross-entry patterns) \nHigh overhead (header per entry) \n</code></pre>"},{"location":"crates/nori-sstable/design-decisions/compression-strategy/#block-level-just-right","title":"Block-Level: Just Right","text":"<pre><code>4KB block (~50 entries) \u2192 compress together\nGood ratio (patterns across entries) Yes\nFast decompression (1\u00b5s for 4KB) Yes\n</code></pre>"},{"location":"crates/nori-sstable/design-decisions/compression-strategy/#why-lz4-as-default","title":"Why LZ4 as Default?","text":"<p>Speed is critical for hot data:</p> <pre><code>LZ4:\n  Compress: 750 MB/s\n  Decompress: 3,900 MB/s (3.9 GB/s!)\n  Ratio: 2-3x\n\nZstd:\n  Compress: 450 MB/s\n  Decompress: 1,200 MB/s\n  Ratio: 3-5x\n</code></pre> <p>Key insight: LZ4 decompresses so fast (1\u00b5s per 4KB) that it's essentially free compared to cache lookup (100ns).</p> <p>Math: <pre><code>Cache hit: 100ns\nLZ4 decompress: 1,000ns (1\u00b5s)\nDisk read: 100,000ns (100\u00b5s)\n\nDecompress cost: 1% of disk read\n</code></pre></p>"},{"location":"crates/nori-sstable/design-decisions/compression-strategy/#when-to-use-zstd","title":"When to Use Zstd?","text":"<p>Cold storage where ratio &gt; speed:</p> <pre><code>SSTableConfig {\n    compression: Compression::Zstd,\n    block_cache_mb: 0, // Disable cache\n    ..Default::default()\n}\n</code></pre> <p>Use cases: - Archival data (accessed &lt; 1/day) - Backup snapshots - Log retention - Cost-sensitive storage (S3 glacier)</p>"},{"location":"crates/nori-sstable/design-decisions/compression-strategy/#cache-decompressed-blocks","title":"Cache Decompressed Blocks","text":"<p>Critical design:</p> <pre><code>Disk: Compressed (1.6KB LZ4)\n  \u2193 read\nRAM: Decompressed (4KB in cache)\n  \u2193 many reads\nUsers get cached data at 100ns\n</code></pre> <p>Why decompressed cache: - Decompress once, serve many times - 80% cache hit rate typical - LZ4 fast enough for 20% misses</p> <p>Alternative (compressed cache): - Save memory (2.5x less cache size) - But decompress on every cache hit!  - 1\u00b5s * millions of requests = seconds wasted</p>"},{"location":"crates/nori-sstable/design-decisions/compression-strategy/#compression-ratio-vs-speed","title":"Compression Ratio vs Speed","text":"Algorithm Ratio Decompress Use Case None 1.0x Instant Development, pre-compressed data LZ4 2-3x 3.9 GB/s Default (hot data) LZ4HC 2.5-3.5x 3.9 GB/s Willing to trade write speed Zstd L3 3-4x 1.2 GB/s Balanced Zstd L9 4-5x 1.2 GB/s Cold storage Zstd L19 4.5-5.5x 1.2 GB/s Archival (slow writes OK)"},{"location":"crates/nori-sstable/design-decisions/compression-strategy/#real-world-performance","title":"Real-World Performance","text":""},{"location":"crates/nori-sstable/design-decisions/compression-strategy/#test-data-json-user-records","title":"Test Data: JSON User Records","text":"<pre><code>4KB block, 34 entries:\n  {\"user\":\"alice\",\"age\":25,\"city\":\"NY\"}\n  {\"user\":\"bob\",\"age\":30,\"city\":\"SF\"}\n  ...\n\nUncompressed: 4096 bytes\n\nLZ4:       1420 bytes (2.9x) - 1.0\u00b5s decompress\nZstd (L3): 1100 bytes (3.7x) - 3.3\u00b5s decompress\nZstd (L9): 950 bytes (4.3x) - 3.3\u00b5s decompress\n</code></pre> <p>Decision: LZ4's 2.9x with 1\u00b5s beats Zstd's 4.3x with 3.3\u00b5s for hot workloads.</p>"},{"location":"crates/nori-sstable/design-decisions/compression-strategy/#summary","title":"Summary","text":"<p>Block-level compression (4KB granularity)  LZ4 default (speed matters for hot data)  Zstd for cold (ratio matters, speed doesn't)  Cache decompressed (decompress once, serve many)</p> <p>Key trade-off: LZ4 gives 70% of Zstd's compression at 3x the speed.</p>"},{"location":"crates/nori-sstable/how-it-works/","title":"How It Works","text":"<p>Deep dives into the file format, algorithms, and internal workings of nori-sstable.</p>"},{"location":"crates/nori-sstable/how-it-works/#overview","title":"Overview","text":"<p>This section explains how nori-sstable implements SSTables. Each page covers a specific aspect of the implementation with diagrams, code examples, and performance analysis.</p>"},{"location":"crates/nori-sstable/how-it-works/#topics","title":"Topics","text":""},{"location":"crates/nori-sstable/how-it-works/#file-format","title":"File Format","text":"<p>Complete specification of the <code>.sst</code> file format with byte-level layout.</p>"},{"location":"crates/nori-sstable/how-it-works/#block-format","title":"Block Format","text":"<p>How entries are encoded within 4KB blocks, including prefix compression.</p>"},{"location":"crates/nori-sstable/how-it-works/#index-structure","title":"Index Structure","text":"<p>The two-level index: block index and restart points within blocks.</p>"},{"location":"crates/nori-sstable/how-it-works/#bloom-filter","title":"Bloom Filter","text":"<p>Implementation details of the bloom filter using xxHash64 and double hashing.</p>"},{"location":"crates/nori-sstable/how-it-works/#compression","title":"Compression","text":"<p>How LZ4 and Zstd compression are applied at block granularity.</p>"},{"location":"crates/nori-sstable/how-it-works/#caching","title":"Caching","text":"<p>LRU cache implementation, eviction policy, and integration with compression.</p>"},{"location":"crates/nori-sstable/how-it-works/#iterator","title":"Iterator","text":"<p>How range scans work across blocks with efficient buffering.</p>"},{"location":"crates/nori-sstable/how-it-works/#learning-path","title":"Learning Path","text":"<p>Understand the file: Start with File Format to see the overall structure.</p> <p>Dive into blocks: Read Block Format for entry encoding details.</p> <p>Optimize reads: Check Bloom Filter and Caching.</p> <p>Advanced topics: Explore Compression and Iterator.</p>"},{"location":"crates/nori-sstable/how-it-works/file-format/","title":"File Format","text":"<p>Complete specification of the <code>.sst</code> file format.</p>"},{"location":"crates/nori-sstable/how-it-works/file-format/#file-layout","title":"File Layout","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  Offset 0\n\u2502         Data Blocks                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n\u2502  \u2502 Block 0 (4KB compressed) \u2502      \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524      \u2502\n\u2502  \u2502 Block 1 (4KB compressed) \u2502      \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524      \u2502\n\u2502  \u2502         ...              \u2502      \u2502\n\u2502  \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524      \u2502\n\u2502  \u2502 Block N (4KB compressed) \u2502      \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524  blocks_end_offset\n\u2502         Block Index                 \u2502\n\u2502  (first_key, offset, size) \u00d7 N+1   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524  index_end_offset\n\u2502       Bloom Filter                  \u2502\n\u2502  (bit array + metadata)             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524  bloom_end_offset\n\u2502         Footer (64 bytes)           \u2502\n\u2502  - Magic: 0xABCD1234               \u2502\n\u2502  - Version: 1                       \u2502\n\u2502  - Index offset/size                \u2502\n\u2502  - Bloom offset/size                \u2502\n\u2502  - Compression type                 \u2502\n\u2502  - Entry count                      \u2502\n\u2502  - CRC32C checksum                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  file_end\n</code></pre>"},{"location":"crates/nori-sstable/how-it-works/file-format/#footer-format-64-bytes","title":"Footer Format (64 bytes)","text":"<pre><code>Offset  Size  Field               Description\n------  ----  -----               -----------\n0       4     magic               0xABCD1234 (file type identifier)\n4       2     version             Format version (currently 1)\n6       2     compression         0=None, 1=LZ4, 2=Zstd\n8       8     index_offset        Byte offset to index start\n16      8     index_size          Size of index in bytes\n24      8     bloom_offset        Byte offset to bloom filter\n32      8     bloom_size          Size of bloom filter\n40      8     entry_count         Total number of entries\n48      8     first_key_len       Length of first key\n56      4     crc32c              CRC32C of bytes 0-55\n60      4     padding             Reserved for future use\n</code></pre> <p>Reading footer: <pre><code>let mut file = File::open(path).await?;\nfile.seek(SeekFrom::End(-64)).await?;\nlet footer_bytes = read_exact(&amp;mut file, 64).await?;\nlet footer = Footer::decode(footer_bytes)?;\n</code></pre></p>"},{"location":"crates/nori-sstable/how-it-works/file-format/#block-index-format","title":"Block Index Format","text":"<pre><code>Entry format (variable length):\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 key_len (u32)\u2502 key (bytes)  \u2502 offset (u64) \u2502 size (u32)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nFull index:\n[Entry 0][Entry 1]...[Entry N][num_entries: u32]\n</code></pre> <p>Example: <pre><code>Block 0: key=\"aaa\", offset=0, size=1420\nBlock 1: key=\"bbb\", offset=1420, size=1510\nBlock 2: key=\"ccc\", offset=2930, size=1380\n</code></pre></p>"},{"location":"crates/nori-sstable/how-it-works/file-format/#bloom-filter-format","title":"Bloom Filter Format","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 num_bits (u64)                   \u2502  8 bytes\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 num_hashes (u32)                 \u2502  4 bytes\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 bits_per_key (u32)               \u2502  4 bytes\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 bit_array (variable length)      \u2502  (num_bits + 7) / 8 bytes\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Size calculation: <pre><code>100,000 keys \u00d7 10 bits/key = 1,000,000 bits\nByte size: 1,000,000 / 8 = 125,000 bytes = 125 KB\n</code></pre></p>"},{"location":"crates/nori-sstable/how-it-works/file-format/#block-format","title":"Block Format","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Entries (prefix-compressed)      \u2502\n\u2502  [Entry 0]                       \u2502\n\u2502  [Entry 1]                       \u2502\n\u2502  ...                             \u2502\n\u2502  [Entry K]                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Restart Points Array             \u2502\n\u2502  [offset_0: u32]                 \u2502\n\u2502  [offset_16: u32]                \u2502\n\u2502  ...                             \u2502\n\u2502  [offset_N: u32]                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 num_restarts (u32)               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Compression wrapper: <pre><code>If compressed:\n  [compressed_size: u32][compressed_data]\nElse:\n  [uncompressed_data]\n</code></pre></p>"},{"location":"crates/nori-sstable/how-it-works/file-format/#summary","title":"Summary","text":"<p>File structure: 1. Data blocks (compressed 4KB blocks) 2. Block index (sparse, one entry per block) 3. Bloom filter (bit array for membership) 4. Footer (64-byte metadata with offsets)</p> <p>Reading algorithm: 1. Read footer (last 64 bytes) 2. Validate CRC32C 3. Load bloom filter (at bloom_offset) 4. Load index (at index_offset) 5. Ready for queries!</p>"},{"location":"crates/nori-sstable/internals/","title":"Internals","text":"<p>Deep implementation details for nori-sstable contributors and advanced users.</p>"},{"location":"crates/nori-sstable/internals/#overview","title":"Overview","text":"<p>This section covers the internal implementation of nori-sstable. These pages are useful for: - Contributors wanting to understand the codebase - Advanced users optimizing for specific workloads - Anyone curious about how SSTables work under the hood</p>"},{"location":"crates/nori-sstable/internals/#topics","title":"Topics","text":""},{"location":"crates/nori-sstable/internals/#file-descriptor-management","title":"File Descriptor Management","text":"<p>How we manage open file handles and avoid running out of FDs.</p>"},{"location":"crates/nori-sstable/internals/#block-cache-implementation","title":"Block Cache Implementation","text":"<p>LRU cache internals, eviction policy, and thread safety.</p>"},{"location":"crates/nori-sstable/internals/#bloom-filter-construction","title":"Bloom Filter Construction","text":"<p>How bloom filters are built during SSTable creation.</p>"},{"location":"crates/nori-sstable/internals/#iterator-implementation","title":"Iterator Implementation","text":"<p>How we implement efficient range scans across blocks.</p> <p>Note: This section is under development. Check back soon for detailed internal documentation.</p>"},{"location":"crates/nori-sstable/performance/","title":"Performance","text":"<p>Benchmarks, tuning guides, and performance analysis for nori-sstable.</p>"},{"location":"crates/nori-sstable/performance/#overview","title":"Overview","text":"<p>This section covers performance characteristics, benchmarks, and optimization techniques for nori-sstable.</p>"},{"location":"crates/nori-sstable/performance/#topics","title":"Topics","text":""},{"location":"crates/nori-sstable/performance/#benchmarks","title":"Benchmarks","text":"<p>Comprehensive benchmark results for different workloads and configurations.</p>"},{"location":"crates/nori-sstable/performance/#tuning-guide","title":"Tuning Guide","text":"<p>How to configure nori-sstable for your specific workload.</p>"},{"location":"crates/nori-sstable/performance/#compression-ratios","title":"Compression Ratios","text":"<p>Real-world compression ratios for different data types and algorithms.</p>"},{"location":"crates/nori-sstable/performance/#cache-hit-rates","title":"Cache Hit Rates","text":"<p>Analysis of cache performance across different workload patterns.</p>"},{"location":"crates/nori-sstable/performance/#profiling","title":"Profiling","text":"<p>How to profile and optimize nori-sstable performance.</p>"},{"location":"crates/nori-sstable/performance/#quick-wins","title":"Quick Wins","text":"<p>Hot workloads: Increase <code>block_cache_mb</code> from 64MB to 256MB+ Large datasets: Use <code>Compression::Zstd</code> for 3-5x size reduction Cold storage: Disable cache (<code>block_cache_mb: 0</code>) to save memory</p>"},{"location":"crates/nori-sstable/performance/benchmarks/","title":"Benchmarks","text":"<p>Performance measurements for nori-sstable operations.</p>"},{"location":"crates/nori-sstable/performance/benchmarks/#test-environment","title":"Test Environment","text":"<p>Hardware: - CPU: Apple M1 Pro (10 cores) - RAM: 16GB - Storage: 1TB SSD</p> <p>Software: - Rust: 1.75 - OS: macOS 14</p> <p>Configuration: - Block size: 4KB - Compression: LZ4 - Cache: 64MB (unless noted)</p>"},{"location":"crates/nori-sstable/performance/benchmarks/#write-performance","title":"Write Performance","text":""},{"location":"crates/nori-sstable/performance/benchmarks/#sstable-building","title":"SSTable Building","text":"<pre><code>100,000 entries (120 bytes avg):\n  Total size: ~12MB uncompressed\n  Build time: 145ms\n  Throughput: 689K entries/sec\n\nWith LZ4 compression:\n  Compressed size: 4.8MB (2.5x ratio)\n  Build time: 178ms\n  Throughput: 562K entries/sec\n  Compression overhead: +33ms (+23%)\n\nWith Zstd compression:\n  Compressed size: 3.4MB (3.5x ratio)\n  Build time: 312ms\n  Throughput: 320K entries/sec\n  Compression overhead: +167ms (+115%)\n</code></pre>"},{"location":"crates/nori-sstable/performance/benchmarks/#read-performance","title":"Read Performance","text":""},{"location":"crates/nori-sstable/performance/benchmarks/#point-lookups","title":"Point Lookups","text":"<p>Cache hit (warm): <pre><code>Operation: reader.get(key) where key in cache\nLatency p50: 450ns\nLatency p95: 777\u00b5s\nLatency p99: 1.2ms\nThroughput: 2.2M ops/sec\n</code></pre></p> <p>Cache miss (cold, LZ4): <pre><code>Operation: reader.get(key) where key not cached\nLatency p50: 95\u00b5s\nLatency p95: 145\u00b5s\nLatency p99: 210\u00b5s\nThroughput: 10.5K ops/sec\n</code></pre></p> <p>Cache miss (cold, Zstd): <pre><code>Latency p50: 98\u00b5s\nLatency p95: 158\u00b5s\nLatency p99: 225\u00b5s\nThroughput: 10.2K ops/sec\n</code></pre></p>"},{"location":"crates/nori-sstable/performance/benchmarks/#bloom-filter","title":"Bloom Filter","text":"<pre><code>Operation: bloom.contains(key)\nLatency: 67ns avg\nThroughput: 14.9M checks/sec\n\nFalse positive check (key absent, bloom says present):\n  Full lookup: ~100\u00b5s (wasted)\n  FP rate: 0.9%\n  99.1% of absent keys saved from disk I/O\n</code></pre>"},{"location":"crates/nori-sstable/performance/benchmarks/#range-scans","title":"Range Scans","text":"<pre><code>Scan 1,000 consecutive entries:\n  Cache hot: 1.2ms (833K entries/sec)\n  Cache cold (LZ4): 15ms (66K entries/sec)\n  Cache cold (Zstd): 18ms (55K entries/sec)\n\nScan 10,000 entries:\n  Cache hot: 11ms (909K entries/sec)\n  Cache cold (LZ4): 142ms (70K entries/sec)\n</code></pre>"},{"location":"crates/nori-sstable/performance/benchmarks/#compression-performance","title":"Compression Performance","text":""},{"location":"crates/nori-sstable/performance/benchmarks/#lz4","title":"LZ4","text":"<pre><code>4KB block compression:\n  Time: 5.3\u00b5s\n  Throughput: 754 MB/s\n  Ratio: 2.5x (4096 \u2192 1638 bytes)\n\n4KB block decompression:\n  Time: 1.05\u00b5s\n  Throughput: 3.9 GB/s\n</code></pre>"},{"location":"crates/nori-sstable/performance/benchmarks/#zstd-level-3","title":"Zstd (Level 3)","text":"<pre><code>4KB block compression:\n  Time: 9.1\u00b5s\n  Throughput: 450 MB/s\n  Ratio: 3.5x (4096 \u2192 1170 bytes)\n\n4KB block decompression:\n  Time: 3.4\u00b5s\n  Throughput: 1.2 GB/s\n</code></pre>"},{"location":"crates/nori-sstable/performance/benchmarks/#cache-performance","title":"Cache Performance","text":""},{"location":"crates/nori-sstable/performance/benchmarks/#hit-rate-impact","title":"Hit Rate Impact","text":"<pre><code>1M reads, 80/20 distribution:\n\nNo cache:\n  Total time: 95s (all disk reads)\n\n64MB cache (64% coverage):\n  Cache hits: 800K (80%)\n  Cache misses: 200K (20%)\n  Total time: 19.7s\n  Speedup: 4.8x\n\n256MB cache (100% coverage):\n  Cache hits: 990K (99%)\n  Cache misses: 10K (1%)\n  Total time: 1.4s\n  Speedup: 67x\n</code></pre>"},{"location":"crates/nori-sstable/performance/benchmarks/#scalability","title":"Scalability","text":""},{"location":"crates/nori-sstable/performance/benchmarks/#sstable-size-impact","title":"SSTable Size Impact","text":"Size Blocks Index Bloom Open Time Get (p95) 1MB 256 8KB 1.2KB 1ms 850ns 10MB 2,560 80KB 12KB 2ms 900ns 100MB 25,600 800KB 120KB 12ms 950ns 1GB 256K 8MB 1.2MB 95ms 1.1\u00b5s <p>Key insight: Get latency barely increases with file size (bloom + cache effectiveness).</p>"},{"location":"crates/nori-sstable/performance/benchmarks/#real-world-workload","title":"Real-World Workload","text":""},{"location":"crates/nori-sstable/performance/benchmarks/#hot-key-pattern-8020","title":"Hot Key Pattern (80/20)","text":"<pre><code>Dataset: 1GB SSTable, 10M keys\nWorkload: 80% reads on 20% of keys\nCache: 256MB\n\nResults:\n  Cache hit rate: 92%\n  p50 latency: 520ns\n  p95 latency: 1.2\u00b5s\n  p99 latency: 120\u00b5s (cache misses)\n  Throughput: 1.9M reads/sec\n</code></pre>"},{"location":"crates/nori-sstable/performance/benchmarks/#summary","title":"Summary","text":"<p>Key takeaways:</p> <ul> <li>Writes: 500-700K entries/sec with compression</li> <li>Hot reads: &lt;1\u00b5s p95 with cache</li> <li>Cold reads: ~100\u00b5s p95 from SSD</li> <li>Bloom: 67ns checks, 99%+ absent key savings</li> <li>Compression: LZ4 adds &lt;10% overhead, Zstd +100%</li> <li>Cache: 80% hit rate \u2192 5x speedup, 99% \u2192 60x speedup</li> </ul>"},{"location":"crates/nori-sstable/performance/tuning/","title":"Tuning Guide","text":"<p>Optimize nori-sstable for your specific workload.</p>"},{"location":"crates/nori-sstable/performance/tuning/#hot-workloads-high-read-rate","title":"Hot Workloads (High Read Rate)","text":"<p>Goal: Minimize p95/p99 read latency</p> <p>Configuration: <pre><code>SSTableConfig {\n    compression: Compression::Lz4,  // Fast decompression\n    block_cache_mb: 512,             // Large cache\n    bloom_bits_per_key: 12,          // Lower FP rate\n    ..Default::default()\n}\n</code></pre></p> <p>Rationale: - LZ4 decompresses in &lt;1\u00b5s vs Zstd 3\u00b5s - 512MB cache = high hit rate - 12 bits/key = 0.3% FP vs 0.9%</p> <p>Expected: - p95: &lt;1\u00b5s (cache hits) - p99: ~100\u00b5s (cache misses) - Hit rate: 90%+</p>"},{"location":"crates/nori-sstable/performance/tuning/#cold-storage-infrequent-access","title":"Cold Storage (Infrequent Access)","text":"<p>Goal: Maximize compression ratio</p> <p>Configuration: <pre><code>SSTableConfig {\n    compression: Compression::Zstd,  // Best ratio\n    block_cache_mb: 0,               // Disable cache\n    bloom_bits_per_key: 10,          // Standard\n    block_size: 8192,                // Larger blocks\n    ..Default::default()\n}\n</code></pre></p> <p>Rationale: - Zstd: 3-5x compression - No cache: Save RAM - 8KB blocks: Better compression</p> <p>Savings: - 1TB \u2192 250GB (75% savings)</p>"},{"location":"crates/nori-sstable/performance/tuning/#write-heavy-workloads","title":"Write-Heavy Workloads","text":"<p>Goal: Maximize write throughput</p> <p>Configuration: <pre><code>SSTableConfig {\n    compression: Compression::None,  // No compression overhead\n    block_cache_mb: 64,              // Moderate cache\n    bloom_bits_per_key: 10,\n    ..Default::default()\n}\n</code></pre></p> <p>Or: <pre><code>SSTableConfig {\n    compression: Compression::Lz4,  // Minimal overhead\n    ..Default::default()\n}\n</code></pre></p> <p>Expected: - No compression: 700K entries/sec - LZ4: 560K entries/sec (-20%)</p>"},{"location":"crates/nori-sstable/performance/tuning/#memory-constrained","title":"Memory-Constrained","text":"<p>Goal: Minimize memory usage</p> <p>Configuration: <pre><code>SSTableConfig {\n    compression: Compression::Zstd,\n    block_cache_mb: 16,             // Small cache\n    bloom_bits_per_key: 8,          // Smaller bloom\n    ..Default::default()\n}\n</code></pre></p> <p>Memory breakdown: <pre><code>100K entry SSTable:\n  Bloom (8 bits/key): 100KB\n  Index: ~200KB\n  Cache (16MB): 16MB\n  Total: ~16.3MB\n</code></pre></p>"},{"location":"crates/nori-sstable/performance/tuning/#range-scan-heavy","title":"Range-Scan Heavy","text":"<p>Goal: Optimize sequential reads</p> <p>Configuration: <pre><code>SSTableConfig {\n    block_size: 16384,              // Larger blocks\n    compression: Compression::Lz4,\n    block_cache_mb: 128,\n    ..Default::default()\n}\n</code></pre></p> <p>Rationale: - Larger blocks = fewer block boundaries - Better sequential throughput - LZ4: Fast decompression for scans</p>"},{"location":"crates/nori-sstable/performance/tuning/#monitoring-adjustment","title":"Monitoring &amp; Adjustment","text":""},{"location":"crates/nori-sstable/performance/tuning/#key-metrics","title":"Key Metrics","text":"<pre><code>// Cache hit rate\nlet hit_rate = cache_hits / total_reads;\nif hit_rate &lt; 0.7 {\n    // Increase block_cache_mb\n}\n\n// False positive rate\nlet fp_rate = false_positives / bloom_checks;\nif fp_rate &gt; 0.02 {\n    // Increase bloom_bits_per_key\n}\n\n// Compression ratio\nlet ratio = uncompressed_size / compressed_size;\nif ratio &lt; 1.5 {\n    // Consider Compression::None\n}\n</code></pre>"},{"location":"crates/nori-sstable/performance/tuning/#quick-decision-table","title":"Quick Decision Table","text":"Workload Compression Cache Bloom Block Size Hot reads LZ4 256-512MB 12 bits 4KB Cold storage Zstd 0MB 10 bits 8KB Write-heavy None/LZ4 64MB 10 bits 4KB Memory-limited Zstd 16MB 8 bits 4KB Range scans LZ4 128MB 10 bits 16KB Development None 64MB 10 bits 4KB"},{"location":"crates/nori-sstable/recipes/","title":"Recipes","text":"<p>Common patterns and practical examples for using nori-sstable.</p>"},{"location":"crates/nori-sstable/recipes/#overview","title":"Overview","text":"<p>This section provides practical, copy-paste-ready examples for common SSTable use cases.</p>"},{"location":"crates/nori-sstable/recipes/#recipes_1","title":"Recipes","text":""},{"location":"crates/nori-sstable/recipes/#basic-usage","title":"Basic Usage","text":"<p>Building and reading your first SSTable with complete error handling.</p>"},{"location":"crates/nori-sstable/recipes/#hot-workloads","title":"Hot Workloads","text":"<p>Optimizing for high-throughput, cache-friendly workloads.</p>"},{"location":"crates/nori-sstable/recipes/#cold-storage","title":"Cold Storage","text":"<p>Configuring SSTables for archival data with maximum compression.</p>"},{"location":"crates/nori-sstable/recipes/#iterator-patterns","title":"Iterator Patterns","text":"<p>Efficient range scans, filtering, and merge patterns.</p>"},{"location":"crates/nori-sstable/recipes/#batch-building","title":"Batch Building","text":"<p>Building multiple SSTables efficiently from large datasets.</p>"},{"location":"crates/nori-sstable/recipes/#integration-with-lsm","title":"Integration with LSM","text":"<p>Using nori-sstable as part of an LSM-tree storage engine.</p>"},{"location":"crates/nori-sstable/recipes/#quick-examples","title":"Quick Examples","text":""},{"location":"crates/nori-sstable/recipes/#minimal-example","title":"Minimal Example","text":"<pre><code>let mut builder = SSTableBuilder::new(config).await?;\nbuilder.add(&amp;Entry::put(\"key\", \"value\")).await?;\nbuilder.finish().await?;\n</code></pre>"},{"location":"crates/nori-sstable/recipes/#with-compression","title":"With Compression","text":"<pre><code>let config = SSTableConfig {\n    compression: Compression::Lz4,\n    ..Default::default()\n};\n</code></pre>"},{"location":"crates/nori-sstable/recipes/#with-custom-cache","title":"With Custom Cache","text":"<pre><code>let reader = SSTableReader::open_with_config(\n    path,\n    Arc::new(NoopMeter),\n    256  // 256MB cache\n).await?;\n</code></pre>"},{"location":"crates/nori-sstable/recipes/basic-usage/","title":"Basic Usage","text":"<p>Complete examples for building and reading SSTables.</p>"},{"location":"crates/nori-sstable/recipes/basic-usage/#minimal-example","title":"Minimal Example","text":"<pre><code>use nori_sstable::{Entry, SSTableBuilder, SSTableReader, SSTableConfig};\nuse std::path::PathBuf;\nuse std::sync::Arc;\n\n#[tokio::main]\nasync fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {\n    // Build\n    let config = SSTableConfig {\n        path: PathBuf::from(\"data.sst\"),\n        estimated_entries: 100,\n        ..Default::default()\n    };\n\n    let mut builder = SSTableBuilder::new(config).await?;\n    builder.add(&amp;Entry::put(\"alice\", \"engineer\")).await?;\n    builder.add(&amp;Entry::put(\"bob\", \"designer\")).await?;\n    builder.add(&amp;Entry::put(\"carol\", \"manager\")).await?;\n    builder.finish().await?;\n\n    // Read\n    let reader = Arc::new(SSTableReader::open(PathBuf::from(\"data.sst\")).await?);\n    if let Some(entry) = reader.get(b\"bob\").await? {\n        println!(\"bob is a {}\", String::from_utf8_lossy(&amp;entry.value));\n    }\n\n    Ok(())\n}\n</code></pre>"},{"location":"crates/nori-sstable/recipes/basic-usage/#building-with-sorted-data","title":"Building with Sorted Data","text":"<pre><code>use std::collections::BTreeMap;\n\nlet mut data = BTreeMap::new();\ndata.insert(b\"user:1\".to_vec(), b\"alice\".to_vec());\ndata.insert(b\"user:2\".to_vec(), b\"bob\".to_vec());\ndata.insert(b\"user:3\".to_vec(), b\"carol\".to_vec());\n\nlet mut builder = SSTableBuilder::new(config).await?;\nfor (key, value) in data {\n    builder.add(&amp;Entry::put(key, value)).await?;\n}\nlet metadata = builder.finish().await?;\n\nprintln!(\"Built SSTable:\");\nprintln!(\"  Entries: {}\", metadata.entry_count);\nprintln!(\"  Size: {} bytes\", metadata.file_size);\nprintln!(\"  Blocks: {}\", metadata.block_count);\n</code></pre>"},{"location":"crates/nori-sstable/recipes/basic-usage/#reading-with-error-handling","title":"Reading with Error Handling","text":"<pre><code>match reader.get(b\"nonexistent\").await {\n    Ok(Some(entry)) =&gt; {\n        if entry.tombstone {\n            println!(\"Key was deleted\");\n        } else {\n            println!(\"Found: {:?}\", entry.value);\n        }\n    }\n    Ok(None) =&gt; println!(\"Key not found\"),\n    Err(e) =&gt; eprintln!(\"Error: {}\", e),\n}\n</code></pre>"},{"location":"crates/nori-sstable/recipes/basic-usage/#range-scanning","title":"Range Scanning","text":"<pre><code>use futures::TryStreamExt;\n\nlet mut iter = reader.iter_range(\n    Bytes::from(\"user:1\"),\n    Bytes::from(\"user:9\")\n);\n\nwhile let Some(entry) = iter.try_next().await? {\n    println!(\"{:?} = {:?}\",\n        String::from_utf8_lossy(&amp;entry.key),\n        String::from_utf8_lossy(&amp;entry.value)\n    );\n}\n</code></pre>"},{"location":"crates/nori-sstable/recipes/basic-usage/#with-compression","title":"With Compression","text":"<pre><code>use nori_sstable::Compression;\n\nlet config = SSTableConfig {\n    path: PathBuf::from(\"compressed.sst\"),\n    estimated_entries: 1000,\n    compression: Compression::Lz4,\n    ..Default::default()\n};\n\nlet mut builder = SSTableBuilder::new(config).await?;\n// Add entries...\nbuilder.finish().await?;\n\n// Reader automatically detects compression\nlet reader = Arc::new(SSTableReader::open(\"compressed.sst\".into()).await?);\n</code></pre>"},{"location":"crates/nori-sstable/recipes/basic-usage/#custom-cache-size","title":"Custom Cache Size","text":"<pre><code>use nori_observe::NoopMeter;\n\n// 256MB cache for hot workloads\nlet reader = SSTableReader::open_with_config(\n    PathBuf::from(\"data.sst\"),\n    Arc::new(NoopMeter),\n    256  // MB\n).await?;\n</code></pre>"},{"location":"crates/nori-sstable/recipes/basic-usage/#batch-building","title":"Batch Building","text":"<pre><code>let entries = vec![\n    Entry::put(\"key1\", \"value1\"),\n    Entry::put(\"key2\", \"value2\"),\n    Entry::put(\"key3\", \"value3\"),\n];\n\nlet mut builder = SSTableBuilder::new(config).await?;\nfor entry in entries {\n    builder.add(&amp;entry).await?;\n}\nbuilder.finish().await?;\n</code></pre>"},{"location":"crates/nori-sstable/recipes/basic-usage/#concurrent-reads","title":"Concurrent Reads","text":"<pre><code>let reader = Arc::new(SSTableReader::open(\"data.sst\".into()).await?);\n\nlet mut handles = vec![];\nfor i in 0..10 {\n    let r = reader.clone();\n    let handle = tokio::spawn(async move {\n        let key = format!(\"key{}\", i);\n        r.get(key.as_bytes()).await\n    });\n    handles.push(handle);\n}\n\nfor handle in handles {\n    let result = handle.await??;\n    println!(\"Result: {:?}\", result);\n}\n</code></pre>"},{"location":"crates/nori-sstable/recipes/hot-workloads/","title":"Hot Workloads","text":"<p>Optimizing for high-throughput, cache-friendly read workloads.</p>"},{"location":"crates/nori-sstable/recipes/hot-workloads/#scenario","title":"Scenario","text":"<p>Workload characteristics: - 1M+ reads/sec - 80/20 distribution (20% of keys = 80% of reads) - Low latency required (p95 &lt; 1ms, p99 &lt; 5ms) - Dataset: 10GB across multiple SSTables</p>"},{"location":"crates/nori-sstable/recipes/hot-workloads/#optimal-configuration","title":"Optimal Configuration","text":"<pre><code>use nori_sstable::{SSTableConfig, Compression};\n\nlet config = SSTableConfig {\n    path: PathBuf::from(\"hot_data.sst\"),\n    estimated_entries: 1_000_000,\n\n    // Fast decompression\n    compression: Compression::Lz4,\n\n    // Large cache for hot keys\n    block_cache_mb: 512,\n\n    // Lower false positive rate\n    bloom_bits_per_key: 12,\n\n    ..Default::default()\n};\n</code></pre>"},{"location":"crates/nori-sstable/recipes/hot-workloads/#cache-sizing","title":"Cache Sizing","text":"<p>Calculate working set: <pre><code>Hot keys: 20% of 10M = 2M keys\nEntries per block: ~50\nHot blocks: 2M / 50 = 40K blocks\nWorking set: 40K * 4KB = 160MB\n</code></pre></p> <p>Recommended cache: <pre><code>// 1.5-2x working set\nblock_cache_mb: 256  // Good\nblock_cache_mb: 512  // Better (accounts for variance)\n</code></pre></p>"},{"location":"crates/nori-sstable/recipes/hot-workloads/#reader-setup","title":"Reader Setup","text":"<pre><code>use nori_observe::NoopMeter;\nuse std::sync::Arc;\n\n// Share reader across threads\nlet reader = Arc::new(\n    SSTableReader::open_with_config(\n        PathBuf::from(\"hot_data.sst\"),\n        Arc::new(NoopMeter),\n        512  // 512MB cache\n    ).await?\n);\n\n// Spawn worker threads\nfor i in 0..num_cpus::get() {\n    let r = reader.clone();\n    tokio::spawn(async move {\n        handle_requests(r).await\n    });\n}\n</code></pre>"},{"location":"crates/nori-sstable/recipes/hot-workloads/#concurrent-access-pattern","title":"Concurrent Access Pattern","text":"<pre><code>async fn handle_requests(reader: Arc&lt;SSTableReader&gt;) -&gt; Result&lt;()&gt; {\n    loop {\n        let key = receive_request().await?;\n\n        // Fast path: bloom + cache\n        if let Some(entry) = reader.get(&amp;key).await? {\n            send_response(entry.value).await?;\n        } else {\n            send_not_found().await?;\n        }\n    }\n}\n</code></pre> <p>Performance: <pre><code>Cache hits (80%): &lt;1\u00b5s p95\nCache misses (20%): ~100\u00b5s p95\nOverall p95: ~20\u00b5s\n</code></pre></p>"},{"location":"crates/nori-sstable/recipes/hot-workloads/#pre-warming-cache","title":"Pre-warming Cache","text":"<pre><code>// Load hot keys into cache at startup\nasync fn prewarm_cache(\n    reader: Arc&lt;SSTableReader&gt;,\n    hot_keys: Vec&lt;Bytes&gt;\n) -&gt; Result&lt;()&gt; {\n    println!(\"Pre-warming cache with {} keys...\", hot_keys.len());\n\n    for key in hot_keys {\n        reader.get(&amp;key).await?;\n    }\n\n    println!(\"Cache warmed!\");\n    Ok(())\n}\n</code></pre>"},{"location":"crates/nori-sstable/recipes/hot-workloads/#monitoring","title":"Monitoring","text":"<pre><code>struct CacheStats {\n    hits: AtomicU64,\n    misses: AtomicU64,\n}\n\nlet stats = Arc::new(CacheStats::default());\n\n// Report periodically\ntokio::spawn({\n    let s = stats.clone();\n    async move {\n        loop {\n            tokio::time::sleep(Duration::from_secs(10)).await;\n            let hits = s.hits.load(Ordering::Relaxed);\n            let misses = s.misses.load(Ordering::Relaxed);\n            let rate = hits as f64 / (hits + misses) as f64;\n            println!(\"Cache hit rate: {:.1}%\", rate * 100.0);\n        }\n    }\n});\n</code></pre>"},{"location":"crates/nori-sstable/recipes/hot-workloads/#expected-performance","title":"Expected Performance","text":"<pre><code>Configuration:\n  - 512MB cache\n  - LZ4 compression\n  - 12 bits/key bloom\n\nResults:\n  - Throughput: 1.5M reads/sec\n  - p50 latency: 450ns\n  - p95 latency: 950ns\n  - p99 latency: 85\u00b5s\n  - Cache hit rate: 92%\n</code></pre>"},{"location":"crates/nori-wal/","title":"nori-wal","text":"<p>Production-ready Write-Ahead Log for Rust with automatic recovery, rotation, and configurable durability.</p> <p>Quickstart API Reference</p>"},{"location":"crates/nori-wal/#what-is-nori-wal","title":"What is nori-wal?","text":"<p>nori-wal is a production-ready write-ahead log (WAL) implementation in Rust. It provides the foundation for durable, crash-safe storage systems.</p>"},{"location":"crates/nori-wal/#key-features","title":"Key Features","text":"<ul> <li>Append-only writes with sequential I/O (~110K writes/sec)</li> <li>Automatic crash recovery with prefix-valid truncation</li> <li>CRC32C checksumming for corruption detection</li> <li>Configurable fsync policies (every write, batch, async)</li> <li>Automatic rotation with size/time triggers</li> <li>LZ4/Zstd compression support</li> <li>Zero-copy reads with mmap support</li> </ul>"},{"location":"crates/nori-wal/#quick-example","title":"Quick Example","text":"<pre><code>use nori_wal::{Wal, WalConfig, Record};\n\n#[tokio::main]\nasync fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {\n    // Open WAL with automatic recovery\n    let (wal, recovery_info) = Wal::open(WalConfig::default()).await?;\n\n    // Append a record\n    let record = Record::put(b\"user:42\", b\"alice@example.com\");\n    let lsn = wal.append(&amp;record).await?;\n\n    // Iterate over all records\n    let mut iter = wal.iter();\n    while let Some(entry) = iter.try_next().await? {\n        println!(\"LSN {}: {:?}\", entry.lsn, entry.record);\n    }\n\n    Ok(())\n}\n</code></pre>"},{"location":"crates/nori-wal/#documentation","title":"Documentation","text":""},{"location":"crates/nori-wal/#getting-started","title":"Getting Started","text":"<p>Quick tutorials to get up and running with nori-wal.</p> <p>Getting Started \u2192</p>"},{"location":"crates/nori-wal/#core-concepts","title":"Core Concepts","text":"<p>Learn the fundamentals of WALs and how nori-wal implements them.</p> <p>Core Concepts \u2192</p>"},{"location":"crates/nori-wal/#api-reference","title":"API Reference","text":"<p>Complete API documentation for all public types and methods.</p> <p>API Reference \u2192</p>"},{"location":"crates/nori-wal/#how-it-works","title":"How It Works","text":"<p>Deep dives into internals, record format, and recovery.</p> <p>How It Works \u2192</p>"},{"location":"crates/nori-wal/#performance","title":"Performance","text":"<p>Benchmarks and optimization guides.</p> <p>Performance \u2192</p>"},{"location":"crates/nori-wal/#recipes","title":"Recipes","text":"<p>Common patterns and use cases.</p> <p>Recipes \u2192</p>"},{"location":"crates/nori-wal/#when-to-use-nori-wal","title":"When to Use nori-wal","text":""},{"location":"crates/nori-wal/#great-fit","title":"Great Fit","text":"<ul> <li>Building storage engines (LSM, B-trees)</li> <li>Event sourcing systems</li> <li>Message queues and streaming</li> <li>Any system requiring crash consistency</li> <li>Replication logs (Raft, Paxos)</li> </ul>"},{"location":"crates/nori-wal/#not-the-right-tool","title":"Not the Right Tool","text":"<ul> <li>In-memory only systems (no durability needed)</li> <li>Read-heavy workloads (use indexes)</li> <li>Random writes (WAL is append-only)</li> </ul>"},{"location":"crates/nori-wal/#project-status","title":"Project Status","text":"<p>Production-ready - Used in nori-lsm and norikv-server.</p> <ul> <li>108+ tests passing</li> <li>Property testing with deterministic chaos</li> <li>Crash recovery validated</li> <li>Performance benchmarked</li> </ul>"},{"location":"crates/nori-wal/#next-steps","title":"Next Steps","text":"<p>New to WALs? Start with What is a Write-Ahead Log? to understand the fundamentals.</p> <p>Ready to build? Jump into the Quickstart to get hands-on.</p> <p>Want details? Check out How It Works for implementation details.</p>"},{"location":"crates/nori-wal/api-reference/","title":"API Reference","text":"<p>Complete API documentation for all public types and methods in nori-wal.</p>"},{"location":"crates/nori-wal/api-reference/#quick-reference","title":"Quick Reference","text":""},{"location":"crates/nori-wal/api-reference/#core-types","title":"Core Types","text":"Type Purpose Page <code>Wal</code> Main WAL interface API \u2192 <code>Record</code> Key-value record with metadata API \u2192 <code>WalConfig</code> Configuration builder API \u2192 <code>Position</code> Location in the log API \u2192 <code>RecoveryInfo</code> Recovery statistics API \u2192"},{"location":"crates/nori-wal/api-reference/#enums","title":"Enums","text":"Type Purpose Page <code>FsyncPolicy</code> Durability policy API \u2192 <code>Compression</code> Compression algorithm API \u2192"},{"location":"crates/nori-wal/api-reference/#error-types","title":"Error Types","text":"Type Purpose Page <code>SegmentError</code> Segment-level errors API \u2192 <code>RecordError</code> Record-level errors API \u2192"},{"location":"crates/nori-wal/api-reference/#import-paths","title":"Import Paths","text":"<pre><code>// Main types\nuse nori_wal::{Wal, WalConfig, Record, Position, RecoveryInfo};\n\n// Enums\nuse nori_wal::{FsyncPolicy, Compression};\n\n// Errors\nuse nori_wal::{SegmentError, RecordError};\n</code></pre>"},{"location":"crates/nori-wal/api-reference/#usage-patterns","title":"Usage Patterns","text":""},{"location":"crates/nori-wal/api-reference/#basic-write","title":"Basic Write","text":"<pre><code>use nori_wal::{Wal, WalConfig, Record};\n\n#[tokio::main]\nasync fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {\n    let config = WalConfig::default();\n    let (wal, _) = Wal::open(config).await?;\n\n    let record = Record::put(b\"key\", b\"value\");\n    let position = wal.append(&amp;record).await?;\n    wal.sync().await?;\n\n    Ok(())\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/#configuration","title":"Configuration","text":"<pre><code>use nori_wal::{WalConfig, FsyncPolicy};\nuse std::time::Duration;\nuse std::path::PathBuf;\n\nlet config = WalConfig {\n    dir: PathBuf::from(\"/var/lib/myapp/wal\"),\n    max_segment_size: 256 * 1024 * 1024,  // 256 MB\n    fsync_policy: FsyncPolicy::Batch(Duration::from_millis(10)),\n    preallocate: true,\n    node_id: 1,\n};\n\nlet (wal, recovery_info) = Wal::open(config).await?;\n</code></pre>"},{"location":"crates/nori-wal/api-reference/#reading","title":"Reading","text":"<pre><code>use nori_wal::Position;\n\nlet mut reader = wal.read_from(Position { segment_id: 0, offset: 0 }).await?;\n\nwhile let Some((record, position)) = reader.next_record().await? {\n    println!(\"Record at {:?}: key={:?}\", position, record.key);\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/#error-handling","title":"Error Handling","text":"<pre><code>use nori_wal::{Wal, SegmentError};\n\nmatch Wal::open(config).await {\n    Ok((wal, info)) =&gt; {\n        if info.corruption_detected {\n            log::warn!(\"Corruption detected: {} bytes truncated\",\n                       info.bytes_truncated);\n        }\n    }\n    Err(SegmentError::Io(e)) =&gt; {\n        eprintln!(\"I/O error: {}\", e);\n    }\n    Err(SegmentError::InvalidConfig(msg)) =&gt; {\n        eprintln!(\"Invalid config: {}\", msg);\n    }\n    Err(e) =&gt; {\n        eprintln!(\"Other error: {}\", e);\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/#api-conventions","title":"API Conventions","text":""},{"location":"crates/nori-wal/api-reference/#async-methods","title":"Async Methods","text":"<p>All I/O methods are async and require a Tokio runtime:</p> <pre><code>// Correct: Use with async runtime\n#[tokio::main]\nasync fn main() {\n    wal.append(&amp;record).await?;\n}\n\n// Wrong: Can't call async methods in sync context\nfn main() {\n    wal.append(&amp;record).await?;  // Compile error!\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/#error-handling_1","title":"Error Handling","text":"<p>All fallible operations return <code>Result&lt;T, E&gt;</code>:</p> <pre><code>// Always handle errors\nlet position = wal.append(&amp;record).await?;  // Propagate with ?\n\n// Or match explicitly\nmatch wal.append(&amp;record).await {\n    Ok(pos) =&gt; println!(\"Wrote at {:?}\", pos),\n    Err(e) =&gt; eprintln!(\"Failed: {}\", e),\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/#thread-safety","title":"Thread Safety","text":"<p>All types are <code>Send + Sync</code> and can be shared:</p> <pre><code>let wal = Arc::new(wal);\n\nfor _ in 0..4 {\n    let wal = wal.clone();\n    tokio::spawn(async move {\n        wal.append(&amp;record).await?;\n    });\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/#type-categories","title":"Type Categories","text":""},{"location":"crates/nori-wal/api-reference/#primary-api","title":"Primary API","text":"<p>Start here for most use cases:</p> <ul> <li><code>Wal</code> - Open, append, sync, read</li> <li><code>Record</code> - Create PUT/DELETE records</li> <li><code>WalConfig</code> - Configure behavior</li> </ul>"},{"location":"crates/nori-wal/api-reference/#advanced-api","title":"Advanced API","text":"<p>For fine-grained control:</p> <ul> <li><code>Position</code> - Seek to specific locations</li> <li><code>SegmentReader</code> - Manual reading</li> <li><code>FsyncPolicy</code> - Custom durability</li> </ul>"},{"location":"crates/nori-wal/api-reference/#observability","title":"Observability","text":"<p>For monitoring and debugging:</p> <ul> <li><code>RecoveryInfo</code> - Recovery statistics</li> <li><code>Meter</code> trait - Custom metrics (advanced)</li> </ul>"},{"location":"crates/nori-wal/api-reference/#examples-by-use-case","title":"Examples by Use Case","text":""},{"location":"crates/nori-wal/api-reference/#event-sourcing","title":"Event Sourcing","text":"<pre><code>// Append events\nlet event = serde_json::to_vec(&amp;MyEvent { id: 1, data: \"...\" })?;\nlet record = Record::put(b\"aggregate:1\", event);\nwal.append(&amp;record).await?;\n\n// Replay events\nlet mut reader = wal.read_from(Position::start()).await?;\nwhile let Some((record, _)) = reader.next_record().await? {\n    let event: MyEvent = serde_json::from_slice(&amp;record.value)?;\n    apply_event(event);\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/#key-value-store","title":"Key-Value Store","text":"<pre><code>// PUT\nlet record = Record::put(b\"user:123\", b\"alice@example.com\");\nwal.append(&amp;record).await?;\n\n// DELETE\nlet record = Record::delete(b\"user:123\");\nwal.append(&amp;record).await?;\n\n// Rebuild state from log\nlet mut kv = HashMap::new();\nlet mut reader = wal.read_from(Position::start()).await?;\nwhile let Some((record, _)) = reader.next_record().await? {\n    if record.tombstone {\n        kv.remove(&amp;record.key);\n    } else {\n        kv.insert(record.key, record.value);\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/#message-queue","title":"Message Queue","text":"<pre><code>// Publish\nlet record = Record::put(b\"topic:events\", b\"message payload\");\nlet position = wal.append(&amp;record).await?;\n\n// Consumer tracks position\nlet mut consumer_position = load_consumer_position()?;\nlet mut reader = wal.read_from(consumer_position).await?;\n\nwhile let Some((record, position)) = reader.next_record().await? {\n    process_message(&amp;record);\n    consumer_position = position;\n    save_consumer_position(position)?;\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/#performance-tips","title":"Performance Tips","text":""},{"location":"crates/nori-wal/api-reference/#batching","title":"Batching","text":"<pre><code>// Batch multiple records before syncing\nfor record in records {\n    wal.append(&amp;record).await?;\n}\nwal.sync().await?;  // Single fsync for all\n</code></pre>"},{"location":"crates/nori-wal/api-reference/#compression","title":"Compression","text":"<pre><code>// For large values, use compression\nlet record = Record::put(b\"key\", large_value)\n    .with_compression(Compression::Lz4);\nwal.append(&amp;record).await?;\n</code></pre>"},{"location":"crates/nori-wal/api-reference/#fsync-policy","title":"Fsync Policy","text":"<pre><code>// Choose policy based on durability needs\nWalConfig {\n    fsync_policy: FsyncPolicy::Batch(Duration::from_millis(5)),  // Balanced\n    // or FsyncPolicy::Always  // Maximum durability\n    // or FsyncPolicy::Os      // Maximum performance\n    ..Default::default()\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/#detailed-api-pages","title":"Detailed API Pages","text":"<p>Click through to detailed documentation for each type:</p> <ul> <li>Wal - Main WAL API with all methods</li> <li>Record - Record creation, encoding, and compression</li> <li>Configuration - WalConfig and FsyncPolicy options</li> <li>Errors &amp; Types - Error types, Position, and RecoveryInfo</li> </ul>"},{"location":"crates/nori-wal/api-reference/config/","title":"Configuration API","text":"<p>Complete API reference for configuring nori-wal behavior.</p>"},{"location":"crates/nori-wal/api-reference/config/#table-of-contents","title":"Table of contents","text":""},{"location":"crates/nori-wal/api-reference/config/#overview","title":"Overview","text":"<p>nori-wal provides two main configuration types:</p> <ul> <li><code>WalConfig</code> - High-level WAL configuration</li> <li><code>FsyncPolicy</code> - Durability vs performance trade-offs</li> </ul> <p>These configurations allow you to tune nori-wal for your specific use case, balancing durability, performance, and resource usage.</p>"},{"location":"crates/nori-wal/api-reference/config/#walconfig","title":"WalConfig","text":"<p>Configuration for the Write-Ahead Log.</p>"},{"location":"crates/nori-wal/api-reference/config/#type-definition","title":"Type Definition","text":"<p>View source in <code>crates/nori-wal/src/wal.rs</code></p>"},{"location":"crates/nori-wal/api-reference/config/#fields","title":"Fields","text":"Field Type Default Description <code>dir</code> <code>PathBuf</code> <code>\"wal\"</code> Directory to store WAL segments <code>max_segment_size</code> <code>u64</code> <code>128 * 1024 * 1024</code> (128 MiB) Maximum size of a segment before rotation <code>fsync_policy</code> <code>FsyncPolicy</code> <code>Batch(5ms)</code> Fsync policy for durability <code>preallocate</code> <code>bool</code> <code>true</code> Enable file pre-allocation for new segments <code>node_id</code> <code>u32</code> <code>0</code> Node ID for observability events"},{"location":"crates/nori-wal/api-reference/config/#walconfigdefault","title":"WalConfig::default","text":"<p>Creates a default configuration with sensible defaults for most use cases.</p> <pre><code>impl Default for WalConfig\n</code></pre> <p>Returns: A <code>WalConfig</code> with: - Directory: <code>\"wal\"</code> - Segment size: 128 MiB - Fsync policy: Batch with 5ms window - Pre-allocation: enabled - Node ID: 0</p> <p>Examples:</p> <pre><code>use nori_wal::WalConfig;\n\n// Use default configuration\nlet config = WalConfig::default();\n\nassert_eq!(config.dir, PathBuf::from(\"wal\"));\nassert_eq!(config.max_segment_size, 128 * 1024 * 1024);\nassert_eq!(config.preallocate, true);\n</code></pre>"},{"location":"crates/nori-wal/api-reference/config/#configuration-validation","title":"Configuration Validation","text":"<p><code>WalConfig</code> automatically validates configuration when opening a WAL.</p> <p>Validation Rules:</p> <ol> <li><code>max_segment_size</code> must be &gt; 0</li> <li> <p>Error: <code>\"max_segment_size must be greater than 0\"</code></p> </li> <li> <p><code>max_segment_size</code> should be \u2265 1 MiB</p> </li> <li> <p>Error: <code>\"max_segment_size should be at least 1MB for reasonable performance\"</code></p> </li> <li> <p>Batch fsync window must be &lt; 1 second</p> </li> <li> <p>Error: <code>\"fsync batch window should be less than 1 second to avoid excessive data loss risk\"</code></p> </li> <li> <p>Batch fsync window cannot be zero</p> </li> <li>Error: <code>\"fsync batch window cannot be zero - use FsyncPolicy::Always instead\"</code></li> </ol> <p>Examples:</p> <pre><code>use nori_wal::{Wal, WalConfig, FsyncPolicy};\nuse std::time::Duration;\n\n// Invalid: zero segment size\nlet config = WalConfig {\n    max_segment_size: 0,\n    ..Default::default()\n};\nassert!(Wal::open(config).await.is_err());\n\n// Invalid: segment too small\nlet config = WalConfig {\n    max_segment_size: 512, // Less than 1MB\n    ..Default::default()\n};\nassert!(Wal::open(config).await.is_err());\n\n// Invalid: batch window too large\nlet config = WalConfig {\n    fsync_policy: FsyncPolicy::Batch(Duration::from_secs(2)),\n    ..Default::default()\n};\nassert!(Wal::open(config).await.is_err());\n\n// Invalid: zero batch window\nlet config = WalConfig {\n    fsync_policy: FsyncPolicy::Batch(Duration::ZERO),\n    ..Default::default()\n};\nassert!(Wal::open(config).await.is_err());\n\n// Valid configurations\nlet config = WalConfig {\n    max_segment_size: 64 * 1024 * 1024, // 64 MiB\n    fsync_policy: FsyncPolicy::Batch(Duration::from_millis(10)),\n    ..Default::default()\n};\nlet (wal, _) = Wal::open(config).await?;\n</code></pre>"},{"location":"crates/nori-wal/api-reference/config/#field-details","title":"Field Details","text":""},{"location":"crates/nori-wal/api-reference/config/#dir-pathbuf","title":"<code>dir: PathBuf</code>","text":"<p>Directory where WAL segment files are stored.</p> <p>Default: <code>\"wal\"</code></p> <p>Behavior: - Created automatically if it doesn't exist (via <code>tokio::fs::create_dir_all</code>) - Segments are named <code>000000.wal</code>, <code>000001.wal</code>, etc. - Must be writable by the process</p> <p>Examples:</p> <pre><code>use std::path::PathBuf;\n\n// Use default directory\nlet config = WalConfig::default();\nassert_eq!(config.dir, PathBuf::from(\"wal\"));\n\n// Custom directory\nlet config = WalConfig {\n    dir: PathBuf::from(\"/var/lib/myapp/wal\"),\n    ..Default::default()\n};\n\n// Relative path\nlet config = WalConfig {\n    dir: PathBuf::from(\"data/wal\"),\n    ..Default::default()\n};\n\n// Temporary directory for testing\nlet temp_dir = tempfile::TempDir::new()?;\nlet config = WalConfig {\n    dir: temp_dir.path().to_path_buf(),\n    ..Default::default()\n};\n</code></pre>"},{"location":"crates/nori-wal/api-reference/config/#max_segment_size-u64","title":"<code>max_segment_size: u64</code>","text":"<p>Maximum size (in bytes) of a single segment file before rotation.</p> <p>Default: <code>134,217,728</code> (128 MiB)</p> <p>Valid range: <code>\u2265 1,048,576</code> (1 MiB)</p> <p>Behavior: - When a segment reaches this size, a new segment is created - Smaller values \u2192 more segment files \u2192 more overhead - Larger values \u2192 fewer rotations \u2192 larger recovery time</p> <p>Choosing a Value:</p> Segment Size Pros Cons Best For 16-32 MiB Fast recovery, easier GC More files, more overhead Low-latency apps 64-128 MiB Balanced Default choice Most applications 256-512 MiB Fewer files Slower recovery, more memory High-throughput apps 1 GiB+ Minimal overhead Very slow recovery Archival/batch systems <p>Examples:</p> <pre><code>// Small segments for fast recovery\nlet config = WalConfig {\n    max_segment_size: 16 * 1024 * 1024, // 16 MiB\n    ..Default::default()\n};\n\n// Default (balanced)\nlet config = WalConfig {\n    max_segment_size: 128 * 1024 * 1024, // 128 MiB\n    ..Default::default()\n};\n\n// Large segments for high throughput\nlet config = WalConfig {\n    max_segment_size: 512 * 1024 * 1024, // 512 MiB\n    ..Default::default()\n};\n</code></pre> <p>Performance Impact:</p> <pre><code>// Recovery time increases with segment size\n// For 100,000 records of ~100 bytes each (~10 MB data):\n\n// 16 MiB segments: 1 segment to scan, ~10ms recovery\n// 128 MiB segments: 1 segment to scan, ~10ms recovery\n// 512 MiB segments: 1 segment to scan, ~10ms recovery\n\n// For 10 million records (~1 GB data):\n\n// 16 MiB segments: ~64 segments to scan, ~100ms recovery\n// 128 MiB segments: ~8 segments to scan, ~80ms recovery\n// 512 MiB segments: ~2 segments to scan, ~70ms recovery\n</code></pre>"},{"location":"crates/nori-wal/api-reference/config/#fsync_policy-fsyncpolicy","title":"<code>fsync_policy: FsyncPolicy</code>","text":"<p>Controls when data is synced to disk (durability vs performance trade-off).</p> <p>Default: <code>FsyncPolicy::Batch(Duration::from_millis(5))</code></p> <p>See: FsyncPolicy for detailed documentation.</p> <p>Examples:</p> <pre><code>use std::time::Duration;\n\n// Maximum durability (every write synced)\nlet config = WalConfig {\n    fsync_policy: FsyncPolicy::Always,\n    ..Default::default()\n};\n\n// Balanced (batch within 5ms)\nlet config = WalConfig {\n    fsync_policy: FsyncPolicy::Batch(Duration::from_millis(5)),\n    ..Default::default()\n};\n\n// Maximum performance (OS handles syncing)\nlet config = WalConfig {\n    fsync_policy: FsyncPolicy::Os,\n    ..Default::default()\n};\n</code></pre>"},{"location":"crates/nori-wal/api-reference/config/#preallocate-bool","title":"<code>preallocate: bool</code>","text":"<p>Enable file pre-allocation for new segment files.</p> <p>Default: <code>true</code></p> <p>Behavior: - When <code>true</code>, new segments are pre-allocated to <code>max_segment_size</code> using platform-specific APIs   - Linux: <code>fallocate()</code>   - macOS: <code>fcntl(F_PREALLOCATE)</code> - When <code>false</code>, segments grow as data is written</p> <p>Benefits of Pre-allocation:</p> <p>Early error detection - \"No space left on device\" errors happen at segment creation, not during critical writes</p> <p>Better filesystem locality - Reduces fragmentation, keeps data contiguous</p> <p>Improved performance - Some filesystems (ext4, XFS) perform better with pre-allocated files</p> <p>Predictable space usage - Easier to monitor disk usage</p> <p>Drawbacks:</p> <p>Disk space - Reserves full segment size immediately (even if not used)</p> <p>Slower startup - Pre-allocation takes time (usually &lt;100ms per segment)</p> <p>When to Disable:</p> <ul> <li>Running on filesystems that don't support pre-allocation</li> <li>Very tight disk space constraints</li> <li>Want to minimize initial disk usage</li> </ul> <p>Examples:</p> <pre><code>// Enable pre-allocation (default)\nlet config = WalConfig {\n    preallocate: true,\n    max_segment_size: 128 * 1024 * 1024,\n    ..Default::default()\n};\n// \u2192 Immediately reserves 128 MiB on disk\n\n// Disable pre-allocation\nlet config = WalConfig {\n    preallocate: false,\n    max_segment_size: 128 * 1024 * 1024,\n    ..Default::default()\n};\n// \u2192 Only uses disk space as data is written\n</code></pre> <p>Disk Usage Comparison:</p> <pre><code>// With preallocate = true:\n// 3 segments created \u2192 3 \u00d7 128 MiB = 384 MiB disk space used\n// (even if segments only contain 10 MiB of actual data)\n\n// With preallocate = false:\n// 3 segments with 10 MiB data each \u2192 30 MiB disk space used\n</code></pre>"},{"location":"crates/nori-wal/api-reference/config/#node_id-u32","title":"<code>node_id: u32</code>","text":"<p>Identifier for this WAL instance, used in observability events.</p> <p>Default: <code>0</code></p> <p>Purpose: - Distinguishes WAL instances in distributed systems - Included in <code>VizEvent</code> metrics for dashboards - Useful for debugging multi-node deployments</p> <p>Examples:</p> <pre><code>// Single-node deployment (default)\nlet config = WalConfig {\n    node_id: 0,\n    ..Default::default()\n};\n\n// Multi-node deployment\nlet config_node1 = WalConfig {\n    node_id: 1,\n    ..Default::default()\n};\n\nlet config_node2 = WalConfig {\n    node_id: 2,\n    ..Default::default()\n};\n\n// Use server ID from environment\nlet node_id = std::env::var(\"SERVER_ID\")?.parse()?;\nlet config = WalConfig {\n    node_id,\n    ..Default::default()\n};\n</code></pre>"},{"location":"crates/nori-wal/api-reference/config/#fsyncpolicy","title":"FsyncPolicy","text":"<p>Fsync policy controlling durability vs performance trade-offs.</p>"},{"location":"crates/nori-wal/api-reference/config/#type-definition_1","title":"Type Definition","text":"<p>View source in <code>crates/nori-wal/src/segment.rs</code></p>"},{"location":"crates/nori-wal/api-reference/config/#variants","title":"Variants","text":""},{"location":"crates/nori-wal/api-reference/config/#fsyncpolicyalways","title":"<code>FsyncPolicy::Always</code>","text":"<p>Fsync after every write - Maximum durability, lowest performance.</p> <p>Guarantees: - Every <code>append()</code> call syncs to disk before returning - Zero data loss on crash (except in-flight operations) - Writes are durable immediately</p> <p>Performance: - ~5,000-10,000 writes/sec on SSD - ~100-500 writes/sec on HDD - Each write waits for disk fsync (~0.1-1ms on SSD)</p> <p>Use When: - Absolutely cannot lose any committed data - Financial transactions, audit logs - Low write volume (&lt;10k writes/sec)</p> <p>Examples:</p> <pre><code>let config = WalConfig {\n    fsync_policy: FsyncPolicy::Always,\n    ..Default::default()\n};\n\nlet (wal, _) = Wal::open(config).await?;\n\n// Every append is immediately durable\nlet record = Record::put(b\"account:123\", b\"balance:1000\");\nwal.append(&amp;record).await?; // Blocks until synced to disk\n// Data is now durable, even if power fails right after\n</code></pre> <p>Benchmark:</p> <pre><code>FsyncPolicy::Always on NVMe SSD:\n  - Throughput: ~8,000 writes/sec\n  - Latency p50: 0.1ms\n  - Latency p99: 0.3ms\n</code></pre>"},{"location":"crates/nori-wal/api-reference/config/#fsyncpolicybatchduration","title":"<code>FsyncPolicy::Batch(Duration)</code>","text":"<p>Batch fsyncs within a time window - Balanced durability and performance.</p> <p>Guarantees: - Fsyncs happen at most once per <code>Duration</code> - Writes are buffered and synced together - May lose up to <code>Duration</code> of data on crash</p> <p>Parameters: - <code>Duration</code>: Maximum time between fsyncs - Valid range: <code>1ms</code> to <code>999ms</code> (enforced by validation)</p> <p>Performance: - ~50,000-200,000 writes/sec (depending on window size) - Amortizes fsync cost across many writes - Throughput scales with batch window</p> <p>Use When: - Can tolerate small data loss window (milliseconds) - High write volume (&gt;10k writes/sec) - Most database and cache workloads</p> <p>Examples:</p> <pre><code>use std::time::Duration;\n\n// Aggressive batching (default: 5ms window)\nlet config = WalConfig {\n    fsync_policy: FsyncPolicy::Batch(Duration::from_millis(5)),\n    ..Default::default()\n};\n\n// Conservative batching (1ms window)\nlet config = WalConfig {\n    fsync_policy: FsyncPolicy::Batch(Duration::from_millis(1)),\n    ..Default::default()\n};\n\n// Relaxed batching (100ms window)\nlet config = WalConfig {\n    fsync_policy: FsyncPolicy::Batch(Duration::from_millis(100)),\n    ..Default::default()\n};\n\nlet (wal, _) = Wal::open(config).await?;\n\n// Writes are buffered\nwal.append(&amp;record1).await?; // Returns immediately (buffered)\nwal.append(&amp;record2).await?; // Returns immediately (buffered)\nwal.append(&amp;record3).await?; // Returns immediately (buffered)\n\n// After 5ms (or manual sync), all 3 records are synced together\ntokio::time::sleep(Duration::from_millis(6)).await;\n// All 3 records now durable\n\n// Or manually sync before the window expires\nwal.append(&amp;record4).await?;\nwal.sync().await?; // Force immediate fsync\n// record4 is now durable\n</code></pre> <p>Choosing a Window Size:</p> Window Data Loss Risk Throughput Best For 1ms Minimal (~1ms of data) ~50k writes/sec Financial systems 5ms Low (~5ms of data) ~110k writes/sec Databases (default) 10ms Moderate (~10ms of data) ~150k writes/sec High-throughput caches 100ms High (~100ms of data) ~200k writes/sec Analytics, logs <p>Benchmark:</p> <pre><code>FsyncPolicy::Batch on NVMe SSD:\n  Window     Throughput      p50 Latency    p99 Latency\n  1ms        55,000/sec      0.02ms         1.2ms\n  5ms        110,000/sec     0.01ms         5.5ms\n  10ms       145,000/sec     0.01ms         10.5ms\n  100ms      190,000/sec     0.01ms         102ms\n</code></pre>"},{"location":"crates/nori-wal/api-reference/config/#fsyncpolicyos","title":"<code>FsyncPolicy::Os</code>","text":"<p>Let the OS handle fsyncing - Best performance, least durability.</p> <p>Guarantees: - Writes are buffered in OS page cache - No explicit fsync calls (except on <code>sync()</code> or <code>close()</code>) - May lose data on crash or power failure - Data is eventually written to disk (OS dependent)</p> <p>Performance: - ~500,000-1,000,000 writes/sec - Submicrosecond latency - Limited only by memcpy speed</p> <p>Use When: - Durability is not critical - Can reconstruct data from other sources - Ephemeral caches, development/testing - Replication from another durable source</p> <p>Examples:</p> <pre><code>let config = WalConfig {\n    fsync_policy: FsyncPolicy::Os,\n    ..Default::default()\n};\n\nlet (wal, _) = Wal::open(config).await?;\n\n// Writes are buffered in OS page cache (very fast)\nfor i in 0..1_000_000 {\n    let record = Record::put(format!(\"key{}\", i).as_bytes(), b\"value\");\n    wal.append(&amp;record).await?; // Returns in microseconds\n}\n\n// Manually sync when you want durability\nwal.sync().await?; // All 1M records now durable\n\n// Or close WAL (automatically syncs)\nwal.close().await?;\n</code></pre> <p>Risk:</p> <pre><code>let config = WalConfig {\n    fsync_policy: FsyncPolicy::Os,\n    ..Default::default()\n};\nlet (wal, _) = Wal::open(config).await?;\n\nwal.append(&amp;record1).await?;\nwal.append(&amp;record2).await?;\nwal.append(&amp;record3).await?;\n\n// Power failure here \u2192 All 3 records likely lost\n// (unless OS flushed the page cache)\n\n// To guarantee durability with FsyncPolicy::Os:\nwal.append(&amp;record4).await?;\nwal.sync().await?; // Explicit sync\n// Now record4 is durable\n</code></pre> <p>Benchmark:</p> <pre><code>FsyncPolicy::Os on NVMe SSD:\n  - Throughput: ~750,000 writes/sec\n  - Latency p50: 0.001ms (1 microsecond)\n  - Latency p99: 0.003ms\n</code></pre>"},{"location":"crates/nori-wal/api-reference/config/#fsync-policy-comparison","title":"Fsync Policy Comparison","text":"Policy Throughput Latency p99 Data Loss Risk Use Case <code>Always</code> ~8k/sec 0.3ms None Financial, audit logs <code>Batch(1ms)</code> ~55k/sec 1.2ms ~1ms of data Conservative DBs <code>Batch(5ms)</code> ~110k/sec 5.5ms ~5ms of data Default - most apps <code>Batch(10ms)</code> ~145k/sec 10.5ms ~10ms of data High-throughput DBs <code>Batch(100ms)</code> ~190k/sec 102ms ~100ms of data Analytics, logs <code>Os</code> ~750k/sec 0.003ms High (until manual sync) Caches, testing <p>Trade-off Visualization:</p> <pre><code>Durability \u2190\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192 Performance\n\nAlways    Batch(1ms)  Batch(5ms)  Batch(100ms)    Os\n  |          |           |             |            |\n  \u2193          \u2193           \u2193             \u2193            \u2193\n8k/sec   55k/sec    110k/sec      190k/sec     750k/sec\n</code></pre>"},{"location":"crates/nori-wal/api-reference/config/#usage-patterns","title":"Usage Patterns","text":""},{"location":"crates/nori-wal/api-reference/config/#production-database","title":"Production Database","text":"<pre><code>use nori_wal::{WalConfig, FsyncPolicy};\nuse std::time::Duration;\n\nlet config = WalConfig {\n    dir: PathBuf::from(\"/var/lib/mydb/wal\"),\n    max_segment_size: 128 * 1024 * 1024, // 128 MiB\n    fsync_policy: FsyncPolicy::Batch(Duration::from_millis(5)),\n    preallocate: true,\n    node_id: std::env::var(\"NODE_ID\")?.parse()?,\n};\n\nlet (wal, recovery_info) = Wal::open(config).await?;\nlog::info!(\"Recovered {} records\", recovery_info.valid_records);\n</code></pre>"},{"location":"crates/nori-wal/api-reference/config/#high-durability-system-financial","title":"High-Durability System (Financial)","text":"<pre><code>let config = WalConfig {\n    dir: PathBuf::from(\"/mnt/raid1/wal\"),\n    max_segment_size: 64 * 1024 * 1024, // Smaller segments for faster recovery\n    fsync_policy: FsyncPolicy::Always, // Never lose data\n    preallocate: true,\n    node_id: 1,\n};\n\nlet (wal, _) = Wal::open(config).await?;\n\n// Every write is immediately durable\nwal.append(&amp;Record::put(b\"txn:123\", b\"transfer:$1000\")).await?;\n// Guaranteed on disk before returning\n</code></pre>"},{"location":"crates/nori-wal/api-reference/config/#high-throughput-cache","title":"High-Throughput Cache","text":"<pre><code>let config = WalConfig {\n    dir: PathBuf::from(\"cache/wal\"),\n    max_segment_size: 256 * 1024 * 1024, // Larger segments\n    fsync_policy: FsyncPolicy::Batch(Duration::from_millis(100)), // Relaxed\n    preallocate: false, // Save disk space\n    node_id: 0,\n};\n\nlet (wal, _) = Wal::open(config).await?;\n\n// High throughput, can tolerate 100ms data loss\nfor i in 0..1_000_000 {\n    wal.append(&amp;Record::put(format!(\"cache:{}\", i).as_bytes(), b\"data\")).await?;\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/config/#testing-development","title":"Testing / Development","text":"<pre><code>use tempfile::TempDir;\n\nlet temp_dir = TempDir::new()?;\nlet config = WalConfig {\n    dir: temp_dir.path().to_path_buf(),\n    max_segment_size: 16 * 1024 * 1024, // Small segments\n    fsync_policy: FsyncPolicy::Os, // Fast, no durability needed\n    preallocate: false,\n    node_id: 0,\n};\n\nlet (wal, _) = Wal::open(config).await?;\n\n// Fast writes for testing\nwal.append(&amp;Record::put(b\"test\", b\"data\")).await?;\n</code></pre>"},{"location":"crates/nori-wal/api-reference/config/#multi-node-deployment","title":"Multi-Node Deployment","text":"<pre><code>// Node 1\nlet config_node1 = WalConfig {\n    dir: PathBuf::from(\"/data/node1/wal\"),\n    node_id: 1,\n    ..Default::default()\n};\n\n// Node 2\nlet config_node2 = WalConfig {\n    dir: PathBuf::from(\"/data/node2/wal\"),\n    node_id: 2,\n    ..Default::default()\n};\n\n// Node 3\nlet config_node3 = WalConfig {\n    dir: PathBuf::from(\"/data/node3/wal\"),\n    node_id: 3,\n    ..Default::default()\n};\n\n// Observability events will include node_id to distinguish nodes\n</code></pre>"},{"location":"crates/nori-wal/api-reference/config/#best-practices","title":"Best Practices","text":""},{"location":"crates/nori-wal/api-reference/config/#1-choose-appropriate-segment-size","title":"1. Choose Appropriate Segment Size","text":"<pre><code>// GOOD: Balance based on write volume\nlet config = if high_write_volume {\n    WalConfig {\n        max_segment_size: 256 * 1024 * 1024, // 256 MiB\n        ..Default::default()\n    }\n} else {\n    WalConfig {\n        max_segment_size: 64 * 1024 * 1024, // 64 MiB\n        ..Default::default()\n    }\n};\n\n// BAD: Too small (excessive overhead)\nlet config = WalConfig {\n    max_segment_size: 1024 * 1024, // 1 MiB - will rotate constantly\n    ..Default::default()\n};\n</code></pre>"},{"location":"crates/nori-wal/api-reference/config/#2-match-fsync-policy-to-durability-needs","title":"2. Match Fsync Policy to Durability Needs","text":"<pre><code>// GOOD: Match policy to use case\nlet cache_config = WalConfig {\n    fsync_policy: FsyncPolicy::Batch(Duration::from_millis(50)),\n    ..Default::default()\n};\n\nlet txn_config = WalConfig {\n    fsync_policy: FsyncPolicy::Always,\n    ..Default::default()\n};\n\n// BAD: Using Os policy for critical data\nlet config = WalConfig {\n    fsync_policy: FsyncPolicy::Os, // Can lose data!\n    ..Default::default()\n};\n// Then storing financial transactions \u2192 WRONG\n</code></pre>"},{"location":"crates/nori-wal/api-reference/config/#3-use-pre-allocation-on-production-systems","title":"3. Use Pre-allocation on Production Systems","text":"<pre><code>// GOOD: Enable pre-allocation for production\nlet config = WalConfig {\n    preallocate: true, // Fail fast on disk space issues\n    ..Default::default()\n};\n\n//  RISKY: Disable only if necessary\nlet config = WalConfig {\n    preallocate: false, // Might fail mid-write!\n    ..Default::default()\n};\n</code></pre>"},{"location":"crates/nori-wal/api-reference/config/#4-set-meaningful-node-ids","title":"4. Set Meaningful Node IDs","text":"<pre><code>// GOOD: Unique node IDs in distributed systems\nlet node_id = hostname::get()?.to_str().unwrap().parse()?;\nlet config = WalConfig {\n    node_id,\n    ..Default::default()\n};\n\n// BAD: All nodes use default node_id = 0\n// (can't distinguish them in metrics)\n</code></pre>"},{"location":"crates/nori-wal/api-reference/config/#see-also","title":"See Also","text":"<ul> <li>Wal API - Main WAL interface</li> <li>Record API - Record format</li> <li>Errors - Error handling</li> <li>Core Concepts: Fsync Policies - Deep dive into durability trade-offs</li> <li>Performance Benchmarks - Performance comparison of fsync policies</li> </ul>"},{"location":"crates/nori-wal/api-reference/errors/","title":"Errors &amp; Types API","text":"<p>Complete reference for error types and supporting structures in nori-wal.</p>"},{"location":"crates/nori-wal/api-reference/errors/#table-of-contents","title":"Table of contents","text":""},{"location":"crates/nori-wal/api-reference/errors/#overview","title":"Overview","text":"<p>nori-wal uses typed errors and result types for comprehensive error handling. All errors implement <code>std::error::Error</code> and can be converted to other error types using the <code>?</code> operator.</p> <p>Error Types: - <code>SegmentError</code> - Segment-level operations (WAL, file I/O) - <code>RecordError</code> - Record encoding/decoding errors</p> <p>Supporting Types: - <code>Position</code> - Location in the WAL - <code>RecoveryInfo</code> - Recovery statistics</p>"},{"location":"crates/nori-wal/api-reference/errors/#segmenterror","title":"SegmentError","text":"<p>Main error type for WAL operations.</p>"},{"location":"crates/nori-wal/api-reference/errors/#type-definition","title":"Type Definition","text":"<p>View source in <code>crates/nori-wal/src/segment.rs</code></p>"},{"location":"crates/nori-wal/api-reference/errors/#variants","title":"Variants","text":"Variant Description Source <code>Io(io::Error)</code> I/O error from filesystem operations File open, read, write, fsync failures <code>Record(RecordError)</code> Record encoding/decoding error Invalid record format, CRC mismatch <code>NotFound(u64)</code> Segment file not found Segment ID doesn't exist <code>InvalidConfig(String)</code> Configuration validation error Invalid <code>WalConfig</code> parameters"},{"location":"crates/nori-wal/api-reference/errors/#error-conversions","title":"Error Conversions","text":"<p><code>SegmentError</code> automatically converts from: - <code>std::io::Error</code> (via <code>#[from]</code>) - <code>RecordError</code> (via <code>#[from]</code>)</p> <p>Examples:</p> <pre><code>use nori_wal::{Wal, WalConfig, SegmentError};\n\nmatch Wal::open(config).await {\n    Ok((wal, info)) =&gt; println!(\"Opened WAL with {} records\", info.valid_records),\n    Err(SegmentError::Io(e)) =&gt; {\n        eprintln!(\"I/O error: {}\", e);\n        if e.kind() == std::io::ErrorKind::NotFound {\n            eprintln!(\"Directory doesn't exist\");\n        }\n    }\n    Err(SegmentError::Record(e)) =&gt; {\n        eprintln!(\"Record error during recovery: {}\", e);\n    }\n    Err(SegmentError::NotFound(id)) =&gt; {\n        eprintln!(\"Segment {} not found\", id);\n    }\n    Err(SegmentError::InvalidConfig(msg)) =&gt; {\n        eprintln!(\"Invalid configuration: {}\", msg);\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/errors/#segmenterrorio","title":"SegmentError::Io","text":"<p>I/O errors from filesystem operations.</p> <p>Common Causes:</p> Error Kind Cause Solution <code>NotFound</code> Directory or segment doesn't exist Create directory or check path <code>PermissionDenied</code> No write/read permissions Fix file permissions <code>NoSpaceLeft</code> Disk full Free up space or reduce segment size <code>WriteZero</code> Disk write failed Check disk health <code>UnexpectedEof</code> File truncated mid-read Corruption or crash during write <p>Examples:</p> <pre><code>use std::io::ErrorKind;\n\nmatch wal.append(&amp;record).await {\n    Ok(pos) =&gt; println!(\"Written at {:?}\", pos),\n    Err(SegmentError::Io(e)) =&gt; match e.kind() {\n        ErrorKind::NoSpaceLeft =&gt; {\n            eprintln!(\"Disk full! Cannot write more data.\");\n            // Trigger cleanup or alert\n        }\n        ErrorKind::PermissionDenied =&gt; {\n            eprintln!(\"Permission denied. Check file permissions.\");\n        }\n        _ =&gt; {\n            eprintln!(\"I/O error: {}\", e);\n        }\n    },\n    Err(e) =&gt; eprintln!(\"Other error: {}\", e),\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/errors/#segmenterrorrecord","title":"SegmentError::Record","text":"<p>Record-level errors during encoding or decoding.</p> <p>See RecordError documentation for details.</p> <p>When it occurs: - During recovery: corrupt or incomplete records - During append: encoding failures (rare) - During read: decoding failures</p> <p>Examples:</p> <pre><code>match wal.append(&amp;record).await {\n    Ok(_) =&gt; {}\n    Err(SegmentError::Record(RecordError::CrcMismatch { expected, actual })) =&gt; {\n        eprintln!(\"Data corruption: CRC expected {:#x}, got {:#x}\", expected, actual);\n    }\n    Err(SegmentError::Record(RecordError::Incomplete)) =&gt; {\n        eprintln!(\"Incomplete record at end of segment\");\n    }\n    Err(e) =&gt; eprintln!(\"Error: {}\", e),\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/errors/#segmenterrornotfound","title":"SegmentError::NotFound","text":"<p>Segment file not found.</p> <p>When it occurs: - Reading from a segment ID that doesn't exist - Deleted segment files while WAL is running - Incorrect segment directory</p> <p>Examples:</p> <pre><code>let position = Position { segment_id: 999, offset: 0 };\n\nmatch wal.read_from(position).await {\n    Ok(reader) =&gt; { /* ... */ }\n    Err(SegmentError::NotFound(id)) =&gt; {\n        eprintln!(\"Segment {} not found. Was it deleted?\", id);\n        // Either the segment was garbage collected or position is invalid\n    }\n    Err(e) =&gt; eprintln!(\"Error: {}\", e),\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/errors/#segmenterrorinvalidconfig","title":"SegmentError::InvalidConfig","text":"<p>Configuration validation failed.</p> <p>Common Validation Errors:</p> Configuration Invalid Value Error Message <code>max_segment_size</code> <code>0</code> \"max_segment_size must be greater than 0\" <code>max_segment_size</code> <code>&lt; 1MB</code> \"max_segment_size should be at least 1MB for reasonable performance\" <code>fsync_policy</code> <code>Batch(Duration::ZERO)</code> \"fsync batch window cannot be zero - use FsyncPolicy::Always instead\" <code>fsync_policy</code> <code>Batch(&gt; 1 second)</code> \"fsync batch window should be less than 1 second to avoid excessive data loss risk\" <p>Examples:</p> <pre><code>use nori_wal::{WalConfig, FsyncPolicy, SegmentError};\nuse std::time::Duration;\n\nlet config = WalConfig {\n    max_segment_size: 0, // Invalid!\n    ..Default::default()\n};\n\nmatch Wal::open(config).await {\n    Ok(_) =&gt; {}\n    Err(SegmentError::InvalidConfig(msg)) =&gt; {\n        eprintln!(\"Configuration error: {}\", msg);\n        // Fix configuration based on error message\n    }\n    Err(e) =&gt; eprintln!(\"Error: {}\", e),\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/errors/#recorderror","title":"RecordError","text":"<p>Errors related to record encoding and decoding.</p>"},{"location":"crates/nori-wal/api-reference/errors/#type-definition_1","title":"Type Definition","text":"<p>View source in <code>crates/nori-wal/src/record.rs</code></p>"},{"location":"crates/nori-wal/api-reference/errors/#variants_1","title":"Variants","text":"Variant Description When It Occurs <code>Io(io::Error)</code> I/O error (e.g., varint overflow) Malformed varint, buffer issues <code>CrcMismatch { expected, actual }</code> Checksum validation failed Data corruption <code>InvalidCompression(u8)</code> Unknown compression type Corrupt flags byte <code>CompressionFailed(String)</code> Compression error Should never happen <code>DecompressionFailed(String)</code> Decompression error Corrupt compressed data <code>Incomplete</code> Not enough bytes to decode Truncated record"},{"location":"crates/nori-wal/api-reference/errors/#recorderrorio","title":"RecordError::Io","text":"<p>I/O errors during encoding/decoding.</p> <p>Common Causes: - Varint overflow (varint too long) - Buffer underflow during decode</p> <p>Examples:</p> <pre><code>use nori_wal::{Record, RecordError};\n\nlet corrupted_data = &amp;[0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF];\n\nmatch Record::decode(corrupted_data) {\n    Ok(_) =&gt; {}\n    Err(RecordError::Io(e)) =&gt; {\n        eprintln!(\"I/O error: {}\", e);\n        // Likely a varint overflow from malformed data\n    }\n    Err(e) =&gt; eprintln!(\"Other error: {}\", e),\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/errors/#recorderrorcrcmismatch","title":"RecordError::CrcMismatch","text":"<p>CRC32C checksum validation failed - data corruption detected.</p> <p>Fields: - <code>expected: u32</code> - CRC stored in the record - <code>actual: u32</code> - CRC calculated from data</p> <p>When it occurs: - Disk corruption - Memory corruption - Incomplete write (crash mid-write) - Bit flips (hardware issues)</p> <p>Examples:</p> <pre><code>match Record::decode(data) {\n    Ok((record, size)) =&gt; {\n        // CRC validated automatically\n        println!(\"Valid record: {:?}\", record);\n    }\n    Err(RecordError::CrcMismatch { expected, actual }) =&gt; {\n        eprintln!(\"CORRUPTION DETECTED!\");\n        eprintln!(\"  Expected CRC: {:#010x}\", expected);\n        eprintln!(\"  Actual CRC:   {:#010x}\", actual);\n        eprintln!(\"  XOR diff:     {:#010x}\", expected ^ actual);\n\n        // This record is corrupt and should be discarded\n        // Recovery will truncate here\n    }\n    Err(e) =&gt; eprintln!(\"Error: {}\", e),\n}\n</code></pre> <p>What to do: 1. Log the error with offset/position 2. Skip this record during recovery 3. Truncate segment at this point 4. Alert operators (possible hardware issue)</p>"},{"location":"crates/nori-wal/api-reference/errors/#recorderrorinvalidcompression","title":"RecordError::InvalidCompression","text":"<p>Unknown compression type in flags byte.</p> <p>When it occurs: - Corrupt flags byte (bits 2-3) - Reading data written by incompatible version</p> <p>Valid compression types: - <code>0</code> = None - <code>1</code> = LZ4 - <code>2</code> = Zstd - <code>3</code> = Reserved (future use)</p> <p>Examples:</p> <pre><code>match Record::decode(data) {\n    Ok(_) =&gt; {}\n    Err(RecordError::InvalidCompression(typ)) =&gt; {\n        eprintln!(\"Unknown compression type: {}\", typ);\n        eprintln!(\"Valid types: 0 (None), 1 (LZ4), 2 (Zstd)\");\n        // Data is corrupt or from incompatible version\n    }\n    Err(e) =&gt; eprintln!(\"Error: {}\", e),\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/errors/#recorderrorcompressionfailed","title":"RecordError::CompressionFailed","text":"<p>Compression failed during encoding.</p> <p>When it occurs: - Should never happen in practice - LZ4/Zstd libraries return error</p> <p>Examples:</p> <pre><code>let record = Record::put(b\"key\", large_value)\n    .with_compression(Compression::Lz4);\n\nmatch wal.append(&amp;record).await {\n    Ok(_) =&gt; {}\n    Err(SegmentError::Record(RecordError::CompressionFailed(msg))) =&gt; {\n        eprintln!(\"Compression failed: {}\", msg);\n        // This is very rare - may indicate memory issues\n        // Fall back to uncompressed write\n    }\n    Err(e) =&gt; eprintln!(\"Error: {}\", e),\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/errors/#recorderrordecompressionfailed","title":"RecordError::DecompressionFailed","text":"<p>Decompression failed during decoding.</p> <p>When it occurs: - Corrupt compressed data - Truncated compressed value - Memory allocation failure</p> <p>Examples:</p> <pre><code>match Record::decode(data) {\n    Ok(_) =&gt; {}\n    Err(RecordError::DecompressionFailed(msg)) =&gt; {\n        eprintln!(\"Decompression failed: {}\", msg);\n        // Compressed data is corrupt\n        // Recovery should truncate here\n    }\n    Err(e) =&gt; eprintln!(\"Error: {}\", e),\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/errors/#recorderrorincomplete","title":"RecordError::Incomplete","text":"<p>Not enough bytes to decode a complete record.</p> <p>When it occurs: - Reading from end of segment - Truncated write (crash mid-append) - Streaming decode with partial data</p> <p>Examples:</p> <pre><code>let mut offset = 0;\nlet buffer = read_segment_file()?;\n\nloop {\n    match Record::decode(&amp;buffer[offset..]) {\n        Ok((record, size)) =&gt; {\n            println!(\"Record: {:?}\", record);\n            offset += size;\n        }\n        Err(RecordError::Incomplete) =&gt; {\n            // Reached end of valid data\n            // This is normal at end of segment\n            println!(\"End of valid records at offset {}\", offset);\n            break;\n        }\n        Err(RecordError::CrcMismatch { .. }) =&gt; {\n            // Corruption - stop here\n            eprintln!(\"Corruption at offset {}\", offset);\n            break;\n        }\n        Err(e) =&gt; {\n            eprintln!(\"Error: {}\", e);\n            break;\n        }\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/errors/#position","title":"Position","text":"<p>Location within the WAL (segment ID + byte offset).</p>"},{"location":"crates/nori-wal/api-reference/errors/#type-definition_2","title":"Type Definition","text":"<p>View source in <code>crates/nori-wal/src/segment.rs</code></p>"},{"location":"crates/nori-wal/api-reference/errors/#fields","title":"Fields","text":"Field Type Description <code>segment_id</code> <code>u64</code> Segment file number (0, 1, 2, ...) <code>offset</code> <code>u64</code> Byte offset within the segment"},{"location":"crates/nori-wal/api-reference/errors/#ordering","title":"Ordering","text":"<p><code>Position</code> implements <code>Ord</code> and can be compared:</p> <pre><code>use nori_wal::Position;\n\nlet pos1 = Position { segment_id: 0, offset: 100 };\nlet pos2 = Position { segment_id: 0, offset: 200 };\nlet pos3 = Position { segment_id: 1, offset: 0 };\n\nassert!(pos1 &lt; pos2);  // Same segment, earlier offset\nassert!(pos2 &lt; pos3);  // Earlier segment\n</code></pre>"},{"location":"crates/nori-wal/api-reference/errors/#usage","title":"Usage","text":"<p>Starting position for reading:</p> <pre><code>// Read from beginning\nlet start = Position { segment_id: 0, offset: 0 };\nlet mut reader = wal.read_from(start).await?;\n\n// Read from specific position\nlet checkpoint = Position { segment_id: 5, offset: 1024 };\nlet mut reader = wal.read_from(checkpoint).await?;\n</code></pre> <p>Saving checkpoints:</p> <pre><code>// Save position for resume\nlet pos = wal.append(&amp;record).await?;\nsave_checkpoint(pos);\n\n// Later, resume from checkpoint\nlet checkpoint = load_checkpoint();\nlet mut reader = wal.read_from(checkpoint).await?;\n</code></pre>"},{"location":"crates/nori-wal/api-reference/errors/#recoveryinfo","title":"RecoveryInfo","text":"<p>Statistics about WAL recovery operation.</p>"},{"location":"crates/nori-wal/api-reference/errors/#type-definition_3","title":"Type Definition","text":"<p>View source in <code>crates/nori-wal/src/recovery.rs</code></p>"},{"location":"crates/nori-wal/api-reference/errors/#fields_1","title":"Fields","text":"Field Type Description <code>valid_records</code> <code>u64</code> Total valid records recovered <code>segments_scanned</code> <code>u64</code> Number of segment files scanned <code>bytes_truncated</code> <code>u64</code> Bytes removed due to corruption <code>last_valid_position</code> <code>Option&lt;Position&gt;</code> Position of last valid record <code>corruption_detected</code> <code>bool</code> Whether any corruption was found"},{"location":"crates/nori-wal/api-reference/errors/#usage_1","title":"Usage","text":"<p>After opening WAL:</p> <pre><code>let (wal, info) = Wal::open(config).await?;\n\nprintln!(\"Recovery complete:\");\nprintln!(\"  Records recovered: {}\", info.valid_records);\nprintln!(\"  Segments scanned: {}\", info.segments_scanned);\nprintln!(\"  Bytes truncated: {}\", info.bytes_truncated);\n\nif info.corruption_detected {\n    eprintln!(\"WARNING: Corruption detected and truncated\");\n    eprintln!(\"  Lost {} bytes of data\", info.bytes_truncated);\n\n    // Alert operators\n    send_alert(\"WAL corruption detected\");\n}\n\nif let Some(pos) = info.last_valid_position {\n    println!(\"Last valid record at segment {}, offset {}\",\n        pos.segment_id, pos.offset);\n}\n</code></pre> <p>Monitoring recovery metrics:</p> <pre><code>let (wal, info) = Wal::open(config).await?;\n\n// Log to metrics system\nmetrics.gauge(\"wal.recovery.valid_records\", info.valid_records);\nmetrics.gauge(\"wal.recovery.bytes_truncated\", info.bytes_truncated);\nmetrics.gauge(\"wal.recovery.corruption_detected\", info.corruption_detected as u64);\n\n// Alert if significant data loss\nif info.bytes_truncated &gt; 1024 * 1024 {  // &gt; 1 MB lost\n    alert_ops(\"Significant WAL data loss during recovery\");\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/errors/#error-handling-patterns","title":"Error Handling Patterns","text":""},{"location":"crates/nori-wal/api-reference/errors/#pattern-1-graceful-degradation","title":"Pattern 1: Graceful Degradation","text":"<pre><code>async fn write_with_fallback(wal: &amp;Wal, record: &amp;Record) -&gt; Result&lt;Position, AppError&gt; {\n    match wal.append(record).await {\n        Ok(pos) =&gt; Ok(pos),\n        Err(SegmentError::Io(e)) if e.kind() == ErrorKind::NoSpaceLeft =&gt; {\n            // Trigger emergency cleanup\n            wal.delete_segments_before(old_checkpoint).await?;\n\n            // Retry\n            wal.append(record).await.map_err(Into::into)\n        }\n        Err(e) =&gt; Err(e.into()),\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/errors/#pattern-2-retry-with-backoff","title":"Pattern 2: Retry with Backoff","text":"<pre><code>async fn append_with_retry(\n    wal: &amp;Wal,\n    record: &amp;Record,\n    max_retries: u32\n) -&gt; Result&lt;Position, SegmentError&gt; {\n    let mut retries = 0;\n    let mut delay = Duration::from_millis(10);\n\n    loop {\n        match wal.append(record).await {\n            Ok(pos) =&gt; return Ok(pos),\n            Err(SegmentError::Io(e)) if e.kind() == ErrorKind::Interrupted =&gt; {\n                // Transient error, retry\n                if retries &gt;= max_retries {\n                    return Err(SegmentError::Io(e));\n                }\n                retries += 1;\n                tokio::time::sleep(delay).await;\n                delay *= 2;  // Exponential backoff\n            }\n            Err(e) =&gt; return Err(e),  // Don't retry other errors\n        }\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/errors/#pattern-3-error-classification","title":"Pattern 3: Error Classification","text":"<pre><code>#[derive(Debug)]\nenum ErrorSeverity {\n    Transient,  // Retry\n    Fatal,      // Abort\n    Corruption, // Alert + truncate\n}\n\nfn classify_error(err: &amp;SegmentError) -&gt; ErrorSeverity {\n    match err {\n        SegmentError::Io(e) if e.kind() == ErrorKind::Interrupted =&gt; {\n            ErrorSeverity::Transient\n        }\n        SegmentError::Record(RecordError::CrcMismatch { .. }) =&gt; {\n            ErrorSeverity::Corruption\n        }\n        SegmentError::InvalidConfig(_) =&gt; {\n            ErrorSeverity::Fatal\n        }\n        _ =&gt; ErrorSeverity::Fatal,\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/errors/#pattern-4-detailed-error-context","title":"Pattern 4: Detailed Error Context","text":"<pre><code>use thiserror::Error;\n\n#[derive(Debug, Error)]\nenum AppError {\n    #[error(\"WAL operation failed at position {position:?}: {source}\")]\n    WalError {\n        position: Position,\n        #[source]\n        source: SegmentError,\n    },\n\n    #[error(\"Recovery failed after {attempts} attempts: {source}\")]\n    RecoveryError {\n        attempts: u32,\n        #[source]\n        source: SegmentError,\n    },\n}\n\n// Usage\nlet pos = wal.current_position().await;\nwal.append(&amp;record).await.map_err(|e| AppError::WalError {\n    position: pos,\n    source: e,\n})?;\n</code></pre>"},{"location":"crates/nori-wal/api-reference/errors/#see-also","title":"See Also","text":"<ul> <li>Wal API - Main WAL interface</li> <li>Record API - Record operations</li> <li>Configuration - Configuration options</li> <li>Recovery Guarantees - Recovery behavior</li> <li>Troubleshooting - Common issues and solutions</li> </ul>"},{"location":"crates/nori-wal/api-reference/record/","title":"Record API","text":"<p>Complete API reference for the <code>Record</code> type - the fundamental unit of data in nori-wal.</p>"},{"location":"crates/nori-wal/api-reference/record/#table-of-contents","title":"Table of contents","text":""},{"location":"crates/nori-wal/api-reference/record/#overview","title":"Overview","text":"<p>A <code>Record</code> represents a single key-value operation in the WAL. Records support:</p> <ul> <li>PUT operations - Store key-value pairs</li> <li>DELETE operations - Tombstone markers for deletions</li> <li>TTL support - Optional time-to-live for records</li> <li>Compression - LZ4 and Zstd compression for values</li> <li>Integrity - CRC32C checksums for corruption detection</li> </ul>"},{"location":"crates/nori-wal/api-reference/record/#type-definition","title":"Type Definition","text":"<p>View source in <code>crates/nori-wal/src/record.rs</code></p>"},{"location":"crates/nori-wal/api-reference/record/#fields","title":"Fields","text":"Field Type Description <code>key</code> <code>Bytes</code> The record's key (immutable byte buffer) <code>value</code> <code>Bytes</code> The record's value (immutable byte buffer) <code>tombstone</code> <code>bool</code> <code>true</code> for DELETE operations, <code>false</code> for PUT <code>ttl</code> <code>Option&lt;Duration&gt;</code> Optional time-to-live for the record <code>compression</code> <code>Compression</code> Compression algorithm used for the value"},{"location":"crates/nori-wal/api-reference/record/#creating-records","title":"Creating Records","text":""},{"location":"crates/nori-wal/api-reference/record/#recordput","title":"<code>Record::put</code>","text":"<p>Creates a new PUT record.</p> <p>View source</p> <p>Parameters: - <code>key</code> - The record's key (accepts <code>&amp;[u8]</code>, <code>Vec&lt;u8&gt;</code>, <code>String</code>, etc.) - <code>value</code> - The record's value (accepts <code>&amp;[u8]</code>, <code>Vec&lt;u8&gt;</code>, <code>String</code>, etc.)</p> <p>Returns: A new <code>Record</code> with <code>tombstone = false</code> and no TTL or compression.</p> <p>Examples:</p> <pre><code>use nori_wal::Record;\n\n// From byte slices\nlet record = Record::put(b\"user:123\", b\"Alice\");\n\n// From Strings\nlet key = String::from(\"session:abc\");\nlet value = String::from(\"active\");\nlet record = Record::put(key, value);\n\n// From Vecs\nlet key = vec![1, 2, 3];\nlet value = vec![4, 5, 6];\nlet record = Record::put(key, value);\n</code></pre>"},{"location":"crates/nori-wal/api-reference/record/#recordput_with_ttl","title":"<code>Record::put_with_ttl</code>","text":"<p>Creates a new PUT record with a time-to-live.</p> <p>View source</p> <p>Parameters: - <code>key</code> - The record's key - <code>value</code> - The record's value - <code>ttl</code> - Time-to-live duration</p> <p>Returns: A new <code>Record</code> with the specified TTL.</p> <p>Examples:</p> <pre><code>use nori_wal::Record;\nuse std::time::Duration;\n\n// Cache entry that expires in 5 minutes\nlet record = Record::put_with_ttl(\n    b\"cache:result:123\",\n    b\"computed value\",\n    Duration::from_secs(300),\n);\n\n// Session that expires in 1 hour\nlet record = Record::put_with_ttl(\n    b\"session:abc\",\n    b\"user_data\",\n    Duration::from_secs(3600),\n);\n</code></pre> <p>Notes: - TTL is stored as milliseconds internally - TTL enforcement is the application's responsibility (nori-wal doesn't auto-expire records) - Maximum TTL is <code>u64::MAX</code> milliseconds (~584 million years)</p>"},{"location":"crates/nori-wal/api-reference/record/#recorddelete","title":"<code>Record::delete</code>","text":"<p>Creates a DELETE record (tombstone).</p> <p>View source</p> <p>Parameters: - <code>key</code> - The key to delete</p> <p>Returns: A new <code>Record</code> with <code>tombstone = true</code> and empty value.</p> <p>Examples:</p> <pre><code>use nori_wal::Record;\n\n// Mark a key as deleted\nlet record = Record::delete(b\"user:123\");\n\nassert!(record.tombstone);\nassert_eq!(record.value.len(), 0);\n</code></pre> <p>Tombstone Semantics: - Tombstones shadow earlier PUT records for the same key - Used in LSM compaction to remove deleted keys - Empty value (storage optimization)</p>"},{"location":"crates/nori-wal/api-reference/record/#compression","title":"Compression","text":""},{"location":"crates/nori-wal/api-reference/record/#recordwith_compression","title":"<code>Record::with_compression</code>","text":"<p>Sets the compression algorithm for the record's value.</p> <p>View source</p> <p>Parameters: - <code>compression</code> - Compression algorithm (<code>Compression::None</code>, <code>Compression::Lz4</code>, or <code>Compression::Zstd</code>)</p> <p>Returns: The modified record (builder pattern).</p> <p>Examples:</p> <pre><code>use nori_wal::{Record, Compression};\n\n// LZ4 compression (fast)\nlet record = Record::put(b\"key\", b\"large value\".repeat(1000))\n    .with_compression(Compression::Lz4);\n\n// Zstd compression (better ratio)\nlet record = Record::put(b\"key\", b\"large value\".repeat(1000))\n    .with_compression(Compression::Zstd);\n\n// No compression (default)\nlet record = Record::put(b\"key\", b\"small value\")\n    .with_compression(Compression::None);\n</code></pre> <p>Compression Algorithms:</p> Algorithm Speed Ratio Best For <code>Compression::None</code> N/A 1:1 Small values, already compressed data <code>Compression::Lz4</code> Very fast ~2-3x Hot path, large text/JSON <code>Compression::Zstd</code> Moderate ~3-5x Cold storage, maximum space savings <p>Performance Tips: - Use LZ4 for hot path writes (microseconds overhead) - Use Zstd for cold storage or archival - Skip compression for small values (&lt;100 bytes) - overhead not worth it - Skip compression for already compressed data (JPEG, PNG, etc.)</p> <p>Compression Test Results:</p> <pre><code>// Highly compressible data (repeated text)\nlet value = \"hello world \".repeat(100); // 1200 bytes\n\nlet none = Record::put(b\"k\", value.as_bytes()).encode();\nlet lz4 = Record::put(b\"k\", value.as_bytes())\n    .with_compression(Compression::Lz4)\n    .encode();\nlet zstd = Record::put(b\"k\", value.as_bytes())\n    .with_compression(Compression::Zstd)\n    .encode();\n\n// none.len() = 1215 bytes\n// lz4.len()  = ~50 bytes (24x compression)\n// zstd.len() = ~30 bytes (40x compression)\n</code></pre>"},{"location":"crates/nori-wal/api-reference/record/#encoding-and-decoding","title":"Encoding and Decoding","text":""},{"location":"crates/nori-wal/api-reference/record/#recordencode","title":"<code>Record::encode</code>","text":"<p>Encodes the record into bytes with CRC32C checksum.</p> <p>View source</p> <p>Returns: Encoded record as immutable <code>Bytes</code>.</p> <p>Format: <pre><code>[klen: varint]\n[vlen: varint]\n[flags: u8]\n[ttl_ms?: varint] (if TTL present)\n[key: bytes]\n[value: bytes]\n[crc32c: u32 LE]\n</code></pre></p> <p>Flags byte: - Bit 0: <code>tombstone</code> (1 = DELETE, 0 = PUT) - Bit 1: <code>ttl_present</code> (1 = TTL follows, 0 = no TTL) - Bits 2-3: <code>compression</code> (0 = None, 1 = LZ4, 2 = Zstd) - Bits 4-7: Reserved (must be 0)</p> <p>Examples:</p> <pre><code>use nori_wal::Record;\n\nlet record = Record::put(b\"user:123\", b\"Alice\");\nlet encoded = record.encode();\n\n// Write to WAL\nwal.append(&amp;record).await?;\n\n// Or write to arbitrary storage\nfile.write_all(&amp;encoded).await?;\n</code></pre> <p>Varint Encoding: - Key and value lengths use LEB128 variable-length encoding - 1 byte for lengths &lt; 128 - 2 bytes for lengths &lt; 16,384 - Etc.</p> <p>CRC32C Checksum: - Computed over entire record (excluding the CRC itself) - Detects corruption during recovery - Hardware-accelerated on modern CPUs (SSE 4.2)</p>"},{"location":"crates/nori-wal/api-reference/record/#recorddecode","title":"<code>Record::decode</code>","text":"<p>Decodes a record from bytes, validating the CRC32C checksum.</p> <p>View source</p> <p>Parameters: - <code>data</code> - Byte slice containing the encoded record</p> <p>Returns: - <code>Ok((record, bytes_consumed))</code> - Successfully decoded record and number of bytes read - <code>Err(RecordError)</code> - Decoding failed</p> <p>Errors:</p> Error Cause <code>RecordError::Incomplete</code> Not enough bytes to decode <code>RecordError::CrcMismatch</code> Checksum validation failed <code>RecordError::InvalidCompression</code> Unknown compression type <code>RecordError::DecompressionFailed</code> Decompression error <code>RecordError::Io</code> I/O error (e.g., varint overflow) <p>Examples:</p> <pre><code>use nori_wal::Record;\n\n// Decode a record\nlet (record, bytes_consumed) = Record::decode(&amp;encoded)?;\n\n// Handle errors\nmatch Record::decode(&amp;corrupted_data) {\n    Ok((record, _)) =&gt; println!(\"Decoded: {:?}\", record),\n    Err(RecordError::CrcMismatch { expected, actual }) =&gt; {\n        eprintln!(\"Corruption detected: expected {:#x}, got {:#x}\", expected, actual);\n    }\n    Err(RecordError::Incomplete) =&gt; {\n        eprintln!(\"Incomplete record, need more data\");\n    }\n    Err(e) =&gt; eprintln!(\"Decode error: {}\", e),\n}\n</code></pre> <p>Decoding from Streams:</p> <pre><code>use nori_wal::Record;\n\nlet mut buffer = Vec::new();\nfile.read_to_end(&amp;mut buffer).await?;\n\nlet mut offset = 0;\nwhile offset &lt; buffer.len() {\n    match Record::decode(&amp;buffer[offset..]) {\n        Ok((record, size)) =&gt; {\n            println!(\"Record: {:?}\", record);\n            offset += size;\n        }\n        Err(RecordError::Incomplete) =&gt; {\n            // Need more data\n            break;\n        }\n        Err(e) =&gt; {\n            eprintln!(\"Decode error at offset {}: {}\", offset, e);\n            break;\n        }\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/record/#compression-enum","title":"Compression Enum","text":""},{"location":"crates/nori-wal/api-reference/record/#compression_1","title":"<code>Compression</code>","text":"<p>Compression algorithm for record values.</p> <p>View source</p> <p>Variants:</p> Variant Value Description <code>None</code> 0 No compression <code>Lz4</code> 1 LZ4 block compression (fast) <code>Zstd</code> 2 Zstandard compression (high ratio) <p>Examples:</p> <pre><code>use nori_wal::Compression;\n\nlet comp = Compression::Lz4;\nassert_eq!(comp as u8, 1);\n</code></pre>"},{"location":"crates/nori-wal/api-reference/record/#error-handling","title":"Error Handling","text":""},{"location":"crates/nori-wal/api-reference/record/#recorderror","title":"<code>RecordError</code>","text":"<p>Errors that can occur during record encoding/decoding.</p> <p>View source</p> <p>Variants:</p> Variant Description <code>Io(io::Error)</code> I/O error (e.g., varint overflow) <code>CrcMismatch { expected, actual }</code> Checksum validation failed <code>InvalidCompression(u8)</code> Unknown compression type byte <code>CompressionFailed(String)</code> Compression error (shouldn't happen) <code>DecompressionFailed(String)</code> Decompression error (data corruption) <code>Incomplete</code> Not enough bytes to decode record <p>Examples:</p> <pre><code>use nori_wal::{Record, RecordError};\n\nmatch Record::decode(data) {\n    Ok((record, _)) =&gt; { /* success */ }\n    Err(RecordError::CrcMismatch { expected, actual }) =&gt; {\n        // Corruption detected\n        log::error!(\"CRC mismatch: expected {:#x}, got {:#x}\", expected, actual);\n    }\n    Err(RecordError::Incomplete) =&gt; {\n        // Need more data (normal for streaming)\n    }\n    Err(RecordError::DecompressionFailed(msg)) =&gt; {\n        // Compressed data is corrupt\n        log::error!(\"Decompression failed: {}\", msg);\n    }\n    Err(e) =&gt; {\n        log::error!(\"Decode error: {}\", e);\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/record/#wire-format-details","title":"Wire Format Details","text":""},{"location":"crates/nori-wal/api-reference/record/#record-format","title":"Record Format","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 klen (varint)          \u2502 1-10 bytes             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 vlen (varint)          \u2502 1-10 bytes             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 flags (u8)             \u2502 1 byte                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ttl_ms (varint)        \u2502 0 or 1-10 bytes        \u2502 (if TTL_PRESENT bit set)\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 key                    \u2502 klen bytes             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 value                  \u2502 vlen bytes             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 crc32c (u32 LE)        \u2502 4 bytes                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"crates/nori-wal/api-reference/record/#flags-byte","title":"Flags Byte","text":"<pre><code> 7  6  5  4  3  2  1  0\n\u250c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2510\n\u2502 Reserved \u2502Cmp\u2502TL\u2502TS\u2502\n\u2514\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2518\n            \u2502 \u2502  \u2502  \u2514\u2500 Tombstone (0=PUT, 1=DELETE)\n            \u2502 \u2502  \u2514\u2500\u2500\u2500\u2500 TTL present (0=no, 1=yes)\n            \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Compression (00=None, 01=LZ4, 10=Zstd, 11=reserved)\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Reserved (must be 0)\n</code></pre>"},{"location":"crates/nori-wal/api-reference/record/#compression-details","title":"Compression Details","text":"<p>LZ4 Compressed Value: <pre><code>[original_size: varint][compressed_data]\n</code></pre></p> <p>Zstd Compressed Value: <pre><code>[compressed_data]  (zstd frame includes original size)\n</code></pre></p>"},{"location":"crates/nori-wal/api-reference/record/#size-examples","title":"Size Examples","text":"<p>Minimal record (empty key/value, no TTL): <pre><code>1 + 1 + 1 + 4 = 7 bytes\n</code></pre></p> <p>Typical record (<code>key=\"user:123\"</code>, <code>value=\"Alice\"</code>): <pre><code>1 (klen) + 1 (vlen) + 1 (flags) + 8 (key) + 5 (value) + 4 (crc) = 20 bytes\n</code></pre></p> <p>Record with TTL (add ~2-5 bytes): <pre><code>1 (klen) + 1 (vlen) + 1 (flags) + 3 (ttl) + key + value + 4 (crc)\n</code></pre></p>"},{"location":"crates/nori-wal/api-reference/record/#usage-patterns","title":"Usage Patterns","text":""},{"location":"crates/nori-wal/api-reference/record/#basic-putdelete","title":"Basic PUT/DELETE","text":"<pre><code>use nori_wal::{Wal, Record, WalConfig};\n\nlet wal = Wal::open(WalConfig::default()).await?;\n\n// Write a key-value pair\nlet record = Record::put(b\"user:123\", b\"Alice\");\nwal.append(&amp;record).await?;\n\n// Delete a key\nlet record = Record::delete(b\"user:456\");\nwal.append(&amp;record).await?;\n</code></pre>"},{"location":"crates/nori-wal/api-reference/record/#ttl-for-caching","title":"TTL for Caching","text":"<pre><code>use std::time::Duration;\n\n// Cache entry expires in 5 minutes\nlet record = Record::put_with_ttl(\n    b\"cache:expensive_query\",\n    b\"cached result\",\n    Duration::from_secs(300),\n);\n\nwal.append(&amp;record).await?;\n\n// Later, check if expired\nif let Some(ttl) = record.ttl {\n    let elapsed = SystemTime::now().duration_since(creation_time)?;\n    if elapsed &gt; ttl {\n        println!(\"Record expired!\");\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/record/#compression-for-large-values","title":"Compression for Large Values","text":"<pre><code>use nori_wal::Compression;\n\n// Large JSON document\nlet json = serde_json::to_vec(&amp;large_object)?;\n\nlet record = Record::put(b\"document:123\", json)\n    .with_compression(Compression::Zstd);\n\nwal.append(&amp;record).await?;\n</code></pre>"},{"location":"crates/nori-wal/api-reference/record/#batched-writes","title":"Batched Writes","text":"<pre><code>let records = vec![\n    Record::put(b\"k1\", b\"v1\"),\n    Record::put(b\"k2\", b\"v2\"),\n    Record::put(b\"k3\", b\"v3\"),\n];\n\nfor record in records {\n    wal.append(&amp;record).await?;\n}\n\n// Sync once for all records\nwal.sync().await?;\n</code></pre>"},{"location":"crates/nori-wal/api-reference/record/#recovery-from-wal","title":"Recovery from WAL","text":"<pre><code>use nori_wal::{Wal, WalConfig, Position};\nuse std::collections::HashMap;\n\n// Replay WAL to reconstruct state\nlet wal = Wal::open(WalConfig::default()).await?;\nlet mut state: HashMap&lt;Vec&lt;u8&gt;, Vec&lt;u8&gt;&gt; = HashMap::new();\n\nlet mut reader = wal.read_from(Position::start()).await?;\nwhile let Some((record, _pos)) = reader.next_record().await? {\n    if record.tombstone {\n        state.remove(&amp;record.key.to_vec());\n    } else {\n        state.insert(record.key.to_vec(), record.value.to_vec());\n    }\n}\n\nprintln!(\"Recovered {} keys\", state.len());\n</code></pre>"},{"location":"crates/nori-wal/api-reference/record/#best-practices","title":"Best Practices","text":""},{"location":"crates/nori-wal/api-reference/record/#1-choose-appropriate-compression","title":"1. Choose Appropriate Compression","text":"<pre><code>// GOOD: Compress large, repetitive data\nlet large_json = serde_json::to_vec(&amp;data)?;\nif large_json.len() &gt; 1000 {\n    Record::put(key, large_json).with_compression(Compression::Lz4)\n} else {\n    Record::put(key, large_json)\n}\n\n// BAD: Compress already compressed data\nlet jpeg = fs::read(\"photo.jpg\")?;\nRecord::put(b\"photo\", jpeg).with_compression(Compression::Lz4) // Wastes CPU\n</code></pre>"},{"location":"crates/nori-wal/api-reference/record/#2-handle-ttl-properly","title":"2. Handle TTL Properly","text":"<pre><code>// GOOD: Application enforces TTL\nstruct CacheEntry {\n    record: Record,\n    inserted_at: SystemTime,\n}\n\nimpl CacheEntry {\n    fn is_expired(&amp;self) -&gt; bool {\n        if let Some(ttl) = self.record.ttl {\n            self.inserted_at.elapsed().unwrap() &gt; ttl\n        } else {\n            false\n        }\n    }\n}\n\n// BAD: Assuming WAL auto-expires records\n// (it doesn't - TTL is just metadata)\n</code></pre>"},{"location":"crates/nori-wal/api-reference/record/#3-use-tombstones-correctly","title":"3. Use Tombstones Correctly","text":"<pre><code>// GOOD: Tombstone to mark deletion\nmemtable.insert(key, value);\nwal.append(&amp;Record::put(key, value)).await?;\n\n// Later, to delete:\nmemtable.remove(key);\nwal.append(&amp;Record::delete(key)).await?;\n\n// BAD: Overwriting with empty value\nwal.append(&amp;Record::put(key, b\"\")).await? // Not a deletion!\n</code></pre>"},{"location":"crates/nori-wal/api-reference/record/#4-validate-after-decode","title":"4. Validate After Decode","text":"<pre><code>// GOOD: Check CRC on recovery\nmatch Record::decode(data) {\n    Ok((record, size)) =&gt; {\n        // CRC validated automatically\n        process(record);\n    }\n    Err(RecordError::CrcMismatch { .. }) =&gt; {\n        log::warn!(\"Skipping corrupt record at offset {}\", offset);\n        // Continue or abort recovery\n    }\n    Err(e) =&gt; return Err(e.into()),\n}\n\n// BAD: Skipping CRC check (don't do this)\n// (decode() always validates CRC)\n</code></pre>"},{"location":"crates/nori-wal/api-reference/record/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"crates/nori-wal/api-reference/record/#encoding-performance","title":"Encoding Performance","text":"Operation Time Notes <code>encode()</code> (no compression) ~100-200ns Varint + copy + CRC <code>encode()</code> (LZ4, 1KB value) ~2-5\u00b5s Fast compression <code>encode()</code> (Zstd, 1KB value) ~10-50\u00b5s Slower, better ratio"},{"location":"crates/nori-wal/api-reference/record/#decoding-performance","title":"Decoding Performance","text":"Operation Time Notes <code>decode()</code> (no compression) ~100-200ns Varint + copy + CRC <code>decode()</code> (LZ4, 1KB value) ~1-3\u00b5s Fast decompression <code>decode()</code> (Zstd, 1KB value) ~5-20\u00b5s Slower decompression"},{"location":"crates/nori-wal/api-reference/record/#memory-efficiency","title":"Memory Efficiency","text":"<ul> <li>Zero-copy: Uses <code>Bytes</code> (reference-counted) for key/value</li> <li>Shared buffers: Cloning a <code>Record</code> only increments refcount</li> <li>Compression: Can reduce memory footprint 3-10x for text data</li> </ul>"},{"location":"crates/nori-wal/api-reference/record/#see-also","title":"See Also","text":"<ul> <li>Wal API - Main WAL interface</li> <li>WalConfig API - Configuration options</li> <li>RecordError - Error handling</li> <li>How It Works: Record Format - Deep dive into wire format</li> <li>Core Concepts: Append-Only - Why records are immutable</li> </ul>"},{"location":"crates/nori-wal/api-reference/wal/","title":"Wal","text":"<p>Main WAL interface for append-only logging with automatic recovery and rotation.</p>"},{"location":"crates/nori-wal/api-reference/wal/#table-of-contents","title":"Table of contents","text":""},{"location":"crates/nori-wal/api-reference/wal/#type-definition","title":"Type Definition","text":"<pre><code>pub struct Wal: Send + Sync\n</code></pre> <p>The main write-ahead log type. Provides methods for: - Appending records - Syncing to disk - Reading records - Garbage collection</p> <p>Thread Safety: <code>Wal</code> is <code>Send + Sync</code> and can be safely shared across threads using <code>Arc&lt;Wal&gt;</code>.</p>"},{"location":"crates/nori-wal/api-reference/wal/#constructor-methods","title":"Constructor Methods","text":""},{"location":"crates/nori-wal/api-reference/wal/#walopen","title":"<code>Wal::open</code>","text":"<pre><code>pub async fn open(config: WalConfig) -&gt; Result&lt;(Self, RecoveryInfo), SegmentError&gt;\n</code></pre> <p>Opens a WAL, performing automatic recovery if needed.</p> <p>Parameters: - <code>config</code>: Configuration for the WAL</p> <p>Returns: - <code>Ok((Wal, RecoveryInfo))</code>: Opened WAL and recovery statistics - <code>Err(SegmentError)</code>: If opening failed</p> <p>What it does: 1. Validates configuration 2. Creates WAL directory if it doesn't exist 3. Scans existing segments and recovers valid records 4. Truncates any corrupted data 5. Resumes writing from the last valid position</p> <p>Example: <pre><code>use nori_wal::{Wal, WalConfig};\n\nlet config = WalConfig::default();\nlet (wal, recovery_info) = Wal::open(config).await?;\n\nprintln!(\"Recovered {} records\", recovery_info.valid_records);\n\nif recovery_info.corruption_detected {\n    log::warn!(\"Truncated {} bytes\", recovery_info.bytes_truncated);\n}\n</code></pre></p> <p>Errors: - <code>SegmentError::InvalidConfig</code>: Invalid configuration - <code>SegmentError::Io</code>: I/O error (disk full, permissions, etc.)</p>"},{"location":"crates/nori-wal/api-reference/wal/#walopen_with_meter","title":"<code>Wal::open_with_meter</code>","text":"<pre><code>pub async fn open_with_meter(\n    config: WalConfig,\n    meter: Arc&lt;dyn Meter&gt;,\n) -&gt; Result&lt;(Self, RecoveryInfo), SegmentError&gt;\n</code></pre> <p>Opens a WAL with custom observability.</p> <p>Parameters: - <code>config</code>: Configuration for the WAL - <code>meter</code>: Custom metrics collector (implements <code>nori_observe::Meter</code>)</p> <p>Returns: Same as <code>Wal::open</code></p> <p>Use when: - Integrating with custom metrics systems - Emitting events to dashboards - Advanced monitoring/debugging</p> <p>Example: <pre><code>use nori_wal::Wal;\nuse std::sync::Arc;\n\nlet meter = Arc::new(MyCustomMeter::new());\nlet (wal, info) = Wal::open_with_meter(config, meter).await?;\n</code></pre></p>"},{"location":"crates/nori-wal/api-reference/wal/#write-methods","title":"Write Methods","text":""},{"location":"crates/nori-wal/api-reference/wal/#append","title":"<code>append</code>","text":"<pre><code>pub async fn append(&amp;self, record: &amp;Record) -&gt; Result&lt;Position, SegmentError&gt;\n</code></pre> <p>Appends a single record to the WAL.</p> <p>Parameters: - <code>record</code>: The record to append</p> <p>Returns: - <code>Ok(Position)</code>: Where the record was written (segment ID + offset) - <code>Err(SegmentError)</code>: If append failed</p> <p>Behavior: - Record is encoded and written to the active segment - Segment rotates automatically if size limit reached - Fsync behavior depends on <code>FsyncPolicy</code> - Thread-safe: multiple threads can call concurrently (serialized internally)</p> <p>Example: <pre><code>use nori_wal::{Record, Position};\n\nlet record = Record::put(b\"user:123\", b\"alice@example.com\");\nlet position = wal.append(&amp;record).await?;\n\nprintln!(\"Wrote record at {:?}\", position);\n// Output: Wrote record at Position { segment_id: 0, offset: 1024 }\n</code></pre></p> <p>Performance: - Without fsync: ~10-50\u03bcs - With fsync (Always policy): ~1-5ms - With fsync (Batch policy): ~10-50\u03bcs (most writes), ~1-5ms (periodic)</p>"},{"location":"crates/nori-wal/api-reference/wal/#append_batch","title":"<code>append_batch</code>","text":"<pre><code>pub async fn append_batch(&amp;self, records: &amp;[Record]) -&gt; Result&lt;Vec&lt;Position&gt;, SegmentError&gt;\n</code></pre> <p>Appends multiple records in a batch.</p> <p>Parameters: - <code>records</code>: Slice of records to append</p> <p>Returns: - <code>Ok(Vec&lt;Position&gt;)</code>: Positions where each record was written - <code>Err(SegmentError)</code>: If batch append failed</p> <p>Benefits over repeated <code>append()</code>: - Acquires lock only once (not once per record) - Single fsync for entire batch (with <code>Always</code> policy) - Sequential writes without interleaving from other threads</p> <p>Example: <pre><code>let records = vec![\n    Record::put(b\"key1\", b\"value1\"),\n    Record::put(b\"key2\", b\"value2\"),\n    Record::put(b\"key3\", b\"value3\"),\n];\n\nlet positions = wal.append_batch(&amp;records).await?;\n\nfor (i, pos) in positions.iter().enumerate() {\n    println!(\"Record {} at {:?}\", i, pos);\n}\n</code></pre></p> <p>Performance: <pre><code>Single append:      1000 records = 1000 lock acquisitions, 1000 fsyncs (Always)\nBatch append:       1000 records = 1 lock acquisition, 1 fsync (Always)\nSpeedup:            ~100-1000x for large batches with Always policy\n</code></pre></p>"},{"location":"crates/nori-wal/api-reference/wal/#sync-methods","title":"Sync Methods","text":""},{"location":"crates/nori-wal/api-reference/wal/#flush","title":"<code>flush</code>","text":"<pre><code>pub async fn flush(&amp;self) -&gt; Result&lt;(), SegmentError&gt;\n</code></pre> <p>Flushes buffered data to the OS (but doesn't call fsync).</p> <p>Use when: - You want data in OS cache but don't need disk persistence yet - Rarely needed (OS handles buffering efficiently)</p> <p>Example: <pre><code>wal.append(&amp;record).await?;\nwal.flush().await?;  // Data in OS cache, not on disk yet\n</code></pre></p> <p>Warning: <code>flush()</code> does NOT guarantee durability! Use <code>sync()</code> for that.</p>"},{"location":"crates/nori-wal/api-reference/wal/#sync","title":"<code>sync</code>","text":"<pre><code>pub async fn sync(&amp;self) -&gt; Result&lt;(), SegmentError&gt;\n</code></pre> <p>Syncs all data to physical disk (fsync).</p> <p>Guarantees: - All previously appended records are durable - Survives power failure after this returns</p> <p>Use when: - Using <code>FsyncPolicy::Os</code> and need manual durability - End of a logical transaction - Before shutting down</p> <p>Example: <pre><code>// Write a batch\nfor record in records {\n    wal.append(&amp;record).await?;\n}\n\n// Ensure all durable\nwal.sync().await?;\n</code></pre></p> <p>Performance: ~1-5ms on SSD</p>"},{"location":"crates/nori-wal/api-reference/wal/#read-methods","title":"Read Methods","text":""},{"location":"crates/nori-wal/api-reference/wal/#read_from","title":"<code>read_from</code>","text":"<pre><code>pub async fn read_from(\n    &amp;self,\n    position: Position,\n) -&gt; Result&lt;SegmentReader, SegmentError&gt;\n</code></pre> <p>Creates a reader starting at the given position.</p> <p>Parameters: - <code>position</code>: Where to start reading (segment ID + offset)</p> <p>Returns: - <code>Ok(SegmentReader)</code>: Iterator over records - <code>Err(SegmentError)</code>: If position is invalid or segment missing</p> <p>Example: <pre><code>use nori_wal::Position;\n\n// Read from beginning\nlet mut reader = wal.read_from(Position { segment_id: 0, offset: 0 }).await?;\n\nwhile let Some((record, position)) = reader.next_record().await? {\n    println!(\"Record at {:?}: key={:?}\", position, record.key);\n}\n</code></pre></p> <p>Use cases: - Replaying the entire log (position = <code>Position::start()</code>) - Resuming from last processed position - Replication (followers read from leader's position)</p> <p>Performance: ~200K records/sec sequential read</p>"},{"location":"crates/nori-wal/api-reference/wal/#current_position","title":"<code>current_position</code>","text":"<pre><code>pub async fn current_position(&amp;self) -&gt; Position\n</code></pre> <p>Returns the current write position (where next record will be written).</p> <p>Returns: <code>Position</code> of the next write</p> <p>Example: <pre><code>let pos_before = wal.current_position().await;\nwal.append(&amp;record).await?;\nlet pos_after = wal.current_position().await;\n\nassert!(pos_after &gt; pos_before);\n</code></pre></p> <p>Use when: - Tracking progress for replication - Checkpointing - Testing</p>"},{"location":"crates/nori-wal/api-reference/wal/#management-methods","title":"Management Methods","text":""},{"location":"crates/nori-wal/api-reference/wal/#delete_segments_before","title":"<code>delete_segments_before</code>","text":"<pre><code>pub async fn delete_segments_before(&amp;self, position: Position) -&gt; Result&lt;u64, SegmentError&gt;\n</code></pre> <p>Deletes all segments before the given position.</p> <p>Parameters: - <code>position</code>: Delete all segments before this position</p> <p>Returns: - <code>Ok(count)</code>: Number of segments deleted - <code>Err(SegmentError)</code>: If deletion failed</p> <p>Safety Requirements: IMPORTANT: Caller must ensure data is no longer needed before deleting!</p> <p>Typical workflow: 1. Compact old segments into new format (e.g., SSTables) 2. Verify compaction succeeded 3. Delete old segments</p> <p>Example: <pre><code>// Compact segments 0-9 into SSTable\ncompact_to_sstable(0..10).await?;\n\n// Safe to delete old segments\nlet cutoff = Position { segment_id: 10, offset: 0 };\nlet deleted = wal.delete_segments_before(cutoff).await?;\n\nprintln!(\"Deleted {} old segments\", deleted);\n</code></pre></p> <p>What gets deleted: <pre><code>Before:\n  000000.wal  \u2190 Delete\n  000001.wal  \u2190 Delete\n  ...\n  000009.wal  \u2190 Delete\n  000010.wal  \u2190 Keep (cutoff segment)\n  000011.wal  \u2190 Keep (active segment)\n\nAfter:\n  000010.wal\n  000011.wal\n</code></pre></p> <p>Cannot delete: - Active segment (currently being written to) - Segments at or after the cutoff position</p>"},{"location":"crates/nori-wal/api-reference/wal/#close","title":"<code>close</code>","text":"<pre><code>pub async fn close(self) -&gt; Result&lt;(), SegmentError&gt;\n</code></pre> <p>Gracefully closes the WAL, ensuring all data is durable.</p> <p>What it does: 1. Syncs any pending data to disk 2. Finalizes the current segment (truncates to actual size) 3. Consumes the <code>Wal</code> (can't be used after)</p> <p>Use when: - Shutting down application - Want to ensure clean shutdown</p> <p>Example: <pre><code>// Write data\nwal.append(&amp;record).await?;\n\n// Graceful shutdown\nwal.close().await?;\n\n// wal is consumed, can't use anymore\n</code></pre></p> <p>Alternative: Just drop the <code>Wal</code>. The <code>Drop</code> impl will do best-effort finalization.</p>"},{"location":"crates/nori-wal/api-reference/wal/#accessor-methods","title":"Accessor Methods","text":""},{"location":"crates/nori-wal/api-reference/wal/#config","title":"<code>config</code>","text":"<pre><code>pub fn config(&amp;self) -&gt; &amp;WalConfig\n</code></pre> <p>Returns a reference to the WAL configuration.</p> <p>Returns: <code>&amp;WalConfig</code></p> <p>Example: <pre><code>let cfg = wal.config();\nprintln!(\"Max segment size: {} MB\", cfg.max_segment_size / (1024 * 1024));\nprintln!(\"Fsync policy: {:?}\", cfg.fsync_policy);\n</code></pre></p>"},{"location":"crates/nori-wal/api-reference/wal/#complete-example","title":"Complete Example","text":"<pre><code>use nori_wal::{Wal, WalConfig, Record, Position, FsyncPolicy};\nuse std::time::Duration;\nuse std::path::PathBuf;\n\n#[tokio::main]\nasync fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {\n    // 1. Configure WAL\n    let config = WalConfig {\n        dir: PathBuf::from(\"/var/lib/myapp/wal\"),\n        max_segment_size: 256 * 1024 * 1024,  // 256 MB\n        fsync_policy: FsyncPolicy::Batch(Duration::from_millis(10)),\n        preallocate: true,\n        node_id: 1,\n    };\n\n    // 2. Open with recovery\n    let (wal, recovery_info) = Wal::open(config).await?;\n\n    println!(\"Recovered {} records\", recovery_info.valid_records);\n\n    // 3. Write records\n    let records = vec![\n        Record::put(b\"user:1\", b\"alice@example.com\"),\n        Record::put(b\"user:2\", b\"bob@example.com\"),\n        Record::delete(b\"user:1\"),  // Tombstone\n    ];\n\n    let positions = wal.append_batch(&amp;records).await?;\n\n    // 4. Explicitly sync (if using Os policy)\n    wal.sync().await?;\n\n    // 5. Read back\n    let mut reader = wal.read_from(Position { segment_id: 0, offset: 0 }).await?;\n\n    while let Some((record, position)) = reader.next_record().await? {\n        if record.tombstone {\n            println!(\"DELETE {:?} at {:?}\", record.key, position);\n        } else {\n            println!(\"PUT {:?}={:?} at {:?}\", record.key, record.value, position);\n        }\n    }\n\n    // 6. Garbage collection (after compaction)\n    // let deleted = wal.delete_segments_before(cutoff).await?;\n\n    // 7. Graceful shutdown\n    wal.close().await?;\n\n    Ok(())\n}\n</code></pre>"},{"location":"crates/nori-wal/api-reference/wal/#error-handling","title":"Error Handling","text":"<p>All methods return <code>Result&lt;T, SegmentError&gt;</code>. Common errors:</p> Error Cause How to Handle <code>SegmentError::Io(e)</code> Disk full, permissions, etc. Check disk space, permissions <code>SegmentError::InvalidConfig(msg)</code> Bad configuration Fix config values <code>SegmentError::NotFound(id)</code> Segment doesn't exist Normal after deletion <code>SegmentError::Record(e)</code> Record decode error Check for corruption <p>Example: <pre><code>match wal.append(&amp;record).await {\n    Ok(pos) =&gt; println!(\"Success: {:?}\", pos),\n    Err(SegmentError::Io(e)) if e.kind() == io::ErrorKind::OutOfMemory =&gt; {\n        panic!(\"Out of disk space!\");\n    }\n    Err(e) =&gt; {\n        log::error!(\"Append failed: {}\", e);\n        return Err(e);\n    }\n}\n</code></pre></p>"},{"location":"crates/nori-wal/api-reference/wal/#thread-safety","title":"Thread Safety","text":"<p><code>Wal</code> is <code>Send + Sync</code>, so you can share it across threads:</p> <pre><code>use std::sync::Arc;\n\nlet wal = Arc::new(wal);\n\n// Spawn multiple writers\nfor i in 0..4 {\n    let wal = wal.clone();\n    tokio::spawn(async move {\n        let record = Record::put(format!(\"key{}\", i).as_bytes(), b\"value\");\n        wal.append(&amp;record).await.unwrap();\n    });\n}\n\n// Spawn a reader\nlet wal_reader = wal.clone();\ntokio::spawn(async move {\n    let mut reader = wal_reader.read_from(Position::start()).await.unwrap();\n    while let Some((record, _)) = reader.next_record().await.unwrap() {\n        println!(\"Read: {:?}\", record.key);\n    }\n});\n</code></pre> <p>Concurrency behavior: - Writes are serialized (only one thread writes at a time) - Reads don't block writes (and vice versa) - Multiple readers can run concurrently</p> <p>See Concurrency Model for details.</p>"},{"location":"crates/nori-wal/api-reference/wal/#performance-characteristics","title":"Performance Characteristics","text":"Operation Latency Throughput <code>append()</code> (no fsync) 10-50\u03bcs ~110K ops/sec <code>append()</code> (batch fsync) 10-50\u03bcs (avg) ~86K ops/sec <code>append()</code> (always fsync) 1-5ms ~420 ops/sec <code>append_batch(100)</code> (always fsync) ~5ms total ~20K records/sec <code>sync()</code> 1-5ms - <code>read_from() + iterate</code> ~5\u03bcs per record ~200K records/sec <p>See Performance Tuning for optimization tips.</p>"},{"location":"crates/nori-wal/api-reference/wal/#see-also","title":"See Also","text":"<ul> <li>WalConfig - Configuration options</li> <li>Record - Record types</li> <li>Position - Position in the log</li> <li>RecoveryInfo - Recovery statistics</li> <li>Errors - Error types</li> </ul>"},{"location":"crates/nori-wal/core-concepts/","title":"Core Concepts","text":"<p>Fundamental concepts you need to understand to use nori-wal effectively.</p>"},{"location":"crates/nori-wal/core-concepts/#what-youll-learn","title":"What You'll Learn","text":"<p>This section covers the essential concepts behind write-ahead logs:</p>"},{"location":"crates/nori-wal/core-concepts/#what-is-a-write-ahead-log","title":"What is a Write-Ahead Log?","text":"<p>The fundamental concept of WALs, why they exist, and how they're used in modern systems.</p>"},{"location":"crates/nori-wal/core-concepts/#append-only-architecture","title":"Append-Only Architecture","text":"<p>Why WALs are append-only and what that means for your application.</p>"},{"location":"crates/nori-wal/core-concepts/#durability-fsync-policies","title":"Durability &amp; Fsync Policies","text":"<p>How to balance durability and performance with different fsync strategies.</p>"},{"location":"crates/nori-wal/core-concepts/#recovery-guarantees","title":"Recovery Guarantees","text":"<p>What happens after a crash and what guarantees you can rely on.</p>"},{"location":"crates/nori-wal/core-concepts/#when-to-use-a-wal","title":"When to Use a WAL","text":"<p>Scenarios where WALs shine and where they don't.</p>"},{"location":"crates/nori-wal/core-concepts/#prerequisites","title":"Prerequisites","text":"<p>Before diving into these concepts, you should:</p> <ul> <li>Know basic Rust (async/await, Result types)</li> <li>Understand what \"durability\" means in databases</li> <li>Have completed the Quickstart</li> </ul>"},{"location":"crates/nori-wal/core-concepts/#quick-concept-check","title":"Quick Concept Check","text":"<p>Test your understanding with these questions:</p> <p>Q: What does \"write-ahead\" mean?</p> Click to reveal answer <p>It means you write to the log before updating your main data structures. The log is the source of truth - if you crash before applying changes, you can replay the log to recover.</p> <p>Q: Why use append-only storage?</p> Click to reveal answer <p>Append-only is simple and fast: no complex in-place updates, no corruption from partial writes, easy to reason about. Trade-off: you need compaction/garbage collection eventually.</p> <p>Q: What's the difference between <code>fsync()</code> and <code>flush()</code>?</p> Click to reveal answer <ul> <li><code>flush()</code>: Writes data from application buffer to OS buffer (not durable!)</li> <li><code>fsync()</code>: Forces OS to write buffers to physical disk (durable!)</li> </ul> <p>Only <code>fsync()</code> guarantees durability.</p>"},{"location":"crates/nori-wal/core-concepts/#learning-path","title":"Learning Path","text":"<p>Recommended order:</p> <ol> <li>Start here: What is a WAL?</li> <li>Understand Append-Only Architecture</li> <li>Learn about Durability &amp; Fsync</li> <li>Grasp Recovery Guarantees</li> <li>Apply knowledge: When to Use a WAL</li> </ol> <p>Then move on to How It Works for deeper technical details.</p>"},{"location":"crates/nori-wal/core-concepts/append-only/","title":"Append-Only Architecture","text":"<p>Why WALs are append-only, what that means for your application, and the trade-offs involved.</p>"},{"location":"crates/nori-wal/core-concepts/append-only/#table-of-contents","title":"Table of contents","text":""},{"location":"crates/nori-wal/core-concepts/append-only/#what-does-append-only-mean","title":"What Does \"Append-Only\" Mean?","text":"<p>An append-only data structure is one where you can only add new data at the end. You cannot:</p> <ul> <li>Modify existing data in place</li> <li>Delete data in place</li> <li>Insert data in the middle</li> </ul> <p>You can only append to the end.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 [Record 1][Record 2][Record 3]          \u2502  \u2190 Can only append here\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2191\n   Cannot modify or delete these!\n</code></pre> <p>In nori-wal, this means: - New records are always written at the end of the current segment - Old records are never modified - Deletions are represented as tombstone records (append a delete marker) - Updates are represented as new versions (append a new PUT for the same key)</p>"},{"location":"crates/nori-wal/core-concepts/append-only/#why-append-only","title":"Why Append-Only?","text":"<p>Append-only seems limiting at first. Why not just update records in place?</p>"},{"location":"crates/nori-wal/core-concepts/append-only/#reason-1-sequential-io-is-fast","title":"Reason 1: Sequential I/O is Fast","text":"<p>Modern storage (SSDs, HDDs, NVMe) is orders of magnitude faster for sequential writes than random writes.</p> <p>Hard Disk Drives (HDD): - Sequential write: ~100-200 MB/s - Random write: ~1-5 MB/s (40x slower!)</p> <p>Solid State Drives (SSD): - Sequential write: ~500-3000 MB/s - Random write: ~50-300 MB/s (10x slower) - Plus: Random writes cause write amplification, shortening SSD lifespan</p> <p>NVMe SSD: - Sequential write: ~3000-7000 MB/s - Random write: ~500-2000 MB/s (still slower!)</p> <p>By appending to a log, we only do sequential writes. This is the fastest possible I/O pattern.</p> <pre><code>graph LR\n    A[Application] --&gt;|append| B[Log File]\n    B --&gt;|sequential writes| C[Disk]\n\n    style C fill:#90EE90</code></pre>"},{"location":"crates/nori-wal/core-concepts/append-only/#reason-2-no-partial-write-corruption","title":"Reason 2: No Partial Write Corruption","text":"<p>When you write to a file in place, you can corrupt data if you crash mid-write:</p> <p>In-Place Update (BAD): <pre><code>Before:  [Record A: \"user:1=alice\"]\nWriting: [Record A: \"user:1=bob--\"]  \u2190 CRASH!\nAfter:   [Record A: \"user:1=bob--\"]  \u2190 Corrupted!\n</code></pre></p> <p>You now have a partially written record. Is the user \"bob\" or \"alice\"? You don't know.</p> <p>Append-Only (GOOD): <pre><code>Before:  [Record 1: \"user:1=alice\"][empty space]\nWriting: [Record 1: \"user:1=alice\"][Record 2: \"user:1=bob--\"]  \u2190 CRASH!\nAfter:   [Record 1: \"user:1=alice\"][partial garbage]\n\nRecovery: Scan log, validate CRCs\n  - Record 1: Yes Valid CRC \u2192 Keep\n  - Record 2: No Invalid CRC \u2192 Truncate\n\nFinal:   [Record 1: \"user:1=alice\"]\n</code></pre></p> <p>With append-only, you can never corrupt old data. The worst that can happen is you have a partial record at the tail, which you detect with CRC32C and truncate.</p>"},{"location":"crates/nori-wal/core-concepts/append-only/#reason-3-simple-and-correct","title":"Reason 3: Simple and Correct","text":"<p>Append-only is conceptually simple. There's no complex logic for:</p> <ul> <li>Managing free space within a file</li> <li>Defragmenting after deletes</li> <li>Handling variable-length records</li> <li>Ensuring atomic in-place updates</li> </ul> <p>The code is straightforward:</p> <pre><code>// Append-only: Simple!\nasync fn append(&amp;mut self, record: &amp;Record) -&gt; Result&lt;Position&gt; {\n    let position = self.current_offset;\n    let bytes = serialize(record)?;\n\n    self.file.write_all(&amp;bytes).await?;\n    self.current_offset += bytes.len() as u64;\n\n    Ok(position)\n}\n</code></pre> <p>Compare this to the complexity of in-place updates:</p> <pre><code>// In-place update: Complex!\nasync fn update_in_place(&amp;mut self, position: u64, new_record: &amp;Record) -&gt; Result&lt;()&gt; {\n    let new_bytes = serialize(new_record)?;\n    let old_bytes = self.read_at(position).await?;\n\n    // What if new record is larger than old?\n    if new_bytes.len() &gt; old_bytes.len() {\n        // Need to relocate! But where?\n        // Need to update all pointers to this record!\n        // What if we crash during relocation?\n        // ...this is getting complicated\n    }\n\n    // What if new record is smaller?\n    if new_bytes.len() &lt; old_bytes.len() {\n        // Fragmentation! Need a free list? Compaction?\n    }\n\n    // Atomic update: need double-buffering or copy-on-write?\n    // Error handling is now much harder...\n}\n</code></pre> <p>Simple code is correct code.</p>"},{"location":"crates/nori-wal/core-concepts/append-only/#reason-4-crash-recovery-is-easier","title":"Reason 4: Crash Recovery is Easier","text":"<p>With append-only, recovery is a simple scan:</p> <pre><code>async fn recover(&amp;mut self) -&gt; Result&lt;RecoveryInfo&gt; {\n    let mut position = 0;\n    let mut valid_records = 0;\n\n    loop {\n        // Try to read a record at this position\n        match self.read_record_at(position).await {\n            Ok((record, size)) =&gt; {\n                // Valid record, keep it\n                valid_records += 1;\n                position += size;\n            }\n            Err(_) =&gt; {\n                // Invalid record (partial write or corruption)\n                // Truncate everything after this point\n                self.truncate(position).await?;\n                break;\n            }\n        }\n    }\n\n    Ok(RecoveryInfo {\n        valid_records,\n        bytes_truncated: self.file_size - position,\n    })\n}\n</code></pre> <p>This is called \"prefix-valid\" recovery: keep all valid records from the beginning until we hit corruption, then truncate the rest.</p> <p>With in-place updates, recovery is much harder: - Which version of a record is correct? - How do you know if an update completed? - Do you need a transaction log? (Isn't that just... a WAL?)</p>"},{"location":"crates/nori-wal/core-concepts/append-only/#how-append-only-affects-your-application","title":"How Append-Only Affects Your Application","text":"<p>If nori-wal is append-only, how do you handle updates and deletes?</p>"},{"location":"crates/nori-wal/core-concepts/append-only/#updates-write-a-new-version","title":"Updates: Write a New Version","text":"<p>When you update a key, you append a new record with the same key:</p> <pre><code>// Initial write\nlet record = Record::put(b\"user:1\", b\"alice@example.com\");\nwal.append(&amp;record).await?;\n\n// Update: append a new version\nlet record = Record::put(b\"user:1\", b\"bob@example.com\");  // Same key!\nwal.append(&amp;record).await?;\n</code></pre> <p>On disk: <pre><code>[Record 1: user:1=alice@example.com]\n[Record 2: user:1=bob@example.com]    \u2190 Newer version\n</code></pre></p> <p>During recovery, you keep the latest version:</p> <pre><code>let mut state = HashMap::new();\n\nwhile let Some((record, _)) = reader.next_record().await? {\n    // Later records shadow earlier ones\n    state.insert(record.key, record.value);\n}\n\n// Result: user:1 \u2192 bob@example.com\n</code></pre>"},{"location":"crates/nori-wal/core-concepts/append-only/#deletes-write-a-tombstone","title":"Deletes: Write a Tombstone","text":"<p>When you delete a key, you append a tombstone record:</p> <pre><code>let record = Record::delete(b\"user:1\");  // Tombstone\nwal.append(&amp;record).await?;\n</code></pre> <p>A tombstone is a record with the <code>tombstone</code> flag set and no value:</p> <pre><code>[Record 1: user:1=alice@example.com]\n[Record 2: user:1=bob@example.com]\n[Record 3: user:1=(tombstone)]         \u2190 Deleted\n</code></pre> <p>During recovery:</p> <pre><code>while let Some((record, _)) = reader.next_record().await? {\n    if record.tombstone {\n        state.remove(&amp;record.key);  // Delete from state\n    } else {\n        state.insert(record.key, record.value);\n    }\n}\n\n// Result: user:1 does not exist\n</code></pre>"},{"location":"crates/nori-wal/core-concepts/append-only/#the-cost-garbage-collection","title":"The Cost: Garbage Collection","text":"<p>Append-only has a major downside: the log grows forever.</p> <p>Every update and delete appends a new record, but the old records are still on disk:</p> <pre><code>[user:1=v1][user:1=v2][user:1=v3][user:2=v1][user:1=(deleted)]\n     \u2191         \u2191         \u2191                         \u2191\n   Old       Old       Old                    Tombstone\n\nActual state: user:2=v1\nWasted space: 80% of the log!\n</code></pre> <p>You need a garbage collection (GC) strategy to reclaim space.</p>"},{"location":"crates/nori-wal/core-concepts/append-only/#strategy-1-delete-old-segments","title":"Strategy 1: Delete Old Segments","text":"<p>If you only care about recent data (e.g., event logs with a retention policy), you can delete entire old segments:</p> <pre><code>// Keep only last 7 days of data\nlet cutoff = Position {\n    segment_id: old_segment_id,\n    offset: 0,\n};\n\nlet deleted = wal.delete_segments_before(cutoff).await?;\n</code></pre> <p>This is simple and works well for append-only workloads (logs, events, time-series).</p>"},{"location":"crates/nori-wal/core-concepts/append-only/#strategy-2-compaction","title":"Strategy 2: Compaction","text":"<p>If you need to keep all keys but remove old versions, you need compaction:</p> <pre><code>Before compaction:\n  Segment 0: [k1=v1][k2=v1][k1=v2][k3=v1]\n  Segment 1: [k2=v2][k1=v3][k4=v1]\n\nAfter compaction:\n  Segment 2 (compacted): [k1=v3][k2=v2][k3=v1][k4=v1]\n  Segments 0, 1: deleted\n</code></pre> <p>Compaction: 1. Reads multiple old segments 2. Merges records, keeping only the latest version of each key 3. Writes a new compacted segment 4. Deletes the old segments</p> <p>This is what LSM-tree databases (RocksDB, Cassandra, nori-lsm) do.</p> <p>Important: nori-wal itself does not implement compaction. It provides the primitives (<code>delete_segments_before()</code>) but you decide when and how to compact.</p> <p>See Recipes: Compaction for implementation examples.</p>"},{"location":"crates/nori-wal/core-concepts/append-only/#strategy-3-snapshotting","title":"Strategy 3: Snapshotting","text":"<p>If your state is relatively small, you can:</p> <ol> <li>Periodically write a snapshot of your entire state to a separate file</li> <li>Delete all WAL segments before the snapshot</li> <li>On recovery: Load snapshot, then replay WAL from the snapshot point</li> </ol> <pre><code>Snapshot at position 1000: {k1=v3, k2=v2, k3=v1}\nWAL segments before position 1000: DELETE\nWAL segments after position 1000: KEEP (replay these on recovery)\n</code></pre> <p>This is what databases like Redis and PostgreSQL do.</p>"},{"location":"crates/nori-wal/core-concepts/append-only/#append-only-in-practice","title":"Append-Only in Practice","text":"<p>Let's see how append-only affects a real application.</p>"},{"location":"crates/nori-wal/core-concepts/append-only/#example-building-a-simple-kv-store","title":"Example: Building a Simple KV Store","text":"<pre><code>use std::collections::HashMap;\nuse nori_wal::{Wal, WalConfig, Record, Position};\n\nstruct SimpleKV {\n    wal: Wal,\n    memtable: HashMap&lt;Vec&lt;u8&gt;, Vec&lt;u8&gt;&gt;,\n}\n\nimpl SimpleKV {\n    async fn open(config: WalConfig) -&gt; Result&lt;Self&gt; {\n        let (wal, recovery_info) = Wal::open(config).await?;\n\n        // Replay WAL to build in-memory state\n        let mut memtable = HashMap::new();\n        let mut reader = wal.read_from(Position { segment_id: 0, offset: 0 }).await?;\n\n        while let Some((record, _)) = reader.next_record().await? {\n            if record.tombstone {\n                memtable.remove(&amp;record.key);\n            } else {\n                memtable.insert(record.key, record.value);\n            }\n        }\n\n        Ok(Self { wal, memtable })\n    }\n\n    async fn put(&amp;mut self, key: &amp;[u8], value: &amp;[u8]) -&gt; Result&lt;()&gt; {\n        // Write to WAL first (durability)\n        let record = Record::put(key, value);\n        self.wal.append(&amp;record).await?;\n        self.wal.sync().await?;\n\n        // Update in-memory state\n        self.memtable.insert(key.to_vec(), value.to_vec());\n\n        Ok(())\n    }\n\n    async fn delete(&amp;mut self, key: &amp;[u8]) -&gt; Result&lt;()&gt; {\n        // Write tombstone to WAL\n        let record = Record::delete(key);\n        self.wal.append(&amp;record).await?;\n        self.wal.sync().await?;\n\n        // Update in-memory state\n        self.memtable.remove(key);\n\n        Ok(())\n    }\n\n    fn get(&amp;self, key: &amp;[u8]) -&gt; Option&lt;&amp;[u8]&gt; {\n        // Read from in-memory state (NOT the WAL!)\n        self.memtable.get(key).map(|v| v.as_slice())\n    }\n}\n</code></pre> <p>Key points: 1. Writes append to the WAL, then update the memtable 2. Deletes append a tombstone, then remove from memtable 3. Reads come from the memtable, not the WAL 4. Recovery replays the WAL to reconstruct the memtable</p> <p>This is essentially how LevelDB, RocksDB, and nori-lsm work!</p>"},{"location":"crates/nori-wal/core-concepts/append-only/#growing-disk-usage","title":"Growing Disk Usage","text":"<p>As you use this KV store, the WAL grows:</p> <pre><code>After 1000 writes:\n  wal/000000.wal: 50 KB\n\nAfter 10000 writes:\n  wal/000000.wal: 500 KB\n\nAfter 100000 writes:\n  wal/000000.wal: 5 MB\n\nAfter 1M writes (many updates to same keys):\n  wal/000000.wal: 50 MB (but only 10K unique keys!)\n</code></pre> <p>At some point, you need to compact. For example:</p> <pre><code>impl SimpleKV {\n    async fn compact(&amp;mut self) -&gt; Result&lt;()&gt; {\n        // 1. Write a snapshot of current state\n        let snapshot_file = File::create(\"snapshot.dat\").await?;\n        for (key, value) in &amp;self.memtable {\n            snapshot_file.write_all(key).await?;\n            snapshot_file.write_all(value).await?;\n        }\n        snapshot_file.sync_all().await?;\n\n        // 2. Create a new WAL, abandoning the old one\n        let new_config = WalConfig {\n            dir: PathBuf::from(\"wal-new\"),\n            ..Default::default()\n        };\n        let (new_wal, _) = Wal::open(new_config).await?;\n\n        // 3. Swap to new WAL\n        self.wal = new_wal;\n\n        // 4. Delete old WAL directory\n        std::fs::remove_dir_all(\"wal\")?;\n        std::fs::rename(\"wal-new\", \"wal\")?;\n\n        Ok(())\n    }\n}\n</code></pre> <p>This is a simple snapshot-based compaction strategy.</p>"},{"location":"crates/nori-wal/core-concepts/append-only/#append-only-vs-in-place-updates-the-trade-off","title":"Append-Only vs. In-Place Updates: The Trade-Off","text":"<p>Let's compare the two approaches:</p> Aspect Append-Only In-Place Updates Write performance \u2b50\u2b50\u2b50\u2b50\u2b50 Fast (sequential I/O) \u2b50\u2b50\u2b50 Slower (random I/O) Read performance \u2b50\u2b50\u2b50\u2b50 Fast (if indexed) \u2b50\u2b50\u2b50\u2b50 Fast Crash safety \u2b50\u2b50\u2b50\u2b50\u2b50 Excellent (prefix-valid recovery) \u2b50\u2b50 Complex (need transactions) Disk usage \u2b50\u2b50 Grows forever (need GC) \u2b50\u2b50\u2b50\u2b50 Stable Code complexity \u2b50\u2b50\u2b50\u2b50\u2b50 Simple \u2b50\u2b50 Complex SSD wear \u2b50\u2b50\u2b50\u2b50\u2b50 Minimal (sequential) \u2b50\u2b50 Higher (random writes) <p>Append-only is better for: - High write throughput - Simplicity and correctness - Crash recovery - SSD longevity</p> <p>In-place updates are better for: - Stable disk usage - Workloads with very few updates</p> <p>For most modern applications, append-only wins.</p>"},{"location":"crates/nori-wal/core-concepts/append-only/#common-misconceptions","title":"Common Misconceptions","text":""},{"location":"crates/nori-wal/core-concepts/append-only/#append-only-wastes-disk-space","title":"\"Append-only wastes disk space\"","text":"<p>Response: Only if you don't implement garbage collection. With compaction or snapshotting, disk usage is proportional to your actual data size, not write volume.</p>"},{"location":"crates/nori-wal/core-concepts/append-only/#append-only-is-slow-because-you-have-to-scan-the-entire-log","title":"\"Append-only is slow because you have to scan the entire log\"","text":"<p>Response: You don't read from the WAL during normal operation. You read from an in-memory index (memtable, B-tree, hash table). The WAL is only scanned during recovery.</p>"},{"location":"crates/nori-wal/core-concepts/append-only/#tombstones-are-leaked-forever","title":"\"Tombstones are leaked forever\"","text":"<p>Response: No. During compaction, you can drop tombstones that shadow older versions. Once there are no older versions below a tombstone, it's safe to remove.</p> <pre><code>Before compaction:\n  Level 0: [k1=(tombstone)]\n  Level 1: [k1=v1]\n\nAfter compaction to Level 2:\n  Level 2: (k1 completely removed)\n</code></pre>"},{"location":"crates/nori-wal/core-concepts/append-only/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Append-only means you only add data at the end, never modify in place</li> <li>Updates \u2192 append a new version</li> <li> <p>Deletes \u2192 append a tombstone</p> </li> <li> <p>Append-only is fast and simple</p> </li> <li>Sequential I/O is 10-40x faster than random I/O</li> <li>No partial write corruption</li> <li> <p>Simple recovery: scan and validate CRCs</p> </li> <li> <p>The cost is growing disk usage</p> </li> <li>You need a garbage collection strategy</li> <li> <p>Options: delete old segments, compaction, snapshotting</p> </li> <li> <p>Don't read from the WAL during normal operation</p> </li> <li>Use an in-memory index (memtable, hash table, B-tree)</li> <li> <p>WAL is for durability and recovery, not queries</p> </li> <li> <p>Append-only is the foundation of modern storage systems</p> </li> <li>LSM-trees (RocksDB, LevelDB, Cassandra, nori-lsm)</li> <li>Event sourcing</li> <li>Distributed logs (Kafka, Raft)</li> </ol>"},{"location":"crates/nori-wal/core-concepts/append-only/#whats-next","title":"What's Next?","text":"<p>Now that you understand append-only architecture, explore:</p> <ul> <li>Fsync Policies - How to balance durability and performance</li> <li>Recovery Guarantees - What happens after a crash</li> <li>When to Use a WAL - Scenarios where WALs shine</li> </ul> <p>Or dive into implementation details in How It Works.</p>"},{"location":"crates/nori-wal/core-concepts/fsync-policies/","title":"Durability &amp; Fsync Policies","text":"<p>How to balance durability and performance with different fsync strategies.</p>"},{"location":"crates/nori-wal/core-concepts/fsync-policies/#table-of-contents","title":"Table of contents","text":""},{"location":"crates/nori-wal/core-concepts/fsync-policies/#the-durability-problem","title":"The Durability Problem","text":"<p>When you write data to a file, it doesn't go directly to disk. It goes through multiple layers of buffering:</p> <pre><code>graph TD\n    A[Your Code] --&gt;|write| B[Application Buffer]\n    B --&gt;|flush| C[OS Page Cache]\n    C --&gt;|fsync| D[Disk Controller Cache]\n    D --&gt; E[Physical Disk Platter/NAND]\n\n    style E fill:#90EE90\n    style A fill:#FFB6C1\n    style C fill:#FFD700</code></pre> <p>Problem: At each layer, your data can be lost if power fails.</p> Layer Survives Process Crash? Survives OS Crash/Power Failure? Application buffer No No OS page cache Yes No Disk controller cache Yes Maybe (if battery-backed) Physical disk Yes Yes <p>Only data on physical disk is truly durable.</p>"},{"location":"crates/nori-wal/core-concepts/fsync-policies/#what-is-fsync","title":"What is fsync()?","text":"<p><code>fsync()</code> is a system call that forces the operating system to flush all buffers to physical disk:</p> <pre><code>use tokio::fs::File;\n\nlet mut file = File::create(\"data.log\").await?;\nfile.write_all(b\"important data\").await?;\n\n// Data is in OS cache, NOT on disk yet!\n\nfile.sync_all().await?;  // Calls fsync() - forces to disk\n\n// Now data is guaranteed to be on physical disk\n</code></pre>"},{"location":"crates/nori-wal/core-concepts/fsync-policies/#flush-vs-sync","title":"flush() vs sync()","text":"<p>Don't confuse <code>flush()</code> and <code>sync()</code>:</p> <pre><code>// flush() - Writes from app buffer to OS cache (not durable!)\nfile.flush().await?;\n\n// sync_all() - Forces OS cache to physical disk (durable!)\nfile.sync_all().await?;\n</code></pre> <p>Key difference: - <code>flush()</code>: App buffer \u2192 OS page cache (survives process crash, NOT power failure) - <code>sync_all()</code> / <code>fsync()</code>: OS page cache \u2192 physical disk (survives power failure)</p>"},{"location":"crates/nori-wal/core-concepts/fsync-policies/#the-performance-cost-of-fsync","title":"The Performance Cost of fsync()","text":"<p><code>fsync()</code> is expensive. Here's why:</p>"},{"location":"crates/nori-wal/core-concepts/fsync-policies/#latency","title":"Latency","text":"<p>On a typical SSD:</p> <pre><code>write() call:       ~10 microseconds  (in-memory)\nfsync() call:       ~1-5 milliseconds (force to disk)\n\nThat's 100-500x slower!\n</code></pre> <p>On a typical HDD:</p> <pre><code>write() call:       ~10 microseconds  (in-memory)\nfsync() call:       ~5-10 milliseconds (seek + rotate + write)\n\nThat's 500-1000x slower!\n</code></pre>"},{"location":"crates/nori-wal/core-concepts/fsync-policies/#throughput","title":"Throughput","text":"<p>If you <code>fsync()</code> after every write:</p> <pre><code>for i in 0..1000 {\n    file.write_all(&amp;data).await?;\n    file.sync_all().await?;  // fsync after every write\n}\n</code></pre> <p>Performance: - Without fsync: 1,000,000 writes/second (limited by CPU/memory) - With fsync: ~200-500 writes/second (limited by disk)</p> <p>That's a 2000-5000x slowdown!</p>"},{"location":"crates/nori-wal/core-concepts/fsync-policies/#the-durability-vs-performance-trade-off","title":"The Durability vs. Performance Trade-Off","text":"<p>You have to choose:</p> <p>Option 1: Always fsync() - Maximum Durability - Every write is guaranteed durable before returning - Zero data loss on power failure - Very slow (~200-500 writes/sec)</p> <p>Option 2: Never fsync() - Maximum Performance - Blazing fast (~1M writes/sec) - Data loss on power failure (up to 30-60 seconds of writes) - Not acceptable for critical data</p> <p>Option 3: Batched fsync() - Balanced - Good performance (~50K-100K writes/sec) - Small data loss window (milliseconds) - Acceptable for most applications</p> <p>This is what <code>FsyncPolicy</code> in nori-wal controls.</p>"},{"location":"crates/nori-wal/core-concepts/fsync-policies/#fsyncpolicy-options","title":"FsyncPolicy Options","text":"<p>nori-wal provides three fsync policies. Let's explore each one.</p>"},{"location":"crates/nori-wal/core-concepts/fsync-policies/#fsyncpolicyalways","title":"FsyncPolicy::Always","text":"<p>Calls <code>fsync()</code> after every write.</p> <pre><code>use nori_wal::{WalConfig, FsyncPolicy};\n\nlet config = WalConfig {\n    fsync_policy: FsyncPolicy::Always,\n    ..Default::default()\n};\n</code></pre> <p>Behavior: <pre><code>let record = Record::put(b\"key\", b\"value\");\nwal.append(&amp;record).await?;  // Internally calls fsync() before returning\n</code></pre></p> <p>Guarantees: - Every <code>append()</code> is durable before it returns - Zero data loss on power failure - Suitable for financial transactions, critical data</p> <p>Performance: - ~200-500 writes/sec (disk-bound) - p50 latency: ~2ms - p99 latency: ~10ms</p> <p>Use when: - You cannot tolerate ANY data loss - Examples: financial transactions, medical records, audit logs</p>"},{"location":"crates/nori-wal/core-concepts/fsync-policies/#fsyncpolicybatchduration","title":"FsyncPolicy::Batch(Duration)","text":"<p>Batches <code>fsync()</code> calls within a time window.</p> <pre><code>use std::time::Duration;\n\nlet config = WalConfig {\n    fsync_policy: FsyncPolicy::Batch(Duration::from_millis(5)),\n    ..Default::default()\n};\n</code></pre> <p>Behavior: <pre><code>// First write triggers fsync\nwal.append(&amp;record1).await?;  // Calls fsync()\n\n// Subsequent writes within 5ms window skip fsync\nwal.append(&amp;record2).await?;  // No fsync!\nwal.append(&amp;record3).await?;  // No fsync!\n\n// ... 5ms passes ...\n\n// Next write triggers fsync again\nwal.append(&amp;record4).await?;  // Calls fsync()\n</code></pre></p> <p>Guarantees: - Potential data loss: up to <code>window</code> duration of writes on power failure - All writes are durable within <code>window</code> milliseconds - Good balance of performance and durability</p> <p>Performance (5ms window): - ~50K-100K writes/sec - p50 latency: ~50\u03bcs (no fsync) - p99 latency: ~5ms (fsync)</p> <p>Use when: - You can tolerate small data loss (milliseconds) - Examples: web applications, session state, caches</p> <p>Tuning the window:</p> <pre><code>// More durable: fsync every 1ms\nFsyncPolicy::Batch(Duration::from_millis(1))\n// Performance: ~40K writes/sec, 1ms max data loss\n\n// Balanced: fsync every 5ms (default)\nFsyncPolicy::Batch(Duration::from_millis(5))\n// Performance: ~80K writes/sec, 5ms max data loss\n\n// Higher throughput: fsync every 10ms\nFsyncPolicy::Batch(Duration::from_millis(10))\n// Performance: ~100K writes/sec, 10ms max data loss\n</code></pre>"},{"location":"crates/nori-wal/core-concepts/fsync-policies/#fsyncpolicyos","title":"FsyncPolicy::Os","text":"<p>Lets the operating system decide when to flush.</p> <pre><code>let config = WalConfig {\n    fsync_policy: FsyncPolicy::Os,\n    ..Default::default()\n};\n</code></pre> <p>Behavior: <pre><code>wal.append(&amp;record).await?;  // No fsync! Data stays in OS cache\n</code></pre></p> <p>Data is eventually flushed to disk by the OS, typically every 30-60 seconds (controlled by kernel settings like <code>vm.dirty_expire_centisecs</code> on Linux).</p> <p>Guarantees: - No durability guarantees! - Potential data loss: 30-60 seconds of writes on power failure - Data survives process crash (it's in OS cache)</p> <p>Performance: - ~100K-1M writes/sec (memory-bound) - p50 latency: ~10\u03bcs - p99 latency: ~100\u03bcs</p> <p>Use when: - Acceptable data loss on power failure - Examples: event logs, metrics, caches, analytics</p> <p>Warning: Never use <code>Os</code> policy for critical data!</p>"},{"location":"crates/nori-wal/core-concepts/fsync-policies/#decision-matrix","title":"Decision Matrix","text":"<p>Use this flowchart to pick the right policy:</p> <pre><code>graph TD\n    A[What's your use case?] --&gt; B{Can you tolerate ANY data loss?}\n    B --&gt;|No| C[FsyncPolicy::Always]\n    B --&gt;|Yes| D{How much data loss is OK?}\n    D --&gt;|None| C\n    D --&gt;|&lt; 10ms| E[FsyncPolicy::Batch 1-5ms]\n    D --&gt;|10-100ms| F[FsyncPolicy::Batch 10-50ms]\n    D --&gt;|Seconds OK| G[FsyncPolicy::Os]\n\n    C --&gt; H[~420 writes/sec&lt;br/&gt;0ms data loss]\n    E --&gt; I[~86K writes/sec&lt;br/&gt;1-5ms data loss]\n    F --&gt; J[~95K writes/sec&lt;br/&gt;10-50ms data loss]\n    G --&gt; K[~110K writes/sec&lt;br/&gt;30-60s data loss]\n\n    style C fill:#FFB6C1\n    style E fill:#90EE90\n    style F fill:#FFD700\n    style G fill:#FFA500</code></pre>"},{"location":"crates/nori-wal/core-concepts/fsync-policies/#real-world-examples","title":"Real-World Examples","text":""},{"location":"crates/nori-wal/core-concepts/fsync-policies/#example-1-banking-system","title":"Example 1: Banking System","text":"<pre><code>// Financial transactions - zero data loss acceptable\nlet config = WalConfig {\n    fsync_policy: FsyncPolicy::Always,\n    ..Default::default()\n};\n\nlet (wal, _) = Wal::open(config).await?;\n\n// Every transaction is durable\nlet tx = Record::put(b\"account:1234\", b\"balance:5000\");\nwal.append(&amp;tx).await?;  // Waits for fsync\n\n// If we return success, the transaction is guaranteed on disk\n</code></pre> <p>Trade-off: Low throughput (~420 tx/sec), but every transaction is safe.</p>"},{"location":"crates/nori-wal/core-concepts/fsync-policies/#example-2-web-application-session-store","title":"Example 2: Web Application Session Store","text":"<pre><code>// Session state - 5ms data loss acceptable\nlet config = WalConfig {\n    fsync_policy: FsyncPolicy::Batch(Duration::from_millis(5)),\n    ..Default::default()\n};\n\nlet (wal, _) = Wal::open(config).await?;\n\n// High throughput, small data loss window\nfor session in sessions {\n    let record = Record::put(session.id, session.data);\n    wal.append(&amp;record).await?;  // Fast!\n}\n\n// ~80K sessions/sec throughput\n// Worst case: lose 5ms of session updates on power failure\n</code></pre> <p>Trade-off: High throughput, acceptable data loss (users may need to re-login).</p>"},{"location":"crates/nori-wal/core-concepts/fsync-policies/#example-3-analytics-event-log","title":"Example 3: Analytics Event Log","text":"<pre><code>// Analytics events - data loss acceptable\nlet config = WalConfig {\n    fsync_policy: FsyncPolicy::Os,\n    ..Default::default()\n};\n\nlet (wal, _) = Wal::open(config).await?;\n\n// Maximum throughput\nfor event in events {\n    let record = Record::put(event.id, event.data);\n    wal.append(&amp;record).await?;  // Blazing fast!\n}\n\n// ~110K events/sec throughput\n// Worst case: lose 30-60s of events on power failure\n// Acceptable for analytics (not mission-critical)\n</code></pre> <p>Trade-off: Maximum throughput, but significant data loss possible.</p>"},{"location":"crates/nori-wal/core-concepts/fsync-policies/#batching-how-it-works-internally","title":"Batching: How It Works Internally","text":"<p>Let's look at how <code>FsyncPolicy::Batch</code> actually works inside nori-wal:</p> <pre><code>struct BatchedFsync {\n    window: Duration,\n    last_sync: Instant,\n}\n\nimpl BatchedFsync {\n    async fn append(&amp;mut self, record: &amp;Record) -&gt; Result&lt;Position&gt; {\n        // 1. Write to file (buffered, fast)\n        let position = self.write_to_file(record).await?;\n\n        // 2. Check if we need to fsync\n        let now = Instant::now();\n        if now.duration_since(self.last_sync) &gt;= self.window {\n            // Time window elapsed, fsync now\n            self.file.sync_all().await?;\n            self.last_sync = now;\n        }\n\n        // 3. Return position (might not be synced yet!)\n        Ok(position)\n    }\n}\n</code></pre> <p>Key insight: The first write after the window expires pays the fsync cost. Subsequent writes within the window are fast.</p> <pre><code>Time \u2192\n  0ms: append() \u2192 fsync (2ms)\n  1ms: append() \u2192 no fsync (fast)\n  2ms: append() \u2192 no fsync (fast)\n  3ms: append() \u2192 no fsync (fast)\n  4ms: append() \u2192 no fsync (fast)\n  5ms: append() \u2192 fsync (2ms)\n  6ms: append() \u2192 no fsync (fast)\n  ...\n</code></pre>"},{"location":"crates/nori-wal/core-concepts/fsync-policies/#manual-fsync-with-fsyncpolicyos","title":"Manual fsync() with FsyncPolicy::Os","text":"<p>If you use <code>FsyncPolicy::Os</code>, you can manually call <code>sync()</code> when you want durability:</p> <pre><code>let config = WalConfig {\n    fsync_policy: FsyncPolicy::Os,  // No automatic fsync\n    ..Default::default()\n};\n\nlet (wal, _) = Wal::open(config).await?;\n\n// Fast writes (no fsync)\nfor i in 0..1000 {\n    let record = Record::put(format!(\"key:{}\", i).as_bytes(), b\"value\");\n    wal.append(&amp;record).await?;\n}\n\n// Now manually fsync when you want durability\nwal.sync().await?;  // Force everything to disk\n</code></pre> <p>This gives you fine-grained control over when to pay the fsync cost.</p> <p>Use case: Batch inserts where you want durability at the end of the batch, not after every record.</p>"},{"location":"crates/nori-wal/core-concepts/fsync-policies/#benchmarks-policy-comparison","title":"Benchmarks: Policy Comparison","text":"<p>Here are real benchmark results from nori-wal on a typical SSD (Samsung 970 EVO):</p> Policy Throughput (writes/sec) p50 Latency p99 Latency Data Loss on Power Failure <code>Always</code> 420 2.1ms 9.8ms 0ms <code>Batch(1ms)</code> 45,000 45\u03bcs 1.2ms \u22641ms <code>Batch(5ms)</code> 86,000 38\u03bcs 5.3ms \u22645ms <code>Batch(10ms)</code> 95,000 35\u03bcs 10.4ms \u226410ms <code>Os</code> 110,000 28\u03bcs 95\u03bcs 30-60s <p>Observations: - <code>Always</code> is 200x slower than <code>Batch(5ms)</code> - <code>Batch(5ms)</code> offers good balance (86K writes/sec, 5ms max data loss) - <code>Os</code> is only slightly faster than <code>Batch(10ms)</code>, but loses 30-60s of data</p> <p>Recommendation: Use <code>Batch(5ms)</code> for most applications.</p>"},{"location":"crates/nori-wal/core-concepts/fsync-policies/#common-misconceptions","title":"Common Misconceptions","text":""},{"location":"crates/nori-wal/core-concepts/fsync-policies/#fsync-flushes-to-disk-controller-cache-not-physical-disk","title":"\"fsync() flushes to disk controller cache, not physical disk\"","text":"<p>Response: This used to be true for some old HDDs, but modern drives respect the <code>FUA</code> (Force Unit Access) flag, which bypasses the cache. On Linux, <code>fsync()</code> uses barriers to ensure physical durability.</p> <p>If you're paranoid, use <code>O_DIRECT</code> (but this is rarely necessary and hurts performance).</p>"},{"location":"crates/nori-wal/core-concepts/fsync-policies/#i-can-just-call-fsync-in-the-background","title":"\"I can just call fsync() in the background\"","text":"<p>Response: No! If you acknowledge success to the user before <code>fsync()</code> completes, you've violated the write-ahead guarantee.</p> <p>Wrong: <pre><code>// WRONG!\nasync fn append_wrong(record: &amp;Record) -&gt; Position {\n    let position = write_to_file(record).await;\n\n    // Return immediately (WRONG!)\n    tokio::spawn(async move {\n        file.sync_all().await.unwrap();  // Async fsync\n    });\n\n    position  // User thinks it's durable, but it's not!\n}\n</code></pre></p> <p>Right: <pre><code>// RIGHT!\nasync fn append_right(record: &amp;Record) -&gt; Position {\n    let position = write_to_file(record).await;\n    file.sync_all().await.unwrap();  // Wait for fsync\n    position  // Now it's safe to return\n}\n</code></pre></p>"},{"location":"crates/nori-wal/core-concepts/fsync-policies/#batched-fsync-is-less-durable","title":"\"Batched fsync is less durable\"","text":"<p>Response: It's a trade-off. With <code>Batch(5ms)</code>, you have a 5ms window of potential data loss. But: - You still get durability within 5ms - For most applications, 5ms of data loss is acceptable - Users can retry failed requests anyway</p> <p>If 5ms is unacceptable, use <code>Always</code>. But understand the performance cost.</p>"},{"location":"crates/nori-wal/core-concepts/fsync-policies/#configuring-os-level-durability","title":"Configuring OS-Level Durability","text":"<p>Even with <code>fsync()</code>, the OS and disk have settings that affect durability:</p>"},{"location":"crates/nori-wal/core-concepts/fsync-policies/#linux-disk-write-cache","title":"Linux: Disk Write Cache","text":"<p>Check if write cache is enabled: <pre><code>hdparm -W /dev/sda\n</code></pre></p> <p>If it shows <code>write-caching = 1</code>, the disk controller may cache writes. On power failure, this cache is lost unless the drive has battery backup.</p> <p>To disable write cache (paranoid mode): <pre><code>hdparm -W 0 /dev/sda\n</code></pre></p> <p>Warning: This makes <code>fsync()</code> even slower! Only do this for critical data on drives without battery backup.</p>"},{"location":"crates/nori-wal/core-concepts/fsync-policies/#linux-filesystem-barriers","title":"Linux: Filesystem Barriers","text":"<p>Modern filesystems (ext4, XFS, Btrfs) use barriers to enforce durability. Make sure barriers are enabled:</p> <pre><code># ext4: Check for 'barrier' mount option\nmount | grep ext4\n\n# Should see: (rw,barrier=1)\n</code></pre> <p>If barriers are disabled (<code>barrier=0</code>), <code>fsync()</code> may not be durable!</p>"},{"location":"crates/nori-wal/core-concepts/fsync-policies/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>fsync() is the only way to guarantee durability</li> <li><code>flush()</code> is NOT enough (only goes to OS cache)</li> <li> <p>Only <code>fsync()</code> forces data to physical disk</p> </li> <li> <p>fsync() is expensive</p> </li> <li>100-1000x slower than buffered writes</li> <li>Using <code>Always</code> policy: ~420 writes/sec</li> <li> <p>Using <code>Batch(5ms)</code> policy: ~86K writes/sec</p> </li> <li> <p>Choose the right policy for your use case</p> </li> <li>Critical data \u2192 <code>Always</code></li> <li>Most applications \u2192 <code>Batch(1-10ms)</code></li> <li> <p>Acceptable data loss \u2192 <code>Os</code></p> </li> <li> <p>Batched fsync is a good default</p> </li> <li>5ms data loss window is acceptable for most apps</li> <li>200x performance improvement over <code>Always</code></li> <li> <p>Still provides strong durability guarantees</p> </li> <li> <p>Never acknowledge success before fsync completes</p> </li> <li>This violates the write-ahead guarantee</li> <li>Can lead to data loss despite using a WAL</li> </ol>"},{"location":"crates/nori-wal/core-concepts/fsync-policies/#whats-next","title":"What's Next?","text":"<p>Now that you understand fsync policies, explore:</p> <ul> <li>Recovery Guarantees - What happens after a crash</li> <li>When to Use a WAL - Scenarios where WALs shine</li> <li>Performance Tuning - Optimize for your workload</li> </ul> <p>Or see real-world examples in Recipes.</p>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/","title":"Recovery Guarantees","text":"<p>What happens after a crash and what guarantees you can rely on.</p>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#table-of-contents","title":"Table of contents","text":""},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#the-recovery-promise","title":"The Recovery Promise","text":"<p>When your application crashes or the power goes out, nori-wal makes these guarantees:</p> <p>All records that were successfully <code>sync()</code>'d are preserved.</p> <p>Partial writes are detected and truncated.</p> <p>The last committed version of each key is recoverable.</p> <p>This is called prefix-valid recovery: everything up to the point of corruption is valid.</p>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#what-happens-during-a-crash","title":"What Happens During a Crash","text":"<p>Let's walk through what happens when you crash mid-write.</p>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#scenario-normal-write-sequence","title":"Scenario: Normal Write Sequence","text":"<pre><code>// Write 5 records\nfor i in 1..=5 {\n    let record = Record::put(format!(\"key:{}\", i).as_bytes(), b\"value\");\n    wal.append(&amp;record).await?;\n}\n\n// Sync to disk\nwal.sync().await?;  // All 5 records now durable\n\n// Application continues...\n</code></pre> <p>On disk after sync: <pre><code>Segment 000000.wal:\n  [Record 1: key:1=value] Yes CRC valid\n  [Record 2: key:2=value] Yes CRC valid\n  [Record 3: key:3=value] Yes CRC valid\n  [Record 4: key:4=value] Yes CRC valid\n  [Record 5: key:5=value] Yes CRC valid\n</code></pre></p> <p>After recovery: All 5 records restored. </p>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#scenario-crash-before-sync","title":"Scenario: Crash Before Sync","text":"<pre><code>// Write 5 records\nfor i in 1..=5 {\n    let record = Record::put(format!(\"key:{}\", i).as_bytes(), b\"value\");\n    wal.append(&amp;record).await?;\n}\n\n// Crash here! (before sync)\nstd::process::abort();\n\n// wal.sync().await?;  \u2190 Never reached\n</code></pre> <p>What's on disk?</p> <p>It depends on your <code>FsyncPolicy</code>:</p> <p>With <code>FsyncPolicy::Always</code>: <pre><code>[Record 1: key:1=value] Yes CRC valid (auto-synced)\n[Record 2: key:2=value] Yes CRC valid (auto-synced)\n[Record 3: key:3=value] Yes CRC valid (auto-synced)\n[Record 4: key:4=value] Yes CRC valid (auto-synced)\n[Record 5: key:5=value] Yes CRC valid (auto-synced)\n</code></pre> After recovery: All 5 records restored. </p> <p>With <code>FsyncPolicy::Batch(5ms)</code> or <code>FsyncPolicy::Os</code>: <pre><code>[Random garbage or empty space]\n</code></pre> After recovery: 0 records restored. </p> <p>Key insight: Without <code>sync()</code>, you have no durability guarantee unless using <code>FsyncPolicy::Always</code>.</p>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#scenario-crash-mid-write","title":"Scenario: Crash Mid-Write","text":"<pre><code>let record = Record::put(b\"key:1\", b\"very long value...\");\nwal.append(&amp;record).await?;\n\n// Crash DURING the write!\n// Maybe only half the record made it to disk\n</code></pre> <p>On disk after crash: <pre><code>[Record header: CRC=0x12345678, length=100]\n[Partial data: only 50 bytes written...]\n[Garbage or zeros for remaining 50 bytes]\n</code></pre></p> <p>During recovery: <pre><code>// nori-wal validates CRC\nlet computed_crc = crc32c::compute(&amp;record_data);\n\nif computed_crc != stored_crc {\n    // CRC mismatch! Partial write detected.\n    // Truncate everything from this point onward.\n}\n</code></pre></p> <p>After recovery: Partial record discarded. </p>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#scenario-multiple-partial-writes","title":"Scenario: Multiple Partial Writes","text":"<pre><code>// Successfully write 3 records\nwal.append(&amp;record1).await?;\nwal.append(&amp;record2).await?;\nwal.append(&amp;record3).await?;\nwal.sync().await?;  // These 3 are durable\n\n// Write 2 more records\nwal.append(&amp;record4).await?;\nwal.append(&amp;record5).await?;\n\n// Crash! Records 4 and 5 only partially written\n</code></pre> <p>On disk: <pre><code>[Record 1] Yes CRC valid, synced\n[Record 2] Yes CRC valid, synced\n[Record 3] Yes CRC valid, synced\n[Record 4] No CRC invalid (partial write)\n[Record 5] No CRC invalid (partial write)\n</code></pre></p> <p>During recovery: <pre><code>Scan record 1: CRC valid \u2192 Keep\nScan record 2: CRC valid \u2192 Keep\nScan record 3: CRC valid \u2192 Keep\nScan record 4: CRC INVALID \u2192 Truncate here\n</code></pre></p> <p>After recovery: Records 1-3 restored, records 4-5 discarded. </p>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#recovery-algorithm","title":"Recovery Algorithm","text":"<p>Here's how nori-wal recovers after a crash:</p> <pre><code>flowchart TD\n    A[Start Recovery] --&gt; B[Scan all segment files]\n    B --&gt; C[For each segment]\n    C --&gt; D[Read next record]\n    D --&gt; E{Valid header?}\n    E --&gt;|No| F[Truncate at this position]\n    E --&gt;|Yes| G{CRC32C valid?}\n    G --&gt;|No| F\n    G --&gt;|Yes| H[Add to recovery list]\n    H --&gt; I{More records?}\n    I --&gt;|Yes| D\n    I --&gt;|No| J{More segments?}\n    J --&gt;|Yes| C\n    J --&gt;|No| K[Return RecoveryInfo]\n\n    F --&gt; K\n\n    style F fill:#FFB6C1\n    style H fill:#90EE90</code></pre>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#step-by-step","title":"Step-by-Step","text":"<ol> <li>Scan all segment files in the WAL directory</li> <li>For each segment, read records sequentially</li> <li>Validate each record:</li> <li>Check header magic number</li> <li>Verify CRC32C checksum</li> <li>Ensure length is reasonable</li> <li>On first invalid record:</li> <li>Truncate the file at this position</li> <li>Discard all data after this point</li> <li>Stop scanning this segment</li> <li>Continue to next segment</li> <li>Return recovery info with counts and statistics</li> </ol>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#recoveryinfo-structure","title":"RecoveryInfo Structure","text":"<p>When you open a WAL, you get back a <code>RecoveryInfo</code> struct:</p> <pre><code>let (wal, recovery_info) = Wal::open(config).await?;\n\nprintln!(\"Recovered {} records\", recovery_info.valid_records);\nprintln!(\"Scanned {} segments\", recovery_info.segments_scanned);\nprintln!(\"Corruption detected: {}\", recovery_info.corruption_detected);\nprintln!(\"Bytes truncated: {}\", recovery_info.bytes_truncated);\n</code></pre>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#fields","title":"Fields","text":"Field Type Meaning <code>valid_records</code> <code>u64</code> Number of records successfully recovered <code>segments_scanned</code> <code>usize</code> How many segment files were checked <code>corruption_detected</code> <code>bool</code> Whether any corruption was found <code>bytes_truncated</code> <code>u64</code> How much data was truncated due to corruption"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#interpreting-recoveryinfo","title":"Interpreting RecoveryInfo","text":"<p>Example 1: Clean Recovery <pre><code>RecoveryInfo {\n    valid_records: 10000,\n    segments_scanned: 2,\n    corruption_detected: false,\n    bytes_truncated: 0,\n}\n</code></pre> Meaning: 10K records recovered cleanly from 2 segments. No corruption.</p> <p>Example 2: Partial Write Detected <pre><code>RecoveryInfo {\n    valid_records: 9998,\n    segments_scanned: 2,\n    corruption_detected: true,\n    bytes_truncated: 127,\n}\n</code></pre> Meaning: 9,998 records recovered, but 2 records (127 bytes) were truncated due to partial writes. This is normal if you crashed mid-write.</p> <p>Example 3: Empty WAL <pre><code>RecoveryInfo {\n    valid_records: 0,\n    segments_scanned: 0,\n    corruption_detected: false,\n    bytes_truncated: 0,\n}\n</code></pre> Meaning: New WAL, no existing data. Normal for first run.</p>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#recovery-guarantees-by-fsyncpolicy","title":"Recovery Guarantees by FsyncPolicy","text":"<p>Your recovery guarantees depend on your <code>FsyncPolicy</code>:</p>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#fsyncpolicyalways","title":"FsyncPolicy::Always","text":"<pre><code>let config = WalConfig {\n    fsync_policy: FsyncPolicy::Always,\n    ..Default::default()\n};\n</code></pre> <p>Guarantees: - Every <code>append()</code> is synced before returning - If <code>append()</code> returns <code>Ok</code>, the record is durable - Zero data loss on crash</p> <p>Example: <pre><code>wal.append(&amp;record1).await?;  // Returns \u2192 record1 is durable\nwal.append(&amp;record2).await?;  // Returns \u2192 record2 is durable\n// Crash here\n</code></pre> Recovery: Both record1 and record2 are recovered. </p>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#fsyncpolicybatchduration","title":"FsyncPolicy::Batch(Duration)","text":"<pre><code>let config = WalConfig {\n    fsync_policy: FsyncPolicy::Batch(Duration::from_millis(5)),\n    ..Default::default()\n};\n</code></pre> <p>Guarantees: - Records are synced within the time window - Up to <code>window</code> worth of records may be lost on crash - All records synced before the last fsync are durable</p> <p>Example: <pre><code>wal.append(&amp;record1).await?;  // Triggers fsync\nwal.append(&amp;record2).await?;  // No fsync (within 5ms)\nwal.append(&amp;record3).await?;  // No fsync (within 5ms)\n// Crash here\n</code></pre> Recovery: Only record1 is guaranteed. Records 2-3 may be lost. </p>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#fsyncpolicyos","title":"FsyncPolicy::Os","text":"<pre><code>let config = WalConfig {\n    fsync_policy: FsyncPolicy::Os,\n    ..Default::default()\n};\n</code></pre> <p>Guarantees: - No durability guarantees! - OS flushes to disk eventually (30-60 seconds) - Data survives process crash (it's in OS cache) - Data lost on power failure</p> <p>Example: <pre><code>for i in 1..=100 {\n    wal.append(&amp;record).await?;  // No fsync!\n}\n// Power failure here\n</code></pre> Recovery: All 100 records likely lost. </p> <p>But: <pre><code>for i in 1..=100 {\n    wal.append(&amp;record).await?;\n}\n\n// Manually sync\nwal.sync().await?;\n\n// Power failure here\n</code></pre> Recovery: All 100 records recovered. </p>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#common-recovery-scenarios","title":"Common Recovery Scenarios","text":""},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#scenario-1-clean-shutdown","title":"Scenario 1: Clean Shutdown","text":"<pre><code>// Write data\nwal.append(&amp;record1).await?;\nwal.append(&amp;record2).await?;\nwal.sync().await?;\n\n// Graceful shutdown\ndrop(wal);  // Implicitly syncs\n</code></pre> <p>Recovery: All records recovered. No corruption detected.</p>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#scenario-2-ctrl-c-mid-write","title":"Scenario 2: Ctrl-C Mid-Write","text":"<pre><code>$ cargo run\nWriting records...\n^C  # User presses Ctrl-C\n</code></pre> <p>What happens: - Signal handler (if any) triggers - Rust drops the <code>Wal</code> struct - <code>Drop</code> impl calls <code>sync()</code> (best effort) - If signal is SIGKILL, no drop handlers run</p> <p>Recovery: - If drop handler ran: All synced records recovered - If SIGKILL: Only records up to last explicit <code>sync()</code> recovered</p> <p>Lesson: Don't rely on drop handlers for durability. Call <code>sync()</code> explicitly.</p>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#scenario-3-power-failure","title":"Scenario 3: Power Failure","text":"<pre><code>wal.append(&amp;record1).await?;\nwal.append(&amp;record2).await?;\n\n// Power fails here (no sync!)\n</code></pre> <p>Recovery: - <code>FsyncPolicy::Always</code>: Both records recovered  - <code>FsyncPolicy::Batch</code>: Maybe both, maybe neither  - <code>FsyncPolicy::Os</code>: Both likely lost </p>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#scenario-4-disk-full","title":"Scenario 4: Disk Full","text":"<pre><code>let record = Record::put(b\"key\", &amp;[0u8; 1_000_000_000]);  // 1GB record\n\nmatch wal.append(&amp;record).await {\n    Ok(_) =&gt; println!(\"Success\"),\n    Err(e) =&gt; {\n        // Error: No space left on device\n        println!(\"Disk full: {}\", e);\n    }\n}\n</code></pre> <p>With preallocation (default): - Error happens when creating a new segment - Existing segment writes succeed until segment is full - No data corruption</p> <p>Without preallocation: - Error happens during write - Partial record may be written - Recovery truncates the partial record</p> <p>Lesson: Preallocation provides early error detection.</p>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#scenario-5-filesystem-corruption","title":"Scenario 5: Filesystem Corruption","text":"<p>Rare, but possible: the filesystem itself is corrupted (bad sectors, firmware bug, etc.).</p> <p>nori-wal behavior: - Scans all segments - CRC validation detects corrupted records - Truncates at first corrupted record - Returns <code>corruption_detected: true</code></p> <p>What you should do: <pre><code>let (wal, recovery_info) = Wal::open(config).await?;\n\nif recovery_info.corruption_detected {\n    log::warn!(\n        \"WAL corruption detected! {} bytes truncated\",\n        recovery_info.bytes_truncated\n    );\n\n    // Alert ops team, check filesystem health\n    alert_ops_team(\"WAL corruption detected\");\n}\n</code></pre></p>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#replaying-the-wal","title":"Replaying the WAL","text":"<p>After recovery, you typically replay the WAL to reconstruct your in-memory state:</p> <pre><code>use std::collections::HashMap;\n\nasync fn replay_wal(wal: &amp;Wal) -&gt; Result&lt;HashMap&lt;Vec&lt;u8&gt;, Vec&lt;u8&gt;&gt;&gt; {\n    let mut state = HashMap::new();\n    let mut reader = wal.read_from(Position { segment_id: 0, offset: 0 }).await?;\n\n    while let Some((record, position)) = reader.next_record().await? {\n        if record.tombstone {\n            // Delete\n            state.remove(&amp;record.key);\n        } else {\n            // Put (shadows any previous value)\n            state.insert(record.key.clone(), record.value.clone());\n        }\n\n        log::debug!(\"Replayed record at {:?}: {:?}\", position, record.key);\n    }\n\n    Ok(state)\n}\n</code></pre> <p>Key points: 1. Replay in order (append-only guarantees this) 2. Later records shadow earlier ones (last write wins) 3. Tombstones delete keys from state</p>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#advanced-idempotent-replay","title":"Advanced: Idempotent Replay","text":"<p>If you replay the same WAL multiple times, you should get the same result. This is called idempotent replay.</p> <p>nori-wal guarantees idempotent replay because: - Records are immutable - Append-only ordering is deterministic - Last write wins</p> <p>Example: <pre><code>// First replay\nlet state1 = replay_wal(&amp;wal).await?;\n\n// Replay again (for testing or debugging)\nlet state2 = replay_wal(&amp;wal).await?;\n\nassert_eq!(state1, state2);  // Always passes\n</code></pre></p> <p>This is crucial for: - Testing: Verify replay logic - Debugging: Re-run replay to diagnose issues - Replication: Followers replay leader's log and converge to same state</p>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#recovery-performance","title":"Recovery Performance","text":"<p>How long does recovery take?</p> <p>It depends on: 1. Number of segments: More segments \u2192 longer scan 2. Segment size: Larger segments \u2192 more data to read 3. Disk speed: SSD vs HDD makes a big difference 4. Corruption location: If corruption is at the end, scan is fast</p> <p>Typical performance:</p> Scenario Recovery Time 1 segment (128MB), no corruption ~100ms (SSD) 10 segments (1.28GB), no corruption ~1s (SSD) 100 segments (12.8GB), no corruption ~10s (SSD) 1 segment (128MB), corruption at end ~100ms (SSD) 1 segment (128MB), corruption at start ~1ms (SSD) <p>Optimization: Delete old segments after compaction to reduce recovery time.</p>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#testing-recovery","title":"Testing Recovery","text":"<p>You should test your recovery logic! Here's how:</p>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#test-1-crash-mid-write","title":"Test 1: Crash Mid-Write","text":"<pre><code>#[tokio::test]\nasync fn test_crash_recovery() {\n    let dir = tempfile::tempdir().unwrap();\n    let config = WalConfig {\n        dir: dir.path().to_path_buf(),\n        ..Default::default()\n    };\n\n    // Write some records\n    {\n        let (wal, _) = Wal::open(config.clone()).await.unwrap();\n        wal.append(&amp;Record::put(b\"key1\", b\"value1\")).await.unwrap();\n        wal.append(&amp;Record::put(b\"key2\", b\"value2\")).await.unwrap();\n        wal.sync().await.unwrap();\n\n        // Simulate crash: drop WAL without syncing\n        wal.append(&amp;Record::put(b\"key3\", b\"value3\")).await.unwrap();\n        // Drop here (no sync)\n    }\n\n    // Reopen and verify recovery\n    let (wal, recovery_info) = Wal::open(config).await.unwrap();\n    assert_eq!(recovery_info.valid_records, 2);  // key1, key2\n\n    let state = replay_wal(&amp;wal).await.unwrap();\n    assert_eq!(state.get(b\"key1\".as_slice()), Some(&amp;b\"value1\".to_vec()));\n    assert_eq!(state.get(b\"key2\".as_slice()), Some(&amp;b\"value2\".to_vec()));\n    assert_eq!(state.get(b\"key3\".as_slice()), None);  // Lost!\n}\n</code></pre>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#test-2-corrupted-data","title":"Test 2: Corrupted Data","text":"<pre><code>#[tokio::test]\nasync fn test_corruption_recovery() {\n    let dir = tempfile::tempdir().unwrap();\n    let config = WalConfig {\n        dir: dir.path().to_path_buf(),\n        ..Default::default()\n    };\n\n    // Write and sync\n    {\n        let (wal, _) = Wal::open(config.clone()).await.unwrap();\n        wal.append(&amp;Record::put(b\"key1\", b\"value1\")).await.unwrap();\n        wal.sync().await.unwrap();\n    }\n\n    // Corrupt the segment file\n    let segment_path = dir.path().join(\"000000.wal\");\n    let mut file = std::fs::OpenOptions::new()\n        .write(true)\n        .open(&amp;segment_path)\n        .unwrap();\n    file.seek(std::io::SeekFrom::Start(20)).unwrap();\n    file.write_all(b\"CORRUPT DATA\").unwrap();\n\n    // Reopen and verify truncation\n    let (wal, recovery_info) = Wal::open(config).await.unwrap();\n    assert!(recovery_info.corruption_detected);\n    assert!(recovery_info.bytes_truncated &gt; 0);\n}\n</code></pre>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>nori-wal uses prefix-valid recovery</li> <li>All valid records up to the first corruption are preserved</li> <li> <p>Partial writes are detected via CRC32C and truncated</p> </li> <li> <p>Recovery guarantees depend on FsyncPolicy</p> </li> <li><code>Always</code>: Every record is durable after <code>append()</code> returns</li> <li><code>Batch</code>: Records are durable within the time window</li> <li> <p><code>Os</code>: No guarantees; manual <code>sync()</code> required</p> </li> <li> <p>RecoveryInfo tells you what happened</p> </li> <li>Check <code>corruption_detected</code> and <code>bytes_truncated</code></li> <li> <p>Log warnings if corruption is detected</p> </li> <li> <p>Replay the WAL to reconstruct state</p> </li> <li>Scan records in order</li> <li>Last write wins for each key</li> <li> <p>Tombstones delete keys</p> </li> <li> <p>Test your recovery logic</p> </li> <li>Simulate crashes and corrupted data</li> <li>Verify your state is correctly reconstructed</li> </ol>"},{"location":"crates/nori-wal/core-concepts/recovery-guarantees/#whats-next","title":"What's Next?","text":"<p>Now that you understand recovery, explore:</p> <ul> <li>When to Use a WAL - Scenarios where WALs shine</li> <li>How Recovery Works Internally - Deep dive into the algorithm</li> <li>Recipes: Crash Testing - Property-based testing for recovery</li> </ul> <p>Or jump to Performance Tuning to optimize your WAL.</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/","title":"What is a Write-Ahead Log?","text":"<p>The fundamental concept behind WALs, why they exist, and how they power modern systems.</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#table-of-contents","title":"Table of contents","text":""},{"location":"crates/nori-wal/core-concepts/what-is-wal/#the-core-idea","title":"The Core Idea","text":"<p>A write-ahead log (WAL) is a simple but powerful concept:</p> <p>Write changes to a durable log before modifying your main data structures.</p> <p>That's it. That's the entire concept.</p> <p>But this simple idea solves one of the hardest problems in computing: making changes durable without sacrificing performance.</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#why-wals-exist","title":"Why WALs Exist","text":"<p>Imagine you're building a database. You have a nice in-memory data structure (maybe a B-tree or hash table) that's blazingly fast. But there's a problem:</p> <p>What happens when the power goes out?</p> <p>Your in-memory structure is gone. All data lost.</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#the-naive-solution-sync-after-every-change","title":"The Naive Solution: Sync After Every Change","text":"<pre><code>// Don't do this!\nfn set(key: &amp;str, value: &amp;str) {\n    data_structure.insert(key, value);\n\n    // Write the ENTIRE data structure to disk\n    write_entire_tree_to_disk(&amp;data_structure);\n    fsync();  // Force to physical disk\n}\n</code></pre> <p>Problems: - Slow: Writing a 10GB B-tree to disk for a 10-byte update is absurd - Complex: How do you write a tree to disk atomically? What if you crash mid-write? - Fragmented: Random updates \u2192 random disk writes \u2192 terrible performance</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#the-better-solution-write-ahead-logging","title":"The Better Solution: Write-Ahead Logging","text":"<pre><code>// Much better!\nfn set(key: &amp;str, value: &amp;str) {\n    // 1. Append change to log (sequential, fast)\n    wal.append(Record::put(key, value));\n    wal.sync();  // Just sync the log (cheap!)\n\n    // 2. Update in-memory structure (fast)\n    data_structure.insert(key, value);\n\n    // Done! If we crash, we can replay the log to rebuild the data structure.\n}\n</code></pre> <p>Benefits: - Fast: Appending to a log is sequential I/O (the fastest kind) - Simple: No complex tree serialization - Durable: After <code>sync()</code>, the change is on disk, guaranteed - Recoverable: Replay the log after a crash to rebuild state</p> <p>This is the insight that powers virtually every database you've ever used.</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#historical-context","title":"Historical Context","text":"<p>The write-ahead log is one of the oldest ideas in database systems. It dates back to the 1970s when researchers were figuring out how to make databases reliable.</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#key-milestones","title":"Key Milestones","text":"<p>1976 - IBM System R introduces WAL for ARIES (Algorithm for Recovery and Isolation Exploiting Semantics) - First formal recovery algorithm using WAL - Still the foundation for many modern databases</p> <p>1980s - WAL becomes standard in ACID databases - PostgreSQL, Oracle, DB2 all adopt WAL-based recovery - \"Write-ahead\" becomes a fundamental durability guarantee</p> <p>1990s-2000s - WAL spreads beyond traditional databases - Journaling filesystems (ext3, NTFS) use WAL concepts - Message queues (Kafka) built entirely on logs</p> <p>2010s-Present - \"Log is the database\" - Event sourcing: the log is the primary data structure - Distributed consensus (Raft, Multi-Paxos) built on replicated logs - Modern KV stores (RocksDB, LevelDB) use WAL + LSM trees</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#how-wals-work-high-level","title":"How WALs Work (High Level)","text":"<p>Here's the lifecycle of a write in a WAL-based system:</p> <pre><code>sequenceDiagram\n    participant App as Application\n    participant Mem as In-Memory State\n    participant WAL as Write-Ahead Log\n    participant Disk as Disk Storage\n\n    App-&gt;&gt;WAL: 1. Append record\n    WAL-&gt;&gt;Disk: 2. Write to log file\n    WAL-&gt;&gt;Disk: 3. fsync() - force to disk\n    WAL--&gt;&gt;App: 4. Return success\n    App-&gt;&gt;Mem: 5. Update in-memory state\n\n    Note over WAL,Disk: Change is now durable!\n    Note over Mem: In-memory update happens AFTER durability</code></pre>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#the-key-invariant","title":"The Key Invariant","text":"<p>At all times, one of these is true:</p> <ol> <li>Change is in the log on disk \u2192 Can recover it</li> <li>Change hasn't been acknowledged to the user \u2192 User will retry</li> </ol> <p>This is how WALs provide durability while keeping writes fast.</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#wal-in-different-systems","title":"WAL in Different Systems","text":"<p>The WAL pattern appears everywhere, but with different flavors:</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#traditional-databases-postgresql-mysql","title":"Traditional Databases (PostgreSQL, MySQL)","text":"<pre><code>[WAL Segment 1] [WAL Segment 2] [WAL Segment 3]\n      \u2193\nOn checkpoint: Flush pages to main database files\nAfter flush: Delete old WAL segments\n</code></pre> <p>Purpose: Recover in-memory page cache after crash</p> <p>Key operations: - <code>INSERT/UPDATE/DELETE</code> \u2192 Write to WAL first, then modify pages - Crash \u2192 Replay WAL to reconstruct page cache - Checkpoint \u2192 Flush dirty pages, truncate old WAL</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#log-structured-storage-rocksdb-cassandra-nori-wal","title":"Log-Structured Storage (RocksDB, Cassandra, nori-wal)","text":"<pre><code>[WAL] \u2192 [Memtable] \u2192 flush \u2192 [SSTable L0]\n                              [SSTable L1]\n                              [SSTable L2]\n</code></pre> <p>Purpose: Durability for in-memory write buffer (memtable)</p> <p>Key operations: - Write \u2192 Append to WAL + insert to memtable - Memtable full \u2192 Flush to SSTable on disk - Crash \u2192 Replay WAL to reconstruct memtable</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#message-queues-kafka","title":"Message Queues (Kafka)","text":"<pre><code>[Log Segment 0] [Log Segment 1] [Log Segment 2] ...\n     \u2193               \u2193               \u2193\nConsumers read from offsets (positions in log)\n</code></pre> <p>Purpose: The log is the primary data structure</p> <p>Key operations: - Produce \u2192 Append to log - Consume \u2192 Read from offset, advance offset - Retention \u2192 Delete old segments after time/size threshold</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#distributed-consensus-raft-multi-paxos","title":"Distributed Consensus (Raft, Multi-Paxos)","text":"<pre><code>Leader: [Entry 1] [Entry 2] [Entry 3] [Entry 4]\n          Yes         Yes         Yes        (uncommitted)\n\nReplicate entries to followers \u2192\nWhen majority has entry \u2192 Commit it\n</code></pre> <p>Purpose: Replicate state machine transitions</p> <p>Key operations: - Command \u2192 Leader appends to log - Replicate \u2192 Send to followers - Commit \u2192 When majority has it - Apply \u2192 Execute against state machine</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#the-write-ahead-guarantee","title":"The \"Write-Ahead\" Guarantee","text":"<p>The term \"write-ahead\" is crucial. It means:</p> <p>The log must be written to durable storage BEFORE acknowledging the operation.</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#example-bank-transfer","title":"Example: Bank Transfer","text":"<pre><code>// CORRECT: Write-ahead\nasync fn transfer(from: u64, to: u64, amount: u64) -&gt; Result&lt;()&gt; {\n    // 1. Log the operation FIRST\n    let record = Record::put(\n        b\"transfer\",\n        format!(\"{}\u2192{}: ${}\", from, to, amount).as_bytes()\n    );\n    wal.append(&amp;record).await?;\n    wal.sync().await?;  // CRITICAL: Must sync before continuing!\n\n    // 2. Now update in-memory balances\n    balances.get_mut(&amp;from).unwrap() -= amount;\n    balances.get_mut(&amp;to).unwrap() += amount;\n\n    // 3. Acknowledge to user\n    Ok(())\n}\n</code></pre> <p>If we crash after step 1 (log sync) but before step 2 (in-memory update), that's fine! We can replay the log on recovery and redo the transfer.</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#violation-write-behind-wrong","title":"Violation: Write-Behind (WRONG)","text":"<pre><code>// WRONG: Write-behind (don't do this!)\nasync fn transfer_wrong(from: u64, to: u64, amount: u64) -&gt; Result&lt;()&gt; {\n    // 1. Update in-memory first\n    balances.get_mut(&amp;from).unwrap() -= amount;\n    balances.get_mut(&amp;to).unwrap() += amount;\n\n    // 2. Acknowledge to user\n    println!(\"Transfer complete!\");\n\n    // 3. Log it later (WRONG!)\n    wal.append(&amp;record).await?;\n\n    // If we crash here, the transfer is LOST!\n    // But we already told the user it succeeded!\n}\n</code></pre> <p>Never do this. Always write to the log before acknowledging success.</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#what-wals-are-not","title":"What WALs Are NOT","text":"<p>It's helpful to clarify what WALs are not:</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#not-a-replacement-for-your-main-data-structure","title":"NOT a Replacement for Your Main Data Structure","text":"<p>The WAL is not where you read from during normal operation. It's a recovery mechanism.</p> <pre><code>// BAD: Scanning the entire WAL to find a key\nasync fn get_bad(key: &amp;[u8]) -&gt; Option&lt;Vec&lt;u8&gt;&gt; {\n    let mut reader = wal.read_from(Position::start()).await?;\n    let mut latest = None;\n\n    // This is O(log size) - terrible!\n    while let Some((record, _)) = reader.next_record().await? {\n        if record.key == key {\n            latest = Some(record.value);\n        }\n    }\n\n    latest\n}\n</code></pre> <pre><code>// GOOD: Use an index (memtable, SSTable, B-tree, etc.)\nasync fn get_good(key: &amp;[u8]) -&gt; Option&lt;Vec&lt;u8&gt;&gt; {\n    // O(log n) or O(1) lookup\n    memtable.get(key).or_else(|| sstables.get(key))\n}\n</code></pre> <p>Use the WAL for: - Durability - Recovery - Replication</p> <p>Don't use the WAL for: - Point reads - Range queries - Indexes</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#not-always-the-fastest-storage","title":"NOT Always the Fastest Storage","text":"<p>For some workloads, a WAL might be slower than direct writes:</p> <p>WAL is fast when: - Sequential writes (appending) - Small writes (kilobytes) - Need durability guarantees</p> <p>WAL might be slower when: - Need random reads (use an index) - Large batch writes (direct file write might be faster) - Don't care about durability (can skip fsync)</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#not-a-silver-bullet","title":"NOT a Silver Bullet","text":"<p>WALs solve durability, but they don't solve:</p> <ul> <li>Concurrency control (you need locks, MVCC, or STM)</li> <li>Query optimization (you need indexes)</li> <li>Distributed consensus (you need Raft/Paxos on top of WAL)</li> <li>Schema migrations (you need application-level logic)</li> </ul> <p>A WAL is one tool in your toolbox, not a complete database.</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#why-nori-wal-exists","title":"Why nori-wal Exists","text":"<p>There are many WAL implementations out there. Why build another one?</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#existing-options","title":"Existing Options","text":"<p>RocksDB WAL: Great, but tightly coupled to RocksDB. Can't use it standalone.</p> <p>Kafka: Designed for message queues, not general-purpose storage.</p> <p>PostgreSQL WAL: Internal to PostgreSQL, not reusable.</p> <p>Custom implementation: Most projects roll their own, often poorly.</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#what-nori-wal-provides","title":"What nori-wal Provides","text":"<p>Standalone: Use it in any Rust project, no dependencies on a larger system</p> <p>Production-ready: Comprehensive error handling, recovery, observability</p> <p>Flexible: Choose your durability vs. performance trade-off (fsync policies)</p> <p>Well-documented: You're reading it!</p> <p>Tested: 37 tests including property tests for crash scenarios</p> <p>Fast: 110K writes/sec with batched fsync (see benchmarks)</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#real-world-use-cases","title":"Real-World Use Cases","text":"<p>Here's where you'd actually use a WAL:</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#1-building-a-key-value-store","title":"1. Building a Key-Value Store","text":"<pre><code>struct KvStore {\n    memtable: BTreeMap&lt;Vec&lt;u8&gt;, Vec&lt;u8&gt;&gt;,\n    wal: Wal,\n}\n\nimpl KvStore {\n    async fn put(&amp;mut self, key: &amp;[u8], value: &amp;[u8]) -&gt; Result&lt;()&gt; {\n        // Write-ahead: log first\n        let record = Record::put(key, value);\n        self.wal.append(&amp;record).await?;\n        self.wal.sync().await?;\n\n        // Then update memtable\n        self.memtable.insert(key.to_vec(), value.to_vec());\n\n        Ok(())\n    }\n\n    async fn recover(&amp;mut self) -&gt; Result&lt;()&gt; {\n        // Replay WAL to reconstruct memtable\n        let mut reader = self.wal.read_from(Position::start()).await?;\n        while let Some((record, _)) = reader.next_record().await? {\n            if record.tombstone {\n                self.memtable.remove(&amp;record.key);\n            } else {\n                self.memtable.insert(record.key, record.value);\n            }\n        }\n        Ok(())\n    }\n}\n</code></pre> <p>See Recipes: Key-Value Store for a complete example.</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#2-event-sourcing","title":"2. Event Sourcing","text":"<pre><code>struct EventStore {\n    wal: Wal,\n}\n\nimpl EventStore {\n    async fn append_event(&amp;self, event: &amp;Event) -&gt; Result&lt;Position&gt; {\n        let record = Record::put(\n            event.aggregate_id.as_bytes(),\n            serde_json::to_vec(event)?\n        );\n        let pos = self.wal.append(&amp;record).await?;\n        Ok(pos)\n    }\n\n    async fn replay(&amp;self, aggregate_id: &amp;str) -&gt; Result&lt;Vec&lt;Event&gt;&gt; {\n        let mut events = vec![];\n        let mut reader = self.wal.read_from(Position::start()).await?;\n\n        while let Some((record, _)) = reader.next_record().await? {\n            if record.key == aggregate_id.as_bytes() {\n                let event: Event = serde_json::from_slice(&amp;record.value)?;\n                events.push(event);\n            }\n        }\n\n        Ok(events)\n    }\n}\n</code></pre> <p>See Recipes: Event Sourcing for details.</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#3-replication","title":"3. Replication","text":"<pre><code>struct ReplicatedLog {\n    wal: Wal,\n}\n\nimpl ReplicatedLog {\n    async fn replicate_to_follower(&amp;self, follower: &amp;mut TcpStream) -&gt; Result&lt;()&gt; {\n        let mut reader = self.wal.read_from(Position::start()).await?;\n\n        // Stream entire log to follower\n        while let Some((record, position)) = reader.next_record().await? {\n            follower.write_all(&amp;serialize(&amp;record)?).await?;\n        }\n\n        Ok(())\n    }\n}\n</code></pre> <p>This is how Raft and other consensus protocols work under the hood!</p>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#key-takeaways","title":"Key Takeaways","text":"<p>Before moving on, make sure you understand these core points:</p> <ol> <li>WALs provide durability without sacrificing write performance</li> <li>Sequential appends are fast</li> <li> <p>Only need to sync the log, not the entire data structure</p> </li> <li> <p>Write-ahead means log BEFORE acknowledgment</p> </li> <li>Never acknowledge success until the log is synced</li> <li> <p>If you crash after logging, you can recover</p> </li> <li> <p>The log is not your primary data structure</p> </li> <li>Use it for recovery, not for reads</li> <li> <p>Build indexes (memtables, B-trees, hash tables) for queries</p> </li> <li> <p>WALs are everywhere</p> </li> <li>Databases, filesystems, message queues, consensus protocols</li> <li> <p>Understanding WALs helps you understand modern distributed systems</p> </li> <li> <p>nori-wal is a production-ready, standalone WAL implementation</p> </li> <li>Use it to add durability to your Rust projects</li> <li>Flexible, tested, documented</li> </ol>"},{"location":"crates/nori-wal/core-concepts/what-is-wal/#whats-next","title":"What's Next?","text":"<p>Now that you understand what a WAL is, let's explore the key design decisions:</p> <ul> <li>Append-Only Architecture - Why WALs are append-only and what that means</li> <li>Fsync Policies - How to balance durability and performance</li> <li>Recovery Guarantees - What happens after a crash</li> <li>When to Use a WAL - Scenarios where WALs shine</li> </ul> <p>Or jump ahead to see how nori-wal works internally in How It Works.</p>"},{"location":"crates/nori-wal/core-concepts/when-to-use/","title":"When to Use a WAL","text":"<p>Scenarios where WALs shine and where they don't.</p>"},{"location":"crates/nori-wal/core-concepts/when-to-use/#table-of-contents","title":"Table of contents","text":""},{"location":"crates/nori-wal/core-concepts/when-to-use/#the-decision-framework","title":"The Decision Framework","text":"<p>Use a WAL when you need both durability and performance for sequential writes.</p> <pre><code>graph TD\n    A[Do you need durability?] --&gt;|No| B[Don't use a WAL&lt;br/&gt;Just use in-memory structures]\n    A --&gt;|Yes| C[Are writes mostly sequential/append-only?]\n    C --&gt;|No| D[Consider alternatives&lt;br/&gt;e.g., B-tree with transactions]\n    C --&gt;|Yes| E[Do you need recovery after crashes?]\n    E --&gt;|No| F[Consider periodic snapshots instead]\n    E --&gt;|Yes| G[Use a WAL!]\n\n    style G fill:#90EE90\n    style B fill:#FFB6C1\n    style D fill:#FFD700\n    style F fill:#FFA500</code></pre>"},{"location":"crates/nori-wal/core-concepts/when-to-use/#perfect-use-cases","title":"Perfect Use Cases","text":""},{"location":"crates/nori-wal/core-concepts/when-to-use/#1-building-a-key-value-store","title":"1. Building a Key-Value Store","text":"<p>Why WAL? - Need durability for writes - Writes are append-only - Recovery after crash is critical</p> <p>Example: LevelDB, RocksDB, nori-lsm</p> <pre><code>struct KvStore {\n    memtable: BTreeMap&lt;Vec&lt;u8&gt;, Vec&lt;u8&gt;&gt;,\n    wal: Wal,\n}\n\nimpl KvStore {\n    async fn put(&amp;mut self, key: &amp;[u8], value: &amp;[u8]) -&gt; Result&lt;()&gt; {\n        // Write to WAL first (durability)\n        let record = Record::put(key, value);\n        self.wal.append(&amp;record).await?;\n        self.wal.sync().await?;\n\n        // Then update memtable (performance)\n        self.memtable.insert(key.to_vec(), value.to_vec());\n        Ok(())\n    }\n\n    async fn recover(&amp;mut self) -&gt; Result&lt;()&gt; {\n        // Replay WAL to rebuild memtable\n        let mut reader = self.wal.read_from(Position::start()).await?;\n        while let Some((record, _)) = reader.next_record().await? {\n            if record.tombstone {\n                self.memtable.remove(&amp;record.key);\n            } else {\n                self.memtable.insert(record.key, record.value);\n            }\n        }\n        Ok(())\n    }\n}\n</code></pre> <p>Benefits: - Fast writes (sequential I/O to WAL) - Fast reads (from in-memory memtable) - Durable (WAL survives crashes) - Simple recovery (replay WAL)</p> <p>See Recipes: Key-Value Store for a complete implementation.</p>"},{"location":"crates/nori-wal/core-concepts/when-to-use/#2-event-sourcing","title":"2. Event Sourcing","text":"<p>Why WAL? - Events are append-only by definition - Need to replay events to reconstruct state - Durability is critical (events are source of truth)</p> <p>Example: Order processing system</p> <pre><code>struct OrderService {\n    events: Wal,\n}\n\n#[derive(Serialize, Deserialize)]\nenum OrderEvent {\n    Created { order_id: u64, customer: String },\n    ItemAdded { order_id: u64, item: String, price: u64 },\n    Submitted { order_id: u64 },\n    Paid { order_id: u64, amount: u64 },\n}\n\nimpl OrderService {\n    async fn create_order(&amp;self, customer: &amp;str) -&gt; Result&lt;u64&gt; {\n        let order_id = generate_id();\n        let event = OrderEvent::Created {\n            order_id,\n            customer: customer.to_string(),\n        };\n\n        // Append event to WAL\n        let record = Record::put(\n            order_id.to_string().as_bytes(),\n            serde_json::to_vec(&amp;event)?\n        );\n        self.events.append(&amp;record).await?;\n        self.events.sync().await?;\n\n        Ok(order_id)\n    }\n\n    async fn replay_order(&amp;self, order_id: u64) -&gt; Result&lt;Order&gt; {\n        let mut order = Order::default();\n        let mut reader = self.events.read_from(Position::start()).await?;\n\n        while let Some((record, _)) = reader.next_record().await? {\n            if record.key == order_id.to_string().as_bytes() {\n                let event: OrderEvent = serde_json::from_slice(&amp;record.value)?;\n                order.apply(event);  // Rebuild state from events\n            }\n        }\n\n        Ok(order)\n    }\n}\n</code></pre> <p>Benefits: - Complete audit trail (all events preserved) - Time-travel debugging (replay to any point) - Easy to add new projections (replay events differently)</p> <p>See Recipes: Event Sourcing for details.</p>"},{"location":"crates/nori-wal/core-concepts/when-to-use/#3-message-queue-job-queue","title":"3. Message Queue / Job Queue","text":"<p>Why WAL? - Messages/jobs are append-only - Need durability (can't lose jobs) - Consumers read sequentially</p> <p>Example: Kafka-like message log</p> <pre><code>struct MessageQueue {\n    log: Wal,\n}\n\nimpl MessageQueue {\n    async fn publish(&amp;self, topic: &amp;str, message: &amp;[u8]) -&gt; Result&lt;Position&gt; {\n        let record = Record::put(topic.as_bytes(), message);\n        let position = self.log.append(&amp;record).await?;\n        self.log.sync().await?;\n        Ok(position)\n    }\n\n    async fn consume_from(&amp;self, position: Position) -&gt; Result&lt;Vec&lt;Message&gt;&gt; {\n        let mut messages = vec![];\n        let mut reader = self.log.read_from(position).await?;\n\n        while let Some((record, pos)) = reader.next_record().await? {\n            messages.push(Message {\n                topic: String::from_utf8_lossy(&amp;record.key).to_string(),\n                data: record.value,\n                position: pos,\n            });\n        }\n\n        Ok(messages)\n    }\n}\n</code></pre> <p>Benefits: - Durable message delivery - Consumers can replay from any position - High write throughput (append-only)</p>"},{"location":"crates/nori-wal/core-concepts/when-to-use/#4-database-transaction-log","title":"4. Database Transaction Log","text":"<p>Why WAL? - Redo log for ARIES-style recovery - Guarantees atomicity and durability (the AD in ACID) - Standard in all major databases</p> <p>Example: PostgreSQL, MySQL, SQLite</p> <pre><code>struct Database {\n    pages: HashMap&lt;PageId, Page&gt;,\n    wal: Wal,\n}\n\nimpl Database {\n    async fn begin_transaction(&amp;mut self) -&gt; Transaction {\n        Transaction {\n            wal_start: self.wal.current_position(),\n            changes: vec![],\n        }\n    }\n\n    async fn commit(&amp;mut self, tx: Transaction) -&gt; Result&lt;()&gt; {\n        // Write all changes to WAL\n        for change in &amp;tx.changes {\n            let record = Record::put(\n                change.page_id.to_bytes(),\n                change.new_data.clone()\n            );\n            self.wal.append(&amp;record).await?;\n        }\n\n        // Commit record\n        let commit_record = Record::put(b\"COMMIT\", tx.id.to_bytes());\n        self.wal.append(&amp;commit_record).await?;\n        self.wal.sync().await?;  // Force to disk\n\n        // Now apply changes to in-memory pages\n        for change in &amp;tx.changes {\n            self.pages.insert(change.page_id, change.new_data.clone());\n        }\n\n        Ok(())\n    }\n}\n</code></pre> <p>Benefits: - Atomic commits (all or nothing) - Crash recovery via redo log - Write-ahead guarantee</p>"},{"location":"crates/nori-wal/core-concepts/when-to-use/#5-distributed-consensus-raftpaxos","title":"5. Distributed Consensus (Raft/Paxos)","text":"<p>Why WAL? - Consensus protocols are fundamentally about replicating a log - Leader appends entries, followers replicate them - Log is the source of truth</p> <p>Example: Raft log</p> <pre><code>struct RaftLog {\n    entries: Wal,\n}\n\nimpl RaftLog {\n    async fn append_entry(&amp;self, term: u64, command: &amp;[u8]) -&gt; Result&lt;LogIndex&gt; {\n        let entry = LogEntry {\n            term,\n            index: self.last_index() + 1,\n            command: command.to_vec(),\n        };\n\n        let record = Record::put(\n            entry.index.to_bytes(),\n            bincode::serialize(&amp;entry)?\n        );\n\n        let position = self.entries.append(&amp;record).await?;\n        self.entries.sync().await?;\n\n        Ok(entry.index)\n    }\n\n    async fn replicate_to(&amp;self, follower: &amp;mut Connection, from: LogIndex) -&gt; Result&lt;()&gt; {\n        let mut reader = self.entries.read_from(Position::from_index(from)).await?;\n\n        while let Some((record, _)) = reader.next_record().await? {\n            follower.send_entry(record).await?;\n        }\n\n        Ok(())\n    }\n}\n</code></pre> <p>Benefits: - Durable log for consensus - Sequential replication (leader \u2192 followers) - Idempotent replay (followers converge to same state)</p>"},{"location":"crates/nori-wal/core-concepts/when-to-use/#good-use-cases-with-caveats","title":"Good Use Cases (with caveats)","text":""},{"location":"crates/nori-wal/core-concepts/when-to-use/#6-session-store","title":"6. Session Store","text":"<p>Why WAL? - Sessions need some durability - Append-only writes for session updates</p> <p>Caveat: Session data is ephemeral. Use <code>FsyncPolicy::Batch</code> or <code>Os</code> for better performance.</p> <pre><code>let config = WalConfig {\n    fsync_policy: FsyncPolicy::Batch(Duration::from_millis(10)),  // 10ms data loss OK\n    ..Default::default()\n};\n\nlet (wal, _) = Wal::open(config).await?;\n\n// Fast session updates\nwal.append(&amp;Record::put(session_id, session_data)).await?;\n// No explicit sync - batch policy handles it\n</code></pre>"},{"location":"crates/nori-wal/core-concepts/when-to-use/#7-cache-with-persistence","title":"7. Cache with Persistence","text":"<p>Why WAL? - Want cache to survive restarts - But don't need strict durability (it's a cache!)</p> <p>Caveat: Use <code>FsyncPolicy::Os</code> and periodic snapshots.</p> <pre><code>let config = WalConfig {\n    fsync_policy: FsyncPolicy::Os,  // Max performance\n    ..Default::default()\n};\n\nlet (wal, _) = Wal::open(config).await?;\n\n// High-throughput cache writes\nfor (key, value) in cache_entries {\n    wal.append(&amp;Record::put(key, value)).await?;\n}\n\n// Periodically compact\ntokio::spawn(async move {\n    loop {\n        tokio::time::sleep(Duration::from_secs(3600)).await;\n        snapshot_and_compact(&amp;wal).await;\n    }\n});\n</code></pre>"},{"location":"crates/nori-wal/core-concepts/when-to-use/#8-metricsanalytics","title":"8. Metrics/Analytics","text":"<p>Why WAL? - High write throughput for events - Append-only</p> <p>Caveat: Data loss is acceptable, so use <code>FsyncPolicy::Os</code>.</p> <pre><code>struct MetricsLog {\n    wal: Wal,  // FsyncPolicy::Os\n}\n\nimpl MetricsLog {\n    async fn record_metric(&amp;self, metric: &amp;Metric) -&gt; Result&lt;()&gt; {\n        let record = Record::put(\n            metric.name.as_bytes(),\n            serde_json::to_vec(metric)?\n        );\n        self.wal.append(&amp;record).await?;\n        // No sync - let OS handle it\n        Ok(())\n    }\n\n    async fn batch_insert(&amp;self, metrics: &amp;[Metric]) -&gt; Result&lt;()&gt; {\n        for metric in metrics {\n            self.record_metric(metric).await?;\n        }\n        // Optional: sync after batch\n        self.wal.sync().await?;\n        Ok(())\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/core-concepts/when-to-use/#not-recommended-use-cases","title":"Not Recommended Use Cases","text":""},{"location":"crates/nori-wal/core-concepts/when-to-use/#random-access-workloads","title":"Random Access Workloads","text":"<p>Why not? - WALs are optimized for sequential writes and reads - Random access requires scanning the entire log (slow)</p> <p>Example: Updating random records in a large dataset</p> <pre><code>// BAD: Random access in WAL\nasync fn update_user_bad(user_id: u64, field: &amp;str, value: &amp;[u8]) -&gt; Result&lt;()&gt; {\n    // Have to scan entire WAL to find user\n    let mut reader = wal.read_from(Position::start()).await?;\n    let mut found = false;\n\n    while let Some((record, _)) = reader.next_record().await? {\n        if record.key == user_id.to_bytes() {\n            found = true;\n            break;\n        }\n    }\n\n    // Then append update (this part is fine)\n    wal.append(&amp;Record::put(user_id.to_bytes(), value)).await?;\n\n    Ok(())\n}\n</code></pre> <p>Better alternative: Use a B-tree or hash table for random access, backed by WAL for durability.</p> <pre><code>// GOOD: B-tree for random access, WAL for durability\nstruct Database {\n    index: BTreeMap&lt;u64, Vec&lt;u8&gt;&gt;,\n    wal: Wal,\n}\n\nasync fn update_user_good(&amp;mut self, user_id: u64, value: &amp;[u8]) -&gt; Result&lt;()&gt; {\n    // Fast lookup in B-tree\n    self.index.insert(user_id, value.to_vec());\n\n    // Durable append to WAL\n    wal.append(&amp;Record::put(user_id.to_bytes(), value)).await?;\n\n    Ok(())\n}\n</code></pre>"},{"location":"crates/nori-wal/core-concepts/when-to-use/#read-heavy-workloads","title":"Read-Heavy Workloads","text":"<p>Why not? - WALs are write-optimized - Reading requires scanning or replaying the log</p> <p>Example: Analytics dashboard querying historical data</p> <pre><code>// BAD: Querying WAL directly\nasync fn get_user_events(user_id: u64) -&gt; Result&lt;Vec&lt;Event&gt;&gt; {\n    let mut events = vec![];\n    let mut reader = wal.read_from(Position::start()).await?;\n\n    // Scan entire log - O(n) where n = total records\n    while let Some((record, _)) = reader.next_record().await? {\n        if record.key == user_id.to_bytes() {\n            events.push(deserialize(&amp;record.value)?);\n        }\n    }\n\n    Ok(events)\n}\n</code></pre> <p>Better alternative: Build an index or materialized view from the WAL.</p> <pre><code>// GOOD: Index for fast queries\nstruct EventStore {\n    wal: Wal,\n    index: HashMap&lt;u64, Vec&lt;Event&gt;&gt;,  // User ID \u2192 Events\n}\n\nimpl EventStore {\n    async fn rebuild_index(&amp;mut self) -&gt; Result&lt;()&gt; {\n        let mut reader = self.wal.read_from(Position::start()).await?;\n\n        while let Some((record, _)) = reader.next_record().await? {\n            let user_id = u64::from_bytes(&amp;record.key);\n            let event: Event = deserialize(&amp;record.value)?;\n\n            self.index.entry(user_id).or_default().push(event);\n        }\n\n        Ok(())\n    }\n\n    fn get_user_events(&amp;self, user_id: u64) -&gt; Option&lt;&amp;[Event]&gt; {\n        self.index.get(&amp;user_id).map(|v| v.as_slice())  // O(1)\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/core-concepts/when-to-use/#large-binary-blobs","title":"Large Binary Blobs","text":"<p>Why not? - WALs are optimized for small records (bytes to kilobytes) - Large blobs (megabytes) hurt performance and recovery</p> <p>Example: Storing 100MB video files in WAL</p> <pre><code>// BAD: Large blobs in WAL\nasync fn store_video_bad(video_id: &amp;str, data: &amp;[u8]) -&gt; Result&lt;()&gt; {\n    // data is 100MB!\n    let record = Record::put(video_id.as_bytes(), data);\n    wal.append(&amp;record).await?;  // Slow!\n    wal.sync().await?;  // Very slow!\n    Ok(())\n}\n</code></pre> <p>Problems: - Slow writes (100MB sequential write + fsync) - Slow recovery (have to scan 100MB per record) - Memory usage (entire record loaded during recovery)</p> <p>Better alternative: Store blobs separately, reference them in WAL.</p> <pre><code>// GOOD: Store blob separately, reference in WAL\nasync fn store_video_good(video_id: &amp;str, data: &amp;[u8]) -&gt; Result&lt;()&gt; {\n    // 1. Write blob to object storage (S3, filesystem, etc.)\n    let blob_path = format!(\"/blobs/{}.mp4\", video_id);\n    tokio::fs::write(&amp;blob_path, data).await?;\n\n    // 2. Store reference in WAL (small!)\n    let metadata = VideoMetadata {\n        id: video_id.to_string(),\n        path: blob_path,\n        size: data.len(),\n    };\n    let record = Record::put(\n        video_id.as_bytes(),\n        serde_json::to_vec(&amp;metadata)?  // Only ~100 bytes\n    );\n    wal.append(&amp;record).await?;\n\n    Ok(())\n}\n</code></pre>"},{"location":"crates/nori-wal/core-concepts/when-to-use/#in-place-updates-required","title":"In-Place Updates Required","text":"<p>Why not? - WALs are append-only - Can't modify existing records</p> <p>Example: Updating a single field in a large document</p> <pre><code>// BAD: Updating one field requires rewriting entire document\nstruct Document {\n    id: u64,\n    title: String,\n    body: String,  // 10KB\n    metadata: HashMap&lt;String, String&gt;,\n}\n\nasync fn update_title_bad(doc_id: u64, new_title: &amp;str) -&gt; Result&lt;()&gt; {\n    // 1. Read entire document from WAL (slow)\n    let mut doc = read_document_from_wal(doc_id).await?;\n\n    // 2. Update one field\n    doc.title = new_title.to_string();\n\n    // 3. Rewrite entire document (slow, wastes space)\n    let record = Record::put(doc_id.to_bytes(), serialize(&amp;doc)?);\n    wal.append(&amp;record).await?;\n\n    Ok(())\n}\n</code></pre> <p>Better alternative: Use a database with in-place updates (B-tree), or decompose document into smaller records.</p>"},{"location":"crates/nori-wal/core-concepts/when-to-use/#when-to-use-alternatives","title":"When to Use Alternatives","text":"Use Case Alternative Why? Random reads/writes SQLite, PostgreSQL Optimized B-tree indexes Large binary blobs S3, Object Storage Designed for large objects In-memory cache (no durability) Redis (in-memory mode) No disk overhead Complex queries PostgreSQL, MySQL Full SQL support Graph traversals Neo4j, Graph DB Optimized for relationships Full-text search Elasticsearch, Meilisearch Inverted indexes"},{"location":"crates/nori-wal/core-concepts/when-to-use/#hybrid-approaches","title":"Hybrid Approaches","text":"<p>Often, the best solution combines a WAL with other structures:</p>"},{"location":"crates/nori-wal/core-concepts/when-to-use/#wal-memtable-sstables-lsm-tree","title":"WAL + Memtable + SSTables (LSM-Tree)","text":"<p>This is what LevelDB, RocksDB, and nori-lsm do:</p> <pre><code>Writes \u2192 WAL (durability) + Memtable (fast writes)\n         \u2193\n      Memtable full\n         \u2193\n      Flush to SSTable (sorted, immutable)\n         \u2193\n      Compact SSTables (merge, remove old versions)\n</code></pre> <p>Benefits: - Fast writes (WAL + in-memory memtable) - Fast reads (in-memory memtable + sorted SSTables) - Durable (WAL) - Compact (SSTables deduplicate versions)</p> <p>See Recipes: LSM-Tree for implementation.</p>"},{"location":"crates/nori-wal/core-concepts/when-to-use/#wal-snapshot","title":"WAL + Snapshot","text":"<p>Periodically snapshot your state, then truncate the WAL:</p> <pre><code>Time 0: WAL is empty\nTime 1: Append 1000 records to WAL\nTime 2: Snapshot state to disk\nTime 3: Truncate WAL (keep only records after snapshot)\n</code></pre> <p>Benefits: - Fast recovery (load snapshot + replay small WAL) - Bounded disk usage (old WAL segments deleted)</p> <p>See Recipes: Snapshotting for details.</p>"},{"location":"crates/nori-wal/core-concepts/when-to-use/#wal-replication","title":"WAL + Replication","text":"<p>Replicate the WAL to followers for high availability:</p> <pre><code>Leader:   WAL [Entry 1][Entry 2][Entry 3]\n           \u2193       \u2193       \u2193\nFollower: WAL [Entry 1][Entry 2][Entry 3]\n\nIf leader fails, follower takes over with complete log.\n</code></pre> <p>This is the foundation of Raft, Multi-Paxos, and other consensus protocols.</p>"},{"location":"crates/nori-wal/core-concepts/when-to-use/#quick-decision-checklist","title":"Quick Decision Checklist","text":"<p>Use a WAL if you answer Yes to all:</p> <ul> <li> Do you need durability (survive crashes)?</li> <li> Are writes mostly sequential/append-only?</li> <li> Do you need recovery after crashes?</li> <li> Are records small to medium size (&lt; 1MB)?</li> <li> Is write performance important?</li> </ul> <p>Consider alternatives if you answer Yes to any:</p> <ul> <li> Do you need random reads/writes?</li> <li> Are records very large (&gt; 10MB)?</li> <li> Is read performance more important than write performance?</li> <li> Do you need complex queries (joins, aggregations, full-text search)?</li> </ul>"},{"location":"crates/nori-wal/core-concepts/when-to-use/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>WALs excel at durable, sequential writes</li> <li> <p>Key-value stores, event sourcing, message queues, databases</p> </li> <li> <p>WALs are not for random access</p> </li> <li> <p>Use B-trees or hash tables for random reads/writes</p> </li> <li> <p>WALs are not for large blobs</p> </li> <li> <p>Store blobs separately, reference them in the WAL</p> </li> <li> <p>Combine WAL with other structures for best results</p> </li> <li>WAL + memtable + SSTables (LSM-tree)</li> <li>WAL + snapshots (bounded recovery time)</li> <li> <p>WAL + replication (high availability)</p> </li> <li> <p>Choose the right FsyncPolicy for your use case</p> </li> <li>Critical data \u2192 <code>Always</code></li> <li>Most apps \u2192 <code>Batch(1-10ms)</code></li> <li>Acceptable data loss \u2192 <code>Os</code></li> </ol>"},{"location":"crates/nori-wal/core-concepts/when-to-use/#whats-next","title":"What's Next?","text":"<p>Now that you know when to use a WAL, dive deeper:</p> <ul> <li>How It Works - Understand the internals</li> <li>Recipes - Build real applications</li> <li>Performance Tuning - Optimize for your workload</li> </ul> <p>Or start coding with the Quickstart Guide!</p>"},{"location":"crates/nori-wal/design-decisions/","title":"Design Decisions","text":"<p>Why nori-wal is built the way it is.</p> <p>This section documents the key architectural and implementation decisions made in nori-wal, including the rationale behind each choice and alternative approaches that were considered.</p>"},{"location":"crates/nori-wal/design-decisions/#overview","title":"Overview","text":"<p>nori-wal was designed with several core principles:</p> <ol> <li>Production-Ready - Comprehensive error handling, recovery, and observability</li> <li>Performance - Optimized for modern hardware with careful benchmarking</li> <li>Simplicity - Clear APIs, predictable behavior, minimal surprises</li> <li>Flexibility - Configurable trade-offs between durability and performance</li> <li>Standalone - Usable as a library without dependencies on larger systems</li> </ol>"},{"location":"crates/nori-wal/design-decisions/#key-decisions","title":"Key Decisions","text":""},{"location":"crates/nori-wal/design-decisions/#append-only-architecture","title":"Append-Only Architecture","text":"<p>Why the WAL is strictly append-only and never modifies existing data.</p>"},{"location":"crates/nori-wal/design-decisions/#prefix-valid-recovery","title":"Prefix-Valid Recovery","text":"<p>Why we truncate at the first corruption rather than trying to recover more data.</p>"},{"location":"crates/nori-wal/design-decisions/#segment-based-storage","title":"Segment-Based Storage","text":"<p>Why the WAL is split into multiple files instead of one large file.</p>"},{"location":"crates/nori-wal/design-decisions/#crc32c-checksums","title":"CRC32C Checksums","text":"<p>Why we use CRC32C for data integrity and where it's computed.</p>"},{"location":"crates/nori-wal/design-decisions/#varint-encoding","title":"Varint Encoding","text":"<p>Why record lengths use variable-length encoding instead of fixed sizes.</p>"},{"location":"crates/nori-wal/design-decisions/#fsync-policies","title":"Fsync Policies","text":"<p>How we balance durability and performance with configurable fsync behavior.</p>"},{"location":"crates/nori-wal/design-decisions/#compression-support","title":"Compression Support","text":"<p>Why compression is optional and how it's integrated into the record format.</p>"},{"location":"crates/nori-wal/design-decisions/#zero-copy-design","title":"Zero-Copy Design","text":"<p>Where we use zero-copy techniques and where we don't.</p>"},{"location":"crates/nori-wal/design-decisions/#observability-first","title":"Observability First","text":"<p>Why metrics and events are built into the core rather than added later.</p>"},{"location":"crates/nori-wal/design-decisions/#decision-making-framework","title":"Decision-Making Framework","text":"<p>When making design decisions for nori-wal, we prioritize:</p> <p>1. Correctness First - Never sacrifice data integrity for performance - Clear error handling over silent failures - Predictable behavior over clever optimizations</p> <p>2. Production Reality - Handle crashes, corruption, and operator mistakes - Provide observability for debugging - Document failure modes explicitly</p> <p>3. Performance Where It Matters - Optimize the hot path (append, sync) - Accept slower cold paths (recovery, startup) - Measure before optimizing</p> <p>4. Simple Mental Model - Append-only semantics are easy to reason about - Explicit configuration over magic defaults - Predictable failure modes</p>"},{"location":"crates/nori-wal/design-decisions/#trade-offs","title":"Trade-offs","text":"<p>Every design decision involves trade-offs. We document both what we gained and what we gave up:</p> Decision Gained Cost Append-only Simplicity, crash safety No in-place updates Segments Bounded recovery time Multiple file handles CRC32C Corruption detection 4 bytes per record Varint Space efficiency Parsing overhead Batched fsync 100x write throughput Possible data loss window"},{"location":"crates/nori-wal/design-decisions/#non-goals","title":"Non-Goals","text":"<p>It's also important to document what nori-wal is not designed to do:</p> <p>Not a Database - No query language or indexes - No transactions across multiple records - No schema or type system</p> <p>Not a Message Queue - No consumer group management - No message ordering guarantees beyond append order - No built-in retention policies</p> <p>Not a Distributed System - No replication (use nori-raft on top) - No sharding (use norikv-placement) - No consensus (use nori-raft)</p> <p>nori-wal is a building block, not a complete system.</p>"},{"location":"crates/nori-wal/design-decisions/#evolution-of-design","title":"Evolution of Design","text":"<p>Some decisions were made early and have proven stable. Others evolved based on experience:</p> <p>Stable Since v0.1: - Append-only architecture - Prefix-valid recovery - CRC32C checksums - Segment-based storage</p> <p>Added Based on Feedback: - Compression support (v0.2) - Batch append API (v0.3) - TTL metadata (v0.4) - File pre-allocation (v0.5)</p> <p>Future Considerations: - Record-level encryption - Alternative checksum algorithms (XXH3) - Async fsync with io_uring on Linux</p>"},{"location":"crates/nori-wal/design-decisions/#further-reading","title":"Further Reading","text":"<p>Each subsection goes into detail on a specific design decision. Read them in any order based on your interests.</p>"},{"location":"crates/nori-wal/design-decisions/append-only/","title":"Append-Only Architecture","text":"<p>Why the WAL never modifies existing data.</p>"},{"location":"crates/nori-wal/design-decisions/append-only/#table-of-contents","title":"Table of contents","text":""},{"location":"crates/nori-wal/design-decisions/append-only/#decision","title":"Decision","text":"<p>nori-wal is strictly append-only. Once bytes are written to a segment file, they are never modified in-place. All writes go to the end of the current segment.</p>"},{"location":"crates/nori-wal/design-decisions/append-only/#rationale","title":"Rationale","text":""},{"location":"crates/nori-wal/design-decisions/append-only/#1-crash-safety","title":"1. Crash Safety","text":"<p>The primary reason for append-only design is crash safety:</p> <pre><code>// Append-only (safe)\n1. Append record to end of file\n2. If crash \u2192 Old data intact, new record may be partial\n3. Recovery validates CRC, truncates partial record\n</code></pre> <p>Compare to in-place updates:</p> <pre><code>// In-place update (unsafe)\n1. Seek to offset\n2. Overwrite existing bytes\n3. If crash mid-write \u2192 Data is corrupted, irrecoverable\n</code></pre> <p>With append-only, the worst case is losing the last incomplete record. With in-place updates, you can corrupt arbitrary data.</p>"},{"location":"crates/nori-wal/design-decisions/append-only/#2-simple-recovery","title":"2. Simple Recovery","text":"<p>Recovery is straightforward:</p> <pre><code>async fn recover(segment: &amp;Path) -&gt; Result&lt;ValidData&gt; {\n    let data = read_entire_file(segment).await?;\n    let (valid_records, last_valid_offset) = scan_for_valid_records(&amp;data);\n\n    if last_valid_offset &lt; data.len() {\n        // Truncate corrupted tail\n        truncate_file(segment, last_valid_offset).await?;\n    }\n\n    Ok(valid_records)\n}\n</code></pre> <p>This works because: - Valid records are always at the beginning - Corruption is always at the end (partial write) - No need to scan for holes or validate entire file</p>"},{"location":"crates/nori-wal/design-decisions/append-only/#3-sequential-io-performance","title":"3. Sequential I/O Performance","text":"<p>Appending to a file is fast on all storage devices:</p> Storage Type Sequential Write Random Write NVMe SSD 3-7 GB/s 200-500 MB/s SATA SSD 500 MB/s 100-200 MB/s HDD 100-200 MB/s 1-5 MB/s <p>Sequential writes are 10-100x faster than random writes on traditional hard drives.</p>"},{"location":"crates/nori-wal/design-decisions/append-only/#4-lock-free-reads","title":"4. Lock-Free Reads","text":"<p>Readers don't need to coordinate with writers:</p> <pre><code>// Writer appends to end\nwal.append(&amp;record).await?;  // Acquires write lock\n\n// Reader scans from beginning (no lock needed for old data)\nreader.read_from(Position { segment_id: 0, offset: 0 }).await?;\n</code></pre> <p>Since old data never changes, readers can operate without locks on historical segments. Only the active segment needs synchronization.</p>"},{"location":"crates/nori-wal/design-decisions/append-only/#what-we-gave-up","title":"What We Gave Up","text":""},{"location":"crates/nori-wal/design-decisions/append-only/#no-in-place-updates","title":"No In-Place Updates","text":"<p>Can't modify existing records:</p> <pre><code>// Can't do this:\nwal.update_at_offset(1024, new_value).await?;  // Not supported!\n\n// Must do this instead:\nwal.append(&amp;Record::put(key, new_value)).await?;  // New record\n</code></pre> <p>This means: - Multiple versions of the same key exist in the WAL - Need compaction/garbage collection eventually - Higher storage usage for frequently updated keys</p>"},{"location":"crates/nori-wal/design-decisions/append-only/#no-random-access-optimization","title":"No Random Access Optimization","text":"<p>Can't build an index inside the WAL:</p> <pre><code>// Can't embed an index in the WAL itself\n// Must scan from beginning or maintain external index\n\nlet mut reader = wal.read_from(Position::start()).await?;\nwhile let Some((record, _)) = reader.next_record().await? {\n    if record.key == target_key {\n        return Some(record);  // O(n) scan\n    }\n}\n</code></pre> <p>Solution: Build indexes on top (memtable, SSTable, B-tree).</p>"},{"location":"crates/nori-wal/design-decisions/append-only/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"crates/nori-wal/design-decisions/append-only/#alternative-1-update-in-place-log","title":"Alternative 1: Update-In-Place Log","text":"<p>Approach: Allow overwriting records at specific offsets.</p> <p>Rejected because: - Loses crash safety guarantees - Recovery becomes complex (need checksums for every record, handle partial overwrites) - No performance benefit on modern SSDs - Requires complex locking to coordinate readers/writers</p> <p>Where it makes sense: - Memory-mapped files with OS-managed durability - Systems that can afford full file rewrites - Append-only with compaction (what we do at LSM level)</p>"},{"location":"crates/nori-wal/design-decisions/append-only/#alternative-2-circular-buffer","title":"Alternative 2: Circular Buffer","text":"<p>Approach: Overwrite oldest data when buffer is full.</p> <pre><code>struct CircularWAL {\n    buffer: Vec&lt;u8&gt;,\n    head: usize,  // Write position\n    tail: usize,  // Oldest valid position\n}\n</code></pre> <p>Rejected because: - Loses historical data automatically - Readers must track offsets carefully or lose data - Recovery is complex (where does valid data start?) - Can't support multiple readers at different positions</p> <p>Where it makes sense: - Fixed-size ring buffers for metrics/logs - Systems where old data is truly disposable - Memory-constrained embedded systems</p>"},{"location":"crates/nori-wal/design-decisions/append-only/#alternative-3-copy-on-write","title":"Alternative 3: Copy-on-Write","text":"<p>Approach: Write new version to new location, then atomically update pointer.</p> <pre><code>// Write new version\nlet new_offset = write_record(&amp;record, segment);\n\n// Atomic pointer update\nindex.update(key, new_offset);  // Old version still exists\n</code></pre> <p>Why not: - Still need garbage collection - More complex than pure append - Requires external index (same as our approach) - No clear advantage over append + compaction</p> <p>Where it makes sense: - B-tree nodes (btrfs, ZFS) - Systems with built-in garbage collection - When you need MVCC (we do this at LSM level)</p>"},{"location":"crates/nori-wal/design-decisions/append-only/#interaction-with-other-decisions","title":"Interaction with Other Decisions","text":""},{"location":"crates/nori-wal/design-decisions/append-only/#segments-bounded-files","title":"Segments (Bounded Files)","text":"<p>Append-only + segments = bounded recovery time:</p> <pre><code>// Each segment is append-only\n// When segment reaches 128MB, start new segment\n// Recovery only scans last segment for partial writes\n</code></pre> <p>Without segments, recovery time grows unbounded as WAL grows.</p>"},{"location":"crates/nori-wal/design-decisions/append-only/#compaction-lsm-level","title":"Compaction (LSM Level)","text":"<p>Append-only WAL + compaction at higher level:</p> <pre><code>WAL: [put(k1,v1), put(k2,v2), put(k1,v3), delete(k2)]\n     \u2193 Flush to memtable\nMemtable: {k1: v3}  // Only latest version\n     \u2193 Compact to SSTable\nSSTable: [k1=v3]  // Tombstones removed\n</code></pre> <p>WAL is append-only (simple, fast). LSM compaction removes duplicates (space-efficient).</p>"},{"location":"crates/nori-wal/design-decisions/append-only/#crc-checksums","title":"CRC Checksums","text":"<p>Append-only makes CRC validation simple:</p> <pre><code>// CRC protects against partial writes at the end\nlet crc = compute_crc(&amp;record_bytes);\nappend(&amp;record_bytes);\nappend(&amp;crc);  // Last 4 bytes\n\n// Recovery: scan for valid CRCs, stop at first invalid\n</code></pre> <p>If we allowed in-place updates, every record would need checksums of neighbors to detect corruption.</p>"},{"location":"crates/nori-wal/design-decisions/append-only/#real-world-impact","title":"Real-World Impact","text":""},{"location":"crates/nori-wal/design-decisions/append-only/#sqlite-wal","title":"SQLite WAL","text":"<p>SQLite uses a similar append-only WAL:</p> <pre><code>WAL format: [record1][record2][record3]...\nCheckpoint: Apply WAL to database, then truncate WAL\n</code></pre> <p>Key difference: SQLite WAL is designed for single-process use. nori-wal supports multiple readers and concurrent access.</p>"},{"location":"crates/nori-wal/design-decisions/append-only/#postgresql-wal","title":"PostgreSQL WAL","text":"<p>PostgreSQL also uses append-only WAL:</p> <pre><code>pg_wal/000000010000000000000001\npg_wal/000000010000000000000002\n...\n</code></pre> <p>Each file is append-only. Archives old WAL files for point-in-time recovery.</p>"},{"location":"crates/nori-wal/design-decisions/append-only/#kafka","title":"Kafka","text":"<p>Kafka's log is append-only:</p> <pre><code>Segment 0: [msg1][msg2][msg3]...  (1GB)\nSegment 1: [msg4][msg5][msg6]...  (1GB, active)\n</code></pre> <p>Key difference: Kafka is the primary storage. nori-wal is a durability layer for in-memory structures.</p>"},{"location":"crates/nori-wal/design-decisions/append-only/#testing-strategy","title":"Testing Strategy","text":"<p>We validate append-only semantics with:</p> <p>1. Crash simulation tests:</p> <pre><code>#[tokio::test]\nasync fn test_crash_during_append() {\n    // Append 100 records\n    for i in 0..100 {\n        wal.append(&amp;Record::put(format!(\"k{}\", i), b\"value\")).await?;\n    }\n\n    // Simulate crash (drop WAL without sync)\n    drop(wal);\n\n    // Reopen - should recover all synced records\n    let (wal2, info) = Wal::open(config).await?;\n    assert!(info.valid_records &lt;= 100);  // May lose last few\n}\n</code></pre> <p>2. Corruption injection:</p> <pre><code>#[tokio::test]\nasync fn test_tail_corruption() {\n    // Write clean data\n    wal.append(&amp;record).await?;\n    wal.sync().await?;\n\n    // Corrupt tail of segment\n    corrupt_last_bytes(segment_path, 100);\n\n    // Recovery should truncate corruption\n    let (wal2, info) = Wal::open(config).await?;\n    assert!(info.corruption_detected);\n    assert_eq!(info.bytes_truncated, 100);\n}\n</code></pre> <p>3. Concurrent access:</p> <pre><code>#[tokio::test]\nasync fn test_concurrent_readers() {\n    // Write 1000 records\n    // Spawn 10 readers from different positions\n    // All should read consistent data (append-only guarantee)\n}\n</code></pre>"},{"location":"crates/nori-wal/design-decisions/append-only/#conclusion","title":"Conclusion","text":"<p>Append-only architecture is fundamental to nori-wal's design. It provides:</p> <ul> <li>Crash safety - Partial writes can't corrupt old data</li> <li>Simple recovery - Truncate at first corruption</li> <li>Performance - Sequential I/O is fast</li> <li>Concurrency - Lock-free reads of historical data</li> </ul> <p>The trade-off (no in-place updates) is acceptable because: - WAL is a durability layer, not primary storage - LSM compaction handles deduplication - Sequential writes are faster than random updates anyway</p> <p>This decision has proven stable since v0.1 and is unlikely to change.</p>"},{"location":"crates/nori-wal/design-decisions/recovery-strategy/","title":"Prefix-Valid Recovery Strategy","text":"<p>Why we truncate at the first corruption.</p>"},{"location":"crates/nori-wal/design-decisions/recovery-strategy/#table-of-contents","title":"Table of contents","text":""},{"location":"crates/nori-wal/design-decisions/recovery-strategy/#decision","title":"Decision","text":"<p>nori-wal uses prefix-valid recovery: When a corrupt or incomplete record is detected during recovery, we truncate the segment at that point and discard all data after it.</p>"},{"location":"crates/nori-wal/design-decisions/recovery-strategy/#what-this-means","title":"What This Means","text":"<pre><code>Segment file:\n[valid record 1][valid record 2][corrupt record][valid record 3][valid record 4]\n                                      \u2191\n                                   truncate here\n\nAfter recovery:\n[valid record 1][valid record 2]\n</code></pre> <p>Records 3 and 4 are lost, even though they may be valid, because they come after corruption.</p>"},{"location":"crates/nori-wal/design-decisions/recovery-strategy/#rationale","title":"Rationale","text":""},{"location":"crates/nori-wal/design-decisions/recovery-strategy/#1-append-only-semantics","title":"1. Append-Only Semantics","text":"<p>Because the WAL is strictly append-only, we know:</p> <ul> <li>Records are written in order</li> <li>Newer records come after older records</li> <li>Corruption at offset N means writes stopped at N</li> </ul> <p>If we find corruption at byte 1000, we know: - Bytes 0-999 were written before the crash - Bytes 1000+ were written during or after the crash - We can't trust anything after byte 1000</p>"},{"location":"crates/nori-wal/design-decisions/recovery-strategy/#2-simplicity","title":"2. Simplicity","text":"<p>Prefix-valid recovery is simple to implement and reason about:</p> <pre><code>fn recover_segment(data: &amp;[u8]) -&gt; (Vec&lt;Record&gt;, usize) {\n    let mut records = vec![];\n    let mut offset = 0;\n\n    loop {\n        match Record::decode(&amp;data[offset..]) {\n            Ok((record, size)) =&gt; {\n                records.push(record);\n                offset += size;\n            }\n            Err(_) =&gt; {\n                // Stop at first error\n                return (records, offset);\n            }\n        }\n    }\n}\n</code></pre> <p>No complex logic to skip corruption or search for valid records.</p>"},{"location":"crates/nori-wal/design-decisions/recovery-strategy/#3-no-false-positives","title":"3. No False Positives","text":"<p>Alternative strategies risk accepting invalid data:</p> <pre><code>// Bad: Skip corruption and continue\nmatch Record::decode(&amp;data[offset..]) {\n    Ok((record, size)) =&gt; { /* use record */ }\n    Err(_) =&gt; {\n        offset += 1;  // Skip one byte\n        continue;     // Try again\n    }\n}\n</code></pre> <p>Problems: - May interpret garbage as valid records (false positive) - CRC might accidentally match for random data - Could return records that were never actually written</p>"},{"location":"crates/nori-wal/design-decisions/recovery-strategy/#4-predictable-behavior","title":"4. Predictable Behavior","text":"<p>Users know exactly what to expect:</p> <p>Guarantee: If recovery returns N records, those are the first N records that were successfully synced.</p> <p>No surprises: - No skipping corrupted records - No \"best effort\" recovery - No heuristics that might change behavior</p>"},{"location":"crates/nori-wal/design-decisions/recovery-strategy/#what-we-gave-up","title":"What We Gave Up","text":""},{"location":"crates/nori-wal/design-decisions/recovery-strategy/#cant-recover-data-after-corruption","title":"Can't Recover Data After Corruption","text":"<pre><code>Scenario: Power loss during write\n\nBefore crash:\n[R1][R2][R3][R4][R5][partial R6]\n\nAfter recovery (prefix-valid):\n[R1][R2][R3][R4][R5]\n         \u2193\n    R6 lost permanently\n\nAlternative (scan-and-skip):\n[R1][R2][R3][R4][R5][skip partial R6][R7][R8]\n                                       \u2191\n                                  recovered!\n</code></pre> <p>We accept losing R7 and R8 to maintain simplicity and correctness guarantees.</p>"},{"location":"crates/nori-wal/design-decisions/recovery-strategy/#higher-data-loss-in-some-cases","title":"Higher Data Loss in Some Cases","text":"<p>If corruption happens early in a large segment:</p> <pre><code>Segment (100 MB):\n[5 MB valid][1 KB corrupt][94 MB valid]\n            \u2191\n        truncate here \u2192 lose 94 MB\n</code></pre> <p>We lose 94 MB of potentially valid data.</p>"},{"location":"crates/nori-wal/design-decisions/recovery-strategy/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"crates/nori-wal/design-decisions/recovery-strategy/#alternative-1-scan-and-skip-recovery","title":"Alternative 1: Scan-and-Skip Recovery","text":"<p>Approach: Continue scanning after corruption, try to recover more records.</p> <pre><code>fn scan_and_skip_recovery(data: &amp;[u8]) -&gt; Vec&lt;Record&gt; {\n    let mut records = vec![];\n    let mut offset = 0;\n\n    while offset &lt; data.len() {\n        match Record::decode(&amp;data[offset..]) {\n            Ok((record, size)) =&gt; {\n                records.push(record);\n                offset += size;\n            }\n            Err(_) =&gt; {\n                // Skip one byte, try again\n                offset += 1;\n            }\n        }\n    }\n\n    records\n}\n</code></pre> <p>Rejected because:</p> <ol> <li>False positives: Random bytes might have valid CRC by chance (1 in 4 billion)</li> <li>Undefined behavior: What if \"recovered\" record was never actually written?</li> <li>Complexity: Need heuristics to detect false positives</li> <li>User confusion: Sometimes recovers more, sometimes doesn't</li> </ol> <p>When it makes sense: - Interactive recovery tools where user can inspect results - Systems where false positives are acceptable - When data loss is catastrophic and corruption is localized</p>"},{"location":"crates/nori-wal/design-decisions/recovery-strategy/#alternative-2-checkpointing-with-skip-list","title":"Alternative 2: Checkpointing with Skip-List","text":"<p>Approach: Write periodic checkpoints to help recovery skip over corruption.</p> <pre><code>Segment format:\n[checkpoint 1][records...][checkpoint 2][records...][checkpoint 3][records...]\n                                            \u2191\n                                         corrupt\nRecovery:\n- Find last valid checkpoint\n- Continue from there\n</code></pre> <p>Rejected because:</p> <ol> <li>Complexity: Need to maintain checkpoint format, verify checkpoint integrity</li> <li>Write amplification: Checkpoints add overhead to every segment</li> <li>Limited benefit: Corruption usually at tail (partial write), not middle</li> <li>Still can't recover after tail corruption</li> </ol> <p>When it makes sense: - Very large segments (&gt;1 GB) where tail corruption wastes much space - Systems with frequent mid-segment corruption (hardware issues) - When checkpoint overhead is acceptable</p>"},{"location":"crates/nori-wal/design-decisions/recovery-strategy/#alternative-3-redundant-copies","title":"Alternative 3: Redundant Copies","text":"<p>Approach: Write each record twice to different locations.</p> <pre><code>Segment format:\n[R1 primary][R1 secondary][R2 primary][R2 secondary]...\n\nRecovery:\n- If primary corrupt, use secondary\n- If secondary corrupt, use primary\n</code></pre> <p>Rejected because:</p> <ol> <li>Storage overhead: 2x disk usage</li> <li>Write amplification: 2x writes</li> <li>Doesn't help with common case: Both copies corrupt if crash during write</li> <li>Complex recovery: Need to reconcile primary vs secondary</li> </ol> <p>When it makes sense: - Critical systems where data loss is unacceptable - When storage is cheap and speed is not critical - Distributed systems with replication (different approach)</p>"},{"location":"crates/nori-wal/design-decisions/recovery-strategy/#interaction-with-other-decisions","title":"Interaction with Other Decisions","text":""},{"location":"crates/nori-wal/design-decisions/recovery-strategy/#segments-bounded-loss","title":"Segments (Bounded Loss)","text":"<p>Prefix-valid + segments = bounded data loss:</p> <pre><code>Scenario: Corruption in segment 5\n\nSegments:\n0.wal (128 MB, complete)\n1.wal (128 MB, complete)\n2.wal (128 MB, complete)\n3.wal (128 MB, complete)\n4.wal (128 MB, complete)\n5.wal (50 MB written, corrupt at 10 MB)\n       \u2191\n    truncate to 10 MB\n\nMaximum loss: 40 MB (segment 5 only)\nSegments 0-4 unaffected\n</code></pre> <p>Without segments, corruption could affect entire WAL.</p>"},{"location":"crates/nori-wal/design-decisions/recovery-strategy/#crc-checksums","title":"CRC Checksums","text":"<p>CRC + prefix-valid = reliable detection:</p> <pre><code>// CRC catches corruption immediately\nmatch Record::decode(data) {\n    Ok(_) =&gt; { /* valid */ }\n    Err(RecordError::CrcMismatch { .. }) =&gt; {\n        // Stop here, truncate\n    }\n}\n</code></pre> <p>Without CRC, we might not detect corruption until much later (or never).</p>"},{"location":"crates/nori-wal/design-decisions/recovery-strategy/#fsync-policies","title":"Fsync Policies","text":"<p>Prefix-valid + fsync = predictable loss window:</p> <pre><code>FsyncPolicy::Batch(5ms) means:\n- Crash within 5ms of write \u2192 may lose last writes\n- Crash after successful sync \u2192 no loss\n- Recovery always recovers up to last valid sync\n</code></pre> <p>Users know maximum data loss: batching window duration.</p>"},{"location":"crates/nori-wal/design-decisions/recovery-strategy/#real-world-examples","title":"Real-World Examples","text":""},{"location":"crates/nori-wal/design-decisions/recovery-strategy/#postgresql","title":"PostgreSQL","text":"<p>PostgreSQL uses prefix-valid recovery for WAL:</p> <pre><code>Recovery process:\n1. Read WAL segments in order\n2. Apply each record to database\n3. Stop at first invalid record\n4. Truncate WAL at that point\n</code></pre> <p>Source: PostgreSQL src/backend/access/transam/xlog.c</p>"},{"location":"crates/nori-wal/design-decisions/recovery-strategy/#rocksdb","title":"RocksDB","text":"<p>RocksDB WAL also uses prefix-valid:</p> <pre><code>// From RocksDB log_reader.cc\nStatus ReadRecord(...) {\n  while (true) {\n    ...\n    if (crc_check &amp;&amp; !CheckCrc(...)) {\n      // Corruption detected - stop reading\n      return Status::Corruption(\"CRC mismatch\");\n    }\n  }\n}\n</code></pre>"},{"location":"crates/nori-wal/design-decisions/recovery-strategy/#kafka","title":"Kafka","text":"<p>Kafka uses prefix-valid for each segment:</p> <pre><code>// From Kafka Log.scala\ndef recoverSegment(segment: LogSegment): Int = {\n  var validBytes = 0\n  while (...) {\n    if (record.isValid()) {\n      validBytes += record.size\n    } else {\n      segment.truncateTo(validBytes)\n      return validBytes\n    }\n  }\n}\n</code></pre>"},{"location":"crates/nori-wal/design-decisions/recovery-strategy/#testing-strategy","title":"Testing Strategy","text":"<p>We validate prefix-valid recovery with:</p> <p>1. Corruption injection tests:</p> <pre><code>#[tokio::test]\nasync fn test_truncates_at_first_corruption() {\n    // Write 100 valid records\n    for i in 0..100 {\n        wal.append(&amp;Record::put(format!(\"k{}\", i), b\"v\")).await?;\n    }\n    wal.sync().await?;\n\n    // Corrupt record 50\n    corrupt_record_at_offset(segment_path, 50);\n\n    // Recovery should stop at record 50\n    let (wal2, info) = Wal::open(config).await?;\n    assert_eq!(info.valid_records, 49);  // 0-48 recovered, 49+ lost\n}\n</code></pre> <p>2. Partial write tests:</p> <pre><code>#[tokio::test]\nasync fn test_truncates_partial_tail() {\n    wal.append(&amp;record1).await?;\n    wal.sync().await?;\n\n    // Simulate crash mid-append (write partial record)\n    write_partial_record(segment_path, &amp;record2);\n\n    // Recovery should truncate partial record\n    let (wal2, info) = Wal::open(config).await?;\n    assert_eq!(info.valid_records, 1);\n    assert!(info.bytes_truncated &gt; 0);\n}\n</code></pre> <p>3. Multi-segment recovery:</p> <pre><code>#[tokio::test]\nasync fn test_corruption_only_affects_one_segment() {\n    // Write to segment 0 (full)\n    // Write to segment 1 (full)\n    // Write to segment 2 (partial, corrupt)\n\n    let (wal, info) = Wal::open(config).await?;\n\n    // Segment 0 and 1 should be intact\n    // Only segment 2 truncated\n}\n</code></pre>"},{"location":"crates/nori-wal/design-decisions/recovery-strategy/#monitoring-and-alerting","title":"Monitoring and Alerting","text":"<p>Users should monitor recovery events:</p> <pre><code>let (wal, info) = Wal::open(config).await?;\n\nif info.corruption_detected {\n    log::warn!(\n        \"WAL corruption detected: {} bytes truncated from segment\",\n        info.bytes_truncated\n    );\n\n    // Alert if significant data loss\n    if info.bytes_truncated &gt; 1024 * 1024 {  // &gt; 1 MB\n        alert_ops(\"Significant WAL data loss during recovery\");\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/design-decisions/recovery-strategy/#conclusion","title":"Conclusion","text":"<p>Prefix-valid recovery is the right choice for nori-wal because:</p> <ul> <li>Simple and predictable - Easy to understand and test</li> <li>No false positives - Never returns invalid data</li> <li>Works with append-only - Natural fit for append-only architecture</li> <li>Industry standard - Used by PostgreSQL, RocksDB, Kafka</li> </ul> <p>The trade-off (losing data after corruption) is acceptable because: - Corruption usually at tail (partial write) - Segments bound the maximum loss - Fsync policies control loss window - Replication handles catastrophic failures (at higher levels)</p> <p>This decision has proven stable and is unlikely to change.</p>"},{"location":"crates/nori-wal/design-decisions/segmentation/","title":"Segment-Based Storage","text":"<p>Why the WAL is split into multiple files.</p>"},{"location":"crates/nori-wal/design-decisions/segmentation/#table-of-contents","title":"Table of contents","text":""},{"location":"crates/nori-wal/design-decisions/segmentation/#decision","title":"Decision","text":"<p>nori-wal splits the log into multiple segment files of 128 MB each (configurable), rather than using a single unbounded file.</p>"},{"location":"crates/nori-wal/design-decisions/segmentation/#what-this-means","title":"What This Means","text":"<pre><code>wal/\n  000000.wal  (128 MB, complete)\n  000001.wal  (128 MB, complete)\n  000002.wal  (75 MB, active)\n</code></pre> <p>Each segment is a separate file. When a segment reaches 128 MB, a new segment is created.</p>"},{"location":"crates/nori-wal/design-decisions/segmentation/#rationale","title":"Rationale","text":""},{"location":"crates/nori-wal/design-decisions/segmentation/#1-bounded-recovery-time","title":"1. Bounded Recovery Time","text":"<p>Recovery time is proportional to data size. With segments:</p> <pre><code>// Single file (bad)\nRecovery: Scan 10 GB file = 3 seconds\n\n// Segments (good)\nRecovery: Scan last 128 MB segment = 40 ms\n</code></pre> <p>Only the last (incomplete) segment needs validation. Complete segments were already validated when closed.</p>"},{"location":"crates/nori-wal/design-decisions/segmentation/#2-garbage-collection","title":"2. Garbage Collection","text":"<p>Can delete old segments safely:</p> <pre><code>// Segments\nwal.delete_segments_before(checkpoint_position).await?;\n// Deletes: 000000.wal, 000001.wal\n// Keeps: 000002.wal (still needed)\n\n// Single file (can't do this)\n// Would need to copy entire file to remove old data\n</code></pre> <p>After compaction/checkpointing, old WAL data is no longer needed. With segments, just delete old files.</p>"},{"location":"crates/nori-wal/design-decisions/segmentation/#3-filesystem-limits","title":"3. Filesystem Limits","text":"<p>Many filesystems have performance cliffs at large file sizes:</p> Filesystem Performance Issue Size Threshold ext4 Indirect blocks &gt; 2 TB XFS Extent fragmentation &gt; 100 GB NTFS MFT size &gt; 256 GB <p>Keeping files &lt; 1 GB avoids these issues.</p>"},{"location":"crates/nori-wal/design-decisions/segmentation/#4-operational-safety","title":"4. Operational Safety","text":"<p>Easier to manage multiple small files:</p> <pre><code># Backup\nrsync wal/000000.wal backup/  # Fast, can be done incrementally\n\n# Corruption analysis\nhexdump -C wal/000042.wal | less  # Manageable size\n\n# Space reclamation\nrm wal/000000.wal  # Immediate space recovery\n</code></pre> <p>Compare to a single 100 GB file - harder to copy, analyze, or clean up.</p>"},{"location":"crates/nori-wal/design-decisions/segmentation/#what-we-gave-up","title":"What We Gave Up","text":""},{"location":"crates/nori-wal/design-decisions/segmentation/#more-file-handles","title":"More File Handles","text":"<pre><code>// With segments (many file handles)\nlet mut segments = vec![];\nfor id in 0..100 {\n    segments.push(File::open(segment_path(id)).await?);\n}\n\n// Single file (one file handle)\nlet file = File::open(\"wal.log\").await?;\n</code></pre> <p>Operating systems limit open file handles (typically 1024-65536). With many segments, could hit limits.</p> <p>Mitigation: Only keep active segment open for writing. Open others on-demand for reading.</p>"},{"location":"crates/nori-wal/design-decisions/segmentation/#rotation-overhead","title":"Rotation Overhead","text":"<p>Creating new segments has overhead:</p> <pre><code>// Every 128 MB\n1. Finalize current segment (truncate to exact size)\n2. Sync current segment\n3. Create new segment file\n4. Pre-allocate new segment (fallocate)\n5. Emit rotation event\n\n// Cost: ~10-50ms depending on filesystem\n</code></pre> <p>Mitigation: 128 MB threshold means rotation every ~10-60 seconds for typical workloads.</p>"},{"location":"crates/nori-wal/design-decisions/segmentation/#complexity-in-position-tracking","title":"Complexity in Position Tracking","text":"<p>Positions now have two components:</p> <pre><code>struct Position {\n    segment_id: u64,  // Which file\n    offset: u64,      // Where in file\n}\n\n// vs single file\nstruct Position {\n    offset: u64,  // Just offset\n}\n</code></pre> <p>Mitigation: Helper methods make this transparent to users.</p>"},{"location":"crates/nori-wal/design-decisions/segmentation/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"crates/nori-wal/design-decisions/segmentation/#alternative-1-single-unbounded-file","title":"Alternative 1: Single Unbounded File","text":"<p>Approach: One file that grows forever.</p> <pre><code>// wal.log grows to 10 GB, 100 GB, 1 TB...\n</code></pre> <p>Rejected because:</p> <ol> <li>Recovery time unbounded: Need to scan entire file</li> <li>No garbage collection: Can't remove old data without rewriting entire file</li> <li>Filesystem issues: Large files hit performance cliffs</li> <li>Operational pain: Hard to backup, analyze, or manage</li> </ol> <p>When it makes sense: - Embedded systems with bounded workloads - When recovery time doesn't matter - Short-lived processes that don't accumulate much data</p>"},{"location":"crates/nori-wal/design-decisions/segmentation/#alternative-2-time-based-segments","title":"Alternative 2: Time-Based Segments","text":"<p>Approach: Rotate segments based on time instead of size.</p> <pre><code>// Rotate every hour\nlet segment_name = format!(\"{}.wal\", chrono::Utc::now().timestamp());\n</code></pre> <p>Rejected because:</p> <ol> <li>Unpredictable size: High-traffic hours create huge segments</li> <li>Unpredictable recovery time: Large segments take longer to recover</li> <li>Wasted space: Low-traffic hours create tiny segments</li> </ol> <p>When it makes sense: - Log rotation for human-readable logs - When workload is predictable and uniform - When time-based organization helps debugging</p>"},{"location":"crates/nori-wal/design-decisions/segmentation/#alternative-3-record-count-segments","title":"Alternative 3: Record-Count Segments","text":"<p>Approach: Rotate after N records instead of N bytes.</p> <pre><code>// Rotate after 1 million records\nif record_count &gt;= 1_000_000 {\n    rotate_segment();\n}\n</code></pre> <p>Rejected because:</p> <ol> <li>Variable size: 1M small records \u2260 1M large records</li> <li>Can't predict disk usage: Users don't know how much space needed</li> <li>Unpredictable recovery time: Large records = longer recovery</li> </ol> <p>When it makes sense: - When records are uniform size - When counting records is more intuitive than bytes - Fixed-size record systems</p>"},{"location":"crates/nori-wal/design-decisions/segmentation/#size-selection-128-mb","title":"Size Selection (128 MB)","text":"<p>Why 128 MB specifically?</p> <p>Too Small (&lt; 16 MB): - Frequent rotations (overhead) - Many file handles - Fragmented storage</p> <p>Too Large (&gt; 512 MB): - Longer recovery time - More data loss on corruption - Harder to manage files</p> <p>128 MB is sweet spot: - Recovery: 40ms on NVMe - Rotation: ~30-60 seconds on typical workload - Manageable file size for operations - Fits in Linux page cache</p> <p>Users can configure based on workload:</p> <pre><code>let config = WalConfig {\n    max_segment_size: 64 * 1024 * 1024,  // 64 MB for faster recovery\n    // or\n    max_segment_size: 256 * 1024 * 1024,  // 256 MB for fewer rotations\n    ..Default::default()\n};\n</code></pre>"},{"location":"crates/nori-wal/design-decisions/segmentation/#interaction-with-other-decisions","title":"Interaction with Other Decisions","text":""},{"location":"crates/nori-wal/design-decisions/segmentation/#prefix-valid-recovery-segments","title":"Prefix-Valid Recovery + Segments","text":"<p>Segments bound the data loss from corruption:</p> <pre><code>Corruption in segment 5:\n- Segments 0-4: Unaffected (complete)\n- Segment 5: Truncated at corruption\n- Segments 6+: Don't exist yet\n\nMaximum loss: One segment worth of data (128 MB)\n</code></pre> <p>Without segments, corruption anywhere could affect entire log.</p>"},{"location":"crates/nori-wal/design-decisions/segmentation/#garbage-collection","title":"Garbage Collection","text":"<p>Segments enable simple GC:</p> <pre><code>// After LSM compaction, old WAL data is in SSTables\nlet checkpoint = last_flushed_position;\nwal.delete_segments_before(checkpoint).await?;\n\n// Deletes old files immediately\n// No need to rewrite or compact WAL itself\n</code></pre>"},{"location":"crates/nori-wal/design-decisions/segmentation/#file-pre-allocation","title":"File Pre-allocation","text":"<p>Each segment can be pre-allocated:</p> <pre><code>// When creating segment 5:\nlet file = create_file(\"000005.wal\");\nfallocate(file, 128 * 1024 * 1024);  // Reserve space\n\n// Benefits:\n// - Early \"disk full\" detection\n// - Reduced fragmentation\n// - Better filesystem locality\n</code></pre> <p>Pre-allocation works best with fixed-size segments.</p>"},{"location":"crates/nori-wal/design-decisions/segmentation/#real-world-examples","title":"Real-World Examples","text":""},{"location":"crates/nori-wal/design-decisions/segmentation/#kafka","title":"Kafka","text":"<p>Kafka uses segments (default 1 GB):</p> <pre><code>/var/lib/kafka/topic-0/\n  00000000000000000000.log  (1 GB)\n  00000000000000123456.log  (1 GB)\n  00000000000000456789.log  (500 MB, active)\n  00000000000000000000.index\n  00000000000000123456.index\n</code></pre> <p>Segments enable: - Log retention (delete old segments) - Replication (send segments to followers) - Compaction (rebuild segments without deleted keys)</p>"},{"location":"crates/nori-wal/design-decisions/segmentation/#postgresql","title":"PostgreSQL","text":"<p>PostgreSQL WAL segments (default 16 MB):</p> <pre><code>pg_wal/\n  000000010000000000000001  (16 MB)\n  000000010000000000000002  (16 MB)\n  ...\n</code></pre> <p>Smaller segments because: - PostgreSQL has smaller working set - Frequent checkpointing - Need fast recovery for ACID guarantees</p>"},{"location":"crates/nori-wal/design-decisions/segmentation/#rocksdb","title":"RocksDB","text":"<p>RocksDB WAL rotates with memtable flush:</p> <pre><code>WAL tied to memtable lifecycle:\n- Memtable 1 \u2192 WAL 000001.log\n- Memtable 2 \u2192 WAL 000002.log\n- When memtable flushed \u2192 delete corresponding WAL\n</code></pre> <p>Different approach: Logical rotation (per memtable) vs physical rotation (size-based).</p>"},{"location":"crates/nori-wal/design-decisions/segmentation/#testing-strategy","title":"Testing Strategy","text":"<p>1. Rotation behavior:</p> <pre><code>#[tokio::test]\nasync fn test_rotates_at_threshold() {\n    let config = WalConfig {\n        max_segment_size: 1024 * 1024,  // 1 MB\n        ..Default::default()\n    };\n\n    let (wal, _) = Wal::open(config).await?;\n\n    // Write 2 MB of data\n    for _ in 0..2000 {\n        wal.append(&amp;Record::put(b\"k\", &amp;[0u8; 1024])).await?;\n    }\n\n    // Should have created 2+ segments\n    let segments = list_segments(&amp;config.dir)?;\n    assert!(segments.len() &gt;= 2);\n}\n</code></pre> <p>2. Garbage collection:</p> <pre><code>#[tokio::test]\nasync fn test_deletes_old_segments() {\n    // Create 5 segments\n    // ...\n\n    // Delete first 3\n    let checkpoint = Position { segment_id: 3, offset: 0 };\n    let deleted = wal.delete_segments_before(checkpoint).await?;\n\n    assert_eq!(deleted, 3);\n    assert!(!segment_exists(\"000000.wal\"));\n    assert!(!segment_exists(\"000001.wal\"));\n    assert!(!segment_exists(\"000002.wal\"));\n    assert!(segment_exists(\"000003.wal\"));\n}\n</code></pre> <p>3. Recovery across segments:</p> <pre><code>#[tokio::test]\nasync fn test_recovers_across_segments() {\n    // Write data spanning 3 segments\n    // Close WAL\n    // Reopen\n\n    let (wal, info) = Wal::open(config).await?;\n    assert_eq!(info.segments_scanned, 3);\n    assert_eq!(info.valid_records, expected_count);\n}\n</code></pre>"},{"location":"crates/nori-wal/design-decisions/segmentation/#monitoring","title":"Monitoring","text":"<p>Users should monitor segment metrics:</p> <pre><code>// Observe via nori-observe\nmetrics.gauge(\"wal.active_segment_id\", segment_id);\nmetrics.gauge(\"wal.active_segment_bytes\", bytes_written);\nmetrics.counter(\"wal.segments_rotated\", 1);\nmetrics.counter(\"wal.segments_deleted\", deleted_count);\n</code></pre> <p>Alerts: - Too many segments \u2192 Might need larger segment size or GC - Frequent rotations \u2192 Might need tuning - No rotations \u2192 Workload might be too light</p>"},{"location":"crates/nori-wal/design-decisions/segmentation/#conclusion","title":"Conclusion","text":"<p>Segment-based storage is essential for nori-wal because:</p> <ul> <li>Bounded recovery time - Only validate last segment</li> <li>Garbage collection - Delete old segments easily</li> <li>Operational simplicity - Manageable file sizes</li> <li>Filesystem compatibility - Avoid large file issues</li> </ul> <p>The trade-offs (file handles, rotation overhead) are acceptable because: - Keep only active segment open - Rotation is infrequent (every 30-60s) - Benefits far outweigh costs</p> <p>This decision has proven stable since v0.1 and is unlikely to change.</p>"},{"location":"crates/nori-wal/getting-started/","title":"Getting Started with nori-wal","text":"<p>Everything you need to start using nori-wal in your project.</p>"},{"location":"crates/nori-wal/getting-started/#quick-navigation","title":"Quick Navigation","text":"<p>Brand new to WALs? \u2192 Start with What is a Write-Ahead Log?</p> <p>Ready to code? \u2192 Follow the 5-Minute Quickstart</p> <p>Need to configure? \u2192 Check the Configuration Guide</p> <p>Want deeper understanding? \u2192 Explore How It Works</p>"},{"location":"crates/nori-wal/getting-started/#learning-path","title":"Learning Path","text":"<p>We recommend this order for learning nori-wal:</p>"},{"location":"crates/nori-wal/getting-started/#1-installation","title":"1. Installation","text":"<p>Add nori-wal to your project and verify it works.</p>"},{"location":"crates/nori-wal/getting-started/#2-5-minute-quickstart","title":"2. 5-Minute Quickstart","text":"<p>Write your first WAL program and see recovery in action.</p>"},{"location":"crates/nori-wal/getting-started/#3-configuration-guide","title":"3. Configuration Guide","text":"<p>Understand all configuration options and pick the right settings.</p>"},{"location":"crates/nori-wal/getting-started/#4-core-concepts","title":"4. Core Concepts","text":"<p>Learn the fundamentals: what WALs are, how they work, when to use them.</p>"},{"location":"crates/nori-wal/getting-started/#5-how-it-works","title":"5. How It Works","text":"<p>Deep dive into internals: record format, recovery, concurrency, etc.</p>"},{"location":"crates/nori-wal/getting-started/#6-recipes","title":"6. Recipes","text":"<p>Build real applications with nori-wal.</p>"},{"location":"crates/nori-wal/getting-started/#common-tasks","title":"Common Tasks","text":"<p>Writing records: <pre><code>let record = Record::put(b\"key\", b\"value\");\nlet position = wal.append(&amp;record).await?;\nwal.sync().await?;  // Ensure durability\n</code></pre></p> <p>Reading records: <pre><code>let mut reader = wal.read_from(Position { segment_id: 0, offset: 0 }).await?;\nwhile let Some((record, pos)) = reader.next_record().await? {\n    // Process record\n}\n</code></pre></p> <p>Batch writes: <pre><code>let records = vec![\n    Record::put(b\"key1\", b\"value1\"),\n    Record::put(b\"key2\", b\"value2\"),\n];\nlet positions = wal.append_batch(&amp;records).await?;\n</code></pre></p> <p>Recovery: <pre><code>let (wal, recovery_info) = Wal::open(config).await?;\nprintln!(\"Recovered {} records\", recovery_info.valid_records);\n</code></pre></p>"},{"location":"crates/nori-wal/getting-started/#common-questions","title":"Common Questions","text":"<p>Q: Do I need to call <code>sync()</code> after every write?</p> <p>A: It depends on your <code>FsyncPolicy</code>: - <code>Always</code>: No, sync happens automatically - <code>Batch</code>: No, syncs happen within the time window - <code>Os</code>: Only if you need durability guarantees</p> <p>Q: How do I delete old data?</p> <p>A: Use <code>delete_segments_before()</code> after you've compacted/replicated the data: <pre><code>let cutoff = Position { segment_id: 5, offset: 0 };\nlet deleted = wal.delete_segments_before(cutoff).await?;\n</code></pre></p> <p>Q: Can I use nori-wal in multi-threaded code?</p> <p>A: Yes! <code>Wal</code> is <code>Send + Sync</code> and can be shared across threads: <pre><code>let wal = Arc::new(wal);\n// Share wal across threads\n</code></pre></p> <p>Q: What happens if I crash mid-write?</p> <p>A: The WAL recovery process scans all segments, validates each record with CRC32C, and truncates any partial/corrupt data at the tail. All valid records are preserved.</p>"},{"location":"crates/nori-wal/getting-started/#next-steps","title":"Next Steps","text":"<p>Choose your path:</p> <ul> <li>Start coding - Get hands-on immediately</li> <li>Learn concepts - Understand WALs deeply</li> <li>Configure - Tune for your workload</li> <li>Build something - See real-world examples</li> </ul>"},{"location":"crates/nori-wal/getting-started/configuration/","title":"Configuration Guide","text":"<p>Complete guide to configuring nori-wal for your workload.</p>"},{"location":"crates/nori-wal/getting-started/configuration/#table-of-contents","title":"Table of contents","text":""},{"location":"crates/nori-wal/getting-started/configuration/#walconfig-overview","title":"WalConfig Overview","text":"<p>The <code>WalConfig</code> struct controls all aspects of WAL behavior:</p> <pre><code>use nori_wal::{WalConfig, FsyncPolicy};\nuse std::path::PathBuf;\nuse std::time::Duration;\n\nlet config = WalConfig {\n    dir: PathBuf::from(\"/var/lib/myapp/wal\"),\n    max_segment_size: 256 * 1024 * 1024, // 256MB\n    fsync_policy: FsyncPolicy::Batch(Duration::from_millis(10)),\n    preallocate: true,\n    node_id: 42,\n};\n\nlet (wal, recovery_info) = Wal::open(config).await?;\n</code></pre>"},{"location":"crates/nori-wal/getting-started/configuration/#configuration-fields","title":"Configuration Fields","text":""},{"location":"crates/nori-wal/getting-started/configuration/#dir-pathbuf","title":"<code>dir: PathBuf</code>","text":"<p>Purpose: Where to store WAL segment files</p> <p>Default: <code>\"wal\"</code> (in current working directory)</p> <p>Recommendations: - Use an absolute path in production - Make sure parent directory exists - Consider using a dedicated disk/volume for I/O isolation - Ensure sufficient disk space (at least <code>max_segment_size * 2</code>)</p> <p>Examples:</p> <pre><code>// Development: relative path\ndir: PathBuf::from(\"wal\"),\n\n// Production: absolute path\ndir: PathBuf::from(\"/var/lib/myapp/wal\"),\n\n// Docker: mounted volume\ndir: PathBuf::from(\"/data/wal\"),\n\n// Testing: temporary directory\ndir: temp_dir.path().to_path_buf(),\n</code></pre>"},{"location":"crates/nori-wal/getting-started/configuration/#max_segment_size-u64","title":"<code>max_segment_size: u64</code>","text":"<p>Purpose: Maximum size of a single segment file before rotation</p> <p>Default: <code>134,217,728</code> bytes (128 MiB)</p> <p>Valid range: 1 MiB to unlimited</p> <p>Trade-offs:</p> Size Pros Cons Small (1-32 MB) Faster rotation, smaller files More segments to manage, higher overhead Medium (128 MB) \u2b50 Good balance Default, works for most cases Large (512 MB - 1 GB) Fewer segments Slower rotation, larger files to manage <p>When to use small segments: - Frequent checkpointing/compaction - Limited disk space - Need quick garbage collection</p> <p>When to use large segments: - High write throughput - Infrequent compaction - Want to minimize segment rotation overhead</p> <p>Examples:</p> <pre><code>// Small: 32MB (rotate frequently)\nmax_segment_size: 32 * 1024 * 1024,\n\n// Default: 128MB (recommended)\nmax_segment_size: 128 * 1024 * 1024,\n\n// Large: 512MB (high throughput)\nmax_segment_size: 512 * 1024 * 1024,\n</code></pre> <p>{: .warning } Segments smaller than 1MB will be rejected with an <code>InvalidConfig</code> error. This prevents pathological behavior.</p>"},{"location":"crates/nori-wal/getting-started/configuration/#fsync_policy-fsyncpolicy","title":"<code>fsync_policy: FsyncPolicy</code>","text":"<p>Purpose: Controls when data is synced to disk (durability vs. performance)</p> <p>Default: <code>FsyncPolicy::Batch(Duration::from_millis(5))</code></p> <p>Options:</p>"},{"location":"crates/nori-wal/getting-started/configuration/#fsyncpolicyalways","title":"<code>FsyncPolicy::Always</code>","text":"<p>Calls <code>fsync()</code> after every write.</p> <p>Durability: \u2b50\u2b50\u2b50\u2b50\u2b50 Maximum Performance: \u2b50 ~420 writes/sec Use when: Critical data, financial transactions, strict ACID compliance</p> <pre><code>fsync_policy: FsyncPolicy::Always,\n</code></pre> <p>Characteristics: - Every <code>append()</code> calls <code>fsync()</code> - Data guaranteed on disk before returning - Slowest, but most durable - Disk-bound performance</p>"},{"location":"crates/nori-wal/getting-started/configuration/#fsyncpolicybatchduration","title":"<code>FsyncPolicy::Batch(Duration)</code>","text":"<p>Batches <code>fsync()</code> calls within a time window.</p> <p>Durability: \u2b50\u2b50\u2b50\u2b50 High Performance: \u2b50\u2b50\u2b50\u2b50 ~86K writes/sec Use when: Most applications (recommended default)</p> <pre><code>// Fsync at most once every 5ms\nfsync_policy: FsyncPolicy::Batch(Duration::from_millis(5)),\n\n// More durable: fsync every 1ms\nfsync_policy: FsyncPolicy::Batch(Duration::from_millis(1)),\n\n// Higher throughput: fsync every 10ms\nfsync_policy: FsyncPolicy::Batch(Duration::from_millis(10)),\n</code></pre> <p>Characteristics: - First write triggers fsync - Subsequent writes within window skip fsync - Good balance of durability and performance - Potential data loss: up to <code>window</code> duration of writes</p> <p>{: .important } With a 5ms window, you could lose up to 5ms worth of writes if you crash. For most applications, this is acceptable. Adjust based on your requirements.</p>"},{"location":"crates/nori-wal/getting-started/configuration/#fsyncpolicyos","title":"<code>FsyncPolicy::Os</code>","text":"<p>Lets the operating system decide when to flush.</p> <p>Durability: \u2b50\u2b50 OS-dependent (typically 30-60 seconds) Performance: \u2b50\u2b50\u2b50\u2b50\u2b50 ~110K writes/sec Use when: Event logs, metrics, caches, acceptable data loss</p> <pre><code>fsync_policy: FsyncPolicy::Os,\n</code></pre> <p>Characteristics: - No explicit <code>fsync()</code> calls - Relies on OS page cache - Maximum throughput - Potential data loss: 30-60 seconds of writes on crash</p> <p>{: .warning } Never use <code>Os</code> policy for critical data! On power failure or kernel panic, you could lose significant amounts of data.</p>"},{"location":"crates/nori-wal/getting-started/configuration/#decision-matrix","title":"Decision Matrix","text":"<p>Use this to pick the right policy:</p> <pre><code>graph TD\n    A[What's your use case?] --&gt; B{Can you tolerate ANY data loss?}\n    B --&gt;|No| C[FsyncPolicy::Always]\n    B --&gt;|Yes| D{How much data loss is OK?}\n    D --&gt;|&lt; 10ms| E[FsyncPolicy::Batch 1-5ms]\n    D --&gt;|10-100ms| F[FsyncPolicy::Batch 10-50ms]\n    D --&gt;|Seconds OK| G[FsyncPolicy::Os]\n\n    C --&gt; H[~420 writes/sec]\n    E --&gt; I[~86K writes/sec]\n    F --&gt; J[~95K writes/sec]\n    G --&gt; K[~110K writes/sec]</code></pre>"},{"location":"crates/nori-wal/getting-started/configuration/#preallocate-bool","title":"<code>preallocate: bool</code>","text":"<p>Purpose: Whether to pre-allocate segment files</p> <p>Default: <code>true</code></p> <p>When enabled: - New segments are pre-allocated to <code>max_segment_size</code> using platform-specific APIs - Linux: Uses <code>fallocate()</code> syscall - macOS: Uses <code>F_PREALLOCATE</code> fcntl - Windows/Others: Uses <code>set_len()</code></p> <p>Benefits: - Early error detection: Out-of-space errors happen at segment creation, not mid-write - Reduced fragmentation: OS allocates contiguous disk space - Better performance: Some filesystems optimize for pre-allocated files</p> <p>Drawbacks: - Small latency increase (~1-2ms) when creating segments - Disk space shows as \"used\" even if not written (this is correct behavior)</p> <p>When to disable: - Testing (faster test runs) - Environments with tight disk quotas - When segment size &gt;&gt; actual usage</p> <pre><code>// Enable (recommended for production)\npreallocate: true,\n\n// Disable (testing, development)\npreallocate: false,\n</code></pre>"},{"location":"crates/nori-wal/getting-started/configuration/#node_id-u32","title":"<code>node_id: u32</code>","text":"<p>Purpose: Identifier for observability events</p> <p>Default: <code>0</code></p> <p>Use when: - Running multiple WAL instances - Distributed systems - Want to correlate metrics/events to specific nodes</p> <pre><code>// Single instance\nnode_id: 0,\n\n// Multi-node cluster\nnode_id: server_config.node_id,\n\n// Per-shard WALs\nnode_id: shard_id as u32,\n</code></pre> <p>This field is included in all <code>VizEvent</code> emissions, allowing you to differentiate logs from multiple WAL instances in your metrics system.</p>"},{"location":"crates/nori-wal/getting-started/configuration/#configuration-validation","title":"Configuration Validation","text":"<p><code>WalConfig</code> is validated when you call <code>Wal::open()</code>. Invalid configurations return <code>SegmentError::InvalidConfig</code>:</p> <pre><code>// Too small!\nlet config = WalConfig {\n    max_segment_size: 512,  // Less than 1MB\n    ..Default::default()\n};\n\nmatch Wal::open(config).await {\n    Err(SegmentError::InvalidConfig(msg)) =&gt; {\n        println!(\"Config error: {}\", msg);\n        // \"max_segment_size should be at least 1MB...\"\n    }\n    _ =&gt; unreachable!(),\n}\n</code></pre> <p>Validation rules:</p> Rule Check <code>max_segment_size &gt; 0</code> Must be non-zero <code>max_segment_size &gt;= 1 MiB</code> Must be at least 1MB Batch window &lt; 1 second Batch fsync window must be reasonable Batch window &gt; 0 Batch fsync window cannot be zero"},{"location":"crates/nori-wal/getting-started/configuration/#common-configuration-patterns","title":"Common Configuration Patterns","text":""},{"location":"crates/nori-wal/getting-started/configuration/#high-throughput-event-logging","title":"High-Throughput Event Logging","text":"<pre><code>let config = WalConfig {\n    dir: PathBuf::from(\"/fast-ssd/events\"),\n    max_segment_size: 512 * 1024 * 1024,  // 512MB\n    fsync_policy: FsyncPolicy::Os,         // Max throughput\n    preallocate: true,\n    node_id: 0,\n};\n</code></pre> <p>Characteristics: - Large segments reduce rotation overhead - OS fsync for maximum throughput - Accept 30-60s data loss on crash</p>"},{"location":"crates/nori-wal/getting-started/configuration/#financial-transactions","title":"Financial Transactions","text":"<pre><code>let config = WalConfig {\n    dir: PathBuf::from(\"/reliable-disk/transactions\"),\n    max_segment_size: 128 * 1024 * 1024,  // 128MB\n    fsync_policy: FsyncPolicy::Always,     // Max durability\n    preallocate: true,\n    node_id: server_id,\n};\n</code></pre> <p>Characteristics: - Every write is durable - No data loss on crash - Lower throughput is acceptable</p>"},{"location":"crates/nori-wal/getting-started/configuration/#web-application-state","title":"Web Application State","text":"<pre><code>let config = WalConfig {\n    dir: PathBuf::from(\"/var/lib/webapp/wal\"),\n    max_segment_size: 128 * 1024 * 1024,   // 128MB\n    fsync_policy: FsyncPolicy::Batch(Duration::from_millis(5)),  // Balanced\n    preallocate: true,\n    node_id: 0,\n};\n</code></pre> <p>Characteristics: - Good balance of durability and performance - 5ms worst-case data loss - Suitable for session state, caches, etc.</p>"},{"location":"crates/nori-wal/getting-started/configuration/#developmenttesting","title":"Development/Testing","text":"<pre><code>let config = WalConfig {\n    dir: temp_dir.path().to_path_buf(),\n    max_segment_size: 1 * 1024 * 1024,     // 1MB (small)\n    fsync_policy: FsyncPolicy::Os,          // Fast\n    preallocate: false,                     // Skip prealloc\n    node_id: 0,\n};\n</code></pre> <p>Characteristics: - Small segments for quick tests - No durability guarantees needed - Fast test execution</p>"},{"location":"crates/nori-wal/getting-started/configuration/#environment-specific-configuration","title":"Environment-Specific Configuration","text":""},{"location":"crates/nori-wal/getting-started/configuration/#reading-from-environment-variables","title":"Reading from Environment Variables","text":"<pre><code>use std::env;\n\nlet wal_dir = env::var(\"WAL_DIR\")\n    .unwrap_or_else(|_| \"wal\".to_string());\n\nlet node_id = env::var(\"NODE_ID\")\n    .unwrap_or_else(|_| \"0\".to_string())\n    .parse::&lt;u32&gt;()\n    .unwrap_or(0);\n\nlet config = WalConfig {\n    dir: PathBuf::from(wal_dir),\n    node_id,\n    ..Default::default()\n};\n</code></pre>"},{"location":"crates/nori-wal/getting-started/configuration/#configuration-file-toml-example","title":"Configuration File (TOML example)","text":"<pre><code># config.toml\n[wal]\ndir = \"/var/lib/myapp/wal\"\nmax_segment_size_mb = 256\nfsync_policy = \"batch\"\nfsync_batch_ms = 10\npreallocate = true\nnode_id = 42\n</code></pre> <pre><code>use serde::Deserialize;\n\n#[derive(Deserialize)]\nstruct AppConfig {\n    wal: WalConfigToml,\n}\n\n#[derive(Deserialize)]\nstruct WalConfigToml {\n    dir: String,\n    max_segment_size_mb: u64,\n    fsync_policy: String,\n    fsync_batch_ms: Option&lt;u64&gt;,\n    preallocate: bool,\n    node_id: u32,\n}\n\nimpl From&lt;WalConfigToml&gt; for WalConfig {\n    fn from(config: WalConfigToml) -&gt; Self {\n        let fsync_policy = match config.fsync_policy.as_str() {\n            \"always\" =&gt; FsyncPolicy::Always,\n            \"batch\" =&gt; FsyncPolicy::Batch(\n                Duration::from_millis(config.fsync_batch_ms.unwrap_or(5))\n            ),\n            \"os\" =&gt; FsyncPolicy::Os,\n            _ =&gt; FsyncPolicy::default(),\n        };\n\n        WalConfig {\n            dir: PathBuf::from(config.dir),\n            max_segment_size: config.max_segment_size_mb * 1024 * 1024,\n            fsync_policy,\n            preallocate: config.preallocate,\n            node_id: config.node_id,\n        }\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/getting-started/configuration/#monitoring-configuration","title":"Monitoring Configuration","text":"<p>Once your WAL is running, monitor these metrics to see if your configuration is appropriate:</p> Metric What to Watch Action if Problem Fsync latency Should be &lt; 5ms on SSD Use faster disk or increase batch window Segment rotation frequency Not too often (&lt; 1/minute) Increase <code>max_segment_size</code> Disk usage Growing without bound Implement garbage collection Write throughput Meeting your SLAs Adjust <code>fsync_policy</code> if needed"},{"location":"crates/nori-wal/getting-started/configuration/#next-steps","title":"Next Steps","text":"<p>Now that you understand configuration:</p> <ul> <li>Learn about Fsync Policies in depth</li> <li>Understand Performance Trade-offs</li> <li>See Real-World Examples using different configurations</li> </ul>"},{"location":"crates/nori-wal/getting-started/configuration/#quick-reference","title":"Quick Reference","text":"<pre><code>// Maximum Durability\nWalConfig {\n    fsync_policy: FsyncPolicy::Always,\n    ..Default::default()\n}\n\n// Balanced (Recommended)\nWalConfig::default()  // Uses Batch(5ms)\n\n// Maximum Performance\nWalConfig {\n    fsync_policy: FsyncPolicy::Os,\n    preallocate: false,\n    ..Default::default()\n}\n\n// Large Segments (High Throughput)\nWalConfig {\n    max_segment_size: 512 * 1024 * 1024,\n    ..Default::default()\n}\n\n// Small Segments (Frequent Compaction)\nWalConfig {\n    max_segment_size: 32 * 1024 * 1024,\n    ..Default::default()\n}\n</code></pre>"},{"location":"crates/nori-wal/getting-started/installation/","title":"Installation","text":"<p>How to add nori-wal to your Rust project.</p>"},{"location":"crates/nori-wal/getting-started/installation/#table-of-contents","title":"Table of contents","text":""},{"location":"crates/nori-wal/getting-started/installation/#add-to-cargotoml","title":"Add to Cargo.toml","text":"<p>Add nori-wal as a dependency in your <code>Cargo.toml</code>:</p> <pre><code>[dependencies]\nnori-wal = \"0.1\"\ntokio = { version = \"1\", features = [\"macros\", \"rt-multi-thread\", \"fs\"] }\n</code></pre> <p>{: .important } nori-wal requires tokio for async I/O. Make sure you include the <code>fs</code> feature!</p>"},{"location":"crates/nori-wal/getting-started/installation/#minimum-rust-version","title":"Minimum Rust Version","text":"<p>nori-wal requires Rust 1.75 or newer. Check your version:</p> <pre><code>rustc --version\n</code></pre> <p>If you need to update:</p> <pre><code>rustup update stable\n</code></pre>"},{"location":"crates/nori-wal/getting-started/installation/#platform-support","title":"Platform Support","text":"<p>nori-wal works on all platforms that Rust supports:</p> Platform Status Notes Linux Fully supported Uses <code>fallocate()</code> for optimal pre-allocation macOS Fully supported Uses <code>F_PREALLOCATE</code> for pre-allocation Windows Fully supported Uses standard <code>set_len()</code> for pre-allocation BSD Supported Uses fallback pre-allocation Others Untested Should work, but not regularly tested"},{"location":"crates/nori-wal/getting-started/installation/#dependencies","title":"Dependencies","text":"<p>nori-wal has minimal dependencies:</p>"},{"location":"crates/nori-wal/getting-started/installation/#required","title":"Required","text":"<ul> <li><code>tokio</code> (1.x) with <code>fs</code>, <code>io-util</code>, <code>sync</code>, <code>time</code>, <code>rt</code> features</li> <li><code>bytes</code> (1.x) - Zero-copy byte buffers</li> <li><code>crc32c</code> (0.6) - Fast CRC32C checksums</li> <li><code>thiserror</code> (1.x) - Error handling</li> <li><code>bitflags</code> (2.x) - Type-safe flags</li> </ul>"},{"location":"crates/nori-wal/getting-started/installation/#compression-included-by-default","title":"Compression (included by default)","text":"<ul> <li><code>lz4</code> (1.24) - Fast compression</li> <li><code>zstd</code> (0.13) - High-ratio compression</li> </ul>"},{"location":"crates/nori-wal/getting-started/installation/#platform-specific","title":"Platform-specific","text":"<ul> <li><code>libc</code> (0.2) - Only on Unix for optimized <code>fallocate()</code> and <code>fcntl()</code></li> </ul>"},{"location":"crates/nori-wal/getting-started/installation/#verifying-installation","title":"Verifying Installation","text":"<p>Create a simple test program to verify everything works:</p> <pre><code>use nori_wal::{Wal, WalConfig};\n\n#[tokio::main]\nasync fn main() {\n    let config = WalConfig::default();\n    let result = Wal::open(config).await;\n\n    match result {\n        Ok((wal, recovery_info)) =&gt; {\n            println!(\"nori-wal is working!\");\n            println!(\"   Recovered {} records\", recovery_info.valid_records);\n            drop(wal);\n        }\n        Err(e) =&gt; {\n            println!(\"Error: {}\", e);\n        }\n    }\n}\n</code></pre> <p>Run it:</p> <pre><code>cargo run\n</code></pre> <p>You should see:</p> <pre><code>nori-wal is working!\n   Recovered 0 records\n</code></pre>"},{"location":"crates/nori-wal/getting-started/installation/#development-dependencies","title":"Development Dependencies","text":"<p>If you're contributing to nori-wal, you'll also need:</p> <pre><code>[dev-dependencies]\ntokio = { version = \"1\", features = [\"macros\", \"rt-multi-thread\"] }\ntempfile = \"3\"\nproptest = \"1\"  # For property-based testing\ncriterion = { version = \"0.5\", features = [\"html_reports\", \"async_tokio\"] }\n</code></pre>"},{"location":"crates/nori-wal/getting-started/installation/#next-steps","title":"Next Steps","text":"<p>Now that nori-wal is installed:</p> <ol> <li>Follow the Quickstart to write your first WAL program</li> <li>Learn about Configuration to tune for your use case</li> <li>Understand Core Concepts to use it effectively</li> </ol>"},{"location":"crates/nori-wal/getting-started/installation/#troubleshooting-installation","title":"Troubleshooting Installation","text":""},{"location":"crates/nori-wal/getting-started/installation/#compilation-fails-on-windows","title":"Compilation fails on Windows","text":"<p>Symptom: <pre><code>error: linking with `link.exe` failed\n</code></pre></p> <p>Solution: Make sure you have the Visual C++ Build Tools installed.</p>"},{"location":"crates/nori-wal/getting-started/installation/#tokio-feature-errors","title":"Tokio feature errors","text":"<p>Symptom: <pre><code>error: no method named `read` found for struct `File`\n</code></pre></p> <p>Solution: Make sure you have the <code>fs</code> feature enabled for tokio:</p> <pre><code>tokio = { version = \"1\", features = [\"fs\", \"macros\", \"rt-multi-thread\"] }\n</code></pre>"},{"location":"crates/nori-wal/getting-started/installation/#version-conflicts","title":"Version conflicts","text":"<p>Symptom: <pre><code>error: failed to select a version for `tokio`\n</code></pre></p> <p>Solution: nori-wal is compatible with tokio 1.x. If you have other dependencies requiring a specific tokio version, make sure they're compatible:</p> <pre><code>cargo tree | grep tokio\n</code></pre> <p>You can force a specific version in your <code>Cargo.toml</code>:</p> <pre><code>[dependencies]\ntokio = \"=1.35.0\"  # Pin to a specific version if needed\n</code></pre>"},{"location":"crates/nori-wal/getting-started/installation/#cant-find-nori-wal-on-cratesio","title":"Can't find nori-wal on crates.io","text":"<p>Symptom: <pre><code>error: no matching package named `nori-wal` found\n</code></pre></p> <p>Solution: If nori-wal hasn't been published to crates.io yet, you can use the git repository:</p> <pre><code>[dependencies]\nnori-wal = { git = \"https://github.com/jeffhajewski/norikv\", branch = \"main\" }\n</code></pre> <p>Or use a local path during development:</p> <pre><code>[dependencies]\nnori-wal = { path = \"../norikv/crates/nori-wal\" }\n</code></pre> <p>Need help? Check the Troubleshooting Guide or open an issue on GitHub.</p>"},{"location":"crates/nori-wal/getting-started/quickstart/","title":"5-Minute Quickstart","text":"<p>Get up and running with nori-wal in under 5 minutes.</p>"},{"location":"crates/nori-wal/getting-started/quickstart/#table-of-contents","title":"Table of contents","text":""},{"location":"crates/nori-wal/getting-started/quickstart/#installation","title":"Installation","text":"<p>Add nori-wal to your <code>Cargo.toml</code>:</p> <pre><code>[dependencies]\nnori-wal = \"0.1\"\ntokio = { version = \"1\", features = [\"macros\", \"rt-multi-thread\", \"fs\"] }\n</code></pre> <p>{: .note } nori-wal requires tokio for async I/O. Make sure you have the <code>fs</code> feature enabled.</p>"},{"location":"crates/nori-wal/getting-started/quickstart/#your-first-wal","title":"Your First WAL","text":"<p>Let's write a complete example that demonstrates the key concepts. This example shows: - Opening a WAL (with automatic recovery) - Writing records - Reading records back - Handling crashes gracefully</p> <p>Create a new file <code>src/main.rs</code>:</p> <pre><code>use nori_wal::{Wal, WalConfig, Record};\nuse std::error::Error;\n\n#[tokio::main]\nasync fn main() -&gt; Result&lt;(), Box&lt;dyn Error&gt;&gt; {\n    // Step 1: Open the WAL\n    // This automatically recovers from any previous session\n    let config = WalConfig::default();\n    let (wal, recovery_info) = Wal::open(config).await?;\n\n    // Tell us what happened during recovery\n    println!(\"=== Recovery Stats ===\");\n    println!(\"  Valid records recovered: {}\", recovery_info.valid_records);\n    println!(\"  Segments scanned: {}\", recovery_info.segments_scanned);\n    println!(\"  Corruption detected: {}\", recovery_info.corruption_detected);\n    println!(\"  Bytes truncated: {}\", recovery_info.bytes_truncated);\n\n    // Step 2: Write some records\n    println!(\"\\n=== Writing Records ===\");\n\n    // PUT: Write a key-value pair\n    let record = Record::put(b\"user:1\", b\"alice@example.com\");\n    let pos1 = wal.append(&amp;record).await?;\n    println!(\"Wrote user:1 at position {:?}\", pos1);\n\n    let record = Record::put(b\"user:2\", b\"bob@example.com\");\n    let pos2 = wal.append(&amp;record).await?;\n    println!(\"Wrote user:2 at position {:?}\", pos2);\n\n    // DELETE: Mark a key as deleted (tombstone)\n    let record = Record::delete(b\"user:1\");\n    let pos3 = wal.append(&amp;record).await?;\n    println!(\"Deleted user:1 at position {:?}\", pos3);\n\n    // Step 3: Ensure durability\n    // sync() forces all data to disk\n    wal.sync().await?;\n    println!(\"\\nAll records synced to disk!\");\n\n    // Step 4: Read records back\n    println!(\"\\n=== Reading Records ===\");\n\n    // Create a reader starting from the beginning\n    let mut reader = wal.read_from(\n        nori_wal::Position { segment_id: 0, offset: 0 }\n    ).await?;\n\n    // Scan through all records\n    let mut count = 0;\n    while let Some((record, position)) = reader.next_record().await? {\n        count += 1;\n        println!(\"Record #{} at {:?}:\", count, position);\n        println!(\"  Key: {}\", String::from_utf8_lossy(&amp;record.key));\n\n        if record.tombstone {\n            println!(\"  Type: DELETE (tombstone)\");\n        } else {\n            println!(\"  Type: PUT\");\n            println!(\"  Value: {}\", String::from_utf8_lossy(&amp;record.value));\n        }\n    }\n\n    println!(\"\\nRead {} records total\", count);\n\n    Ok(())\n}\n</code></pre>"},{"location":"crates/nori-wal/getting-started/quickstart/#run-it","title":"Run It!","text":"<pre><code>cargo run\n</code></pre> <p>You should see output like this:</p> <pre><code>=== Recovery Stats ===\n  Valid records recovered: 0\n  Segments scanned: 0\n  Corruption detected: false\n  Bytes truncated: 0\n\n=== Writing Records ===\nWrote user:1 at position Position { segment_id: 0, offset: 0 }\nWrote user:2 at position Position { segment_id: 0, offset: 27 }\nDeleted user:1 at position Position { segment_id: 0, offset: 54 }\n\nAll records synced to disk!\n\n=== Reading Records ===\nRecord #1 at Position { segment_id: 0, offset: 0 }:\n  Key: user:1\n  Type: PUT\n  Value: alice@example.com\n\nRecord #2 at Position { segment_id: 0, offset: 27 }:\n  Key: user:2\n  Type: PUT\n  Value: bob@example.com\n\nRecord #3 at Position { segment_id: 0, offset: 54 }:\n  Key: user:1\n  Type: DELETE (tombstone)\n\nRead 3 records total\n</code></pre>"},{"location":"crates/nori-wal/getting-started/quickstart/#run-it-again","title":"Run It Again!","text":"<p>Now run the same program again:</p> <pre><code>cargo run\n</code></pre> <p>Notice something different?</p> <pre><code>=== Recovery Stats ===\n  Valid records recovered: 3    &lt;--- Now we recovered data!\n  Segments scanned: 1\n  Corruption detected: false\n  Bytes truncated: 0\n\n=== Writing Records ===\nWrote user:1 at position Position { segment_id: 0, offset: 71 }\nWrote user:2 at position Position { segment_id: 0, offset: 98 }\nDeleted user:1 at position Position { segment_id: 0, offset: 125 }\n</code></pre> <p>The WAL automatically recovered the 3 records from the previous run! This is the power of a WAL - your data survives across restarts.</p>"},{"location":"crates/nori-wal/getting-started/quickstart/#understanding-the-output","title":"Understanding the Output","text":""},{"location":"crates/nori-wal/getting-started/quickstart/#recovery-stats","title":"Recovery Stats","text":"<pre><code>let (wal, recovery_info) = Wal::open(config).await?;\n</code></pre> <p>Every time you open a WAL, it scans existing segment files and recovers valid records. The <code>RecoveryInfo</code> tells you:</p> Field Meaning <code>valid_records</code> How many records were successfully recovered <code>segments_scanned</code> How many segment files were checked <code>corruption_detected</code> Whether any corruption was found (and truncated) <code>bytes_truncated</code> How much data was removed due to corruption <p>{: .highlight } If <code>corruption_detected</code> is <code>true</code>, don't panic! The WAL uses a \"prefix-valid\" recovery strategy: it keeps all valid records and only discards incomplete or corrupted data at the tail.</p>"},{"location":"crates/nori-wal/getting-started/quickstart/#positions","title":"Positions","text":"<pre><code>let pos = wal.append(&amp;record).await?;\n// Position { segment_id: 0, offset: 27 }\n</code></pre> <p>Every record has a position in the log: - <code>segment_id</code>: Which segment file (starts at 0) - <code>offset</code>: Byte offset within that segment</p> <p>You can use positions to: - Read from a specific point - Track your progress through the log - Implement checkpointing</p>"},{"location":"crates/nori-wal/getting-started/quickstart/#whats-happening-under-the-hood","title":"What's Happening Under the Hood?","text":"<p>When you run this example:</p> <ol> <li>First Run</li> <li><code>Wal::open()</code> creates a new directory <code>wal/</code></li> <li>Creates segment file <code>wal/000000.wal</code></li> <li>Pre-allocates it to 128MB (on supported platforms)</li> <li>Writes 3 records (total ~71 bytes)</li> <li> <p><code>sync()</code> calls <code>fsync()</code> to ensure durability</p> </li> <li> <p>Second Run</p> </li> <li><code>Wal::open()</code> finds existing <code>wal/000000.wal</code></li> <li>Scans it and validates CRC32C for each record</li> <li>Recovers all 3 valid records</li> <li> <p>Continues appending new records after them</p> </li> <li> <p>On Disk <pre><code>wal/\n  000000.wal  (128MB pre-allocated, ~142 bytes used)\n</code></pre></p> </li> </ol>"},{"location":"crates/nori-wal/getting-started/quickstart/#try-simulating-a-crash","title":"Try Simulating a Crash","text":"<p>Let's see recovery in action! Modify your program to crash mid-write:</p> <pre><code>// Write a few records\nfor i in 1..=5 {\n    let key = format!(\"key:{}\", i);\n    let value = format!(\"value:{}\", i);\n    let record = Record::put(key.as_bytes(), value.as_bytes());\n    wal.append(&amp;record).await?;\n\n    // Crash after record 3 (before sync!)\n    if i == 3 {\n        println!(\"CRASH!\");\n        std::process::exit(1);\n    }\n}\n\nwal.sync().await?;  // Never reached!\n</code></pre> <p>Run it:</p> <pre><code>$ cargo run\nWrote record 1\nWrote record 2\nWrote record 3\nCRASH!\n\n$ cargo run\n=== Recovery Stats ===\n  Valid records recovered: 3    &lt;--- Only 3 recovered!\n</code></pre> <p>Why only 3? Because we didn't call <code>sync()</code> after records 4 and 5. They were in the OS buffer but never made it to disk.</p> <p>{: .important } Key Takeaway: If you want durability, you must call <code>sync()</code>. Or use <code>FsyncPolicy::Always</code> to sync after every write (slower but maximally safe).</p>"},{"location":"crates/nori-wal/getting-started/quickstart/#next-steps","title":"Next Steps","text":"<p>Now that you've written your first WAL program, you can:</p> <ul> <li>Understand configuration options - Tune for your workload</li> <li>Learn about fsync policies - Balance durability vs performance</li> <li>Explore record types - TTL, compression, tombstones</li> <li>Dive into recovery - How crash recovery really works</li> </ul> <p>Or jump straight into building something real with our Recipes section!</p>"},{"location":"crates/nori-wal/getting-started/quickstart/#common-questions","title":"Common Questions","text":""},{"location":"crates/nori-wal/getting-started/quickstart/#where-does-the-data-go","title":"Where does the data go?","text":"<p>By default, the WAL directory is <code>wal/</code> in your current working directory. You can change this:</p> <pre><code>let config = WalConfig {\n    dir: PathBuf::from(\"/var/lib/myapp/wal\"),\n    ..Default::default()\n};\n</code></pre>"},{"location":"crates/nori-wal/getting-started/quickstart/#how-much-disk-space-do-i-need","title":"How much disk space do I need?","text":"<p>Each segment is pre-allocated to 128MB by default. The WAL creates a new segment when the current one fills up. So you need: - Minimum: 128MB (one active segment) - Typical: 256-512MB (active segment + a few for history) - Maximum: Unlimited (unless you call <code>delete_segments_before()</code> to garbage collect)</p>"},{"location":"crates/nori-wal/getting-started/quickstart/#can-i-use-this-in-production","title":"Can I use this in production?","text":"<p>Yes! nori-wal is designed for production use. It includes: - Comprehensive error handling - Detailed observability - Extensive test coverage (37 tests including property tests) - No unsafe code in the public API - Battle-tested recovery logic</p>"},{"location":"crates/nori-wal/getting-started/quickstart/#what-happens-if-the-disk-fills-up","title":"What happens if the disk fills up?","text":"<p>With file pre-allocation (default), you'll get an error when creating a new segment, not when writing. This is good - you can handle the error gracefully instead of discovering you're out of space mid-write.</p>"},{"location":"crates/nori-wal/getting-started/quickstart/#troubleshooting","title":"Troubleshooting","text":"<p>Q: I get <code>No such file or directory</code> error <pre><code>Error: IO error: No such file or directory (os error 2)\n</code></pre></p> <p>A: Make sure your WAL directory's parent exists. For example, if you set <code>dir: \"/var/lib/myapp/wal\"</code>, make sure <code>/var/lib/myapp/</code> exists first.</p> <p>Q: Recovery says I have corruption <pre><code>Recovery Stats:\n  Corruption detected: true\n  Bytes truncated: 1234\n</code></pre></p> <p>A: This is usually harmless! It just means the last write was incomplete (e.g., you ctrl-C'd mid-write). The WAL truncates the partial data and keeps all complete records.</p> <p>Q: Performance is slow <pre><code>// Takes 2ms per write!\nwal.append(&amp;record).await?\n</code></pre></p> <p>A: You're probably using <code>FsyncPolicy::Always</code> (the default is <code>Batch</code>). Check your config:</p> <pre><code>let config = WalConfig {\n    fsync_policy: FsyncPolicy::Batch(Duration::from_millis(5)),  // Much faster!\n    ..Default::default()\n};\n</code></pre> <p>Congrats! You now understand the basics of nori-wal. Ready to dive deeper? Check out Core Concepts next.</p>"},{"location":"crates/nori-wal/how-it-works/","title":"How It Works","text":"<p>Deep dive into nori-wal's internals: record format, segment lifecycle, recovery, and concurrency.</p>"},{"location":"crates/nori-wal/how-it-works/#what-youll-learn","title":"What You'll Learn","text":"<p>This section explains the technical implementation details of nori-wal. If you want to understand:</p> <ul> <li>How records are structured on disk</li> <li>How segments are created, rotated, and managed</li> <li>How recovery works after a crash</li> <li>How concurrent operations are handled</li> <li>How file preallocation works on different platforms</li> </ul> <p>...then you're in the right place.</p>"},{"location":"crates/nori-wal/how-it-works/#navigation","title":"Navigation","text":""},{"location":"crates/nori-wal/how-it-works/#record-format","title":"Record Format","text":"<p>The on-disk structure of WAL records: header, CRC32C, compression, flags, and layout.</p>"},{"location":"crates/nori-wal/how-it-works/#segment-lifecycle","title":"Segment Lifecycle","text":"<p>How segments are created, rotated, and deleted. Pre-allocation strategies across platforms.</p>"},{"location":"crates/nori-wal/how-it-works/#recovery-process","title":"Recovery Process","text":"<p>Detailed walkthrough of the recovery algorithm: scanning, validation, truncation, and rebuild.</p>"},{"location":"crates/nori-wal/how-it-works/#concurrency-model","title":"Concurrency Model","text":"<p>How nori-wal handles concurrent reads and writes. Lock-free reading, write serialization.</p>"},{"location":"crates/nori-wal/how-it-works/#who-should-read-this","title":"Who Should Read This","text":"<p>You should read this section if: - You're implementing your own WAL - You're debugging nori-wal behavior - You're contributing to nori-wal - You want deep technical understanding</p> <p>You can skip this section if: - You just want to use nori-wal (see Getting Started) - You want high-level concepts (see Core Concepts) - You want recipes and examples (see Recipes)</p>"},{"location":"crates/nori-wal/how-it-works/#prerequisites","title":"Prerequisites","text":"<p>Before diving in, make sure you understand:</p> <ul> <li>What is a WAL - The fundamental concept</li> <li>Append-Only Architecture - Why WALs are append-only</li> <li>Fsync Policies - Durability vs performance trade-offs</li> </ul> <p>If you haven't read those yet, start there first!</p>"},{"location":"crates/nori-wal/how-it-works/#architecture-overview","title":"Architecture Overview","text":"<p>Here's a quick overview of how nori-wal components fit together:</p> <pre><code>graph TD\n    A[Application] --&gt;|append| B[Wal]\n    B --&gt;|serialize| C[Record]\n    C --&gt;|write| D[Segment]\n    D --&gt;|flush| E[OS Page Cache]\n    E --&gt;|fsync| F[Disk]\n\n    B --&gt;|rotate when full| G[New Segment]\n    B --&gt;|delete old| H[Garbage Collection]\n\n    I[Recovery] --&gt;|scan| D\n    I --&gt;|validate CRC| C\n    I --&gt;|rebuild state| J[Application State]\n\n    style B fill:#90EE90\n    style D fill:#FFD700\n    style I fill:#FFB6C1</code></pre> <p>Key components: - Wal: Top-level API, manages segments - Segment: Single file on disk (e.g., <code>000000.wal</code>) - Record: Individual entry in the log - Recovery: Scans segments, validates records, rebuilds state</p>"},{"location":"crates/nori-wal/how-it-works/#code-organization","title":"Code Organization","text":"<p>nori-wal is organized into modules:</p> <pre><code>nori-wal/\n  src/\n    lib.rs           - Public API (Wal, WalConfig, Record)\n    segment.rs       - Segment management (create, rotate, delete)\n    record.rs        - Record serialization/deserialization\n    recovery.rs      - Recovery algorithm\n    reader.rs        - Sequential record reading\n    fsync.rs         - Fsync policy implementations\n    error.rs         - Error types\n    observe.rs       - Observability (metrics, events)\n</code></pre> <p>Each \"How It Works\" page corresponds to one or more of these modules.</p>"},{"location":"crates/nori-wal/how-it-works/#reading-order","title":"Reading Order","text":"<p>We recommend reading in this order:</p> <ol> <li>Record Format - Start here to understand the on-disk format</li> <li>Segment Lifecycle - How segments are managed</li> <li>Recovery Process - How we recover from crashes</li> <li>Concurrency Model - How concurrent operations work</li> </ol> <p>You can read them independently, but they build on each other.</p>"},{"location":"crates/nori-wal/how-it-works/#visual-learning","title":"Visual Learning","text":"<p>Each page includes:</p> <ul> <li>Mermaid diagrams - Flowcharts and sequence diagrams</li> <li>Byte layout diagrams - Visual representation of on-disk format</li> <li>Code snippets - Actual implementation from nori-wal</li> <li>Examples - Concrete scenarios and edge cases</li> </ul> <p>If you're a visual learner, you'll love this section!</p>"},{"location":"crates/nori-wal/how-it-works/#next-steps","title":"Next Steps","text":"<p>Ready to dive in? Start with:</p> <ul> <li>Record Format - Learn how data is structured on disk</li> <li>Or jump to a specific topic that interests you</li> </ul> <p>If you're looking for something else: - API Reference - Documentation for all public types - Recipes - Build real applications with nori-wal - Troubleshooting - Debug common issues</p>"},{"location":"crates/nori-wal/how-it-works/concurrency/","title":"Concurrency Model","text":"<p>How nori-wal handles concurrent reads and writes safely and efficiently.</p>"},{"location":"crates/nori-wal/how-it-works/concurrency/#table-of-contents","title":"Table of contents","text":""},{"location":"crates/nori-wal/how-it-works/concurrency/#overview","title":"Overview","text":"<p>nori-wal is designed to be safe for concurrent use across multiple threads. The type signature reflects this:</p> <pre><code>pub struct Wal: Send + Sync\n</code></pre> <p>This means: - Send: Can be moved between threads - Sync: Can be shared between threads (via <code>Arc&lt;Wal&gt;</code>)</p> <p>However, the concurrency model has specific characteristics you need to understand.</p>"},{"location":"crates/nori-wal/how-it-works/concurrency/#thread-safety-guarantees","title":"Thread Safety Guarantees","text":""},{"location":"crates/nori-wal/how-it-works/concurrency/#what-is-safe","title":"What is Safe","text":"<pre><code>// Safe: Multiple threads can share a WAL\nlet wal = Arc::new(wal);\n\nlet wal1 = wal.clone();\ntokio::spawn(async move {\n    wal1.append(&amp;record).await?;  // Safe\n});\n\nlet wal2 = wal.clone();\ntokio::spawn(async move {\n    wal2.append(&amp;record).await?;  // Safe\n});\n</code></pre>"},{"location":"crates/nori-wal/how-it-works/concurrency/#what-is-serialized","title":"What is Serialized","text":"<p>All writes are serialized internally. Even if multiple threads call <code>append()</code> concurrently, they execute sequentially:</p> <pre><code>Thread 1: append(R1) \u2500\u2510\nThread 2: append(R2) \u2500\u2500\u253c\u2500\u2192 Mutex \u2192 [R1][R2] (sequential on disk)\nThread 3: append(R3) \u2500\u2518\n</code></pre> <p>Why? - Append-only log must maintain order - Only one thread can write to a file at a time - Serialization ensures consistency</p>"},{"location":"crates/nori-wal/how-it-works/concurrency/#internal-locking-structure","title":"Internal Locking Structure","text":"<pre><code>pub struct SegmentManager {\n    config: SegmentConfig,\n\n    // Protected by Mutex - one writer at a time\n    current: Arc&lt;Mutex&lt;SegmentFile&gt;&gt;,\n    current_id: Arc&lt;Mutex&lt;u64&gt;&gt;,\n    last_fsync: Arc&lt;Mutex&lt;Option&lt;Instant&gt;&gt;&gt;,\n\n    // FD cache for readers\n    fd_cache: Arc&lt;Mutex&lt;FdCache&gt;&gt;,\n\n    // Immutable (no lock needed)\n    meter: Arc&lt;dyn Meter&gt;,\n    node_id: u32,\n}\n</code></pre>"},{"location":"crates/nori-wal/how-it-works/concurrency/#locks-explained","title":"Locks Explained","text":"Field Lock Type Purpose Contention <code>current</code> <code>Mutex&lt;SegmentFile&gt;</code> Active segment for writing High on writes <code>current_id</code> <code>Mutex&lt;u64&gt;</code> Current segment ID Low (rarely changes) <code>last_fsync</code> <code>Mutex&lt;Option&lt;Instant&gt;&gt;</code> Last fsync time (for batching) High on writes <code>fd_cache</code> <code>Mutex&lt;FdCache&gt;</code> File descriptor cache Medium on reads"},{"location":"crates/nori-wal/how-it-works/concurrency/#write-path-concurrency","title":"Write Path Concurrency","text":""},{"location":"crates/nori-wal/how-it-works/concurrency/#append-operation","title":"Append Operation","text":"<pre><code>pub async fn append(&amp;self, record: &amp;Record) -&gt; Result&lt;Position&gt; {\n    // 1. Acquire lock (blocks if another thread is writing)\n    let mut current = self.current.lock().await;\n\n    // 2. Encode record (CPU-bound, lock held)\n    let encoded = record.encode();\n\n    // 3. Check if rotation needed\n    if current.would_exceed(encoded.len(), self.config.max_segment_size) {\n        // Rotation requires multiple locks - deadlock potential?\n        // Answer: No, because we hold current lock exclusively\n        self.rotate(&amp;mut current).await?;\n    }\n\n    // 4. Append to segment (I/O-bound, lock held)\n    let offset = current.append(record).await?;\n\n    // 5. Fsync based on policy (I/O-bound, lock held)\n    self.maybe_fsync(&amp;mut current).await?;\n\n    // 6. Release lock (implicit on drop)\n    Ok(Position {\n        segment_id: current.id,\n        offset,\n    })\n}\n</code></pre> <p>Critical section duration: - Without fsync: ~10-50\u03bcs (encoding + write) - With fsync: ~1-5ms (encoding + write + fsync)</p>"},{"location":"crates/nori-wal/how-it-works/concurrency/#write-contention","title":"Write Contention","text":"<p>When multiple threads write concurrently:</p> <pre><code>Time \u2192\nThread 1: [acquire lock] [encode] [write] [fsync] [release]\nThread 2:                 [blocked................] [acquire lock] [encode] [write] [fsync] [release]\nThread 3:                                          [blocked...................] [acquire lock] ...\n</code></pre> <p>Performance impact:</p> Fsync Policy Single Thread 4 Threads Contention Overhead Always ~420 writes/sec ~420 writes/sec None (disk-bound) Batch(5ms) ~86K writes/sec ~70K writes/sec ~18% (lock overhead) Os ~110K writes/sec ~85K writes/sec ~23% (lock overhead) <p>Why contention? - Lock is held during encode, write, and fsync - Multiple threads can't make progress in parallel - CPU encoding happens while lock is held (could be optimized)</p>"},{"location":"crates/nori-wal/how-it-works/concurrency/#optimization-pre-encode-before-locking","title":"Optimization: Pre-Encode Before Locking","text":"<p>Current: <pre><code>async fn append(&amp;self, record: &amp;Record) -&gt; Result&lt;Position&gt; {\n    let mut current = self.current.lock().await;  // Lock\n    let encoded = record.encode();                 // Encode (CPU)\n    current.write_all(&amp;encoded).await?;            // Write\n    // ...\n}\n</code></pre></p> <p>Potential optimization (not implemented): <pre><code>async fn append(&amp;self, record: &amp;Record) -&gt; Result&lt;Position&gt; {\n    let encoded = record.encode();                 // Encode BEFORE lock\n    let mut current = self.current.lock().await;  // Lock\n    current.write_all(&amp;encoded).await?;            // Write\n    // ...\n}\n</code></pre></p> <p>Benefit: Reduce lock hold time by ~5-10\u03bcs (encoding time)</p> <p>Not implemented because: - Encoding is fast (~2-10\u03bcs) - Optimization adds complexity - Lock contention is not the bottleneck for most workloads</p>"},{"location":"crates/nori-wal/how-it-works/concurrency/#read-path-concurrency","title":"Read Path Concurrency","text":""},{"location":"crates/nori-wal/how-it-works/concurrency/#sequential-reading","title":"Sequential Reading","text":"<pre><code>pub async fn read_from(&amp;self, position: Position) -&gt; Result&lt;SegmentReader&gt; {\n    // 1. Acquire FD cache lock\n    let fd = self.fd_cache.lock().await.get_or_open(position.segment_id).await?;\n\n    // 2. Create reader (does not hold lock)\n    Ok(SegmentReader {\n        file: fd,  // Arc&lt;Mutex&lt;File&gt;&gt;\n        position: position.offset,\n        buffer: Vec::new(),\n    })\n}\n</code></pre>"},{"location":"crates/nori-wal/how-it-works/concurrency/#reading-with-concurrent-writes","title":"Reading with Concurrent Writes","text":"<p>Readers do NOT block writers (and vice versa):</p> <pre><code>Writer Thread: [append R1] [append R2] [append R3]\nReader Thread:               [read R1] [read R2] [block until R3 written]\n</code></pre> <p>Why? - Readers have separate file descriptors (via FD cache) - Reads and writes use different syscalls (no OS-level conflicts) - append-only means no in-place modifications</p>"},{"location":"crates/nori-wal/how-it-works/concurrency/#multiple-concurrent-readers","title":"Multiple Concurrent Readers","text":"<p>Multiple readers can read simultaneously:</p> <pre><code>let wal = Arc::new(wal);\n\n// Reader 1: Read from beginning\nlet wal1 = wal.clone();\ntokio::spawn(async move {\n    let mut reader = wal1.read_from(Position::start()).await?;\n    while let Some((record, _)) = reader.next_record().await? {\n        // Process\n    }\n});\n\n// Reader 2: Read from position 1000\nlet wal2 = wal.clone();\ntokio::spawn(async move {\n    let mut reader = wal2.read_from(Position { segment_id: 0, offset: 1000 }).await?;\n    while let Some((record, _)) = reader.next_record().await? {\n        // Process\n    }\n});\n</code></pre> <p>Performance: No contention between readers (each has independent FD)</p>"},{"location":"crates/nori-wal/how-it-works/concurrency/#file-descriptor-caching","title":"File Descriptor Caching","text":""},{"location":"crates/nori-wal/how-it-works/concurrency/#why-cache-fds","title":"Why Cache FDs?","text":"<p>Opening files is expensive: - ~100\u03bcs per <code>File::open()</code> syscall - ~1\u03bcs for cache hit</p> <p>Without caching: <pre><code>// Reader 1 opens segment 0: 100\u03bcs\n// Reader 2 opens segment 0: 100\u03bcs (redundant!)\n// Reader 3 opens segment 0: 100\u03bcs (redundant!)\n</code></pre></p> <p>With caching: <pre><code>// Reader 1 opens segment 0: 100\u03bcs (cache miss, opens FD)\n// Reader 2 opens segment 0: 1\u03bcs (cache hit, reuses FD)\n// Reader 3 opens segment 0: 1\u03bcs (cache hit, reuses FD)\n</code></pre></p>"},{"location":"crates/nori-wal/how-it-works/concurrency/#fd-cache-structure","title":"FD Cache Structure","text":"<pre><code>struct FdCache {\n    cache: HashMap&lt;u64, Arc&lt;Mutex&lt;File&gt;&gt;&gt;,  // segment_id \u2192 File\n    max_size: usize,                         // LRU limit (default: 16)\n    access_order: Vec&lt;u64&gt;,                  // LRU tracking\n}\n</code></pre>"},{"location":"crates/nori-wal/how-it-works/concurrency/#lru-eviction","title":"LRU Eviction","text":"<p>When cache reaches capacity, evict least-recently-used FD:</p> <pre><code>fn insert(&amp;mut self, segment_id: u64, file: File) {\n    if self.cache.len() &gt;= self.max_size {\n        // Evict LRU\n        let lru_id = self.access_order.remove(0);\n        self.cache.remove(&amp;lru_id);\n        // FD automatically closed when Arc&lt;File&gt; is dropped\n    }\n\n    self.cache.insert(segment_id, Arc::new(Mutex::new(file)));\n    self.access_order.push(segment_id);\n}\n</code></pre> <p>Example: <pre><code>Cache size: 3\nAccess pattern: [0, 1, 2, 3, 0, 1]\n\n0: Cache miss \u2192 Open FD0, cache = [0]\n1: Cache miss \u2192 Open FD1, cache = [0, 1]\n2: Cache miss \u2192 Open FD2, cache = [0, 1, 2]\n3: Cache miss \u2192 Open FD3, evict 0, cache = [1, 2, 3]\n0: Cache miss \u2192 Open FD0, evict 1, cache = [2, 3, 0]\n1: Cache miss \u2192 Open FD1, evict 2, cache = [3, 0, 1]\n</code></pre></p>"},{"location":"crates/nori-wal/how-it-works/concurrency/#rotation-and-concurrency","title":"Rotation and Concurrency","text":""},{"location":"crates/nori-wal/how-it-works/concurrency/#rotation-algorithm","title":"Rotation Algorithm","text":"<pre><code>async fn rotate(&amp;self, current: &amp;mut SegmentFile) -&gt; Result&lt;()&gt; {\n    // 1. Finalize current segment (truncate to actual size)\n    current.finalize().await?;\n\n    // 2. Increment segment ID\n    let mut current_id = self.current_id.lock().await;\n    *current_id += 1;\n    let new_id = *current_id;\n    drop(current_id);\n\n    // 3. Create new segment\n    let new_segment = SegmentFile::open(\n        &amp;self.config.dir,\n        new_id,\n        true,  // create\n        if self.config.preallocate {\n            Some(self.config.max_segment_size)\n        } else {\n            None\n        },\n    ).await?;\n\n    // 4. Swap in new segment (still holding current lock)\n    *current = new_segment;\n\n    Ok(())\n}\n</code></pre> <p>Key point: Rotation happens while holding the <code>current</code> lock, so no other thread can write during rotation.</p>"},{"location":"crates/nori-wal/how-it-works/concurrency/#rotation-latency","title":"Rotation Latency","text":"<p>Rotation adds latency to the write that triggers it:</p> Step Latency Finalize old segment (truncate + sync) ~2-5 ms Open new segment file ~100 \u03bcs Preallocate 128MB ~1-2 ms Total ~3-7 ms <p>Impact on concurrent writers: <pre><code>Thread 1: append(triggers rotation) [3-7ms rotation] [return]\nThread 2: append(blocked)            [wait...........] [acquire lock] [append] [return]\nThread 3: append(blocked)                               [wait......] [acquire lock] [append] [return]\n</code></pre></p> <p>Mitigation: Rotation is rare (once per 128MB by default), so amortized cost is negligible.</p>"},{"location":"crates/nori-wal/how-it-works/concurrency/#sync-and-concurrency","title":"Sync and Concurrency","text":""},{"location":"crates/nori-wal/how-it-works/concurrency/#explicit-sync","title":"Explicit Sync","text":"<pre><code>wal.sync().await?;\n</code></pre> <p>Acquires the lock and forces fsync:</p> <pre><code>async fn sync(&amp;self) -&gt; Result&lt;()&gt; {\n    let mut current = self.current.lock().await;\n    current.sync().await?;\n\n    // Update last_fsync time\n    let mut last_fsync = self.last_fsync.lock().await;\n    *last_fsync = Some(Instant::now());\n\n    Ok(())\n}\n</code></pre> <p>Blocks all writers until fsync completes (~1-5ms).</p>"},{"location":"crates/nori-wal/how-it-works/concurrency/#batched-sync-fsyncpolicybatch","title":"Batched Sync (FsyncPolicy::Batch)","text":"<pre><code>async fn maybe_fsync(&amp;self, current: &amp;mut SegmentFile) -&gt; Result&lt;()&gt; {\n    if let FsyncPolicy::Batch(window) = self.config.fsync_policy {\n        let mut last_fsync = self.last_fsync.lock().await;\n        let now = Instant::now();\n\n        if last_fsync.map_or(true, |t| now.duration_since(t) &gt;= window) {\n            current.sync().await?;\n            *last_fsync = Some(now);\n        }\n    }\n\n    Ok(())\n}\n</code></pre> <p>First write in window: Pays fsync cost (~1-5ms) Subsequent writes in window: No fsync (fast)</p>"},{"location":"crates/nori-wal/how-it-works/concurrency/#drop-handler-and-finalization","title":"Drop Handler and Finalization","text":""},{"location":"crates/nori-wal/how-it-works/concurrency/#best-effort-finalization","title":"Best-Effort Finalization","text":"<p>When <code>Wal</code> is dropped, we try to finalize the current segment:</p> <pre><code>impl Drop for SegmentManager {\n    fn drop(&amp;mut self) {\n        // Try to acquire lock (non-blocking)\n        if let Ok(current) = self.current.try_lock() {\n            // Synchronous truncation (can't do async in Drop)\n            if current.size != actual_file_size {\n                let _ = std::fs::OpenOptions::new()\n                    .write(true)\n                    .open(&amp;current.path)\n                    .and_then(|f| {\n                        f.set_len(current.size)?;\n                        f.sync_all()\n                    });\n            }\n        }\n        // If lock is held, skip finalization (segment will be recovered on next open)\n    }\n}\n</code></pre> <p>Why best-effort? - Can't do async work in Drop - Can't block indefinitely (may be in async runtime shutdown) - Recovery will fix any unfinalizedSegments</p>"},{"location":"crates/nori-wal/how-it-works/concurrency/#deadlock-analysis","title":"Deadlock Analysis","text":""},{"location":"crates/nori-wal/how-it-works/concurrency/#potential-deadlock-scenario","title":"Potential Deadlock Scenario?","text":"<pre><code>// Thread 1: Holds current lock, tries to acquire current_id lock\nasync fn rotate(&amp;self, current: &amp;mut SegmentFile) {\n    // current lock held\n    let mut current_id = self.current_id.lock().await;  // Acquire current_id\n    // ...\n}\n\n// Thread 2: Holds current_id lock, tries to acquire current lock?\n// ... No such code path exists!\n</code></pre> <p>Conclusion: No deadlock possible - Lock acquisition order is always: <code>current</code> \u2192 <code>current_id</code> \u2192 <code>last_fsync</code> - Never acquire locks in reverse order - Locks are released quickly (no long-held locks)</p>"},{"location":"crates/nori-wal/how-it-works/concurrency/#performance-benchmarks","title":"Performance Benchmarks","text":""},{"location":"crates/nori-wal/how-it-works/concurrency/#single-threaded-performance","title":"Single-Threaded Performance","text":"Fsync Policy Throughput Latency (p50) Latency (p99) Always 420 writes/sec 2.1 ms 9.8 ms Batch(5ms) 86,000 writes/sec 38 \u03bcs 5.3 ms Os 110,000 writes/sec 28 \u03bcs 95 \u03bcs"},{"location":"crates/nori-wal/how-it-works/concurrency/#multi-threaded-performance-4-threads","title":"Multi-Threaded Performance (4 threads)","text":"Fsync Policy Single Thread 4 Threads Scalability Always 420/sec 420/sec 1.0x (disk-bound) Batch(5ms) 86K/sec 70K/sec 0.82x (lock contention) Os 110K/sec 85K/sec 0.77x (lock contention) <p>Observation: Write-heavy workloads don't scale linearly due to serialized append.</p>"},{"location":"crates/nori-wal/how-it-works/concurrency/#read-performance-concurrent","title":"Read Performance (Concurrent)","text":"Scenario Single Reader 4 Readers Scalability Sequential read (cached FDs) 200K records/sec 750K records/sec 3.75x Sequential read (uncached FDs) 180K records/sec 600K records/sec 3.33x <p>Observation: Reads scale well because they don't share locks with writers.</p>"},{"location":"crates/nori-wal/how-it-works/concurrency/#best-practices","title":"Best Practices","text":""},{"location":"crates/nori-wal/how-it-works/concurrency/#1-share-wal-across-threads","title":"1. Share WAL Across Threads","text":"<pre><code>// Good: Share a single WAL instance\nlet wal = Arc::new(wal);\n\nfor _ in 0..num_threads {\n    let wal = wal.clone();\n    tokio::spawn(async move {\n        wal.append(&amp;record).await?;\n    });\n}\n</code></pre> <pre><code>// Bad: Open multiple WALs (file corruption risk!)\n// DON'T DO THIS:\nfor _ in 0..num_threads {\n    tokio::spawn(async move {\n        let (wal, _) = Wal::open(config.clone()).await?;  // Multiple WALs!\n        wal.append(&amp;record).await?;\n    });\n}\n</code></pre>"},{"location":"crates/nori-wal/how-it-works/concurrency/#2-batch-writes-in-application-code","title":"2. Batch Writes in Application Code","text":"<p>If you have high write contention, batch at the application level:</p> <pre><code>// Instead of:\nfor record in records {\n    wal.append(&amp;record).await?;  // Lock per record\n}\n\n// Do this:\nlet mut batch = Vec::new();\nfor record in records {\n    batch.push(record);\n}\n\n// Append batch with single lock acquisition\nfor record in batch {\n    wal.append(&amp;record).await?;\n}\n</code></pre> <p>Or use <code>append_batch()</code> if available (future feature).</p>"},{"location":"crates/nori-wal/how-it-works/concurrency/#3-use-separate-wals-for-independent-data","title":"3. Use Separate WALs for Independent Data","text":"<p>If you have independent streams of data, use separate WALs:</p> <pre><code>// Good: Separate WALs for different purposes\nlet user_wal = Wal::open(WalConfig { dir: \"wal/users\".into(), .. }).await?;\nlet event_wal = Wal::open(WalConfig { dir: \"wal/events\".into(), .. }).await?;\n\n// No lock contention between user and event writes\ntokio::join!(\n    user_wal.append(&amp;user_record),\n    event_wal.append(&amp;event_record),\n);\n</code></pre>"},{"location":"crates/nori-wal/how-it-works/concurrency/#4-dont-hold-locks-across-async-points","title":"4. Don't Hold Locks Across Async Points","text":"<pre><code>// Bad: Don't do this (not possible with current API, but illustrative)\nlet current = wal.manager.current.lock().await;  // Acquire lock\ntokio::time::sleep(Duration::from_secs(1)).await;  // Hold lock across sleep!\ncurrent.append(&amp;record).await?;\n\n// Good: Lock is acquired and released within a single operation\nwal.append(&amp;record).await?;  // Lock acquired and released internally\n</code></pre>"},{"location":"crates/nori-wal/how-it-works/concurrency/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>WAL is thread-safe (Send + Sync)</li> <li>Can be shared across threads via <code>Arc&lt;Wal&gt;</code></li> <li> <p>Multiple readers and writers are safe</p> </li> <li> <p>Writes are serialized internally</p> </li> <li>Only one thread can append at a time</li> <li>Lock held during encode + write + fsync</li> <li> <p>Contention reduces throughput by ~20-30%</p> </li> <li> <p>Reads don't block writes (and vice versa)</p> </li> <li>Separate file descriptors via FD cache</li> <li> <p>Concurrent readers scale linearly (~3.75x with 4 threads)</p> </li> <li> <p>FD cache reduces open() overhead</p> </li> <li>LRU cache with default size 16</li> <li> <p>Cache hit: ~1\u03bcs, cache miss: ~100\u03bcs</p> </li> <li> <p>Rotation happens while holding lock</p> </li> <li>Adds ~3-7ms latency to triggering write</li> <li>Rare event (once per 128MB)</li> <li> <p>No deadlock possible</p> </li> <li> <p>Best practice: Share one WAL per directory</p> </li> <li>Use <code>Arc&lt;Wal&gt;</code> for sharing</li> <li>Don't open multiple WALs for same directory</li> </ol>"},{"location":"crates/nori-wal/how-it-works/concurrency/#whats-next","title":"What's Next?","text":"<p>You've completed the \"How It Works\" section! Now explore:</p> <ul> <li>API Reference - Documentation for all public types</li> <li>Recipes - Build real applications with nori-wal</li> <li>Performance Tuning - Optimize for your workload</li> </ul> <p>Or dive into the implementation in <code>crates/nori-wal/src/</code> on GitHub.</p>"},{"location":"crates/nori-wal/how-it-works/record-format/","title":"Record Format","text":"<p>The on-disk structure of WAL records: header, CRC32C, compression, flags, and byte layout.</p>"},{"location":"crates/nori-wal/how-it-works/record-format/#table-of-contents","title":"Table of contents","text":""},{"location":"crates/nori-wal/how-it-works/record-format/#overview","title":"Overview","text":"<p>Every record in nori-wal has a well-defined binary format optimized for:</p> <ul> <li>Space efficiency: Variable-length encoding (varints) for lengths</li> <li>Data integrity: CRC32C checksum to detect corruption</li> <li>Flexibility: Flags for tombstones, TTL, and compression</li> <li>Performance: Fixed-size CRC at the end for fast validation</li> </ul>"},{"location":"crates/nori-wal/how-it-works/record-format/#byte-layout","title":"Byte Layout","text":"<p>Here's the complete on-disk format of a record:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        Record Format                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 klen:        varint (key length)                            \u2502\n\u2502 vlen:        varint (value length, compressed if applicable)\u2502\n\u2502 flags:       u8 (1 byte)                                    \u2502\n\u2502   bit 0:     tombstone (1 = delete, 0 = put)               \u2502\n\u2502   bit 1:     ttl_present (1 = has TTL, 0 = no TTL)         \u2502\n\u2502   bit 2-3:   compression (00=None, 01=LZ4, 10=Zstd)        \u2502\n\u2502   bit 4-7:   reserved (must be 0)                          \u2502\n\u2502 ttl_ms:      varint (milliseconds, only if ttl_present=1)  \u2502\n\u2502 key:         bytes[klen]                                    \u2502\n\u2502 value:       bytes[vlen] (compressed if compression != None)\u2502\n\u2502 crc32c:      u32 (little-endian)                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"crates/nori-wal/how-it-works/record-format/#size-calculation","title":"Size Calculation","text":"<p>Minimum record size: <pre><code>klen=1 (for key length 0) +\nvlen=1 (for value length 0) +\nflags=1 +\nkey=0 +\nvalue=0 +\ncrc32c=4\n= 7 bytes\n</code></pre></p> <p>Typical record size (key=\"user:123\", value=\"alice@example.com\"): <pre><code>klen=1 (8 &lt; 128) +\nvlen=1 (17 &lt; 128) +\nflags=1 +\nkey=8 +\nvalue=17 +\ncrc32c=4\n= 32 bytes\n</code></pre></p>"},{"location":"crates/nori-wal/how-it-works/record-format/#varint-encoding","title":"Varint Encoding","text":"<p>nori-wal uses LEB128 (Little Endian Base 128) for variable-length integers. This encodes small numbers in fewer bytes:</p> Value Bytes Encoding 0 1 <code>0x00</code> 127 1 <code>0x7F</code> 128 2 <code>0x80 0x01</code> 255 2 <code>0xFF 0x01</code> 16,383 2 <code>0xFF 0x7F</code> 16,384 3 <code>0x80 0x80 0x01</code>"},{"location":"crates/nori-wal/how-it-works/record-format/#varint-algorithm","title":"Varint Algorithm","text":"<p>Encoding: <pre><code>fn encode_varint(buf: &amp;mut BytesMut, mut value: u64) {\n    loop {\n        let mut byte = (value &amp; 0x7F) as u8;  // Take lower 7 bits\n        value &gt;&gt;= 7;                           // Shift right 7 bits\n        if value != 0 {\n            byte |= 0x80;                      // Set continuation bit\n        }\n        buf.put_u8(byte);\n        if value == 0 {\n            break;\n        }\n    }\n}\n</code></pre></p> <p>Decoding: <pre><code>fn decode_varint(data: &amp;mut &amp;[u8]) -&gt; Result&lt;u64, RecordError&gt; {\n    let mut result = 0u64;\n    let mut shift = 0;\n\n    loop {\n        if data.is_empty() {\n            return Err(RecordError::Incomplete);\n        }\n\n        let byte = data[0];\n        data.advance(1);\n\n        result |= ((byte &amp; 0x7F) as u64) &lt;&lt; shift;\n\n        if byte &amp; 0x80 == 0 {  // No continuation bit\n            break;\n        }\n\n        shift += 7;\n    }\n\n    Ok(result)\n}\n</code></pre></p> <p>Why varints? - Most keys and values are small (&lt; 128 bytes) \u2192 Only 1 byte overhead - Large keys/values (&gt; 16KB) \u2192 Only 3-4 bytes overhead - More efficient than fixed u32 (4 bytes for all sizes)</p>"},{"location":"crates/nori-wal/how-it-works/record-format/#flags-byte","title":"Flags Byte","text":"<p>The flags byte packs multiple boolean and enum fields into a single byte:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         Flags Byte (1 byte)           \u2502\n\u251c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 7 \u2502 6 \u2502 5 \u2502 4 \u2502 3 \u2502 2 \u2502 1 \u2502   0   \u2502\n\u251c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   Reserved    \u2502 Comp  \u2502TTL\u2502  Tomb \u2502\n\u2502   (must be 0) \u2502 ression\u2502   \u2502 stone \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"crates/nori-wal/how-it-works/record-format/#bit-meanings","title":"Bit Meanings","text":"Bit(s) Name Meaning 0 <code>TOMBSTONE</code> 1 = DELETE record, 0 = PUT record 1 <code>TTL_PRESENT</code> 1 = TTL field follows, 0 = no TTL 2-3 <code>COMPRESSION</code> <code>00</code> = None, <code>01</code> = LZ4, <code>10</code> = Zstd, <code>11</code> = reserved 4-7 Reserved Must be 0 (reserved for future use)"},{"location":"crates/nori-wal/how-it-works/record-format/#examples","title":"Examples","text":"<pre><code>// PUT record, no TTL, no compression\nflags = 0b0000_0000  // 0x00\n\n// DELETE record (tombstone)\nflags = 0b0000_0001  // 0x01\n\n// PUT record with TTL\nflags = 0b0000_0010  // 0x02\n\n// PUT record with LZ4 compression\nflags = 0b0000_0100  // 0x04\n\n// PUT record with TTL and Zstd compression\nflags = 0b0000_1010  // 0x0A\n</code></pre>"},{"location":"crates/nori-wal/how-it-works/record-format/#crc32c-checksum","title":"CRC32C Checksum","text":"<p>nori-wal uses CRC32C (Castagnoli) for data integrity:</p>"},{"location":"crates/nori-wal/how-it-works/record-format/#why-crc32c","title":"Why CRC32C?","text":"<ul> <li>Fast: Hardware-accelerated on modern CPUs (SSE4.2 instruction)</li> <li>Strong: Detects all 1-bit and 2-bit errors</li> <li>Standard: Used by ext4, Btrfs, iSCSI, etc.</li> </ul>"},{"location":"crates/nori-wal/how-it-works/record-format/#crc-calculation","title":"CRC Calculation","text":"<p>The CRC covers everything except the CRC itself:</p> <pre><code>Data for CRC = klen + vlen + flags + [ttl_ms] + key + value\n\nCRC32C = crc32c(data)\n</code></pre> <p>Example: <pre><code>Record bytes: [0x08, 0x11, 0x00, ...key..., ...value..., 0xAB, 0xCD, 0xEF, 0x12]\n                                                           \\_________________/\n                                                                  CRC32C\nCRC is calculated over:  [0x08, 0x11, 0x00, ...key..., ...value...]\n</code></pre></p>"},{"location":"crates/nori-wal/how-it-works/record-format/#crc-validation-on-read","title":"CRC Validation on Read","text":"<pre><code>fn verify_crc(data: &amp;[u8], bytes_consumed: usize, cursor: &amp;mut &amp;[u8])\n    -&gt; Result&lt;(), RecordError&gt;\n{\n    if cursor.len() &lt; 4 {\n        return Err(RecordError::Incomplete);\n    }\n\n    let stored_crc = cursor.get_u32_le();\n    let data_for_crc = &amp;data[..bytes_consumed - 4];\n    let calculated_crc = crc32c::crc32c(data_for_crc);\n\n    if stored_crc != calculated_crc {\n        return Err(RecordError::CrcMismatch {\n            expected: stored_crc,\n            actual: calculated_crc,\n        });\n    }\n\n    Ok(())\n}\n</code></pre>"},{"location":"crates/nori-wal/how-it-works/record-format/#compression","title":"Compression","text":"<p>nori-wal supports three compression modes:</p> Mode Flag Bits Use Case None <code>00</code> Small values, already compressed data LZ4 <code>01</code> Fast compression, good for text/JSON Zstd <code>10</code> Higher compression ratio, slightly slower"},{"location":"crates/nori-wal/how-it-works/record-format/#lz4-compression","title":"LZ4 Compression","text":"<p>LZ4 is optimized for speed with decent compression ratios.</p> <p>Compressed value format: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 original_size: varint            \u2502\n\u2502 compressed_data: bytes           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>Why prepend original size? - LZ4 decompression requires knowing the output buffer size - Varint is more efficient than fixed u32</p> <p>Example: <pre><code>let record = Record::put(b\"key\", b\"value\".repeat(100))\n    .with_compression(Compression::Lz4);\n\n// Original value: 500 bytes\n// Compressed: ~20 bytes + 2 bytes for original size = 22 bytes\n// Savings: 96%\n</code></pre></p>"},{"location":"crates/nori-wal/how-it-works/record-format/#zstd-compression","title":"Zstd Compression","text":"<p>Zstd provides better compression ratios at the cost of slightly more CPU.</p> <p>Compressed value format: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 compressed_data: bytes           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>Zstd doesn't need the original size prepended because it's embedded in the compressed stream.</p> <p>Example: <pre><code>let record = Record::put(b\"key\", b\"the quick brown fox\".repeat(50))\n    .with_compression(Compression::Zstd);\n\n// Original value: 950 bytes\n// Compressed: ~30 bytes\n// Savings: 97%\n</code></pre></p>"},{"location":"crates/nori-wal/how-it-works/record-format/#compression-trade-offs","title":"Compression Trade-offs","text":"Aspect None LZ4 Zstd Speed (encode) Instant ~500 MB/s ~400 MB/s Speed (decode) Instant ~2000 MB/s ~600 MB/s Ratio (text) 1.0x 3-4x 4-5x Ratio (JSON) 1.0x 4-6x 6-8x Ratio (random) 1.0x 1.0x 1.0x CPU overhead None Low Medium <p>Recommendations: - None: Small values (&lt;100 bytes), binary data, pre-compressed - LZ4: Text, JSON, logs (default for most use cases) - Zstd: Archival, cold storage, maximum compression</p>"},{"location":"crates/nori-wal/how-it-works/record-format/#examples-complete-records","title":"Examples: Complete Records","text":""},{"location":"crates/nori-wal/how-it-works/record-format/#example-1-simple-put","title":"Example 1: Simple PUT","text":"<pre><code>let record = Record::put(b\"user:1\", b\"alice\");\n</code></pre> <p>Encoded bytes: <pre><code>klen:    0x06                    (varint: 6)\nvlen:    0x05                    (varint: 5)\nflags:   0x00                    (no tombstone, no TTL, no compression)\nkey:     75 73 65 72 3A 31       (\"user:1\")\nvalue:   61 6C 69 63 65          (\"alice\")\ncrc32c:  AB CD EF 12             (little-endian u32)\n</code></pre></p> <p>Total size: 1 + 1 + 1 + 6 + 5 + 4 = 18 bytes</p>"},{"location":"crates/nori-wal/how-it-works/record-format/#example-2-delete-tombstone","title":"Example 2: DELETE (Tombstone)","text":"<pre><code>let record = Record::delete(b\"user:1\");\n</code></pre> <p>Encoded bytes: <pre><code>klen:    0x06                    (varint: 6)\nvlen:    0x00                    (varint: 0, no value)\nflags:   0x01                    (tombstone bit set)\nkey:     75 73 65 72 3A 31       (\"user:1\")\nvalue:   (empty)\ncrc32c:  12 34 56 78\n</code></pre></p> <p>Total size: 1 + 1 + 1 + 6 + 0 + 4 = 13 bytes</p>"},{"location":"crates/nori-wal/how-it-works/record-format/#example-3-put-with-ttl","title":"Example 3: PUT with TTL","text":"<pre><code>let record = Record::put_with_ttl(\n    b\"session:abc\",\n    b\"data\",\n    Duration::from_millis(3600000)  // 1 hour\n);\n</code></pre> <p>Encoded bytes: <pre><code>klen:    0x0B                    (varint: 11)\nvlen:    0x04                    (varint: 4)\nflags:   0x02                    (TTL bit set)\nttl_ms:  80 8D 36                (varint: 3600000)\nkey:     73 65 73 73 69 6F 6E... (\"session:abc\")\nvalue:   64 61 74 61             (\"data\")\ncrc32c:  AB CD EF 12\n</code></pre></p> <p>Total size: 1 + 1 + 1 + 3 + 11 + 4 + 4 = 25 bytes</p>"},{"location":"crates/nori-wal/how-it-works/record-format/#example-4-put-with-lz4-compression","title":"Example 4: PUT with LZ4 Compression","text":"<pre><code>let record = Record::put(b\"log\", b\"ERROR: \".repeat(20))\n    .with_compression(Compression::Lz4);\n</code></pre> <p>Encoded bytes: <pre><code>klen:           0x03             (varint: 3)\nvlen:           0x10             (varint: 16, compressed size)\nflags:          0x04             (compression = 01 &lt;&lt; 2)\nkey:            6C 6F 67          (\"log\")\nvalue (comp):   78 00 00 00 ...   (original_size=120, then compressed)\ncrc32c:         AB CD EF 12\n</code></pre></p> <p>Sizes: - Original value: 120 bytes - Compressed value: 16 bytes (13% of original) - Total record: 1 + 1 + 1 + 3 + 16 + 4 = 26 bytes</p>"},{"location":"crates/nori-wal/how-it-works/record-format/#decoding-algorithm","title":"Decoding Algorithm","text":"<p>Here's how nori-wal decodes a record from bytes:</p> <pre><code>flowchart TD\n    A[Start with byte slice] --&gt; B[Decode klen varint]\n    B --&gt; C[Decode vlen varint]\n    C --&gt; D[Read flags byte]\n    D --&gt; E{TTL present?}\n    E --&gt;|Yes| F[Decode ttl_ms varint]\n    E --&gt;|No| G[Extract key bytes]\n    F --&gt; G\n    G --&gt; H[Extract value bytes]\n    H --&gt; I[Read CRC32C u32]\n    I --&gt; J{CRC valid?}\n    J --&gt;|No| K[Return CrcMismatch error]\n    J --&gt;|Yes| L{Compression?}\n    L --&gt;|None| M[Return record]\n    L --&gt;|LZ4| N[Decompress with LZ4]\n    L --&gt;|Zstd| O[Decompress with Zstd]\n    N --&gt; M\n    O --&gt; M\n\n    style K fill:#FFB6C1\n    style M fill:#90EE90</code></pre>"},{"location":"crates/nori-wal/how-it-works/record-format/#error-handling","title":"Error Handling","text":""},{"location":"crates/nori-wal/how-it-works/record-format/#recorderror-types","title":"RecordError Types","text":"Error Cause Recovery <code>Incomplete</code> Not enough bytes to read Wait for more data or truncate <code>CrcMismatch</code> Corrupted data Truncate at this position <code>InvalidCompression</code> Unknown compression type Truncate (forward compatibility issue) <code>CompressionFailed</code> Compression library error Log and skip record <code>DecompressionFailed</code> Corrupted compressed data Truncate at this position"},{"location":"crates/nori-wal/how-it-works/record-format/#handling-corruption","title":"Handling Corruption","text":"<pre><code>match Record::decode(data) {\n    Ok((record, size)) =&gt; {\n        // Valid record, process it\n    }\n    Err(RecordError::CrcMismatch { expected, actual }) =&gt; {\n        // Corruption detected, truncate here\n        log::warn!(\"CRC mismatch at position {}: expected {:#x}, got {:#x}\",\n                   position, expected, actual);\n        truncate_at(position)?;\n    }\n    Err(RecordError::Incomplete) =&gt; {\n        // Partial write at end of log, truncate\n        truncate_at(position)?;\n    }\n    Err(e) =&gt; {\n        // Other errors: log and skip or truncate\n        log::error!(\"Failed to decode record: {}\", e);\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/how-it-works/record-format/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"crates/nori-wal/how-it-works/record-format/#encoding-performance","title":"Encoding Performance","text":"<pre><code>Operation: record.encode()\nSize: 1KB key + value\nTime: ~2\u03bcs (no compression)\nTime: ~15\u03bcs (LZ4 compression)\nTime: ~30\u03bcs (Zstd compression)\n</code></pre>"},{"location":"crates/nori-wal/how-it-works/record-format/#decoding-performance","title":"Decoding Performance","text":"<pre><code>Operation: Record::decode(&amp;bytes)\nSize: 1KB key + value\nTime: ~1\u03bcs (no compression)\nTime: ~0.5\u03bcs (LZ4 decompression)\nTime: ~2\u03bcs (Zstd decompression)\n</code></pre> <p>Why is LZ4 decompression faster than no compression? - Less data to copy from disk/memory - LZ4 decompression is extremely fast (~2 GB/s) - For large values, the I/O savings outweigh decompression cost</p>"},{"location":"crates/nori-wal/how-it-works/record-format/#design-decisions","title":"Design Decisions","text":""},{"location":"crates/nori-wal/how-it-works/record-format/#why-crc32c-instead-of-crc32","title":"Why CRC32C instead of CRC32?","text":"<ul> <li>Hardware acceleration: SSE4.2 on x86, CRC32 instruction on ARM</li> <li>10-100x faster than software CRC32</li> <li>Better error detection than CRC32 for certain patterns</li> </ul>"},{"location":"crates/nori-wal/how-it-works/record-format/#why-crc-at-the-end-not-the-beginning","title":"Why CRC at the end, not the beginning?","text":"<p>Pros of CRC at end: - Can stream-encode without buffering entire record - Can calculate CRC incrementally while writing - Simpler code</p> <p>Cons: - Must read entire record before validating CRC</p> <p>For WAL use case (sequential reads), the trade-off favors simplicity.</p>"},{"location":"crates/nori-wal/how-it-works/record-format/#why-varints-instead-of-fixed-size-lengths","title":"Why varints instead of fixed-size lengths?","text":"<p>Space savings: - Most records have small keys/values (&lt; 128 bytes) - Varint: 1 byte for lengths &lt; 128 - Fixed u32: 4 bytes always - Savings: 75% for typical workloads</p> <p>Performance: - Varint encoding: ~10ns - Varint decoding: ~8ns - Negligible compared to I/O cost</p>"},{"location":"crates/nori-wal/how-it-works/record-format/#why-not-use-protobufflatbuffers","title":"Why not use protobuf/flatbuffers?","text":"<ul> <li>Overkill: WAL records are simple, don't need schema evolution</li> <li>Overhead: Protobuf adds ~20-30% size overhead for small messages</li> <li>Performance: Custom format is 2-3x faster for this use case</li> <li>Simplicity: 200 lines of code vs dependency on large library</li> </ul>"},{"location":"crates/nori-wal/how-it-works/record-format/#forward-compatibility","title":"Forward Compatibility","text":"<p>The format is designed for forward compatibility:</p>"},{"location":"crates/nori-wal/how-it-works/record-format/#reserved-flag-bits","title":"Reserved Flag Bits","text":"<p>Bits 4-7 are reserved. Future versions can use them for: - Encryption - Different checksum algorithms - Record versioning - Replication metadata</p>"},{"location":"crates/nori-wal/how-it-works/record-format/#unknown-compression-types","title":"Unknown Compression Types","text":"<p>If a newer version writes compression type <code>11</code> (reserved), older versions will return <code>InvalidCompression</code> and truncate. This is safe: - Newer records are always at the end (append-only) - Truncating at first unknown record preserves all older data</p>"},{"location":"crates/nori-wal/how-it-works/record-format/#reading-older-formats","title":"Reading Older Formats","text":"<p>Current format can read all records written by older versions (there are none yet, but the design supports it).</p>"},{"location":"crates/nori-wal/how-it-works/record-format/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Compact format: Varints save space for small keys/values</li> <li>Strong integrity: CRC32C detects all corruption</li> <li>Flexible: Flags support tombstones, TTL, compression</li> <li>Fast: Hardware-accelerated CRC, efficient encoding/decoding</li> <li>Forward-compatible: Reserved bits for future features</li> </ol>"},{"location":"crates/nori-wal/how-it-works/record-format/#whats-next","title":"What's Next?","text":"<p>Now that you understand the record format, explore:</p> <ul> <li>Segment Lifecycle - How segments manage records</li> <li>Recovery Process - How records are validated during recovery</li> <li>Concurrency Model - How concurrent writes are handled</li> </ul> <p>Or dive into the actual implementation in <code>crates/nori-wal/src/record.rs</code> on GitHub.</p>"},{"location":"crates/nori-wal/how-it-works/recovery/","title":"Recovery Process","text":"<p>Detailed walkthrough of the recovery algorithm: scanning, validation, truncation, and rebuild.</p>"},{"location":"crates/nori-wal/how-it-works/recovery/#table-of-contents","title":"Table of contents","text":""},{"location":"crates/nori-wal/how-it-works/recovery/#recovery-overview","title":"Recovery Overview","text":"<p>When you open a WAL, nori-wal automatically recovers by scanning all segment files, validating records, and truncating any corruption.</p> <p>This process implements a prefix-valid recovery strategy:</p> <p>Keep all valid records from the beginning until corruption is detected, then truncate.</p> <pre><code>graph TD\n    A[Open WAL] --&gt; B[Discover Segment Files]\n    B --&gt; C[Sort Segments by ID]\n    C --&gt; D[For Each Segment]\n    D --&gt; E[Read Entire Segment into Memory]\n    E --&gt; F[Scan Records Sequentially]\n    F --&gt; G{Valid Record?}\n    G --&gt;|Yes| H[Count as Valid]\n    H --&gt; I{More Data?}\n    I --&gt;|Yes| F\n    I --&gt;|No| J[Segment Complete]\n    G --&gt;|No - CRC Mismatch| K[Truncate at This Position]\n    G --&gt;|No - Incomplete| K\n    K --&gt; L[Emit Corruption Event]\n    L --&gt; J\n    J --&gt; M{More Segments?}\n    M --&gt;|Yes| D\n    M --&gt;|No| N[Return RecoveryInfo]\n\n    style H fill:#90EE90\n    style K fill:#FFB6C1\n    style N fill:#90EE90</code></pre>"},{"location":"crates/nori-wal/how-it-works/recovery/#recoveryinfo-structure","title":"RecoveryInfo Structure","text":"<p>Recovery returns comprehensive information about what was found:</p> <pre><code>pub struct RecoveryInfo {\n    /// Total number of valid records recovered.\n    pub valid_records: u64,\n\n    /// Number of segments scanned.\n    pub segments_scanned: u64,\n\n    /// Total bytes truncated due to corruption.\n    pub bytes_truncated: u64,\n\n    /// Position of the last valid record.\n    pub last_valid_position: Option&lt;Position&gt;,\n\n    /// Whether any corruption was detected and truncated.\n    pub corruption_detected: bool,\n}\n</code></pre> <p>Example: <pre><code>let (wal, recovery_info) = Wal::open(config).await?;\n\nprintln!(\"Recovered {} records from {} segments\",\n         recovery_info.valid_records,\n         recovery_info.segments_scanned);\n\nif recovery_info.corruption_detected {\n    log::warn!(\"Corruption detected! Truncated {} bytes\",\n               recovery_info.bytes_truncated);\n}\n</code></pre></p>"},{"location":"crates/nori-wal/how-it-works/recovery/#step-by-step-recovery-algorithm","title":"Step-by-Step Recovery Algorithm","text":""},{"location":"crates/nori-wal/how-it-works/recovery/#step-1-discover-segment-files","title":"Step 1: Discover Segment Files","text":"<p>Scan the WAL directory for <code>.wal</code> files:</p> <pre><code>async fn find_all_segments(dir: &amp;Path) -&gt; Result&lt;Vec&lt;u64&gt;, SegmentError&gt; {\n    let mut entries = tokio::fs::read_dir(dir).await?;\n    let mut segment_ids = Vec::new();\n\n    while let Some(entry) = entries.next_entry().await? {\n        if let Some(id) = parse_segment_id_from_path(&amp;entry.path()) {\n            segment_ids.push(id);\n        }\n    }\n\n    Ok(segment_ids)\n}\n\nfn parse_segment_id_from_path(path: &amp;Path) -&gt; Option&lt;u64&gt; {\n    // Check extension is \"wal\"\n    if path.extension()?.to_str()? != \"wal\" {\n        return None;\n    }\n\n    // Parse filename stem as u64\n    let stem_str = path.file_stem()?.to_str()?;\n    stem_str.parse::&lt;u64&gt;().ok()\n}\n</code></pre> <p>Example: <pre><code>wal/\n  000000.wal  \u2192 segment_id = 0\n  000001.wal  \u2192 segment_id = 1\n  000005.wal  \u2192 segment_id = 5\n  temp.txt    \u2192 Ignored (not .wal)\n  README.md   \u2192 Ignored\n\nDiscovered segments: [0, 1, 5]\n</code></pre></p>"},{"location":"crates/nori-wal/how-it-works/recovery/#step-2-sort-segments-by-id","title":"Step 2: Sort Segments by ID","text":"<p>Process segments in order (oldest to newest):</p> <pre><code>segments.sort_unstable();\n// [0, 1, 5] \u2192 already sorted\n</code></pre> <p>Why sort? - Records must be replayed in order (append-only guarantee) - Later records shadow earlier ones (last write wins) - Recovery must preserve this ordering</p>"},{"location":"crates/nori-wal/how-it-works/recovery/#step-3-recover-each-segment","title":"Step 3: Recover Each Segment","text":"<p>For each segment, validate all records and truncate corruption:</p> <pre><code>async fn recover_segment(\n    wal_dir: &amp;Path,\n    segment_id: u64,\n    meter: Arc&lt;dyn Meter&gt;,\n    node_id: u32,\n) -&gt; Result&lt;SegmentRecoveryInfo, SegmentError&gt; {\n    let path = segment_path(wal_dir, segment_id);\n    let mut file = File::open(&amp;path).await?;\n\n    // Read entire segment into memory for fast validation\n    let file_size = file.metadata().await?.len();\n    let mut buffer = vec![0u8; file_size as usize];\n    file.read_exact(&amp;mut buffer).await?;\n\n    // Scan for valid records\n    let (valid_records, last_valid_offset) = scan_valid_records(&amp;buffer, file_size);\n\n    let bytes_truncated = file_size - last_valid_offset;\n\n    // Truncate if needed\n    if bytes_truncated &gt; 0 {\n        truncate_segment_atomically(&amp;path, &amp;buffer, last_valid_offset).await?;\n\n        // Emit observability event\n        meter.emit(VizEvent::Wal(WalEvt {\n            node: node_id,\n            seg: segment_id,\n            kind: WalKind::CorruptionTruncated,\n        }));\n    }\n\n    Ok(SegmentRecoveryInfo {\n        valid_records,\n        bytes_truncated,\n        last_valid_position: if valid_records &gt; 0 {\n            Some(Position { segment_id, offset: last_valid_offset })\n        } else {\n            None\n        },\n    })\n}\n</code></pre>"},{"location":"crates/nori-wal/how-it-works/recovery/#step-4-scan-and-validate-records","title":"Step 4: Scan and Validate Records","text":"<p>Read records sequentially, validating CRC32C for each:</p> <pre><code>fn scan_valid_records(buffer: &amp;[u8], file_size: u64) -&gt; (u64, u64) {\n    let mut offset = 0u64;\n    let mut valid_records = 0u64;\n    let mut last_valid_offset = 0u64;\n\n    while offset &lt; file_size {\n        let remaining = &amp;buffer[offset as usize..];\n\n        match Record::decode(remaining) {\n            Ok((_record, size)) =&gt; {\n                // Valid record - keep going\n                valid_records += 1;\n                offset += size as u64;\n                last_valid_offset = offset;\n            }\n            Err(RecordError::Incomplete) =&gt; {\n                // Partial record at tail - expected during crash\n                break;\n            }\n            Err(RecordError::CrcMismatch { .. }) | Err(_) =&gt; {\n                // Corruption detected - truncate here\n                break;\n            }\n        }\n    }\n\n    (valid_records, last_valid_offset)\n}\n</code></pre> <p>Example: <pre><code>Segment buffer (100 bytes):\n  [0..20]    Record 1 (CRC valid)   \u2192 valid_records = 1, last_valid_offset = 20\n  [20..45]   Record 2 (CRC valid)   \u2192 valid_records = 2, last_valid_offset = 45\n  [45..70]   Record 3 (CRC valid)   \u2192 valid_records = 3, last_valid_offset = 70\n  [70..85]   Record 4 (CRC INVALID) \u2192 STOP, truncate at offset 70\n  [85..100]  Garbage                \u2192 Discarded\n\nResult: (valid_records=3, last_valid_offset=70)\nBytes truncated: 100 - 70 = 30 bytes\n</code></pre></p>"},{"location":"crates/nori-wal/how-it-works/recovery/#step-5-atomic-truncation","title":"Step 5: Atomic Truncation","text":"<p>If corruption is detected, truncate the segment atomically:</p> <pre><code>async fn truncate_segment_atomically(\n    path: &amp;PathBuf,\n    buffer: &amp;[u8],\n    last_valid_offset: u64,\n) -&gt; Result&lt;(), SegmentError&gt; {\n    let temp_path = path.with_extension(\"wal.tmp\");\n\n    // 1. Write valid data to temp file\n    let mut temp_file = OpenOptions::new()\n        .create(true)\n        .write(true)\n        .truncate(true)\n        .open(&amp;temp_path)\n        .await?;\n\n    temp_file.write_all(&amp;buffer[..last_valid_offset as usize]).await?;\n    temp_file.sync_all().await?;\n    drop(temp_file);\n\n    // 2. Atomic rename (replaces original file)\n    tokio::fs::rename(&amp;temp_path, path).await?;\n\n    Ok(())\n}\n</code></pre> <p>Why atomic?</p> <p>If we crash during truncation: - Without atomic rename: Original file may be partially overwritten (corrupted) - With atomic rename: Either old file survives (untouched) or new file is complete</p> <p>Implementation: 1. Write valid data to <code>000000.wal.tmp</code> 2. Sync temp file to disk 3. Rename <code>000000.wal.tmp</code> \u2192 <code>000000.wal</code> (atomic on all platforms)</p>"},{"location":"crates/nori-wal/how-it-works/recovery/#recovery-scenarios","title":"Recovery Scenarios","text":""},{"location":"crates/nori-wal/how-it-works/recovery/#scenario-1-clean-recovery-no-corruption","title":"Scenario 1: Clean Recovery (No Corruption)","text":"<pre><code>// Before crash: wrote 10 records, synced all\n[Record 1][Record 2]...[Record 10]\n\n// On recovery:\nScan: All 10 records have valid CRCs\nResult: RecoveryInfo {\n    valid_records: 10,\n    segments_scanned: 1,\n    bytes_truncated: 0,\n    corruption_detected: false,\n}\n</code></pre> <p>All data recovered</p>"},{"location":"crates/nori-wal/how-it-works/recovery/#scenario-2-partial-write-at-tail","title":"Scenario 2: Partial Write at Tail","text":"<pre><code>// Before crash: wrote 10 records, synced 9, writing 10th\n[R1][R2]...[R9][R10: partial, only 15 of 30 bytes]\n\n// On recovery:\nScan records 1-9: Valid CRCs \u2192 Keep\nScan record 10: RecordError::Incomplete \u2192 Truncate here\n\nResult: RecoveryInfo {\n    valid_records: 9,\n    bytes_truncated: 15,\n    corruption_detected: true,\n}\n</code></pre> <p>Lost record 10 (was never fully written)</p>"},{"location":"crates/nori-wal/how-it-works/recovery/#scenario-3-corrupted-data-crc-mismatch","title":"Scenario 3: Corrupted Data (CRC Mismatch)","text":"<pre><code>// Before crash: corruption in the middle of a record\n[R1][R2][R3: corrupted data, CRC mismatch][R4][R5]\n\n// On recovery:\nScan R1-R2: Valid \u2192 Keep\nScan R3: CrcMismatch \u2192 Truncate here\nR4-R5: Never scanned (truncated)\n\nResult: RecoveryInfo {\n    valid_records: 2,\n    bytes_truncated: size_of(R3 + R4 + R5),\n    corruption_detected: true,\n}\n</code></pre> <p>Lost R3, R4, R5 (everything from first corruption onward)</p>"},{"location":"crates/nori-wal/how-it-works/recovery/#scenario-4-empty-segment","title":"Scenario 4: Empty Segment","text":"<pre><code>// Segment file exists but contains no data\nFile size: 0 bytes\n\n// On recovery:\nNo records to scan\n\nResult: RecoveryInfo {\n    valid_records: 0,\n    bytes_truncated: 0,\n    corruption_detected: false,\n}\n</code></pre> <p>Valid (no data lost, segment is just empty)</p>"},{"location":"crates/nori-wal/how-it-works/recovery/#scenario-5-multiple-segments-with-mixed-corruption","title":"Scenario 5: Multiple Segments with Mixed Corruption","text":"<pre><code>Segment 0: [R1][R2][R3] (all valid)\nSegment 1: [R4][R5: partial]\nSegment 2: [R6][R7] (never scanned, segment 1 stopped at R5)\n\nRecovery:\n  Segment 0: 3 valid records, 0 bytes truncated\n  Segment 1: 1 valid record (R4), truncate at R5\n  Segment 2: 2 valid records, 0 bytes truncated\n\nResult: RecoveryInfo {\n    valid_records: 6 (R1-R4 from seg 0-1, R6-R7 from seg 2),\n    segments_scanned: 3,\n    bytes_truncated: size_of(partial R5),\n    corruption_detected: true,\n}\n</code></pre> <p>Recovered 6 out of 7 records</p>"},{"location":"crates/nori-wal/how-it-works/recovery/#error-handling","title":"Error Handling","text":""},{"location":"crates/nori-wal/how-it-works/recovery/#recorderror-types","title":"RecordError Types","text":"<p>During recovery, <code>Record::decode()</code> may return:</p> Error Meaning Action <code>Ok((record, size))</code> Valid record Keep scanning <code>Err(Incomplete)</code> Not enough bytes (partial write) Truncate here <code>Err(CrcMismatch)</code> Data corruption Truncate here <code>Err(InvalidCompression)</code> Unknown compression type Truncate here <code>Err(DecompressionFailed)</code> Corrupted compressed data Truncate here <p>All errors result in truncation (prefix-valid recovery).</p>"},{"location":"crates/nori-wal/how-it-works/recovery/#io-errors","title":"I/O Errors","text":"<pre><code>match File::open(&amp;path).await {\n    Ok(file) =&gt; { /* proceed */ }\n    Err(e) if e.kind() == ErrorKind::NotFound =&gt; {\n        // Segment was deleted - skip it\n    }\n    Err(e) =&gt; {\n        // Other I/O error - fail recovery\n        return Err(SegmentError::Io(e));\n    }\n}\n</code></pre> <p>Common I/O errors: - NotFound: Segment was deleted (skip it) - PermissionDenied: No read access (fail) - IOError: Disk failure (fail)</p>"},{"location":"crates/nori-wal/how-it-works/recovery/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"crates/nori-wal/how-it-works/recovery/#recovery-time","title":"Recovery Time","text":"<p>Recovery speed depends on: 1. Number of segments 2. Total data size 3. Disk speed</p> <p>Typical performance (SSD):</p> Scenario Segments Data Size Recovery Time Small 1 1 MB ~5 ms Medium 10 100 MB ~150 ms Large 100 10 GB ~15 s Very Large 1000 100 GB ~150 s <p>Bottleneck: Reading data from disk (I/O bound)</p>"},{"location":"crates/nori-wal/how-it-works/recovery/#memory-usage","title":"Memory Usage","text":"<p>Recovery reads entire segments into memory:</p> <pre><code>Memory usage = max(segment_size)\n\nDefault: 128 MB per segment (one at a time)\n</code></pre> <p>Why read entire segment? - Faster than multiple small reads - Simplifies code (no buffering complexity) - 128 MB is acceptable for modern systems</p> <p>Alternative: Streaming validation (not implemented) - Would use less memory (~1 MB buffer) - Would require more complex code - Would be slower (more syscalls)</p>"},{"location":"crates/nori-wal/how-it-works/recovery/#optimization-parallel-segment-validation","title":"Optimization: Parallel Segment Validation","text":"<p>Current: Segments validated sequentially</p> <p>Possible optimization: Validate segments in parallel</p> <pre><code>// Hypothetical parallel recovery\nlet tasks: Vec&lt;_&gt; = segments.into_iter()\n    .map(|id| tokio::spawn(recover_segment(dir, id, meter, node_id)))\n    .collect();\n\nlet results = futures::future::join_all(tasks).await;\n</code></pre> <p>Benefits: - 2-4x faster for many segments - Better utilization of I/O bandwidth</p> <p>Trade-offs: - More complex code - Higher memory usage (multiple segments in RAM) - Not needed for most use cases (recovery is already fast)</p>"},{"location":"crates/nori-wal/how-it-works/recovery/#testing-recovery","title":"Testing Recovery","text":""},{"location":"crates/nori-wal/how-it-works/recovery/#test-1-clean-recovery","title":"Test 1: Clean Recovery","text":"<pre><code>#[tokio::test]\nasync fn test_recovery_clean() {\n    // Write 10 records, sync all\n    let (wal, _) = Wal::open(config).await?;\n    for i in 0..10 {\n        wal.append(&amp;Record::put(format!(\"key{}\", i), b\"value\")).await?;\n    }\n    wal.sync().await?;\n    drop(wal);\n\n    // Reopen and verify recovery\n    let (wal, info) = Wal::open(config).await?;\n    assert_eq!(info.valid_records, 10);\n    assert_eq!(info.bytes_truncated, 0);\n    assert!(!info.corruption_detected);\n}\n</code></pre>"},{"location":"crates/nori-wal/how-it-works/recovery/#test-2-partial-write","title":"Test 2: Partial Write","text":"<pre><code>#[tokio::test]\nasync fn test_recovery_partial_write() {\n    // Write 5 records, sync\n    let (wal, _) = Wal::open(config).await?;\n    for i in 0..5 {\n        wal.append(&amp;Record::put(format!(\"key{}\", i), b\"value\")).await?;\n    }\n    wal.sync().await?;\n    drop(wal);\n\n    // Append garbage (simulate crash mid-write)\n    let seg_path = dir.join(\"000000.wal\");\n    let mut file = OpenOptions::new().append(true).open(&amp;seg_path).await?;\n    file.write_all(b\"PARTIAL_GARBAGE\").await?;\n    file.sync_all().await?;\n\n    // Recover - should truncate garbage\n    let (wal, info) = Wal::open(config).await?;\n    assert_eq!(info.valid_records, 5);\n    assert!(info.bytes_truncated &gt; 0);\n    assert!(info.corruption_detected);\n}\n</code></pre>"},{"location":"crates/nori-wal/how-it-works/recovery/#test-3-crc-mismatch","title":"Test 3: CRC Mismatch","text":"<pre><code>#[tokio::test]\nasync fn test_recovery_crc_mismatch() {\n    // Write and sync 5 records\n    // ... (same as above)\n\n    // Corrupt data in last record\n    let seg_path = dir.join(\"000000.wal\");\n    let mut data = tokio::fs::read(&amp;seg_path).await?;\n    data[data.len() - 15] ^= 0xFF;  // Flip bits in value\n    tokio::fs::write(&amp;seg_path, &amp;data).await?;\n\n    // Recover - should detect corruption and truncate\n    let (wal, info) = Wal::open(config).await?;\n    assert!(info.valid_records &lt; 5);  // Lost corrupted record\n    assert!(info.bytes_truncated &gt; 0);\n    assert!(info.corruption_detected);\n}\n</code></pre>"},{"location":"crates/nori-wal/how-it-works/recovery/#observability","title":"Observability","text":"<p>Recovery emits events for monitoring:</p> <pre><code>// Corruption detected and truncated\nVizEvent::Wal(WalEvt {\n    node: node_id,\n    seg: segment_id,\n    kind: WalKind::CorruptionTruncated,\n})\n</code></pre> <p>What to monitor: - Frequency of corruption events: Should be rare (only after crashes) - Bytes truncated: Large truncations indicate serious issues - Recovery time: Should be fast (&lt; 1s for most workloads)</p> <p>Alert on: - Corruption events during normal operation (not after restart) - Large amounts of truncated data (&gt; 1% of total) - Slow recovery (&gt; 10s)</p>"},{"location":"crates/nori-wal/how-it-works/recovery/#design-decisions","title":"Design Decisions","text":""},{"location":"crates/nori-wal/how-it-works/recovery/#why-prefix-valid-recovery","title":"Why Prefix-Valid Recovery?","text":"<p>Alternatives: 1. Reject all if any corruption: Too strict (lose all data on single bad record) 2. Try to skip corrupted records: Unsafe (may violate ordering guarantees) 3. Prefix-valid: Keep all good data, truncate from first corruption</p> <p>Prefix-valid is the right trade-off: - Maximizes data recovery - Simple to implement and reason about - Preserves ordering guarantees - Standard approach (used by PostgreSQL, MySQL, etc.)</p>"},{"location":"crates/nori-wal/how-it-works/recovery/#why-read-entire-segment","title":"Why Read Entire Segment?","text":"<p>Alternatives: 1. Stream validation (buffer 1 MB at a time)    - Less memory    - More complex code    - Slower (more syscalls)</p> <ol> <li>Read entire segment</li> <li>Simple code</li> <li>Fast (one large read)</li> <li>Higher memory (128 MB)</li> </ol> <p>Current choice: Read entire segment - 128 MB is acceptable on modern systems - Simplicity &gt; micro-optimization - Can change later if needed (not a breaking change)</p>"},{"location":"crates/nori-wal/how-it-works/recovery/#why-atomic-truncation","title":"Why Atomic Truncation?","text":"<p>Without atomic rename: <pre><code>1. Open segment for writing\n2. Truncate to valid offset\n3. CRASH HERE \u2192 File may be corrupted or empty\n4. Sync\n</code></pre></p> <p>With atomic rename: <pre><code>1. Write valid data to temp file\n2. Sync temp file\n3. CRASH HERE \u2192 Original file untouched\n4. Rename temp \u2192 original (atomic)\n5. CRASH HERE \u2192 New file is complete\n</code></pre></p> <p>Atomic rename ensures either old file or new file exists, never a partial state.</p>"},{"location":"crates/nori-wal/how-it-works/recovery/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Recovery is automatic on WAL open</li> <li>No manual intervention required</li> <li> <p>Scans all segments, validates all records</p> </li> <li> <p>Prefix-valid recovery strategy</p> </li> <li>Keep all valid records from the beginning</li> <li> <p>Truncate from first corruption/incompleteness</p> </li> <li> <p>CRC32C provides strong validation</p> </li> <li>Detects all corruption during recovery</li> <li> <p>Hardware-accelerated for speed</p> </li> <li> <p>Truncation is atomic</p> </li> <li>Temp file + rename pattern</li> <li> <p>Safe even if crash during recovery</p> </li> <li> <p>RecoveryInfo tells you what happened</p> </li> <li>Check <code>corruption_detected</code> and <code>bytes_truncated</code></li> <li> <p>Log warnings if corruption found</p> </li> <li> <p>Recovery is fast</p> </li> <li>~150ms for 100 MB</li> <li>~15s for 10 GB</li> <li>I/O bound, not CPU bound</li> </ol>"},{"location":"crates/nori-wal/how-it-works/recovery/#whats-next","title":"What's Next?","text":"<p>Now that you understand recovery, explore:</p> <ul> <li>Concurrency Model - How concurrent access is handled</li> <li>Recovery Guarantees - High-level guarantees</li> <li>Recipes: Crash Testing - Property-based testing for recovery</li> </ul> <p>Or dive into the implementation in <code>crates/nori-wal/src/recovery.rs</code> on GitHub.</p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/","title":"Segment Lifecycle","text":"<p>How segments are created, rotated, pre-allocated, and deleted. Platform-specific optimizations.</p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#table-of-contents","title":"Table of contents","text":""},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#what-is-a-segment","title":"What is a Segment?","text":"<p>A segment is a single file on disk containing a sequence of WAL records. Segments are:</p> <ul> <li>Numbered sequentially: <code>000000.wal</code>, <code>000001.wal</code>, <code>000002.wal</code>, etc.</li> <li>Append-only: Records are always written at the end</li> <li>Fixed maximum size: Default 128 MiB (configurable)</li> <li>Rotated automatically: New segment created when current one fills up</li> </ul> <pre><code>wal/\n  000000.wal  (128 MB, full)\n  000001.wal  (128 MB, full)\n  000002.wal  (64 MB, active - currently being written to)\n</code></pre>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#segment-lifecycle-states","title":"Segment Lifecycle States","text":"<p>A segment goes through several states during its lifetime:</p> <pre><code>stateDiagram-v2\n    [*] --&gt; Creating: New segment needed\n    Creating --&gt; Preallocating: Open file\n    Preallocating --&gt; Active: Ready for writes\n    Active --&gt; Active: Append records\n    Active --&gt; Rotating: Size limit reached\n    Rotating --&gt; Finalized: Truncate to actual size\n    Finalized --&gt; Archived: No longer active\n    Archived --&gt; Deleted: Garbage collected\n    Deleted --&gt; [*]\n\n    note right of Preallocating\n        Platform-specific:\n        - Linux: fallocate()\n        - macOS: fcntl()\n        - Windows: set_len()\n    end note\n\n    note right of Active\n        Write position tracked\n        Fsync per policy\n    end note\n\n    note right of Finalized\n        Truncate from 128MB\n        to actual data size\n    end note</code></pre>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#creating-a-new-segment","title":"Creating a New Segment","text":""},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#step-1-determine-segment-id","title":"Step 1: Determine Segment ID","text":"<p>Segment IDs start at 0 and increment sequentially:</p> <pre><code>// First segment\nsegment_id = 0  \u2192 \"000000.wal\"\n\n// Second segment (after rotation)\nsegment_id = 1  \u2192 \"000001.wal\"\n\n// 100th segment\nsegment_id = 99 \u2192 \"000099.wal\"\n</code></pre> <p>Filename format: <code>{id:06}.wal</code> (6 digits, zero-padded)</p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#step-2-open-file","title":"Step 2: Open File","text":"<p>Create or open the file with read+write permissions:</p> <pre><code>let path = dir.join(format!(\"{:06}.wal\", segment_id));\n\nlet file = OpenOptions::new()\n    .create(true)       // Create if doesn't exist\n    .truncate(false)    // Don't truncate existing data\n    .write(true)\n    .read(true)\n    .open(&amp;path)\n    .await?;\n</code></pre> <p>Why <code>truncate(false)</code>? - If we crash during segment creation, we may have a partial file - On restart, we want to append to it, not lose existing data - Recovery will truncate any invalid tail data</p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#step-3-pre-allocate-space-optional","title":"Step 3: Pre-allocate Space (Optional)","text":"<p>If <code>preallocate: true</code> in config, reserve disk space for the entire segment:</p> <pre><code>if preallocate &amp;&amp; actual_file_size == 0 {\n    preallocate(&amp;file, max_segment_size).await?;\n    file.sync_all().await?;\n    file.seek(SeekFrom::Start(0)).await?; // Back to beginning\n}\n</code></pre> <p>Benefits: - Early error detection (know immediately if disk is full) - Better filesystem locality (less fragmentation) - Improved performance on some filesystems - Prevents mid-write \"no space left\" errors</p> <p>Cost: - ~1-2ms latency when creating segment - Disk space shows as \"used\" even if not written</p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#platform-specific-pre-allocation","title":"Platform-Specific Pre-allocation","text":"<p>nori-wal uses optimized pre-allocation for each platform:</p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#linux-fallocate2","title":"Linux: fallocate(2)","text":"<pre><code>let fd = file.as_raw_fd();\n\nunsafe {\n    libc::fallocate(\n        fd,\n        0,              // mode: default allocation\n        0,              // offset: start from beginning\n        size as libc::off_t,\n    )\n}\n</code></pre> <p>Characteristics: - Fastest method (~0.5ms for 128MB) - Allocates actual disk blocks (not sparse) - Zeros the allocated space - Supported on ext4, XFS, Btrfs</p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#macos-fcntl2-with-f_preallocate","title":"macOS: fcntl(2) with F_PREALLOCATE","text":"<pre><code>let fd = file.as_raw_fd();\n\nlet mut fstore = FStore {\n    fst_flags: F_ALLOCATECONTIG | F_ALLOCATEALL,\n    fst_posmode: F_PEOFPOSMODE,\n    fst_offset: 0,\n    fst_length: size as libc::off_t,\n    fst_bytesalloc: 0,\n};\n\nunsafe {\n    libc::fcntl(fd, F_PREALLOCATE, &amp;mut fstore)\n}\n\nfile.set_len(size).await?;\n</code></pre> <p>Characteristics: - Tries contiguous allocation first (F_ALLOCATECONTIG) - Falls back to non-contiguous if needed - Fast (~1ms for 128MB on APFS) - Reduces fragmentation</p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#windows-set_len","title":"Windows: set_len()","text":"<pre><code>file.set_len(size).await?;\n</code></pre> <p>Characteristics: - Uses standard set_len() API - NTFS may create sparse file initially - Space allocated on first write - Still provides early error detection</p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#other-platforms-fallback","title":"Other Platforms: Fallback","text":"<pre><code>file.set_len(size).await?;\n</code></pre> <p>Uses standard <code>set_len()</code> which works everywhere but may be less efficient.</p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#writing-to-a-segment","title":"Writing to a Segment","text":""},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#append-operation","title":"Append Operation","text":"<p>Records are always appended to the end of the current segment:</p> <pre><code>async fn append(&amp;mut self, record: &amp;Record) -&gt; Result&lt;u64, SegmentError&gt; {\n    let encoded = record.encode();\n    let offset = self.size;  // Current write position\n\n    self.file.write_all(&amp;encoded).await?;\n    self.size += encoded.len() as u64;\n\n    Ok(offset)  // Return position of written record\n}\n</code></pre> <p>Key points: - <code>self.size</code> tracks logical size (actual data written) - Physical file size may be larger (if pre-allocated) - No seeking required (always append at end)</p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#size-tracking","title":"Size Tracking","text":"<p>nori-wal tracks two sizes:</p> Size Type Meaning When Equal? Logical size Actual data written Always tracked in <code>self.size</code> Physical size Disk space allocated After pre-allocation <pre><code>Newly created segment with pre-allocation:\n  Logical size:  0 bytes (no data yet)\n  Physical size: 128 MB (pre-allocated)\n\nAfter writing 1000 records (~50 KB):\n  Logical size:  50 KB (actual data)\n  Physical size: 128 MB (still pre-allocated)\n\nAfter finalization:\n  Logical size:  50 KB\n  Physical size: 50 KB (truncated to match)\n</code></pre>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#segment-rotation","title":"Segment Rotation","text":"<p>Rotation happens when a segment reaches its size limit.</p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#rotation-trigger","title":"Rotation Trigger","text":"<p>Before each write, check if it would exceed the limit:</p> <pre><code>fn would_exceed(&amp;self, record_size: usize, max_size: u64) -&gt; bool {\n    self.size + record_size as u64 &gt; max_size\n}\n\n// In SegmentManager:\nlet encoded = record.encode();\n\nif active_segment.would_exceed(encoded.len(), config.max_segment_size) {\n    rotate_segment().await?;\n}\n</code></pre> <p>Example: <pre><code>Current segment: 000000.wal\n  - Logical size: 134,217,500 bytes (128 MB - 228 bytes)\n  - Max size: 134,217,728 bytes (128 MB)\n\nNext record size: 500 bytes\n\nCheck: 134,217,500 + 500 &gt; 134,217,728? YES \u2192 Rotate!\n</code></pre></p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#rotation-process","title":"Rotation Process","text":"<pre><code>sequenceDiagram\n    participant App as Application\n    participant SM as SegmentManager\n    participant Old as Active Segment\n    participant New as New Segment\n\n    App-&gt;&gt;SM: append(record)\n    SM-&gt;&gt;SM: Check if would_exceed()\n    alt Would exceed size limit\n        SM-&gt;&gt;Old: finalize()\n        Old-&gt;&gt;Old: truncate to logical size\n        Old-&gt;&gt;Old: sync_all()\n        SM-&gt;&gt;New: create(next_id)\n        New-&gt;&gt;New: preallocate if enabled\n        SM-&gt;&gt;SM: Switch active segment\n        SM-&gt;&gt;New: append(record)\n        New--&gt;&gt;App: Return position\n    else Within limit\n        SM-&gt;&gt;Old: append(record)\n        Old--&gt;&gt;App: Return position\n    end</code></pre>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#finalization","title":"Finalization","text":"<p>When rotating away from a segment, finalize it:</p> <pre><code>async fn finalize(&amp;mut self) -&gt; Result&lt;(), SegmentError&gt; {\n    // Truncate physical file to match logical size\n    self.file.set_len(self.size).await?;\n\n    // Force to disk\n    self.file.sync_all().await?;\n\n    Ok(())\n}\n</code></pre> <p>Why finalize? - Reclaim unused pre-allocated space - Disk usage matches actual data - Safe to archive/replicate the segment</p> <p>Example: <pre><code>Before finalization:\n  000000.wal: 128 MB (pre-allocated), 65 MB actual data\n\nAfter finalization:\n  000000.wal: 65 MB (truncated to actual size)\n</code></pre></p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#fsync-behavior","title":"Fsync Behavior","text":"<p>Segments sync to disk according to the configured <code>FsyncPolicy</code>:</p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#fsyncpolicyalways","title":"FsyncPolicy::Always","text":"<p>Every write is immediately synced:</p> <pre><code>let offset = segment.append(&amp;record).await?;\nsegment.sync().await?;  // fsync after every append\n</code></pre>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#fsyncpolicybatchduration","title":"FsyncPolicy::Batch(Duration)","text":"<p>Sync at most once per time window:</p> <pre><code>struct BatchedFsync {\n    window: Duration,\n    last_sync: Instant,\n}\n\nlet offset = segment.append(&amp;record).await?;\n\nlet now = Instant::now();\nif now.duration_since(self.last_sync) &gt;= self.window {\n    segment.sync().await?;\n    self.last_sync = now;\n}\n// Otherwise: no sync (fast path)\n</code></pre>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#fsyncpolicyos","title":"FsyncPolicy::Os","text":"<p>No explicit sync:</p> <pre><code>let offset = segment.append(&amp;record).await?;\n// No sync! OS will eventually flush to disk\n</code></pre> <p>Manual sync still available: <pre><code>wal.sync().await?;  // Explicit sync when needed\n</code></pre></p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#reading-from-segments","title":"Reading from Segments","text":""},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#sequential-reading","title":"Sequential Reading","text":"<pre><code>pub struct SegmentReader {\n    file: File,\n    buffer: Vec&lt;u8&gt;,\n    position: u64,\n}\n\nimpl SegmentReader {\n    pub async fn next_record(&amp;mut self) -&gt; Result&lt;Option&lt;(Record, u64)&gt;, SegmentError&gt; {\n        // Read enough bytes for header\n        self.file.read_exact(&amp;mut self.buffer[..header_size]).await?;\n\n        // Decode header to determine total record size\n        let total_size = decode_header(&amp;self.buffer)?;\n\n        // Read the rest of the record\n        self.file.read_exact(&amp;mut self.buffer[..total_size]).await?;\n\n        // Decode and validate\n        let (record, _) = Record::decode(&amp;self.buffer)?;\n        let position = self.position;\n        self.position += total_size as u64;\n\n        Ok(Some((record, position)))\n    }\n}\n</code></pre> <p>Optimizations: - Reuses buffer between reads (no allocations) - Reads in chunks (not byte-by-byte) - Validates CRC before returning record</p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#random-access","title":"Random Access","text":"<p>You can seek to a specific position:</p> <pre><code>let position = Position {\n    segment_id: 1,\n    offset: 1024,\n};\n\nlet mut reader = wal.read_from(position).await?;\nwhile let Some((record, pos)) = reader.next_record().await? {\n    // Process records starting from position\n}\n</code></pre> <p>Use cases: - Replication: followers read from specific positions - Recovery: skip already-processed records - Debugging: inspect records at known positions</p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#file-descriptor-caching","title":"File Descriptor Caching","text":"<p>Opening files is expensive (~100\u03bcs). nori-wal caches file descriptors:</p> <pre><code>struct FdCache {\n    cache: HashMap&lt;u64, Arc&lt;Mutex&lt;File&gt;&gt;&gt;,\n    max_size: usize,\n    access_order: Vec&lt;u64&gt;,  // LRU tracking\n}\n</code></pre>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#lru-eviction","title":"LRU Eviction","text":"<p>When cache is full, evict least recently used:</p> <pre><code>fn insert(&amp;mut self, segment_id: u64, file: File) {\n    if self.cache.len() &gt;= self.max_size {\n        // Evict LRU segment\n        let lru_id = self.access_order.remove(0);\n        self.cache.remove(&amp;lru_id);\n        // File drops here, closing FD\n    }\n\n    self.cache.insert(segment_id, Arc::new(Mutex::new(file)));\n    self.access_order.push(segment_id);\n}\n</code></pre> <p>Benefits: - Reading from recently-read segments: ~1\u03bcs (cache hit) - Reading from uncached segment: ~100\u03bcs (cache miss, need to open)</p> <p>Default cache size: 16 file descriptors</p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#deleting-segments","title":"Deleting Segments","text":""},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#manual-deletion","title":"Manual Deletion","text":"<p>Delete all segments before a position:</p> <pre><code>let cutoff = Position {\n    segment_id: 10,\n    offset: 0,\n};\n\nlet deleted_count = wal.delete_segments_before(cutoff).await?;\n</code></pre> <p>What gets deleted: <pre><code>Before:\n  wal/000000.wal  \u2190 Delete\n  wal/000001.wal  \u2190 Delete\n  ...\n  wal/000009.wal  \u2190 Delete\n  wal/000010.wal  \u2190 Keep (cutoff segment)\n  wal/000011.wal  \u2190 Keep (after cutoff)\n\nAfter:\n  wal/000010.wal\n  wal/000011.wal\n</code></pre></p> <p>Safety: - Cannot delete active segment - Cannot delete segments after cutoff - Deletion is atomic per segment (all or nothing)</p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#compaction-driven-deletion","title":"Compaction-Driven Deletion","text":"<p>Typical workflow:</p> <ol> <li>Compact old segments into a new segment</li> <li>Write snapshot of current state</li> <li>Delete old segments that are no longer needed</li> </ol> <pre><code>// 1. Compact segments 0-9 into segment 100\ncompact_segments(0..10, 100).await?;\n\n// 2. All data from 0-9 is now in segment 100\n// 3. Safe to delete old segments\nwal.delete_segments_before(Position { segment_id: 10, offset: 0 }).await?;\n</code></pre> <p>See Recipes: Compaction for details.</p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#segment-naming-and-discovery","title":"Segment Naming and Discovery","text":""},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#naming-convention","title":"Naming Convention","text":"<pre><code>Format: {id:06}.wal\n\nExamples:\n  000000.wal  (segment 0)\n  000001.wal  (segment 1)\n  000042.wal  (segment 42)\n  012345.wal  (segment 12345)\n</code></pre> <p>Why 6 digits? - Supports up to 999,999 segments - At 128MB per segment, that's 128 PB of log data - Sufficient for any realistic use case</p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#discovery-on-startup","title":"Discovery on Startup","text":"<p>When opening a WAL, nori-wal scans the directory:</p> <pre><code>async fn discover_segments(dir: &amp;Path) -&gt; Result&lt;Vec&lt;u64&gt;, SegmentError&gt; {\n    let mut segment_ids = vec![];\n\n    let mut entries = tokio::fs::read_dir(dir).await?;\n    while let Some(entry) = entries.next_entry().await? {\n        let filename = entry.file_name();\n\n        // Parse \"NNNNNN.wal\" format\n        if let Some(id) = parse_segment_id(&amp;filename) {\n            segment_ids.push(id);\n        }\n    }\n\n    segment_ids.sort();  // Oldest to newest\n    Ok(segment_ids)\n}\n</code></pre> <p>Recovery then proceeds: 1. Discover all segments 2. Scan each segment in order (0, 1, 2, ...) 3. Validate records and truncate any corruption 4. Resume writing to the last segment (or create new if full)</p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#configuration-examples","title":"Configuration Examples","text":""},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#small-segments-frequent-rotation","title":"Small Segments (Frequent Rotation)","text":"<pre><code>let config = WalConfig {\n    max_segment_size: 32 * 1024 * 1024,  // 32 MB\n    ..Default::default()\n};\n</code></pre> <p>Use when: - Frequent compaction - Limited disk space - Want quick garbage collection</p> <p>Trade-offs: - More segments to manage - More file descriptor churn - Slightly higher overhead</p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#large-segments-infrequent-rotation","title":"Large Segments (Infrequent Rotation)","text":"<pre><code>let config = WalConfig {\n    max_segment_size: 512 * 1024 * 1024,  // 512 MB\n    ..Default::default()\n};\n</code></pre> <p>Use when: - High write throughput - Infrequent compaction - Want to minimize rotation overhead</p> <p>Trade-offs: - Slower recovery (larger files to scan) - Larger files to manage/replicate - More disk space needed</p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#disable-pre-allocation-testing","title":"Disable Pre-allocation (Testing)","text":"<pre><code>let config = WalConfig {\n    preallocate: false,  // No pre-allocation\n    ..Default::default()\n};\n</code></pre> <p>Use when: - Testing (faster test execution) - Environments with tight disk quotas - Segment size &gt;&gt; actual usage</p> <p>Trade-offs: - No early error detection for disk full - Potential mid-write failures - More filesystem fragmentation</p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#segment-creation","title":"Segment Creation","text":"Operation With Prealloc Without Prealloc Open file ~100\u03bcs ~100\u03bcs Preallocate 128MB ~1-2ms 0 First write ~50\u03bcs ~50\u03bcs Total ~1.2ms ~0.15ms <p>Amortized cost: Negligible (happens once per 128MB of data)</p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#write-performance","title":"Write Performance","text":"Fsync Policy Throughput Latency (p50) Latency (p99) Always ~420 writes/sec 2.1ms 9.8ms Batch(5ms) ~86K writes/sec 38\u03bcs 5.3ms Os ~110K writes/sec 28\u03bcs 95\u03bcs"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#read-performance","title":"Read Performance","text":"Scenario Throughput Notes Sequential read (cached FD) ~200K records/sec No disk seeks Sequential read (uncached FD) ~180K records/sec Open overhead Random access ~50K records/sec Seek penalty"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#observability","title":"Observability","text":"<p>nori-wal emits events for segment operations:</p> <pre><code>// Segment created\nVizEvent::Wal(WalEvt {\n    kind: WalKind::SegmentCreated,\n    segment_id: 42,\n    ..\n})\n\n// Segment rotated\nVizEvent::Wal(WalEvt {\n    kind: WalKind::SegmentRotated,\n    segment_id: 43,\n    ..\n})\n\n// Segment deleted\nVizEvent::Wal(WalEvt {\n    kind: WalKind::SegmentDeleted,\n    segment_id: 10,\n    ..\n})\n</code></pre> <p>See Observability for how to consume these events.</p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#garbage-collection-metrics","title":"Garbage Collection Metrics","text":"<p>Segment deletion emits observability metrics via <code>nori-observe::Meter</code>:</p> <pre><code>// Histogram: Time to delete segments (milliseconds)\nmeter.histo(\"wal_gc_latency_ms\", &amp;[/* standard buckets */], &amp;[])\n    .observe(elapsed_ms);\n\n// Counter: Total segments deleted\nmeter.counter(\"wal_segments_deleted_total\", &amp;[(\"node\", \"0\")])\n    .inc(1);\n\n// Gauge: Current number of segments\nmeter.gauge(\"wal_segment_count\", &amp;[(\"node\", \"0\")])\n    .set(remaining_segments as i64);\n</code></pre> <p>Metrics usage: - <code>wal_gc_latency_ms</code> - Monitor GC performance, set alerts for high p99 - <code>wal_segments_deleted_total</code> - Track GC activity over time - <code>wal_segment_count</code> - Monitor disk space growth, detect GC failures</p> <p>Expected values: - Latency: 1-3ms for 5 segments, 5-10ms for 20 segments, 15-25ms for 50 segments - Deletion rate depends on memtable flush frequency and WAL age policy - Segment count should stabilize based on write throughput and GC interval</p> <p>See Performance Benchmarks for detailed measurements.</p>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Segments are fixed-size files (default 128 MB)</li> <li>Numbered sequentially, rotated automatically</li> <li> <p>Pre-allocated for early error detection and performance</p> </li> <li> <p>Platform-specific pre-allocation</p> </li> <li>Linux: <code>fallocate()</code> (~0.5ms)</li> <li>macOS: <code>fcntl()</code> with F_PREALLOCATE (~1ms)</li> <li> <p>Windows/others: <code>set_len()</code> fallback</p> </li> <li> <p>Rotation is automatic and seamless</p> </li> <li>Triggered when next write would exceed size limit</li> <li>Old segment finalized (truncated to actual size)</li> <li> <p>New segment created and pre-allocated</p> </li> <li> <p>File descriptor caching</p> </li> <li>LRU cache (default 16 FDs)</li> <li>Cache hit: ~1\u03bcs access</li> <li> <p>Cache miss: ~100\u03bcs (open overhead)</p> </li> <li> <p>Deletion is controlled by the application</p> </li> <li>WAL provides <code>delete_segments_before()</code> API</li> <li>Can be manual (explicit calls) or automated (periodic background task)</li> <li>LSM engines typically automate GC after memtable flush</li> <li>Cannot delete active segment (safety guarantee)</li> </ol>"},{"location":"crates/nori-wal/how-it-works/segment-lifecycle/#whats-next","title":"What's Next?","text":"<p>Now that you understand segments, explore:</p> <ul> <li>Recovery Process - How segments are scanned and validated</li> <li>Concurrency Model - How concurrent access to segments works</li> <li>Record Format - What's inside each segment</li> </ul> <p>Or see real-world usage in Recipes.</p>"},{"location":"crates/nori-wal/internals/","title":"Internals","text":"<p>Deep dives into nori-wal implementation details.</p> <p>This section documents the internal implementation of nori-wal for contributors, maintainers, and anyone curious about how it works under the hood.</p>"},{"location":"crates/nori-wal/internals/#target-audience","title":"Target Audience","text":"<ul> <li>Contributors - Want to add features or fix bugs</li> <li>Maintainers - Need to understand design for code review</li> <li>Advanced Users - Curious about implementation details</li> <li>Library Authors - Building similar systems</li> </ul> <p>If you're just using nori-wal, start with Getting Started and API Reference instead.</p>"},{"location":"crates/nori-wal/internals/#module-structure","title":"Module Structure","text":"<p>nori-wal is organized into focused modules:</p> <pre><code>crates/nori-wal/src/\n\u251c\u2500\u2500 lib.rs           # Public API exports\n\u251c\u2500\u2500 wal.rs           # High-level Wal API\n\u251c\u2500\u2500 segment.rs       # Segment management &amp; fsync\n\u251c\u2500\u2500 record.rs        # Record encoding/decoding\n\u251c\u2500\u2500 recovery.rs      # Recovery logic\n\u2514\u2500\u2500 prealloc.rs      # Platform-specific file preallocation\n</code></pre>"},{"location":"crates/nori-wal/internals/#module-responsibilities","title":"Module Responsibilities","text":"Module Purpose Key Types wal.rs Public API, lifecycle <code>Wal</code>, <code>WalConfig</code> segment.rs File I/O, rotation <code>SegmentManager</code>, <code>SegmentFile</code> record.rs Serialization format <code>Record</code>, <code>Compression</code> recovery.rs Crash recovery <code>RecoveryInfo</code> prealloc.rs File preallocation Platform-specific code"},{"location":"crates/nori-wal/internals/#key-internal-concepts","title":"Key Internal Concepts","text":""},{"location":"crates/nori-wal/internals/#segment-lifecycle","title":"Segment Lifecycle","text":"<p>How segments are created, written to, and closed.</p>"},{"location":"crates/nori-wal/internals/#locking-strategy","title":"Locking Strategy","text":"<p>Where locks are used and how we avoid contention.</p>"},{"location":"crates/nori-wal/internals/#buffer-management","title":"Buffer Management","text":"<p>How we minimize allocations and copies.</p>"},{"location":"crates/nori-wal/internals/#fsync-coordination","title":"Fsync Coordination","text":"<p>How batched fsync works internally.</p>"},{"location":"crates/nori-wal/internals/#error-handling","title":"Error Handling","text":"<p>How errors propagate through the system.</p>"},{"location":"crates/nori-wal/internals/#code-walkthrough","title":"Code Walkthrough","text":""},{"location":"crates/nori-wal/internals/#append-path","title":"Append Path","text":"<p>The critical path for <code>wal.append()</code>:</p> <pre><code>// 1. User calls\nwal.append(&amp;record).await?;\n\n// 2. Wal forwards to SegmentManager\nself.manager.append(&amp;record).await?;\n\n// 3. SegmentManager acquires lock\nlet mut state = self.state.lock().await;\n\n// 4. Check if rotation needed\nif state.current_segment.size &gt;= self.config.max_segment_size {\n    self.rotate_segment(&amp;mut state).await?;\n}\n\n// 5. Encode record\nlet encoded = record.encode();\n\n// 6. Write to segment\nstate.current_segment.write(&amp;encoded).await?;\n\n// 7. Apply fsync policy\nmatch self.config.fsync_policy {\n    FsyncPolicy::Always =&gt; state.current_segment.sync().await?,\n    FsyncPolicy::Batch(window) =&gt; self.maybe_sync_batch(window, &amp;mut state).await?,\n    FsyncPolicy::Os =&gt; { /* no fsync */ }\n}\n\n// 8. Return position\nOk(Position { segment_id, offset })\n</code></pre>"},{"location":"crates/nori-wal/internals/#recovery-path","title":"Recovery Path","text":"<p>How recovery works on startup:</p> <pre><code>// 1. Wal::open() calls recovery::recover()\nlet recovery_info = recovery::recover(&amp;config.dir).await?;\n\n// 2. Find all segment files\nlet segments = find_segments(&amp;dir)?;\n\n// 3. For each segment\nfor segment_id in segments {\n    // 4. Read entire segment into memory\n    let data = read_segment(segment_id)?;\n\n    // 5. Scan for valid records\n    let mut offset = 0;\n    while offset &lt; data.len() {\n        match Record::decode(&amp;data[offset..]) {\n            Ok((record, size)) =&gt; {\n                valid_records += 1;\n                offset += size;\n            }\n            Err(_) =&gt; {\n                // 6. Found corruption, truncate here\n                truncate_segment(segment_id, offset)?;\n                break;\n            }\n        }\n    }\n}\n\n// 7. Return recovery info\nOk(RecoveryInfo { valid_records, ... })\n</code></pre>"},{"location":"crates/nori-wal/internals/#performance-considerations","title":"Performance Considerations","text":""},{"location":"crates/nori-wal/internals/#hot-path-optimizations","title":"Hot Path Optimizations","text":"<p>1. Lock-free reads</p> <p>Old segments are immutable:</p> <pre><code>// Readers don't need locks for closed segments\npub async fn read_from(&amp;self, pos: Position) -&gt; Result&lt;SegmentReader&gt; {\n    if pos.segment_id &lt; self.current_segment_id() {\n        // Closed segment - no lock needed\n        let file = File::open(segment_path(pos.segment_id)).await?;\n        return Ok(SegmentReader::new(file, pos.offset));\n    }\n\n    // Active segment - need to coordinate\n    let state = self.state.lock().await;\n    // ...\n}\n</code></pre> <p>2. Minimal allocations</p> <pre><code>// Reuse buffers\nstruct SegmentManager {\n    write_buffer: Mutex&lt;Vec&lt;u8&gt;&gt;,  // Reused across writes\n}\n\n// Encode into pre-allocated buffer\npub fn encode_into(&amp;self, buf: &amp;mut Vec&lt;u8&gt;) {\n    buf.clear();\n    // Write directly to buf\n}\n</code></pre> <p>3. Batch fsync</p> <pre><code>// Multiple appends between fsyncs\nwal.append(&amp;r1).await?;  // Buffered\nwal.append(&amp;r2).await?;  // Buffered\n// 5ms passes...\n// Automatic fsync for both records\n</code></pre>"},{"location":"crates/nori-wal/internals/#cold-path-acceptable-cost","title":"Cold Path Acceptable Cost","text":"<p>Recovery and rotation can be slower:</p> <pre><code>// Recovery: Read entire segments into memory\n// - Happens once at startup\n// - Acceptable to be slow (&lt; 1 second even for GB of data)\n\n// Rotation: Create and preallocate new segment\n// - Happens every 30-60 seconds\n// - Acceptable to take 10-50ms\n</code></pre>"},{"location":"crates/nori-wal/internals/#testing-strategy","title":"Testing Strategy","text":""},{"location":"crates/nori-wal/internals/#unit-tests","title":"Unit Tests","text":"<p>Each module has its own tests:</p> <pre><code>// record.rs\n#[cfg(test)]\nmod tests {\n    #[test]\n    fn test_encode_decode() { /* ... */ }\n}\n\n// segment.rs\n#[cfg(test)]\nmod tests {\n    #[tokio::test]\n    async fn test_rotation() { /* ... */ }\n}\n</code></pre>"},{"location":"crates/nori-wal/internals/#integration-tests","title":"Integration Tests","text":"<p>End-to-end scenarios:</p> <pre><code>// tests/integration_tests.rs\n#[tokio::test]\nasync fn test_full_recovery_scenario() {\n    // Write data\n    // Crash (drop without sync)\n    // Reopen\n    // Verify recovery\n}\n</code></pre>"},{"location":"crates/nori-wal/internals/#property-tests","title":"Property Tests","text":"<p>Use <code>proptest</code> for randomized testing:</p> <pre><code>proptest! {\n    #[test]\n    fn prop_record_roundtrip(\n        key in vec(any::&lt;u8&gt;(), 0..1024),\n        value in vec(any::&lt;u8&gt;(), 0..1024),\n    ) {\n        let record = Record::put(key, value);\n        let encoded = record.encode();\n        let (decoded, _) = Record::decode(&amp;encoded)?;\n        assert_eq!(record, decoded);\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/internals/#contributing-guidelines","title":"Contributing Guidelines","text":"<p>When modifying internals:</p> <p>1. Maintain invariants</p> <pre><code>// INVARIANT: current_segment.size &lt;= max_segment_size\n// Check this invariant in every method that modifies size\n</code></pre> <p>2. Document unsafe code</p> <pre><code>// SAFETY: Buffer is guaranteed to be valid UTF-8 because...\nlet s = unsafe { std::str::from_utf8_unchecked(buf) };\n</code></pre> <p>3. Add tests for edge cases</p> <pre><code>#[test]\nfn test_rotation_at_exact_boundary() {\n    // What happens when size == max_segment_size?\n}\n</code></pre> <p>4. Benchmark performance changes</p> <pre><code>// Run benchmarks before/after\ncargo bench --bench wal_bench\n</code></pre>"},{"location":"crates/nori-wal/internals/#further-reading","title":"Further Reading","text":"<p>Each subsection goes deep on a specific internal component:</p> <ul> <li>Wal Module - High-level API implementation</li> <li>Segment Module - File management and I/O</li> <li>Record Module - Serialization format</li> <li>Recovery Module - Crash recovery logic</li> <li>Preallocation - Platform-specific optimizations</li> </ul> <p>These documents assume familiarity with Rust and systems programming.</p>"},{"location":"crates/nori-wal/internals/segment-lifecycle/","title":"Segment Lifecycle","text":"<p>How segments are created, written to, and closed.</p>"},{"location":"crates/nori-wal/internals/segment-lifecycle/#table-of-contents","title":"Table of contents","text":""},{"location":"crates/nori-wal/internals/segment-lifecycle/#overview","title":"Overview","text":"<p>A segment goes through several states during its lifecycle:</p> <pre><code>[Creating] \u2192 [Active] \u2192 [Closing] \u2192 [Closed] \u2192 [Deleted]\n</code></pre> <p>Each state has specific guarantees and allowed operations.</p>"},{"location":"crates/nori-wal/internals/segment-lifecycle/#segment-states","title":"Segment States","text":""},{"location":"crates/nori-wal/internals/segment-lifecycle/#creating","title":"Creating","text":"<p>When: New segment is being initialized.</p> <p>Operations: - Create file on disk - Pre-allocate space (if enabled) - Initialize metadata</p> <p>Code:</p> <pre><code>async fn create_segment(id: u64, config: &amp;SegmentConfig) -&gt; Result&lt;SegmentFile&gt; {\n    let path = segment_path(&amp;config.dir, id);\n\n    // Create file\n    let mut file = OpenOptions::new()\n        .create(true)\n        .write(true)\n        .read(true)\n        .open(&amp;path)\n        .await?;\n\n    // Pre-allocate if configured\n    if config.preallocate {\n        preallocate(&amp;file, config.max_segment_size).await?;\n        file.sync_all().await?;  // Ensure allocation is durable\n    }\n\n    Ok(SegmentFile {\n        id,\n        file,\n        size: 0,  // No data written yet\n        path,\n    })\n}\n</code></pre> <p>Guarantees: - File exists on disk after creation - If pre-allocation enabled, space is reserved - File handle is open for writing</p> <p>Failure Modes: - Disk full (caught during pre-allocation) - Permission denied - Too many open files</p>"},{"location":"crates/nori-wal/internals/segment-lifecycle/#active","title":"Active","text":"<p>When: Segment is currently being written to.</p> <p>Operations: - Append records - Fsync (based on policy) - Query current size</p> <p>Code:</p> <pre><code>impl SegmentFile {\n    async fn write(&amp;mut self, data: &amp;[u8]) -&gt; Result&lt;()&gt; {\n        self.file.write_all(data).await?;\n        self.size += data.len() as u64;\n        Ok(())\n    }\n\n    async fn sync(&amp;mut self) -&gt; Result&lt;()&gt; {\n        self.file.sync_all().await\n    }\n\n    fn current_size(&amp;self) -&gt; u64 {\n        self.size\n    }\n}\n</code></pre> <p>Invariants: - <code>size &lt;= max_segment_size</code> (always checked before write) - File handle is open - Data may be buffered (not yet on disk until fsync)</p> <p>Thread Safety: - Only one active segment at a time - Protected by <code>Mutex&lt;State&gt;</code> in <code>SegmentManager</code> - Appends are serialized</p>"},{"location":"crates/nori-wal/internals/segment-lifecycle/#closing","title":"Closing","text":"<p>When: Segment has reached max size or is being closed gracefully.</p> <p>Operations: - Finalize writes - Fsync remaining data - Truncate to actual size (if pre-allocated) - Update metadata</p> <p>Code:</p> <pre><code>async fn close_segment(segment: &amp;mut SegmentFile, preallocated: bool) -&gt; Result&lt;()&gt; {\n    // Ensure all data is written\n    segment.sync().await?;\n\n    // If we pre-allocated, truncate to actual size\n    if preallocated {\n        segment.file.set_len(segment.size).await?;\n        segment.file.sync_all().await?;\n    }\n\n    // Emit event\n    emit_event(WalEvt::SegmentRoll {\n        bytes: segment.size,\n    });\n\n    Ok(())\n}\n</code></pre> <p>Why truncate?</p> <p>Pre-allocation reserves space:</p> <pre><code>Created:  [reserved 128 MB]\nWritten:  [data: 75 MB][unused: 53 MB]\nTruncate: [data: 75 MB]  \u2190 Reclaim 53 MB\n</code></pre> <p>Guarantees: - All buffered data is on disk - File size matches actual data - Segment is immutable after closing</p>"},{"location":"crates/nori-wal/internals/segment-lifecycle/#closed","title":"Closed","text":"<p>When: Segment is complete and no longer being written to.</p> <p>Operations: - Read from anywhere in segment - No writes allowed - Can be safely copied/backed up</p> <p>Code:</p> <pre><code>// Reading from closed segment (no lock needed)\nasync fn read_closed_segment(id: u64) -&gt; Result&lt;SegmentReader&gt; {\n    let path = segment_path(id);\n\n    let file = File::open(path).await?;\n\n    Ok(SegmentReader {\n        file,\n        buffer: vec![0u8; 64 * 1024],  // 64KB read buffer\n    })\n}\n</code></pre> <p>Guarantees: - Data is immutable - Multiple readers can access simultaneously - File may be deleted by garbage collection</p>"},{"location":"crates/nori-wal/internals/segment-lifecycle/#deleted","title":"Deleted","text":"<p>When: Segment is no longer needed (garbage collected).</p> <p>Operations: - Remove file from disk - Free resources</p> <p>Code:</p> <pre><code>async fn delete_segment(id: u64, dir: &amp;Path) -&gt; Result&lt;()&gt; {\n    let path = segment_path(dir, id);\n\n    // Remove file\n    tokio::fs::remove_file(&amp;path).await?;\n\n    // Emit event\n    emit_event(WalEvt::SegmentDeleted { segment_id: id });\n\n    Ok(())\n}\n</code></pre> <p>Safety: - Only delete segments before checkpoint - Ensure no readers are accessing segment - Handle \"file not found\" (idempotent delete)</p>"},{"location":"crates/nori-wal/internals/segment-lifecycle/#rotation-process","title":"Rotation Process","text":"<p>Rotation happens when active segment reaches max size:</p> <pre><code>async fn check_and_rotate(&amp;mut self) -&gt; Result&lt;()&gt; {\n    let mut state = self.state.lock().await;\n\n    if state.current_segment.size &gt;= self.config.max_segment_size {\n        self.rotate_segment_locked(&amp;mut state).await?;\n    }\n\n    Ok(())\n}\n\nasync fn rotate_segment_locked(&amp;mut self, state: &amp;mut State) -&gt; Result&lt;()&gt; {\n    let old_segment = &amp;mut state.current_segment;\n\n    // 1. Close current segment\n    old_segment.sync().await?;\n\n    if self.config.preallocate {\n        old_segment.file.set_len(old_segment.size).await?;\n    }\n\n    // 2. Create new segment\n    let new_id = old_segment.id + 1;\n    let new_segment = create_segment(new_id, &amp;self.config).await?;\n\n    // 3. Swap segments\n    state.current_segment = new_segment;\n\n    // 4. Emit event\n    self.meter.emit(VizEvent::Wal(WalEvt::SegmentRoll {\n        bytes: old_segment.size,\n    }));\n\n    Ok(())\n}\n</code></pre> <p>Timing:</p> <pre><code>Before rotation:\n  Segment 5: [====================] 128 MB (full)\n\nDuring rotation (10-50ms):\n  Segment 5: Closing...\n  Segment 6: Creating...\n\nAfter rotation:\n  Segment 5: [====================] 128 MB (closed)\n  Segment 6: [                    ] 0 MB (active)\n</code></pre> <p>What happens to in-flight writes during rotation?</p> <p>They wait for the lock:</p> <pre><code>// Writer 1: Triggers rotation\nwal.append(&amp;record1).await?;  // Acquires lock, sees size &gt; max, rotates\n\n// Writer 2: Waits during rotation\nwal.append(&amp;record2).await?;  // Waits for lock, then writes to new segment\n</code></pre>"},{"location":"crates/nori-wal/internals/segment-lifecycle/#file-naming-convention","title":"File Naming Convention","text":"<p>Segments are named with zero-padded IDs:</p> <pre><code>fn segment_path(dir: &amp;Path, id: u64) -&gt; PathBuf {\n    dir.join(format!(\"{:06}.wal\", id))\n}\n</code></pre> <p>Examples:</p> <pre><code>000000.wal  \u2190 First segment\n000001.wal\n000002.wal\n...\n000999.wal\n001000.wal\n</code></pre> <p>Why 6 digits?</p> <ul> <li>Supports up to 1 million segments</li> <li>Lexicographic ordering matches numeric ordering</li> <li>Easy to glob: <code>*.wal</code></li> </ul> <p>Why .wal extension?</p> <ul> <li>Distinguishes from other files in directory</li> <li>Standard for write-ahead logs</li> <li>Helps monitoring tools identify log files</li> </ul>"},{"location":"crates/nori-wal/internals/segment-lifecycle/#recovery-impact","title":"Recovery Impact","text":"<p>Segments make recovery efficient:</p> <pre><code>async fn recover(dir: &amp;Path) -&gt; Result&lt;RecoveryInfo&gt; {\n    let segments = find_all_segments(dir).await?;\n\n    let mut info = RecoveryInfo::default();\n\n    for segment_id in segments {\n        // Only validate last segment for corruption\n        if segment_id == segments.last() {\n            info += validate_segment(segment_id).await?;\n        } else {\n            // Earlier segments were validated when closed\n            info += count_records(segment_id).await?;\n        }\n    }\n\n    Ok(info)\n}\n</code></pre> <p>Optimization:</p> <p>Closed segments were already validated, so only scan for record count (fast). Only the last (active) segment needs full CRC validation.</p>"},{"location":"crates/nori-wal/internals/segment-lifecycle/#state-machine-diagram","title":"State Machine Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Creating \u2502\n\u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502 create_segment()\n     \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Active  \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518                \u2502\n     \u2502                      \u2502 size &gt;= max\n     \u2502 append()             \u2502\n     \u2502 sync()               \u2502\n     \u2193                      \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Active  \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192 \u2502 Closing  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  rotate  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502 close_segment()\n                           \u2193\n                      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                      \u2502  Closed  \u2502\n                      \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502 delete_segments_before()\n                           \u2193\n                      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                      \u2502 Deleted  \u2502\n                      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"crates/nori-wal/internals/segment-lifecycle/#observability","title":"Observability","text":"<p>Segments emit events at lifecycle transitions:</p> <pre><code>// Rotation\nemit(WalEvt::SegmentRoll {\n    segment_id: new_id,\n    bytes: old_size,\n});\n\n// Deletion\nemit(WalEvt::SegmentDeleted {\n    segment_id: id,\n});\n</code></pre> <p>Monitoring:</p> <pre><code>// Track active segment\nmetrics.gauge(\"wal.active_segment_id\", current_id);\nmetrics.gauge(\"wal.active_segment_bytes\", current_size);\n\n// Track rotations\nmetrics.counter(\"wal.segments_rotated\", 1);\n\n// Track deletions\nmetrics.counter(\"wal.segments_deleted\", count);\n</code></pre> <p>Alerting:</p> <ul> <li>Too many segments \u2192 Need garbage collection</li> <li>No rotations for long time \u2192 Workload might be too light</li> <li>Frequent rotations \u2192 Might need larger segments</li> </ul>"},{"location":"crates/nori-wal/internals/segment-lifecycle/#edge-cases","title":"Edge Cases","text":""},{"location":"crates/nori-wal/internals/segment-lifecycle/#rotation-during-recovery","title":"Rotation During Recovery","text":"<p>If recovery finds active segment is full:</p> <pre><code>if last_segment.size &gt;= config.max_segment_size {\n    // Start new segment immediately\n    rotate_before_any_writes();\n}\n</code></pre>"},{"location":"crates/nori-wal/internals/segment-lifecycle/#empty-segments","title":"Empty Segments","text":"<p>Possible if rotation happens with no writes:</p> <pre><code>Segment 5: [data: 128 MB]\nRotate \u2192 Segment 6: [data: 0 MB]\nNo writes...\nShutdown\n\n// On recovery:\n// Segment 6 exists but is empty (size = 0)\n// This is valid - just delete it\n</code></pre>"},{"location":"crates/nori-wal/internals/segment-lifecycle/#pre-allocation-failure","title":"Pre-allocation Failure","text":"<p>If pre-allocation fails (disk full):</p> <pre><code>match create_segment(id, config).await {\n    Err(SegmentError::Io(e)) if e.kind() == ErrorKind::NoSpaceLeft =&gt; {\n        // Can't create new segment!\n        // Options:\n        // 1. Trigger emergency GC\n        // 2. Fail writes until space available\n        // 3. Alert operators\n        return Err(SegmentError::Io(e));\n    }\n    other =&gt; other,\n}\n</code></pre>"},{"location":"crates/nori-wal/internals/segment-lifecycle/#concurrent-readers-during-rotation","title":"Concurrent Readers During Rotation","text":"<p>Readers of old segments are unaffected:</p> <pre><code>// Reader is reading segment 3\nlet mut reader = wal.read_from(Position { segment_id: 3, offset: 0 });\n\n// Writer rotates from segment 5 to 6\nwal.append(&amp;record);  // Triggers rotation\n\n// Reader continues unaffected\nwhile let Some(record) = reader.next().await? {\n    // Still reading from segment 3\n}\n</code></pre> <p>Only readers of the active segment need to coordinate with writers.</p>"},{"location":"crates/nori-wal/internals/segment-lifecycle/#testing","title":"Testing","text":"<p>Lifecycle tests:</p> <pre><code>#[tokio::test]\nasync fn test_segment_rotation() {\n    let config = WalConfig {\n        max_segment_size: 1024,  // Small for testing\n        ..Default::default()\n    };\n\n    let (wal, _) = Wal::open(config).await?;\n\n    // Write enough to trigger rotation\n    for _ in 0..100 {\n        wal.append(&amp;Record::put(b\"k\", &amp;[0u8; 100])).await?;\n    }\n\n    // Check that segments were created\n    let segments = list_segments(&amp;wal.config().dir)?;\n    assert!(segments.len() &gt; 1);\n}\n</code></pre> <p>Edge case tests:</p> <pre><code>#[tokio::test]\nasync fn test_rotation_at_exact_boundary() {\n    // Write exactly max_segment_size bytes\n    // Verify rotation happens correctly\n}\n\n#[tokio::test]\nasync fn test_empty_segment_on_shutdown() {\n    // Rotate\n    // Shutdown immediately (no writes to new segment)\n    // Verify recovery handles empty segment\n}\n</code></pre>"},{"location":"crates/nori-wal/internals/segment-lifecycle/#conclusion","title":"Conclusion","text":"<p>Segment lifecycle management is critical to nori-wal's design. Key points:</p> <ul> <li>States: Creating \u2192 Active \u2192 Closing \u2192 Closed \u2192 Deleted</li> <li>Rotation: Happens at size threshold</li> <li>Immutability: Closed segments never change</li> <li>Recovery: Only validate last segment</li> <li>Observability: Events at each transition</li> </ul> <p>Understanding this lifecycle is essential for contributing to segment-related code.</p>"},{"location":"crates/nori-wal/performance/","title":"Performance","text":"<p>Benchmarks, optimization guides, and performance tuning for nori-wal.</p> <p>This section helps you understand nori-wal's performance characteristics and optimize for your workload.</p>"},{"location":"crates/nori-wal/performance/#quick-reference","title":"Quick Reference","text":"<p>Typical Performance (Apple M2 Pro, NVMe SSD):</p> Operation Throughput Latency p99 Sequential writes (OS fsync) 110K writes/sec 15\u00b5s Sequential writes (Batch 5ms) 86K writes/sec 5.5ms Batch append (1000 records) 102 MiB/s 9.5ms Sequential reads 52 MiB/s N/A Recovery (10 MB) 3.3 GiB/s 3ms"},{"location":"crates/nori-wal/performance/#sections","title":"Sections","text":""},{"location":"crates/nori-wal/performance/#benchmarks","title":"Benchmarks","text":"<p>Complete benchmark results with methodology and hardware details.</p>"},{"location":"crates/nori-wal/performance/#tuning-guide","title":"Tuning Guide","text":"<p>How to optimize nori-wal for your specific workload.</p>"},{"location":"crates/nori-wal/performance/#hardware-recommendations","title":"Hardware Recommendations","text":"<p>What hardware to use for different performance targets.</p>"},{"location":"crates/nori-wal/performance/#profiling","title":"Profiling","text":"<p>How to measure and analyze performance in your application.</p>"},{"location":"crates/nori-wal/performance/#performance-philosophy","title":"Performance Philosophy","text":"<p>nori-wal is designed with these priorities:</p> <p>1. Correctness First - Never sacrifice durability for speed - Performance within correctness constraints</p> <p>2. Optimize Hot Paths - Append and sync are heavily optimized - Recovery and startup can be slower</p> <p>3. Predictable Performance - No hidden allocation spikes - Configurable trade-offs - No \"magic\" heuristics</p> <p>4. Real-World Workloads - Optimized for typical database/queue patterns - Not micro-benchmark optimized</p>"},{"location":"crates/nori-wal/performance/#when-to-care-about-performance","title":"When to Care About Performance","text":"<p>You should optimize if: - Writing &gt;10K records/sec - Have strict latency requirements (&lt;10ms p99) - Limited disk I/O budget - Need maximum throughput</p> <p>You probably don't need to optimize if: - Writing &lt;1K records/sec - Latency requirements &gt;100ms - Have spare I/O capacity - Durability is more important than speed</p>"},{"location":"crates/nori-wal/performance/#common-performance-questions","title":"Common Performance Questions","text":""},{"location":"crates/nori-wal/performance/#why-is-my-throughput-low","title":"\"Why is my throughput low?\"","text":"<p>Check these first:</p> <ol> <li>Fsync policy - <code>FsyncPolicy::Always</code> is slow by design</li> <li>Batch size - Are you batching writes?</li> <li>Segment size - Too small segments cause frequent rotation</li> <li>Disk - Is your disk actually fast? (check <code>iostat</code>)</li> </ol> <p>See Troubleshooting Performance for details.</p>"},{"location":"crates/nori-wal/performance/#why-does-latency-spike","title":"\"Why does latency spike?\"","text":"<p>Common causes:</p> <ol> <li>Fsync batch window - Batch(5ms) means p99 \u2248 5ms</li> <li>Segment rotation - 10-50ms every 30-60 seconds</li> <li>OS page cache flush - Background disk sync</li> <li>CPU steal - Virtualized environments</li> </ol> <p>See Profiling for how to diagnose.</p>"},{"location":"crates/nori-wal/performance/#can-i-make-it-faster","title":"\"Can I make it faster?\"","text":"<p>Options:</p> <ol> <li>Use batching - Amortize fsync cost across multiple writes</li> <li>Increase segment size - Reduce rotation overhead</li> <li>Use compression - Reduce I/O volume</li> <li>Use faster storage - NVMe &gt;&gt; SATA &gt;&gt; HDD</li> <li>Tune fsync policy - Trade durability for speed</li> </ol> <p>See Tuning Guide for strategies.</p>"},{"location":"crates/nori-wal/performance/#benchmark-methodology","title":"Benchmark Methodology","text":"<p>All benchmarks follow these principles:</p> <p>1. Realistic Workloads - Mix of record sizes - Typical access patterns - Include cold starts</p> <p>2. Reproducible - Fixed hardware configuration - Documented OS settings - Repeatable steps</p> <p>3. Transparent - Show source code - Explain methodology - Include variance</p> <p>4. Fair Comparisons - Apples-to-apples configurations - Same durability guarantees - Realistic scenarios</p>"},{"location":"crates/nori-wal/performance/#hardware-used","title":"Hardware Used","text":"<p>Unless otherwise noted, benchmarks use:</p> <pre><code>CPU: Apple M2 Pro (10 cores, 3.5 GHz)\nRAM: 16 GB\nDisk: 1 TB NVMe SSD\nOS: macOS 14.0\nFilesystem: APFS\n</code></pre> <p>Your results will vary based on hardware.</p>"},{"location":"crates/nori-wal/performance/#further-reading","title":"Further Reading","text":"<ul> <li>Benchmarks - Detailed performance measurements</li> <li>Tuning Guide - Optimization strategies</li> <li>Hardware - Hardware selection guide</li> <li>Profiling - Measurement and analysis</li> </ul>"},{"location":"crates/nori-wal/performance/benchmarks/","title":"Benchmarks","text":"<p>Detailed performance measurements for nori-wal.</p>"},{"location":"crates/nori-wal/performance/benchmarks/#table-of-contents","title":"Table of contents","text":""},{"location":"crates/nori-wal/performance/benchmarks/#test-environment","title":"Test Environment","text":"<p>All benchmarks were run on:</p> <pre><code>Hardware:\n  CPU: Apple M2 Pro (10 cores, 8 performance + 2 efficiency, 3.5 GHz)\n  RAM: 16 GB LPDDR5\n  Disk: 1 TB NVMe SSD (Apple integrated)\n\nSoftware:\n  OS: macOS 14.0 (Sonoma)\n  Filesystem: APFS\n  Rust: 1.75.0\n  Tokio: 1.35.0\n\nBenchmark Tool:\n  Criterion.rs with default settings\n  3 warmup iterations\n  100 measurement iterations\n</code></pre> <p>Note: Your results will vary based on hardware, especially disk type.</p>"},{"location":"crates/nori-wal/performance/benchmarks/#write-performance","title":"Write Performance","text":""},{"location":"crates/nori-wal/performance/benchmarks/#single-threaded-sequential-writes","title":"Single-Threaded Sequential Writes","text":"<p>Measures how fast individual <code>append()</code> calls are.</p> <p>Configuration: - Record: 1 KB key + value - No batching (one append at a time) - Various fsync policies</p> <p>Results:</p> Fsync Policy Throughput Latency p50 Latency p99 Notes <code>Os</code> 110K writes/sec 9.1\u00b5s 15\u00b5s Best performance, no durability guarantee <code>Batch(5ms)</code> 86K writes/sec 11.6\u00b5s 5.5ms Good balance <code>Batch(1ms)</code> 55K writes/sec 18.2\u00b5s 1.2ms Conservative <code>Always</code> 420 writes/sec 2.4ms 3.1ms Maximum durability <p>Analysis:</p> <pre><code>Os vs Always: 262x faster\nBatch(5ms) vs Always: 205x faster\nOs vs Batch(5ms): 1.3x faster\n</code></pre> <p>The batched fsync policies provide excellent performance while maintaining strong durability guarantees.</p> <p>Throughput by Record Size:</p> Record Size OS Fsync Batch(5ms) Always 100 bytes 119K/sec (11 MiB/s) 101K/sec (9 MiB/s) 755/sec (74 KiB/s) 1 KB 110K/sec (108 MiB/s) 86K/sec (84 MiB/s) 420/sec (410 KiB/s) 10 KB 69K/sec (673 MiB/s) 44K/sec (430 MiB/s) 323/sec (3.2 MiB/s) <p>Larger records achieve higher throughput (bytes/sec) but lower write rate (records/sec).</p>"},{"location":"crates/nori-wal/performance/benchmarks/#batched-writes","title":"Batched Writes","text":"<p>Measures throughput when batching multiple appends before syncing.</p> <p>Configuration: - Batch size: N records - Record size: 1 KB - Fsync after each batch</p> <p>Results:</p> Batch Size Throughput Total Time Avg Latency/Record 10 2.8 MiB/s 3.5ms 350\u00b5s 100 22.5 MiB/s 4.3ms 43\u00b5s 1,000 102 MiB/s 9.5ms 9.5\u00b5s 10,000 198 MiB/s 49ms 4.9\u00b5s <p>Analysis:</p> <p>Batching dramatically improves throughput by amortizing fsync cost across many records. The sweet spot is 100-1000 records per batch.</p> <p>Code Example:</p> <pre><code>// Slow: Sync after each record\nfor record in records {\n    wal.append(&amp;record).await?;\n    wal.sync().await?;  // 2-3ms each!\n}\n\n// Fast: Batch sync\nfor record in records {\n    wal.append(&amp;record).await?;\n}\nwal.sync().await?;  // Single 2-3ms for all\n</code></pre>"},{"location":"crates/nori-wal/performance/benchmarks/#concurrent-writes","title":"Concurrent Writes","text":"<p>Multiple async tasks writing concurrently.</p> <p>Configuration: - Concurrent tasks: 1, 2, 4, 8 - Each task: 100 writes of 1 KB records - Fsync policy: Os</p> <p>Results:</p> Threads Throughput Total Time Scaling 1 19.2 MiB/s 5.1ms 1.0x 2 19.8 MiB/s 9.9ms 1.0x 4 14.7 MiB/s 26.7ms 0.7x 8 17.5 MiB/s 44.6ms 0.9x <p>Analysis:</p> <p>Concurrency doesn't improve throughput much because writes are serialized by a mutex. For high-concurrency workloads, use batching instead.</p>"},{"location":"crates/nori-wal/performance/benchmarks/#read-performance","title":"Read Performance","text":""},{"location":"crates/nori-wal/performance/benchmarks/#sequential-scan","title":"Sequential Scan","text":"<p>Reading all records from beginning to end.</p> <p>Configuration: - Pre-written WAL with N records - Record size: 1 KB - Scan from start to end</p> <p>Results:</p> Record Count Total Size Time Throughput 100 100 KB 1.9ms 52 MiB/s 1,000 1 MB 18.6ms 52 MiB/s 10,000 10 MB 182ms 54 MiB/s <p>Analysis:</p> <p>Read throughput is consistent at ~52 MiB/s regardless of record count. Bottleneck is decode + CRC validation, not I/O (NVMe can do &gt;3 GB/s).</p> <p>Optimization opportunity: Batch CRC validation or use SIMD.</p>"},{"location":"crates/nori-wal/performance/benchmarks/#random-reads","title":"Random Reads","text":"<p>WAL doesn't support random reads efficiently. You must scan from a position:</p> <pre><code>// To read record at position 1000:\n// 1. Scan from beginning (or last checkpoint)\n// 2. Skip first 999 records\n// 3. Read record 1000\n\n// This is O(n), not O(1)\n</code></pre> <p>For random access, build an index on top of WAL (see Key-Value Store recipe).</p>"},{"location":"crates/nori-wal/performance/benchmarks/#recovery-performance","title":"Recovery Performance","text":""},{"location":"crates/nori-wal/performance/benchmarks/#cold-start-recovery","title":"Cold Start Recovery","text":"<p>Time to recover and validate WAL on startup.</p> <p>Configuration: - WAL with N records pre-written - Record size: 1 KB - Includes full CRC validation</p> <p>Results:</p> Record Count WAL Size Recovery Time Throughput 1,000 1 MB 458\u00b5s 2.1 GiB/s 10,000 10 MB 2.9ms 3.3 GiB/s 50,000 50 MB 14.6ms 3.3 GiB/s 100,000 100 MB 30ms 3.2 GiB/s <p>Analysis:</p> <p>Recovery is very fast (~3.3 GiB/s) because: 1. Sequential read from disk (fast on NVMe) 2. Efficient CRC validation (hardware accelerated) 3. Simple format (varint + bytes)</p> <p>A 1 GB WAL recovers in ~300ms.</p>"},{"location":"crates/nori-wal/performance/benchmarks/#multi-segment-recovery","title":"Multi-Segment Recovery","text":"<p>Recovery with multiple segments.</p> <p>Configuration: - 5 segments of 1 MB each - Total: 5,000 records - Fsync policy: Batch(5ms)</p> <p>Results:</p> Segments Total Size Recovery Time Notes 2 2 MB 1.3ms 3.6 GiB/s 5 5 MB 1.5ms 3.2 GiB/s 10 10 MB 2.8ms 3.4 GiB/s <p>Analysis:</p> <p>Multiple segments don't significantly slow recovery. Slight overhead from opening multiple files is minimal.</p>"},{"location":"crates/nori-wal/performance/benchmarks/#compression-performance","title":"Compression Performance","text":""},{"location":"crates/nori-wal/performance/benchmarks/#lz4-compression","title":"LZ4 Compression","text":"<p>Configuration: - Record: 1 KB of compressible data (repeated text) - Compression: LZ4</p> <p>Results:</p> Operation Uncompressed LZ4 Compressed Overhead Encode 100ns 2.1\u00b5s 21x slower Decode 100ns 1.3\u00b5s 13x slower Size 1024 bytes 89 bytes 11.5x smaller <p>Throughput Impact:</p> Fsync Policy Uncompressed LZ4 Slowdown Os 110K writes/sec 95K writes/sec 1.16x Batch(5ms) 86K writes/sec 78K writes/sec 1.10x <p>Analysis:</p> <p>LZ4 adds ~2\u00b5s per write but can save 10x+ storage for compressible data. Good trade-off for text, JSON, or repetitive data.</p>"},{"location":"crates/nori-wal/performance/benchmarks/#zstd-compression","title":"Zstd Compression","text":"<p>Configuration: - Same as LZ4 test - Compression: Zstd (level 3)</p> <p>Results:</p> Operation Uncompressed Zstd Overhead Encode 100ns 8.5\u00b5s 85x slower Decode 100ns 3.2\u00b5s 32x slower Size 1024 bytes 62 bytes 16.5x smaller <p>Throughput Impact:</p> Fsync Policy Uncompressed Zstd Slowdown Os 110K writes/sec 72K writes/sec 1.53x Batch(5ms) 86K writes/sec 61K writes/sec 1.41x <p>Analysis:</p> <p>Zstd provides better compression than LZ4 but is slower. Best for cold storage or when storage is expensive.</p>"},{"location":"crates/nori-wal/performance/benchmarks/#fsync-latency","title":"Fsync Latency","text":"<p>Direct measurement of fsync() system call.</p> <p>Configuration: - 128 MB file - macOS APFS - Varying amounts of dirty data</p> <p>Results:</p> Dirty Data Fsync Time 0 KB (clean) 12\u00b5s 4 KB 245\u00b5s 64 KB 1.2ms 1 MB 2.1ms 10 MB 8.7ms <p>Analysis:</p> <p>Fsync time is proportional to amount of dirty data. This is why batching helps - amortize the 2-8ms fsync across many writes.</p>"},{"location":"crates/nori-wal/performance/benchmarks/#segment-rotation-overhead","title":"Segment Rotation Overhead","text":"<p>Time to rotate to a new segment.</p> <p>Configuration: - Segment size: 128 MB - Pre-allocation: enabled - Fsync before rotation: yes</p> <p>Results:</p> Operation Time Close old segment 2.1ms Truncate to actual size 180\u00b5s Create new segment file 85\u00b5s Pre-allocate 128 MB 12ms Total rotation time ~15ms <p>Analysis:</p> <p>Rotation takes ~15ms every 30-60 seconds (depending on write rate). This is acceptable overhead. Most time is spent in pre-allocation.</p> <p>Without pre-allocation:</p> Operation Time Close old segment 2.1ms Create new segment 85\u00b5s Total ~2.2ms <p>Disabling pre-allocation makes rotation 7x faster but loses early disk-full detection.</p>"},{"location":"crates/nori-wal/performance/benchmarks/#comparison-with-other-wals","title":"Comparison with Other WALs","text":"<p>Methodology: Same hardware, same durability guarantees (Always fsync).</p> System Throughput Latency p99 Notes nori-wal 420 writes/sec 3.1ms This benchmark SQLite WAL 380 writes/sec 3.4ms Same fsync policy RocksDB WAL 450 writes/sec 2.9ms Slightly faster Raw fsync 400 writes/sec 2.5ms Theoretical max <p>Analysis:</p> <p>nori-wal is within 10% of theoretical maximum and competitive with mature systems.</p> <p>With batching (Batch 5ms):</p> System Throughput Latency p99 nori-wal 86K writes/sec 5.5ms RocksDB WAL 91K writes/sec 5.3ms <p>Performance is similar across well-designed WAL implementations.</p>"},{"location":"crates/nori-wal/performance/benchmarks/#performance-summary","title":"Performance Summary","text":"<p>Best Performance: - Use <code>FsyncPolicy::Batch(5ms)</code> for good balance - Batch writes before syncing - Use LZ4 compression for text/JSON - NVMe SSD for storage</p> <p>Expect: - 86K writes/sec with 5ms durability guarantee - 102 MiB/s with 1000-record batches - 52 MiB/s sequential read - &lt;100ms recovery for multi-GB WALs</p> <p>Limits: - Always fsync: ~400 writes/sec (disk bound) - Concurrent writes: Limited by single writer lock - Random reads: Not supported (by design)</p> <p>See Tuning Guide for optimization strategies.</p>"},{"location":"crates/nori-wal/performance/hardware/","title":"Hardware Recommendations","text":"<p>What hardware to use for different performance targets.</p>"},{"location":"crates/nori-wal/performance/hardware/#table-of-contents","title":"Table of contents","text":""},{"location":"crates/nori-wal/performance/hardware/#quick-reference","title":"Quick Reference","text":"Target Workload CPU RAM Disk Cost Development/Testing 2 cores 4 GB Any SSD $ Light Production 4 cores 8 GB SATA SSD $$ Standard Production 8 cores 16 GB NVMe SSD $$$ High Performance 16+ cores 32 GB Multiple NVMe $$$$"},{"location":"crates/nori-wal/performance/hardware/#disk-most-important","title":"Disk (Most Important)","text":"<p>WAL performance is heavily disk-bound. Disk choice has the biggest impact.</p>"},{"location":"crates/nori-wal/performance/hardware/#hdd-not-recommended","title":"HDD (Not Recommended)","text":"<p>Performance: - Random IOPS: 100-200 - Sequential throughput: 100-200 MB/s - Fsync latency: 5-10ms</p> <p>WAL Performance: - Max writes/sec: 100-200 (with <code>FsyncPolicy::Always</code>) - With batching: 10-20K writes/sec - Recovery: 100 MB/s</p> <p>Use case: Archival/backup only. Not suitable for production WAL.</p> <p>Cost: $20-30 per TB</p>"},{"location":"crates/nori-wal/performance/hardware/#sata-ssd","title":"SATA SSD","text":"<p>Performance: - Random IOPS: 10K-50K - Sequential throughput: 300-500 MB/s - Fsync latency: 0.5-2ms</p> <p>WAL Performance: - Max writes/sec: 500-1000 (with <code>FsyncPolicy::Always</code>) - With batching: 40-60K writes/sec - Recovery: 300-500 MB/s</p> <p>Use case: Budget-conscious deployments, light workloads.</p> <p>Cost: $100-150 per TB</p> <p>Recommendation: Samsung 870 EVO, Crucial MX500</p>"},{"location":"crates/nori-wal/performance/hardware/#nvme-ssd-recommended","title":"NVMe SSD (Recommended)","text":"<p>Performance: - Random IOPS: 100K-500K - Sequential throughput: 2-7 GB/s - Fsync latency: 0.1-0.5ms</p> <p>WAL Performance: - Max writes/sec: 2000-5000 (with <code>FsyncPolicy::Always</code>) - With batching: 80-120K writes/sec - Recovery: 2-3 GB/s</p> <p>Use case: Production deployments, standard recommendation.</p> <p>Cost: $150-300 per TB</p> <p>Recommendation: - Consumer: Samsung 980 Pro, WD Black SN850 - Enterprise: Intel P5520, Samsung PM9A3</p>"},{"location":"crates/nori-wal/performance/hardware/#optane-ssd-premium","title":"Optane SSD (Premium)","text":"<p>Performance: - Random IOPS: 500K+ - Sequential throughput: 2-3 GB/s - Fsync latency: &lt;0.1ms (extremely low)</p> <p>WAL Performance: - Max writes/sec: 10,000+ (with <code>FsyncPolicy::Always</code>) - With batching: 150K+ writes/sec - Recovery: 3+ GB/s</p> <p>Use case: Latency-critical, high-durability workloads.</p> <p>Cost: $1000+ per TB</p> <p>Recommendation: Intel Optane P5800X</p>"},{"location":"crates/nori-wal/performance/hardware/#disk-comparison","title":"Disk Comparison","text":"Metric HDD SATA SSD NVMe SSD Optane Fsync latency 5-10ms 0.5-2ms 0.1-0.5ms &lt;0.1ms Max writes/sec (Always) 200 1000 5000 10000 Max writes/sec (Batch) 20K 60K 120K 150K Recovery (100 MB) 1s 300ms 50ms 30ms Cost per TB $ $$ $$$ $$$$ <p>Bottom line: Use NVMe SSD minimum. Optane if budget allows.</p>"},{"location":"crates/nori-wal/performance/hardware/#cpu","title":"CPU","text":"<p>WAL is not CPU-intensive, but parallelism helps for recovery and compression.</p>"},{"location":"crates/nori-wal/performance/hardware/#2-cores-development","title":"2 Cores (Development)","text":"<p>Suitable for: - Local development - Testing - Low-rate workloads (&lt;1K writes/sec)</p> <p>Not suitable for: - Production - High concurrency - Parallel recovery</p>"},{"location":"crates/nori-wal/performance/hardware/#4-8-cores-production","title":"4-8 Cores (Production)","text":"<p>Suitable for: - Standard production workloads - Up to 50K writes/sec - Single-node deployments</p> <p>Performance: - Compression: 4 cores can compress 100K records/sec with LZ4 - Recovery: 4 cores can replay 1M records/sec</p> <p>Recommendation: Intel Xeon Silver, AMD EPYC 7002 series, or equivalent</p>"},{"location":"crates/nori-wal/performance/hardware/#16-cores-high-performance","title":"16+ Cores (High Performance)","text":"<p>Suitable for: - &gt;100K writes/sec - Large-scale distributed systems - Parallel compaction/recovery</p> <p>Performance: - Compression: 16 cores can compress 400K records/sec with LZ4 - Recovery: 16 cores can replay 4M records/sec</p> <p>Recommendation: Intel Xeon Gold, AMD EPYC 7003 series</p>"},{"location":"crates/nori-wal/performance/hardware/#cpu-comparison","title":"CPU Comparison","text":"Cores Compression (LZ4) Recovery Use Case 2 50K records/sec 500K records/sec Dev/test 4 100K records/sec 1M records/sec Light prod 8 200K records/sec 2M records/sec Standard prod 16 400K records/sec 4M records/sec High perf <p>Bottom line: 4-8 cores is sufficient for most workloads.</p>"},{"location":"crates/nori-wal/performance/hardware/#ram","title":"RAM","text":"<p>WAL uses minimal memory. RAM is mainly for OS page cache and in-memory indexes.</p>"},{"location":"crates/nori-wal/performance/hardware/#4-gb-minimum","title":"4 GB (Minimum)","text":"<p>Suitable for: - Development - Very small datasets (&lt;1 GB WAL)</p> <p>Limitations: - Limited OS page cache - Frequent disk I/O - Slow recovery</p>"},{"location":"crates/nori-wal/performance/hardware/#8-16-gb-recommended","title":"8-16 GB (Recommended)","text":"<p>Suitable for: - Production workloads - WAL size: 10-50 GB - In-memory indexes for KV stores</p> <p>Benefits: - OS can cache active segments in RAM - Fast read access to recent data - Good recovery performance</p>"},{"location":"crates/nori-wal/performance/hardware/#32-gb-high-performance","title":"32+ GB (High Performance)","text":"<p>Suitable for: - Large datasets (&gt;100 GB WAL) - Multiple concurrent readers - Complex in-memory state</p> <p>Benefits: - Entire active segment set cached - No disk reads for recent data - Very fast recovery</p>"},{"location":"crates/nori-wal/performance/hardware/#ram-sizing-guide","title":"RAM Sizing Guide","text":"<p>Rule of thumb: RAM \u2265 2x active segment size</p> <pre><code>Active segment size: 128 MB\nMin RAM for caching: 256 MB\nRecommended: 2-4 GB (for OS + other processes)\n</code></pre> <p>For in-memory indexes (KV store):</p> <pre><code>Keys: 1M\nAvg key size: 32 bytes\nAvg value size: 512 bytes\n\nMemory for HashMap:\n  Keys: 1M \u00d7 32 bytes = 32 MB\n  Values: 1M \u00d7 512 bytes = 512 MB\n  Overhead: ~50% = 272 MB\n  Total: ~816 MB\n\nRecommended RAM: 2 GB (for index) + 4 GB (for OS/cache) = 6 GB\n</code></pre> <p>Bottom line: 8-16 GB is sufficient for most deployments.</p>"},{"location":"crates/nori-wal/performance/hardware/#network-distributed-systems","title":"Network (Distributed Systems)","text":"<p>For replicated WAL (multi-node setups).</p>"},{"location":"crates/nori-wal/performance/hardware/#1-gbps-basic","title":"1 Gbps (Basic)","text":"<p>Throughput: 125 MB/s</p> <p>Suitable for: - Replication lag &lt;1 second - Write rate &lt;50 MB/s - 2-3 replicas</p> <p>Bottleneck: Network becomes bottleneck at &gt;50 MB/s sustained write rate.</p>"},{"location":"crates/nori-wal/performance/hardware/#10-gbps-recommended","title":"10 Gbps (Recommended)","text":"<p>Throughput: 1.25 GB/s</p> <p>Suitable for: - Standard production - Write rate &lt;500 MB/s - 3-5 replicas - Fast catchup after failures</p> <p>Performance: - Can replicate 100 MB/s writes to 5 replicas with &lt;100ms lag - Catchup: 1 GB/s (8 seconds for 8 GB lag)</p>"},{"location":"crates/nori-wal/performance/hardware/#25-gbps-high-performance","title":"25+ Gbps (High Performance)","text":"<p>Throughput: 3+ GB/s</p> <p>Suitable for: - High-throughput replication - Many replicas (&gt;5) - Large bursts</p> <p>Performance: - Can handle 500+ MB/s sustained writes - Catchup: 3 GB/s (1 second for 3 GB lag)</p> <p>Bottom line: 10 Gbps is sufficient unless replicating &gt;500 MB/s.</p>"},{"location":"crates/nori-wal/performance/hardware/#storage-configurations","title":"Storage Configurations","text":""},{"location":"crates/nori-wal/performance/hardware/#single-disk-development","title":"Single Disk (Development)","text":"<pre><code>/data/wal/\n  \u251c\u2500\u2500 000000.wal\n  \u251c\u2500\u2500 000001.wal\n  \u2514\u2500\u2500 ...\n</code></pre> <p>Pros: - Simple - Low cost</p> <p>Cons: - No redundancy - Disk failure = data loss</p> <p>Use case: Development, non-critical data</p>"},{"location":"crates/nori-wal/performance/hardware/#raid-1-mirroring","title":"RAID 1 (Mirroring)","text":"<pre><code>/dev/md0 (mirror of /dev/sda1 + /dev/sdb1)\n  \u2514\u2500\u2500 /data/wal/\n</code></pre> <p>Pros: - Disk redundancy - Read performance 2x (reads from either disk)</p> <p>Cons: - Write performance same as single disk - 50% capacity (2x cost)</p> <p>Use case: Production with durability requirements</p>"},{"location":"crates/nori-wal/performance/hardware/#raid-10-stripe-mirror","title":"RAID 10 (Stripe + Mirror)","text":"<pre><code>/dev/md0 (stripe of two mirrors)\n  \u251c\u2500\u2500 Mirror 1: /dev/sda1 + /dev/sdb1\n  \u2514\u2500\u2500 Mirror 2: /dev/sdc1 + /dev/sdd1\n</code></pre> <p>Pros: - Redundancy - 2x write performance (parallel writes to mirrors) - 2x read performance</p> <p>Cons: - 50% capacity (4 disks \u2192 2 disks capacity) - Higher cost</p> <p>Use case: High-performance production</p>"},{"location":"crates/nori-wal/performance/hardware/#separate-wal-and-data-disks","title":"Separate WAL and Data Disks","text":"<pre><code>/data/wal/     \u2190 Fast NVMe SSD (for writes)\n/data/archive/ \u2190 Slower SATA SSD (for old segments)\n</code></pre> <p>Strategy: 1. Write to fast NVMe 2. Move old segments to slower disk for archival</p> <p>Pros: - Optimize cost (fast disk only for active data) - Good write performance</p> <p>Cons: - More complex setup - Need automated archival</p>"},{"location":"crates/nori-wal/performance/hardware/#cloud-configurations","title":"Cloud Configurations","text":""},{"location":"crates/nori-wal/performance/hardware/#aws","title":"AWS","text":"<p>Recommended instance types:</p> Workload Instance Disk Cost/month Light t3.medium 100 GB gp3 $50 Standard m6i.xlarge 500 GB gp3 $300 High perf m6i.2xlarge 1 TB io2 $800 <p>Storage options: - gp3: 3000 IOPS baseline, 125 MB/s. Good for most workloads. - io2: Provisioned IOPS (up to 64K). For high-performance needs. - Local NVMe: Best performance, but ephemeral (data lost on stop).</p> <p>Network: Use Enhanced Networking (10-100 Gbps) for replication.</p>"},{"location":"crates/nori-wal/performance/hardware/#gcp","title":"GCP","text":"<p>Recommended instance types:</p> Workload Instance Disk Cost/month Light e2-standard-2 100 GB pd-ssd $80 Standard n2-standard-4 500 GB pd-ssd $350 High perf n2-standard-8 1 TB pd-extreme $900 <p>Storage options: - pd-ssd: 30 IOPS/GB. Good balance. - pd-extreme: Provisioned IOPS (up to 100K). For high-performance. - Local SSD: 375 GB, very fast, but ephemeral.</p> <p>Network: 10-32 Gbps depending on instance size.</p>"},{"location":"crates/nori-wal/performance/hardware/#azure","title":"Azure","text":"<p>Recommended instance types:</p> Workload Instance Disk Cost/month Light Standard_D2s_v3 100 GB Premium SSD $100 Standard Standard_D4s_v3 500 GB Premium SSD $400 High perf Standard_D8s_v3 1 TB Ultra Disk $1000 <p>Storage options: - Premium SSD: Up to 20K IOPS. Good for most workloads. - Ultra Disk: Up to 160K IOPS. For high-performance.</p> <p>Network: 10-40 Gbps depending on instance size.</p>"},{"location":"crates/nori-wal/performance/hardware/#sizing-examples","title":"Sizing Examples","text":""},{"location":"crates/nori-wal/performance/hardware/#small-deployment-10k-writessec","title":"Small Deployment (10K writes/sec)","text":"<p>Hardware: - CPU: 4 cores - RAM: 8 GB - Disk: 256 GB NVMe SSD</p> <p>Configuration:</p> <pre><code>let config = WalConfig {\n    max_segment_size: 128 * 1024 * 1024,\n    fsync_policy: FsyncPolicy::Batch(Duration::from_millis(5)),\n    preallocate: true,\n    node_id: 0,\n};\n</code></pre> <p>Expected Performance: - 10K writes/sec sustained - 1 GB/day WAL growth - Recovery time: &lt;1 second for full disk</p> <p>Cost: $200-300/month (cloud)</p>"},{"location":"crates/nori-wal/performance/hardware/#medium-deployment-50k-writessec","title":"Medium Deployment (50K writes/sec)","text":"<p>Hardware: - CPU: 8 cores - RAM: 16 GB - Disk: 1 TB NVMe SSD</p> <p>Configuration:</p> <pre><code>let config = WalConfig {\n    max_segment_size: 256 * 1024 * 1024,\n    fsync_policy: FsyncPolicy::Batch(Duration::from_millis(5)),\n    preallocate: true,\n    node_id: 0,\n};\n</code></pre> <p>Expected Performance: - 50K writes/sec sustained - 5 GB/day WAL growth - Recovery time: &lt;5 seconds for full disk</p> <p>Cost: $500-700/month (cloud)</p>"},{"location":"crates/nori-wal/performance/hardware/#large-deployment-200k-writessec","title":"Large Deployment (200K writes/sec)","text":"<p>Hardware: - CPU: 16 cores - RAM: 32 GB - Disk: 2x 2 TB NVMe SSD (RAID 1)</p> <p>Configuration:</p> <pre><code>let config = WalConfig {\n    max_segment_size: 512 * 1024 * 1024,\n    fsync_policy: FsyncPolicy::Batch(Duration::from_millis(10)),\n    preallocate: true,\n    node_id: 0,\n};\n</code></pre> <p>Expected Performance: - 200K writes/sec sustained - 20 GB/day WAL growth - Recovery time: &lt;30 seconds for full disk</p> <p>Cost: $1500-2000/month (cloud)</p>"},{"location":"crates/nori-wal/performance/hardware/#performance-testing","title":"Performance Testing","text":"<p>Before deploying, benchmark on your hardware:</p>"},{"location":"crates/nori-wal/performance/hardware/#disk-throughput","title":"Disk Throughput","text":"<pre><code># Sequential write\ndd if=/dev/zero of=/path/to/wal/testfile bs=1M count=1000 oflag=direct\n\n# Result: X MB/s\n</code></pre>"},{"location":"crates/nori-wal/performance/hardware/#disk-latency","title":"Disk Latency","text":"<pre><code># Single fsync\ntime dd if=/dev/zero of=/path/to/wal/testfile bs=4k count=1 conv=fsync\n\n# Result: X ms\n</code></pre>"},{"location":"crates/nori-wal/performance/hardware/#wal-benchmark","title":"WAL Benchmark","text":"<pre><code>#[tokio::main]\nasync fn main() -&gt; Result&lt;()&gt; {\n    let config = WalConfig {\n        dir: PathBuf::from(\"/path/to/wal\"),\n        ..Default::default()\n    };\n\n    let (wal, _) = Wal::open(config).await?;\n\n    // Measure write throughput\n    let start = Instant::now();\n    for i in 0..100_000 {\n        wal.append(&amp;Record::put(&amp;i.to_le_bytes(), b\"value\")).await?;\n    }\n    let elapsed = start.elapsed();\n\n    println!(\"Throughput: {} writes/sec\", 100_000.0 / elapsed.as_secs_f64());\n\n    Ok(())\n}\n</code></pre>"},{"location":"crates/nori-wal/performance/hardware/#conclusion","title":"Conclusion","text":"<p>For most deployments: - Disk: NVMe SSD (Samsung 980 Pro or equivalent) - CPU: 4-8 cores - RAM: 8-16 GB - Network: 10 Gbps (if replicated)</p> <p>Total cost: $300-700/month (cloud) or $2000-5000 (on-prem hardware)</p> <p>This gives 50-100K writes/sec with good durability and recovery characteristics.</p>"},{"location":"crates/nori-wal/performance/profiling/","title":"Performance Profiling","text":"<p>How to measure and analyze nori-wal performance in your application.</p>"},{"location":"crates/nori-wal/performance/profiling/#table-of-contents","title":"Table of contents","text":""},{"location":"crates/nori-wal/performance/profiling/#quick-start","title":"Quick Start","text":"<p>Add basic timing to your code:</p> <pre><code>use std::time::Instant;\n\n// Measure write latency\nlet start = Instant::now();\nwal.append(&amp;record).await?;\nlet latency = start.elapsed();\nprintln!(\"Write latency: {:?}\", latency);\n\n// Measure throughput\nlet start = Instant::now();\nfor i in 0..10_000 {\n    wal.append(&amp;Record::put(&amp;i.to_le_bytes(), b\"value\")).await?;\n}\nlet elapsed = start.elapsed();\nprintln!(\"Throughput: {} writes/sec\", 10_000.0 / elapsed.as_secs_f64());\n</code></pre>"},{"location":"crates/nori-wal/performance/profiling/#metrics-to-track","title":"Metrics to Track","text":""},{"location":"crates/nori-wal/performance/profiling/#write-performance","title":"Write Performance","text":"<p>Append latency (p50, p95, p99):</p> <pre><code>use hdrhistogram::Histogram;\n\nlet mut histogram = Histogram::&lt;u64&gt;::new(3)?;\n\nfor _ in 0..100_000 {\n    let start = Instant::now();\n    wal.append(&amp;record).await?;\n    histogram.record(start.elapsed().as_micros() as u64)?;\n}\n\nprintln!(\"p50: {}\u00b5s\", histogram.value_at_quantile(0.50));\nprintln!(\"p95: {}\u00b5s\", histogram.value_at_quantile(0.95));\nprintln!(\"p99: {}\u00b5s\", histogram.value_at_quantile(0.99));\n</code></pre> <p>Typical values: - p50: 8-15\u00b5s (in-memory write) - p95: 20-50\u00b5s - p99: 100\u00b5s - 5ms (depends on fsync policy)</p> <p>Fsync latency:</p> <pre><code>let start = Instant::now();\nwal.sync().await?;\nlet fsync_latency = start.elapsed();\nprintln!(\"Fsync latency: {:?}\", fsync_latency);\n</code></pre> <p>Typical values: - Clean file: 10-50\u00b5s - 1 MB dirty: 1-2ms - 10 MB dirty: 5-10ms</p> <p>Throughput (writes/sec):</p> <pre><code>let start = Instant::now();\nlet count = 10_000;\n\nfor i in 0..count {\n    wal.append(&amp;Record::put(&amp;i.to_le_bytes(), b\"value\")).await?;\n}\n\nlet throughput = count as f64 / start.elapsed().as_secs_f64();\nprintln!(\"Throughput: {:.0} writes/sec\", throughput);\n</code></pre> <p>Typical values: - With <code>FsyncPolicy::Always</code>: 400-500 writes/sec - With <code>FsyncPolicy::Batch(5ms)</code>: 80-100K writes/sec - With <code>FsyncPolicy::Os</code>: 100-120K writes/sec</p>"},{"location":"crates/nori-wal/performance/profiling/#read-performance","title":"Read Performance","text":"<p>Sequential scan throughput:</p> <pre><code>let start = Instant::now();\nlet mut count = 0u64;\nlet mut bytes = 0u64;\n\nlet mut reader = wal.read_from(Position { segment_id: 0, offset: 0 }).await?;\nwhile let Some((record, _)) = reader.next_record().await? {\n    count += 1;\n    bytes += record.key.len() as u64 + record.value.len() as u64;\n}\n\nlet elapsed = start.elapsed();\nlet throughput_mbs = (bytes as f64 / 1_000_000.0) / elapsed.as_secs_f64();\n\nprintln!(\"Read {} records in {:?}\", count, elapsed);\nprintln!(\"Throughput: {:.1} MB/s\", throughput_mbs);\n</code></pre> <p>Typical values: - Sequential read: 50-100 MB/s (decode + CRC validation bottleneck) - Raw disk read: 2-7 GB/s (NVMe)</p>"},{"location":"crates/nori-wal/performance/profiling/#recovery-performance","title":"Recovery Performance","text":"<p>Recovery time:</p> <pre><code>let start = Instant::now();\nlet (wal, recovery_info) = Wal::open(config).await?;\nlet elapsed = start.elapsed();\n\nprintln!(\"Recovery complete:\");\nprintln!(\"  Time: {:?}\", elapsed);\nprintln!(\"  Records: {}\", recovery_info.valid_records);\nprintln!(\"  Segments: {}\", recovery_info.segments_scanned);\nprintln!(\"  Throughput: {:.1} GiB/s\",\n    (recovery_info.bytes_scanned as f64 / 1_073_741_824.0) / elapsed.as_secs_f64()\n);\n</code></pre> <p>Typical values: - 10 MB: 2-5ms (3.3 GiB/s) - 100 MB: 30ms - 1 GB: 300ms</p>"},{"location":"crates/nori-wal/performance/profiling/#segment-operations","title":"Segment Operations","text":"<p>Rotation overhead:</p> <pre><code>// Track when rotation happens\nlet old_segment_id = wal.current_segment_id();\n\nlet start = Instant::now();\nwal.append(&amp;large_record).await?;  // Triggers rotation\nlet elapsed = start.elapsed();\n\nif wal.current_segment_id() != old_segment_id {\n    println!(\"Segment rotation took: {:?}\", elapsed);\n}\n</code></pre> <p>Typical values: - With pre-allocation: 10-15ms - Without pre-allocation: 2-3ms</p> <p>Segment deletion:</p> <pre><code>let start = Instant::now();\nwal.delete_segments_before(segment_id).await?;\nlet elapsed = start.elapsed();\nprintln!(\"Deleted segments in {:?}\", elapsed);\n</code></pre>"},{"location":"crates/nori-wal/performance/profiling/#profiling-tools","title":"Profiling Tools","text":""},{"location":"crates/nori-wal/performance/profiling/#cpu-profiling","title":"CPU Profiling","text":"<p>Use <code>cargo flamegraph</code> to identify hot paths:</p> <pre><code>cargo install flamegraph\n\n# Profile your application\ncargo flamegraph --bin your_app\n\n# Open flamegraph.svg in browser\n</code></pre> <p>What to look for: - High time in <code>write_all()</code> \u2192 Disk bottleneck - High time in <code>crc32()</code> \u2192 Consider larger records (amortize CRC cost) - High time in <code>compress()</code> \u2192 Consider disabling compression</p>"},{"location":"crates/nori-wal/performance/profiling/#memory-profiling","title":"Memory Profiling","text":"<p>Use <code>heaptrack</code> or <code>valgrind</code> to track allocations:</p> <pre><code># Install heaptrack\nsudo apt install heaptrack\n\n# Profile\nheaptrack ./target/release/your_app\n\n# Analyze\nheaptrack_gui heaptrack.your_app.*.gz\n</code></pre> <p>What to look for: - Large allocations in hot path \u2192 Use object pools - Memory growth over time \u2192 Memory leak</p>"},{"location":"crates/nori-wal/performance/profiling/#disk-io-profiling","title":"Disk I/O Profiling","text":""},{"location":"crates/nori-wal/performance/profiling/#linux-iostat","title":"Linux (iostat)","text":"<pre><code>iostat -x 1\n\n# Look at:\n# - %util: Disk utilization (&gt;80% = bottleneck)\n# - await: Average I/O latency (&gt;10ms = slow)\n# - w/s: Writes per second\n# - wMB/s: Write throughput\n</code></pre>"},{"location":"crates/nori-wal/performance/profiling/#macos-fs_usage","title":"macOS (fs_usage)","text":"<pre><code>sudo fs_usage -f filesys -w\n\n# Filter for your process:\nsudo fs_usage -f filesys -w | grep your_app\n</code></pre>"},{"location":"crates/nori-wal/performance/profiling/#windows-performance-monitor","title":"Windows (Performance Monitor)","text":"<pre><code>perfmon /res\n\n# Add counters:\n# - PhysicalDisk: Disk Writes/sec\n# - PhysicalDisk: Avg. Disk Write Queue Length\n# - PhysicalDisk: % Disk Time\n</code></pre>"},{"location":"crates/nori-wal/performance/profiling/#network-io-replication","title":"Network I/O (Replication)","text":""},{"location":"crates/nori-wal/performance/profiling/#linux-iftop","title":"Linux (iftop)","text":"<pre><code>sudo iftop -i eth0\n\n# Shows:\n# - Bandwidth usage per connection\n# - Peak/avg throughput\n</code></pre>"},{"location":"crates/nori-wal/performance/profiling/#application-level","title":"Application-level","text":"<pre><code>use std::sync::atomic::{AtomicU64, Ordering};\nuse std::sync::Arc;\n\nlet bytes_sent = Arc::new(AtomicU64::new(0));\n\n// In replication code:\nbytes_sent.fetch_add(record.len() as u64, Ordering::Relaxed);\n\n// Periodically report:\nlet sent = bytes_sent.swap(0, Ordering::Relaxed);\nprintln!(\"Replication throughput: {} MB/s\", sent / 1_000_000);\n</code></pre>"},{"location":"crates/nori-wal/performance/profiling/#benchmarking-framework","title":"Benchmarking Framework","text":"<p>Create a reusable benchmarking harness:</p> <pre><code>use criterion::{black_box, criterion_group, criterion_main, Criterion, BenchmarkId};\nuse nori_wal::*;\n\nfn bench_append(c: &amp;mut Criterion) {\n    let rt = tokio::runtime::Runtime::new().unwrap();\n\n    let mut group = c.benchmark_group(\"append\");\n\n    for size in [100, 1024, 10_240] {\n        group.bench_with_input(\n            BenchmarkId::from_parameter(size),\n            &amp;size,\n            |b, &amp;size| {\n                b.to_async(&amp;rt).iter(|| async {\n                    let config = WalConfig {\n                        dir: PathBuf::from(\"/tmp/bench_wal\"),\n                        fsync_policy: FsyncPolicy::Os,\n                        ..Default::default()\n                    };\n\n                    let (wal, _) = Wal::open(config).await.unwrap();\n                    let record = Record::put(b\"key\", &amp;vec![0u8; size]);\n\n                    black_box(wal.append(&amp;record).await.unwrap());\n                });\n            },\n        );\n    }\n\n    group.finish();\n}\n\ncriterion_group!(benches, bench_append);\ncriterion_main!(benches);\n</code></pre> <p>Run benchmarks:</p> <pre><code>cargo bench\n\n# Results:\n# append/100    9.8 \u00b5s\n# append/1024   11.2 \u00b5s\n# append/10240  45.3 \u00b5s\n</code></pre>"},{"location":"crates/nori-wal/performance/profiling/#production-monitoring","title":"Production Monitoring","text":""},{"location":"crates/nori-wal/performance/profiling/#prometheus-metrics","title":"Prometheus Metrics","text":"<p>Export metrics for monitoring:</p> <pre><code>use prometheus::{Counter, Histogram, Gauge, register_counter, register_histogram, register_gauge};\n\nlazy_static! {\n    static ref APPEND_DURATION: Histogram = register_histogram!(\n        \"wal_append_duration_seconds\",\n        \"Time to append a record\"\n    ).unwrap();\n\n    static ref APPEND_TOTAL: Counter = register_counter!(\n        \"wal_append_total\",\n        \"Total number of appends\"\n    ).unwrap();\n\n    static ref FSYNC_DURATION: Histogram = register_histogram!(\n        \"wal_fsync_duration_seconds\",\n        \"Time to fsync\"\n    ).unwrap();\n\n    static ref ACTIVE_SEGMENT_SIZE: Gauge = register_gauge!(\n        \"wal_active_segment_bytes\",\n        \"Size of active segment in bytes\"\n    ).unwrap();\n\n    static ref SEGMENT_ROTATIONS: Counter = register_counter!(\n        \"wal_segment_rotations_total\",\n        \"Total number of segment rotations\"\n    ).unwrap();\n}\n\n// In append:\nlet timer = APPEND_DURATION.start_timer();\nwal.append(&amp;record).await?;\ntimer.observe_duration();\nAPPEND_TOTAL.inc();\n\n// In sync:\nlet timer = FSYNC_DURATION.start_timer();\nwal.sync().await?;\ntimer.observe_duration();\n\n// Periodically update:\nACTIVE_SEGMENT_SIZE.set(wal.current_segment_size() as f64);\n</code></pre>"},{"location":"crates/nori-wal/performance/profiling/#opentelemetry-tracing","title":"OpenTelemetry Tracing","text":"<p>Add distributed tracing:</p> <pre><code>use tracing::{info_span, instrument};\n\n#[instrument]\npub async fn append(&amp;mut self, record: &amp;Record) -&gt; Result&lt;()&gt; {\n    let span = info_span!(\"wal.append\", record_size = record.len());\n    let _enter = span.enter();\n\n    // ... append logic ...\n\n    Ok(())\n}\n</code></pre> <p>View traces in Jaeger/Zipkin:</p> <pre><code>Request                             [==================] 45ms\n  \u251c\u2500 wal.append                    [====              ]  8ms\n  \u2502   \u251c\u2500 serialize                 [==                ]  2ms\n  \u2502   \u251c\u2500 write                     [==                ]  3ms\n  \u2502   \u2514\u2500 crc                       [=                 ]  1ms\n  \u2514\u2500 wal.sync                      [              ====] 35ms\n      \u2514\u2500 fsync                     [              ====] 35ms\n</code></pre>"},{"location":"crates/nori-wal/performance/profiling/#custom-dashboards","title":"Custom Dashboards","text":"<p>Track key metrics:</p> <p>Grafana Dashboard:</p> <pre><code>{\n  \"panels\": [\n    {\n      \"title\": \"Write Throughput\",\n      \"targets\": [\n        {\n          \"expr\": \"rate(wal_append_total[1m])\"\n        }\n      ]\n    },\n    {\n      \"title\": \"Append Latency (p99)\",\n      \"targets\": [\n        {\n          \"expr\": \"histogram_quantile(0.99, wal_append_duration_seconds)\"\n        }\n      ]\n    },\n    {\n      \"title\": \"Fsync Latency\",\n      \"targets\": [\n        {\n          \"expr\": \"rate(wal_fsync_duration_seconds_sum[1m]) / rate(wal_fsync_duration_seconds_count[1m])\"\n        }\n      ]\n    },\n    {\n      \"title\": \"Segment Size\",\n      \"targets\": [\n        {\n          \"expr\": \"wal_active_segment_bytes\"\n        }\n      ]\n    }\n  ]\n}\n</code></pre>"},{"location":"crates/nori-wal/performance/profiling/#troubleshooting-performance-issues","title":"Troubleshooting Performance Issues","text":""},{"location":"crates/nori-wal/performance/profiling/#symptom-low-throughput","title":"Symptom: Low Throughput","text":"<p>Check:</p> <ol> <li> <p>Fsync policy: <pre><code>println!(\"Fsync policy: {:?}\", wal.config().fsync_policy);\n</code></pre></p> </li> <li> <p>Batching: <pre><code>// Are you syncing after every write?\nfor record in records {\n    wal.append(&amp;record).await?;\n    wal.sync().await?;  // \u2190 This kills throughput\n}\n</code></pre></p> </li> <li> <p>Disk speed: <pre><code>iostat -x 1\n# Look at %util and wMB/s\n</code></pre></p> </li> </ol> <p>Fix: - Use <code>FsyncPolicy::Batch(5ms)</code> - Batch multiple appends before sync - Upgrade to faster disk</p>"},{"location":"crates/nori-wal/performance/profiling/#symptom-high-p99-latency","title":"Symptom: High p99 Latency","text":"<p>Check:</p> <ol> <li> <p>Segment rotation: <pre><code>// Add logging\nprintln!(\"Segment rotation: {:?}\", elapsed);\n</code></pre></p> </li> <li> <p>Fsync spikes: <pre><code># Linux\nsudo iotop -ao\n</code></pre></p> </li> <li> <p>CPU throttling: <pre><code># Linux\ncat /proc/cpuinfo | grep MHz\n</code></pre></p> </li> </ol> <p>Fix: - Increase segment size - Monitor for GC pauses (if using JVM languages) - Check for thermal throttling</p>"},{"location":"crates/nori-wal/performance/profiling/#symptom-slow-recovery","title":"Symptom: Slow Recovery","text":"<p>Check:</p> <ol> <li> <p>Segment count: <pre><code>ls -l /path/to/wal/ | wc -l\n</code></pre></p> </li> <li> <p>CRC validation time: <pre><code>let start = Instant::now();\nlet (wal, info) = Wal::open(config).await?;\nprintln!(\"Validated {} records in {:?}\", info.valid_records, start.elapsed());\n</code></pre></p> </li> </ol> <p>Fix: - Reduce number of segments (increase segment size) - Run compaction to merge segments - Use parallel recovery (if available)</p>"},{"location":"crates/nori-wal/performance/profiling/#performance-testing-checklist","title":"Performance Testing Checklist","text":"<p>Before deploying:</p> <ul> <li> Benchmarked on target hardware</li> <li> Measured p99 latency under load</li> <li> Tested recovery time with realistic data size</li> <li> Profiled CPU usage (no hot spots &gt;20%)</li> <li> Profiled memory usage (no leaks)</li> <li> Monitored disk I/O (utilization &lt;80%)</li> <li> Tested segment rotation overhead (&lt;10ms)</li> <li> Set up production monitoring (Prometheus/Grafana)</li> <li> Created alerts for slow operations</li> <li> Load tested for 24+ hours</li> </ul>"},{"location":"crates/nori-wal/performance/profiling/#conclusion","title":"Conclusion","text":"<p>Key metrics to monitor:</p> <ol> <li>Append latency (p99): Should be &lt;10ms</li> <li>Throughput: Should match workload requirements</li> <li>Fsync latency: Should be &lt;5ms</li> <li>Recovery time: Should be &lt;1 second per GB</li> </ol> <p>Use profiling tools to identify bottlenecks: - CPU: flamegraph - Memory: heaptrack - Disk: iostat - Application: Prometheus + Grafana</p> <p>For more details, see: - Benchmarks - Performance measurements - Tuning Guide - Optimization strategies - Hardware - Hardware selection</p>"},{"location":"crates/nori-wal/performance/tuning/","title":"Performance Tuning Guide","text":"<p>How to optimize nori-wal for your specific workload.</p>"},{"location":"crates/nori-wal/performance/tuning/#table-of-contents","title":"Table of contents","text":""},{"location":"crates/nori-wal/performance/tuning/#quick-wins","title":"Quick Wins","text":"<p>Before diving into complex tuning, try these common optimizations:</p>"},{"location":"crates/nori-wal/performance/tuning/#1-use-batched-fsync","title":"1. Use Batched Fsync","text":"<p>Problem: <code>FsyncPolicy::Always</code> gives you 400 writes/sec maximum.</p> <p>Solution:</p> <pre><code>let config = WalConfig {\n    fsync_policy: FsyncPolicy::Batch(Duration::from_millis(5)),\n    ..Default::default()\n};\n</code></pre> <p>Impact: 200x throughput improvement (400 \u2192 86,000 writes/sec)</p> <p>Trade-off: Up to 5ms of data loss on crash (uncommitted writes in buffer).</p>"},{"location":"crates/nori-wal/performance/tuning/#2-batch-your-writes","title":"2. Batch Your Writes","text":"<p>Problem: Individual <code>append()</code> calls are fast, but each one waits for the next fsync window.</p> <p>Solution:</p> <pre><code>// Bad: One at a time\nfor record in records {\n    wal.append(&amp;record).await?;\n    wal.sync().await?;  // 2-3ms each\n}\n\n// Good: Batch them\nfor record in records {\n    wal.append(&amp;record).await?;\n}\nwal.sync().await?;  // Single 2-3ms for all\n</code></pre> <p>Impact: 100-1000x throughput improvement depending on batch size.</p>"},{"location":"crates/nori-wal/performance/tuning/#3-increase-segment-size","title":"3. Increase Segment Size","text":"<p>Problem: Frequent segment rotation (every 30 seconds) adds latency spikes.</p> <p>Solution:</p> <pre><code>let config = WalConfig {\n    max_segment_size: 512 * 1024 * 1024,  // 512 MB (default is 128 MB)\n    ..Default::default()\n};\n</code></pre> <p>Impact: Reduces rotation frequency 4x (every 2 minutes instead of 30 seconds).</p> <p>Trade-off: Larger segments mean longer recovery time and more disk space.</p>"},{"location":"crates/nori-wal/performance/tuning/#4-use-compression-for-large-records","title":"4. Use Compression for Large Records","text":"<p>Problem: Writing large text/JSON records saturates disk I/O.</p> <p>Solution:</p> <pre><code>let record = Record::put(key, value)\n    .with_compression(Compression::Lz4);\n\nwal.append(&amp;record).await?;\n</code></pre> <p>Impact: 10x storage savings, 1.2x slower writes (still net win for I/O bound workloads).</p> <p>Trade-off: CPU overhead (2\u00b5s per write for LZ4).</p>"},{"location":"crates/nori-wal/performance/tuning/#workload-specific-tuning","title":"Workload-Specific Tuning","text":""},{"location":"crates/nori-wal/performance/tuning/#high-throughput-writes","title":"High-Throughput Writes","text":"<p>Goal: Maximize writes/sec.</p> <p>Configuration:</p> <pre><code>let config = WalConfig {\n    max_segment_size: 512 * 1024 * 1024,       // Large segments\n    fsync_policy: FsyncPolicy::Batch(\n        Duration::from_millis(10)              // Longer batch window\n    ),\n    preallocate: true,                         // Avoid allocation pauses\n    node_id: 0,\n};\n</code></pre> <p>Code Pattern:</p> <pre><code>// Batch writes before syncing\nlet mut batch = Vec::new();\nfor i in 0..1000 {\n    batch.push(Record::put(&amp;format!(\"key{}\", i), b\"value\"));\n}\n\nfor record in batch {\n    wal.append(&amp;record).await?;\n}\nwal.sync().await?;  // Single fsync for 1000 records\n</code></pre> <p>Expected Performance: - 100K+ writes/sec - p99 latency: 10ms</p>"},{"location":"crates/nori-wal/performance/tuning/#low-latency-reads","title":"Low-Latency Reads","text":"<p>Goal: Minimize read latency.</p> <p>Strategy:</p> <p>WAL is optimized for writes, not reads. For fast reads:</p> <ol> <li>Build an in-memory index (see Key-Value Store recipe)</li> <li>Use snapshots to avoid scanning entire WAL</li> <li>Keep frequently accessed data in memory</li> </ol> <p>Example:</p> <pre><code>pub struct FastKvStore {\n    data: HashMap&lt;Bytes, Bytes&gt;,  // In-memory for O(1) reads\n    wal: Wal,                      // For durability\n}\n\nimpl FastKvStore {\n    pub fn get(&amp;self, key: &amp;[u8]) -&gt; Option&lt;&amp;[u8]&gt; {\n        // O(1) read from memory\n        self.data.get(key).map(|v| v.as_ref())\n    }\n\n    pub async fn put(&amp;mut self, key: &amp;[u8], value: &amp;[u8]) -&gt; Result&lt;()&gt; {\n        // Write to WAL first\n        self.wal.append(&amp;Record::put(key, value)).await?;\n\n        // Then update in-memory\n        self.data.insert(key.into(), value.into());\n\n        Ok(())\n    }\n}\n</code></pre> <p>Expected Performance: - Read latency: &lt;1\u00b5s (memory lookup) - Write latency: 10ms (WAL write + fsync)</p>"},{"location":"crates/nori-wal/performance/tuning/#durability-critical-workloads","title":"Durability-Critical Workloads","text":"<p>Goal: Never lose data, even on crash.</p> <p>Configuration:</p> <pre><code>let config = WalConfig {\n    fsync_policy: FsyncPolicy::Always,         // Fsync every write\n    max_segment_size: 128 * 1024 * 1024,       // Smaller segments\n    preallocate: true,                         // Detect disk full early\n    node_id: 0,\n};\n</code></pre> <p>Code Pattern:</p> <pre><code>// Sync after every write\nwal.append(&amp;record).await?;\nwal.sync().await?;  // Ensure on disk before proceeding\n</code></pre> <p>Expected Performance: - 400 writes/sec (disk bound) - p99 latency: 3ms</p> <p>Optimization: Use faster storage (NVMe SSD, Optane).</p>"},{"location":"crates/nori-wal/performance/tuning/#large-record-workloads","title":"Large Record Workloads","text":"<p>Goal: Store large values (&gt;100 KB) efficiently.</p> <p>Configuration:</p> <pre><code>let config = WalConfig {\n    max_segment_size: 1024 * 1024 * 1024,      // 1 GB segments\n    fsync_policy: FsyncPolicy::Batch(\n        Duration::from_millis(5)\n    ),\n    preallocate: false,                        // Don't preallocate (wastes space)\n    node_id: 0,\n};\n</code></pre> <p>Code Pattern:</p> <pre><code>// Compress large records\nlet large_value = vec![0u8; 1_000_000];  // 1 MB\n\nlet record = Record::put(b\"key\", &amp;large_value)\n    .with_compression(Compression::Zstd);\n\nwal.append(&amp;record).await?;\n</code></pre> <p>Expected Performance: - 50 MB/sec throughput - 16x compression ratio for text</p>"},{"location":"crates/nori-wal/performance/tuning/#configuration-parameters","title":"Configuration Parameters","text":""},{"location":"crates/nori-wal/performance/tuning/#max_segment_size","title":"<code>max_segment_size</code>","text":"<p>What it does: Maximum size of a single segment file before rotation.</p> <p>Default: 128 MB</p> <p>Tuning:</p> Workload Recommended Size Reason High write rate 512 MB - 1 GB Reduce rotation overhead Low write rate 64 MB - 128 MB Faster recovery, less space waste Large records 1 GB+ Avoid frequent rotation <p>Trade-offs:</p> <ul> <li>Larger: Less rotation, but longer recovery time</li> <li>Smaller: Faster recovery, but more rotation overhead</li> </ul>"},{"location":"crates/nori-wal/performance/tuning/#fsync_policy","title":"<code>fsync_policy</code>","text":"<p>What it does: Controls when data is fsynced to disk.</p> <p>Options:</p> Policy Use Case Throughput Durability <code>Always</code> Financial transactions, critical data 400 writes/sec Maximum <code>Batch(1ms)</code> Conservative durability 55K writes/sec 1ms loss window <code>Batch(5ms)</code> Balanced (recommended) 86K writes/sec 5ms loss window <code>Batch(10ms)</code> High throughput 100K writes/sec 10ms loss window <code>Os</code> Maximum speed, no guarantees 110K writes/sec None <p>Recommendation: Start with <code>Batch(5ms)</code> and adjust based on needs.</p>"},{"location":"crates/nori-wal/performance/tuning/#preallocate","title":"<code>preallocate</code>","text":"<p>What it does: Pre-allocates segment file space on creation.</p> <p>Default: <code>true</code></p> <p>Trade-offs:</p> Setting Pros Cons <code>true</code> Early disk-full detection, less fragmentation Slower segment creation (12ms) <code>false</code> Fast segment creation (2ms) Disk full errors during writes <p>Recommendation: Keep <code>true</code> unless you have very frequent rotation (&lt;1 second segments).</p>"},{"location":"crates/nori-wal/performance/tuning/#advanced-techniques","title":"Advanced Techniques","text":""},{"location":"crates/nori-wal/performance/tuning/#custom-batching-strategy","title":"Custom Batching Strategy","text":"<p>Implement application-level batching:</p> <pre><code>pub struct BatchingWal {\n    wal: Wal,\n    buffer: Vec&lt;Record&gt;,\n    batch_size: usize,\n}\n\nimpl BatchingWal {\n    pub async fn append(&amp;mut self, record: Record) -&gt; Result&lt;()&gt; {\n        self.buffer.push(record);\n\n        if self.buffer.len() &gt;= self.batch_size {\n            self.flush().await?;\n        }\n\n        Ok(())\n    }\n\n    pub async fn flush(&amp;mut self) -&gt; Result&lt;()&gt; {\n        for record in self.buffer.drain(..) {\n            self.wal.append(&amp;record).await?;\n        }\n        self.wal.sync().await?;\n\n        Ok(())\n    }\n}\n</code></pre> <p>Benefit: Amortize fsync cost across many writes.</p>"},{"location":"crates/nori-wal/performance/tuning/#parallel-segment-readers","title":"Parallel Segment Readers","text":"<p>For replay/recovery, read segments in parallel:</p> <pre><code>pub async fn parallel_replay(wal: &amp;Wal) -&gt; Result&lt;Vec&lt;Record&gt;&gt; {\n    let segments = wal.list_segments().await?;\n\n    let handles: Vec&lt;_&gt; = segments.into_iter()\n        .map(|segment_id| {\n            let wal = wal.clone();\n            tokio::spawn(async move {\n                let mut records = Vec::new();\n                let mut reader = wal.read_segment(segment_id).await?;\n\n                while let Some((record, _)) = reader.next_record().await? {\n                    records.push(record);\n                }\n\n                Ok::&lt;_, anyhow::Error&gt;(records)\n            })\n        })\n        .collect();\n\n    let mut all_records = Vec::new();\n    for handle in handles {\n        all_records.extend(handle.await??);\n    }\n\n    Ok(all_records)\n}\n</code></pre> <p>Benefit: 4-8x faster recovery on multi-core systems.</p>"},{"location":"crates/nori-wal/performance/tuning/#compression-selection","title":"Compression Selection","text":"<p>Choose compression based on data:</p> <pre><code>fn choose_compression(value: &amp;[u8]) -&gt; Compression {\n    if value.len() &lt; 1024 {\n        Compression::None  // Small values: overhead not worth it\n    } else if is_text_or_json(value) {\n        Compression::Lz4  // Fast compression for text\n    } else {\n        Compression::None  // Binary data often incompressible\n    }\n}\n</code></pre> <p>Benefit: Only compress when it helps.</p>"},{"location":"crates/nori-wal/performance/tuning/#monitoring-and-tuning-workflow","title":"Monitoring and Tuning Workflow","text":""},{"location":"crates/nori-wal/performance/tuning/#1-establish-baseline","title":"1. Establish Baseline","text":"<p>Measure current performance:</p> <pre><code>let start = Instant::now();\n\nfor i in 0..10_000 {\n    wal.append(&amp;Record::put(&amp;format!(\"key{}\", i), b\"value\")).await?;\n}\nwal.sync().await?;\n\nlet elapsed = start.elapsed();\nprintln!(\"Throughput: {} writes/sec\", 10_000.0 / elapsed.as_secs_f64());\n</code></pre>"},{"location":"crates/nori-wal/performance/tuning/#2-identify-bottleneck","title":"2. Identify Bottleneck","text":"<p>Check metrics:</p> <pre><code>// Write latency\nlet start = Instant::now();\nwal.append(&amp;record).await?;\nlet write_latency = start.elapsed();\n\n// Fsync latency\nlet start = Instant::now();\nwal.sync().await?;\nlet fsync_latency = start.elapsed();\n\nprintln!(\"Write: {:?}, Fsync: {:?}\", write_latency, fsync_latency);\n</code></pre> <p>Common bottlenecks: - High fsync latency \u2192 Use batching or faster disk - High write latency \u2192 Reduce record size or use compression - Frequent rotation \u2192 Increase segment size</p>"},{"location":"crates/nori-wal/performance/tuning/#3-apply-tuning","title":"3. Apply Tuning","text":"<p>Make one change at a time:</p> <ol> <li>Change <code>fsync_policy</code> to <code>Batch(5ms)</code></li> <li>Measure improvement</li> <li>If not enough, try batching writes</li> <li>If still not enough, increase segment size</li> <li>If still not enough, upgrade hardware</li> </ol>"},{"location":"crates/nori-wal/performance/tuning/#4-verify","title":"4. Verify","text":"<p>Run for extended period (24+ hours):</p> <pre><code>// Track p99 latency\nlet mut latencies = Vec::new();\n\nfor _ in 0..100_000 {\n    let start = Instant::now();\n    wal.append(&amp;record).await?;\n    latencies.push(start.elapsed());\n}\n\nlatencies.sort();\nlet p99 = latencies[(latencies.len() * 99) / 100];\nprintln!(\"p99 latency: {:?}\", p99);\n</code></pre>"},{"location":"crates/nori-wal/performance/tuning/#common-pitfalls","title":"Common Pitfalls","text":""},{"location":"crates/nori-wal/performance/tuning/#1-not-batching-syncs","title":"1. Not Batching Syncs","text":"<p>Problem:</p> <pre><code>// Bad: Sync after every write\nfor record in records {\n    wal.append(&amp;record).await?;\n    wal.sync().await?;  // 2-3ms penalty each time\n}\n</code></pre> <p>Solution: Batch syncs (see Batched Writes benchmark).</p>"},{"location":"crates/nori-wal/performance/tuning/#2-segments-too-small","title":"2. Segments Too Small","text":"<p>Problem: <code>max_segment_size: 1024 * 1024</code> (1 MB) causes rotation every second.</p> <p>Impact: 15ms pause every second (1.5% overhead).</p> <p>Solution: Use at least 64 MB segments.</p>"},{"location":"crates/nori-wal/performance/tuning/#3-ignoring-disk-speed","title":"3. Ignoring Disk Speed","text":"<p>Problem: HDD gives 100 IOPS, NVMe gives 500K IOPS.</p> <p>Impact: 5000x performance difference.</p> <p>Solution: Profile disk speed:</p> <pre><code># Linux\nsudo fio --name=random-write --ioengine=libaio --rw=randwrite --bs=4k --size=1G --numjobs=1 --runtime=60 --direct=1 --filename=/path/to/wal/testfile\n\n# macOS\ndd if=/dev/zero of=/path/to/wal/testfile bs=4k count=250000\n</code></pre> <p>If disk is slow, WAL performance will be limited.</p>"},{"location":"crates/nori-wal/performance/tuning/#4-not-pre-allocating","title":"4. Not Pre-allocating","text":"<p>Problem: <code>preallocate: false</code> + full disk = corruption.</p> <p>Solution: Keep <code>preallocate: true</code> unless you have good monitoring.</p>"},{"location":"crates/nori-wal/performance/tuning/#performance-checklist","title":"Performance Checklist","text":"<p>Before deploying to production:</p> <ul> <li> Measured baseline performance on target hardware</li> <li> Chose appropriate <code>fsync_policy</code> for durability requirements</li> <li> Implemented write batching (if needed)</li> <li> Set <code>max_segment_size</code> based on write rate</li> <li> Enabled compression for large text/JSON records</li> <li> Verified disk is fast enough (SSD minimum, NVMe recommended)</li> <li> Tested recovery time with realistic data size</li> <li> Monitored p99 latency under load</li> <li> Set up alerts for slow writes/rotation</li> </ul>"},{"location":"crates/nori-wal/performance/tuning/#conclusion","title":"Conclusion","text":"<p>Performance tuning is iterative:</p> <ol> <li>Measure current performance</li> <li>Identify bottleneck</li> <li>Apply one change</li> <li>Verify improvement</li> <li>Repeat</li> </ol> <p>Most workloads get good performance with:</p> <pre><code>let config = WalConfig {\n    max_segment_size: 256 * 1024 * 1024,\n    fsync_policy: FsyncPolicy::Batch(Duration::from_millis(5)),\n    preallocate: true,\n    node_id: 0,\n};\n</code></pre> <p>Adjust from there based on your specific needs.</p>"},{"location":"crates/nori-wal/recipes/","title":"Recipes","text":"<p>Practical examples and common patterns for using nori-wal.</p> <p>This section provides complete, working examples for common use cases. Each recipe is a fully functional implementation you can adapt for your needs.</p>"},{"location":"crates/nori-wal/recipes/#available-recipes","title":"Available Recipes","text":""},{"location":"crates/nori-wal/recipes/#building-a-key-value-store","title":"Building a Key-Value Store","text":"<p>Complete implementation of an in-memory key-value store with WAL durability.</p> <p>What you'll learn: - Using WAL for durability - Rebuilding state from WAL on recovery - Handling PUT and DELETE operations - Implementing snapshots</p>"},{"location":"crates/nori-wal/recipes/#event-sourcing","title":"Event Sourcing","text":"<p>Event-sourced system with command handling and event replay.</p> <p>What you'll learn: - Appending events to WAL - Event replay and state reconstruction - Handling event versioning - Snapshotting for performance</p>"},{"location":"crates/nori-wal/recipes/#message-queue","title":"Message Queue","text":"<p>Simple message queue with consumer position tracking.</p> <p>What you'll learn: - Publishing messages to WAL - Consumer offset management - Multiple consumers - Retention and cleanup</p>"},{"location":"crates/nori-wal/recipes/#replication","title":"Replication","text":"<p>Replicating WAL to followers for high availability.</p> <p>What you'll learn: - Streaming WAL to replicas - Handling network failures - Catchup after disconnection - Consistency guarantees</p>"},{"location":"crates/nori-wal/recipes/#custom-serialization","title":"Custom Serialization","text":"<p>Using different serialization formats with WAL.</p> <p>What you'll learn: - Protobuf with WAL - JSON with compression - MessagePack for efficiency - Schema evolution</p>"},{"location":"crates/nori-wal/recipes/#performance-tuning","title":"Performance Tuning","text":"<p>Optimizing WAL for your workload.</p> <p>What you'll learn: - Choosing segment size - Batching strategies - Compression trade-offs - Monitoring and profiling</p>"},{"location":"crates/nori-wal/recipes/#using-these-recipes","title":"Using These Recipes","text":"<p>Each recipe follows this structure:</p> <ol> <li>Problem - What we're trying to solve</li> <li>Solution - Complete working code</li> <li>How it works - Step-by-step explanation</li> <li>Testing - How to verify it works</li> <li>Production considerations - What to watch out for</li> </ol> <p>You can copy and adapt the code directly into your projects.</p>"},{"location":"crates/nori-wal/recipes/#code-examples","title":"Code Examples","text":"<p>All examples use: - Rust 2021 edition - <code>tokio</code> for async runtime - <code>anyhow</code> for error handling (you can use any error handling) - Latest stable Rust</p>"},{"location":"crates/nori-wal/recipes/#running-the-examples","title":"Running the Examples","text":"<pre><code># Clone the examples\ngit clone https://github.com/jeffhajewski/norikv\ncd nori/examples\n\n# Run a recipe\ncargo run --example key-value-store\ncargo run --example event-sourcing\ncargo run --example message-queue\n</code></pre> <p>Or copy the code from the recipe pages and integrate into your project.</p>"},{"location":"crates/nori-wal/recipes/#contributing-recipes","title":"Contributing Recipes","text":"<p>Have a useful pattern? Contribute it!</p> <ol> <li>Fork the repository</li> <li>Add your recipe to <code>docs/recipes/</code></li> <li>Follow the recipe template</li> <li>Submit a pull request</li> </ol> <p>See Contributing Guide for details.</p>"},{"location":"crates/nori-wal/recipes/event-sourcing/","title":"Event Sourcing with nori-wal","text":"<p>Building an event-sourced system using WAL for durable event storage.</p>"},{"location":"crates/nori-wal/recipes/event-sourcing/#table-of-contents","title":"Table of contents","text":""},{"location":"crates/nori-wal/recipes/event-sourcing/#problem","title":"Problem","text":"<p>You want to build an event-sourced application where: - All state changes are captured as events - Events are immutable and append-only - State can be reconstructed by replaying events - Events survive crashes and restarts</p>"},{"location":"crates/nori-wal/recipes/event-sourcing/#solution","title":"Solution","text":"<pre><code>use nori_wal::{Wal, WalConfig, Record, Position};\nuse serde::{Serialize, Deserialize};\nuse bytes::Bytes;\nuse anyhow::Result;\nuse std::path::PathBuf;\n\n/// Base event trait with metadata\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Event {\n    pub event_id: u64,\n    pub event_type: String,\n    pub timestamp: u64,\n    pub payload: Bytes,\n}\n\n/// Example: Bank account events\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum AccountEvent {\n    AccountOpened { account_id: String, initial_balance: i64 },\n    MoneyDeposited { account_id: String, amount: i64 },\n    MoneyWithdrawn { account_id: String, amount: i64 },\n    AccountClosed { account_id: String },\n}\n\n/// Account state (derived from events)\n#[derive(Debug, Clone)]\npub struct Account {\n    pub id: String,\n    pub balance: i64,\n    pub is_closed: bool,\n}\n\n/// Event store using WAL\npub struct EventStore {\n    wal: Wal,\n    next_event_id: u64,\n}\n\nimpl EventStore {\n    /// Opens or creates an event store\n    pub async fn open(path: impl Into&lt;PathBuf&gt;) -&gt; Result&lt;Self&gt; {\n        let path = path.into();\n\n        let config = WalConfig {\n            dir: path.join(\"events\"),\n            max_segment_size: 128 * 1024 * 1024,\n            fsync_policy: nori_wal::FsyncPolicy::Batch(\n                std::time::Duration::from_millis(5)\n            ),\n            preallocate: true,\n            node_id: 0,\n        };\n\n        let (wal, recovery_info) = Wal::open(config).await?;\n\n        println!(\"Event store recovered:\");\n        println!(\"  Events: {}\", recovery_info.valid_records);\n        println!(\"  Segments: {}\", recovery_info.segments_scanned);\n\n        // Find highest event ID\n        let mut next_event_id = 0u64;\n        let mut reader = wal.read_from(Position { segment_id: 0, offset: 0 }).await?;\n\n        while let Some((record, _)) = reader.next_record().await? {\n            if let Ok(event) = serde_json::from_slice::&lt;Event&gt;(&amp;record.value) {\n                next_event_id = next_event_id.max(event.event_id + 1);\n            }\n        }\n\n        println!(\"  Next event ID: {}\", next_event_id);\n\n        Ok(Self { wal, next_event_id })\n    }\n\n    /// Appends an event to the store\n    pub async fn append_event(\n        &amp;mut self,\n        event_type: String,\n        payload: Bytes,\n    ) -&gt; Result&lt;u64&gt; {\n        let event = Event {\n            event_id: self.next_event_id,\n            event_type,\n            timestamp: std::time::SystemTime::now()\n                .duration_since(std::time::UNIX_EPOCH)?\n                .as_secs(),\n            payload,\n        };\n\n        // Serialize event\n        let event_bytes = serde_json::to_vec(&amp;event)?;\n\n        // Write to WAL\n        let record = Record::put(&amp;event.event_id.to_le_bytes(), &amp;event_bytes);\n        self.wal.append(&amp;record).await?;\n\n        let event_id = self.next_event_id;\n        self.next_event_id += 1;\n\n        Ok(event_id)\n    }\n\n    /// Syncs events to disk\n    pub async fn sync(&amp;self) -&gt; Result&lt;()&gt; {\n        self.wal.sync().await?;\n        Ok(())\n    }\n\n    /// Reads all events from the store\n    pub async fn read_all_events(&amp;self) -&gt; Result&lt;Vec&lt;Event&gt;&gt; {\n        let mut events = Vec::new();\n        let mut reader = self.wal.read_from(Position { segment_id: 0, offset: 0 }).await?;\n\n        while let Some((record, _)) = reader.next_record().await? {\n            if let Ok(event) = serde_json::from_slice::&lt;Event&gt;(&amp;record.value) {\n                events.push(event);\n            }\n        }\n\n        Ok(events)\n    }\n\n    /// Reads events from a specific position\n    pub async fn read_from(&amp;self, from_event_id: u64) -&gt; Result&lt;Vec&lt;Event&gt;&gt; {\n        let mut events = Vec::new();\n        let mut reader = self.wal.read_from(Position { segment_id: 0, offset: 0 }).await?;\n\n        while let Some((record, _)) = reader.next_record().await? {\n            if let Ok(event) = serde_json::from_slice::&lt;Event&gt;(&amp;record.value) {\n                if event.event_id &gt;= from_event_id {\n                    events.push(event);\n                }\n            }\n        }\n\n        Ok(events)\n    }\n\n    /// Gracefully closes the event store\n    pub async fn close(self) -&gt; Result&lt;()&gt; {\n        self.wal.close().await?;\n        Ok(())\n    }\n}\n\n/// Application service using event sourcing\npub struct AccountService {\n    event_store: EventStore,\n}\n\nimpl AccountService {\n    pub async fn new(path: impl Into&lt;PathBuf&gt;) -&gt; Result&lt;Self&gt; {\n        let event_store = EventStore::open(path).await?;\n        Ok(Self { event_store })\n    }\n\n    /// Opens a new account\n    pub async fn open_account(&amp;mut self, account_id: String, initial_balance: i64) -&gt; Result&lt;u64&gt; {\n        let event = AccountEvent::AccountOpened {\n            account_id,\n            initial_balance,\n        };\n\n        let payload = serde_json::to_vec(&amp;event)?;\n        let event_id = self.event_store.append_event(\n            \"AccountOpened\".to_string(),\n            Bytes::from(payload),\n        ).await?;\n\n        Ok(event_id)\n    }\n\n    /// Deposits money\n    pub async fn deposit(&amp;mut self, account_id: String, amount: i64) -&gt; Result&lt;u64&gt; {\n        let event = AccountEvent::MoneyDeposited {\n            account_id,\n            amount,\n        };\n\n        let payload = serde_json::to_vec(&amp;event)?;\n        let event_id = self.event_store.append_event(\n            \"MoneyDeposited\".to_string(),\n            Bytes::from(payload),\n        ).await?;\n\n        Ok(event_id)\n    }\n\n    /// Withdraws money\n    pub async fn withdraw(&amp;mut self, account_id: String, amount: i64) -&gt; Result&lt;u64&gt; {\n        // First, check current balance by replaying events\n        let account = self.get_account_state(&amp;account_id).await?;\n\n        if account.balance &lt; amount {\n            return Err(anyhow::anyhow!(\"Insufficient balance\"));\n        }\n\n        let event = AccountEvent::MoneyWithdrawn {\n            account_id,\n            amount,\n        };\n\n        let payload = serde_json::to_vec(&amp;event)?;\n        let event_id = self.event_store.append_event(\n            \"MoneyWithdrawn\".to_string(),\n            Bytes::from(payload),\n        ).await?;\n\n        Ok(event_id)\n    }\n\n    /// Gets account state by replaying events\n    pub async fn get_account_state(&amp;self, account_id: &amp;str) -&gt; Result&lt;Account&gt; {\n        let events = self.event_store.read_all_events().await?;\n\n        let mut account = Account {\n            id: account_id.to_string(),\n            balance: 0,\n            is_closed: false,\n        };\n\n        for event in events {\n            if let Ok(account_event) = serde_json::from_slice::&lt;AccountEvent&gt;(&amp;event.payload) {\n                match account_event {\n                    AccountEvent::AccountOpened { account_id: id, initial_balance } =&gt; {\n                        if id == account_id {\n                            account.balance = initial_balance;\n                        }\n                    }\n                    AccountEvent::MoneyDeposited { account_id: id, amount } =&gt; {\n                        if id == account_id {\n                            account.balance += amount;\n                        }\n                    }\n                    AccountEvent::MoneyWithdrawn { account_id: id, amount } =&gt; {\n                        if id == account_id {\n                            account.balance -= amount;\n                        }\n                    }\n                    AccountEvent::AccountClosed { account_id: id } =&gt; {\n                        if id == account_id {\n                            account.is_closed = true;\n                        }\n                    }\n                }\n            }\n        }\n\n        Ok(account)\n    }\n\n    /// Syncs events to disk\n    pub async fn sync(&amp;self) -&gt; Result&lt;()&gt; {\n        self.event_store.sync().await\n    }\n\n    /// Closes the service\n    pub async fn close(self) -&gt; Result&lt;()&gt; {\n        self.event_store.close().await\n    }\n}\n\n// Example usage\n#[tokio::main]\nasync fn main() -&gt; Result&lt;()&gt; {\n    let mut service = AccountService::new(\"./event_store\").await?;\n\n    // Open account\n    service.open_account(\"alice\".to_string(), 1000).await?;\n\n    // Perform operations\n    service.deposit(\"alice\".to_string(), 500).await?;\n    service.withdraw(\"alice\".to_string(), 200).await?;\n\n    // Sync to ensure durability\n    service.sync().await?;\n\n    // Query current state\n    let account = service.get_account_state(\"alice\").await?;\n    println!(\"Alice's balance: ${}\", account.balance);\n\n    // Close service\n    service.close().await?;\n\n    Ok(())\n}\n</code></pre>"},{"location":"crates/nori-wal/recipes/event-sourcing/#how-it-works","title":"How It Works","text":""},{"location":"crates/nori-wal/recipes/event-sourcing/#1-event-storage","title":"1. Event Storage","text":"<p>Events are stored as WAL records:</p> <pre><code>pub async fn append_event(&amp;mut self, event_type: String, payload: Bytes) -&gt; Result&lt;u64&gt; {\n    let event = Event {\n        event_id: self.next_event_id,\n        event_type,\n        timestamp: current_timestamp(),\n        payload,\n    };\n\n    let event_bytes = serde_json::to_vec(&amp;event)?;\n    let record = Record::put(&amp;event.event_id.to_le_bytes(), &amp;event_bytes);\n    self.wal.append(&amp;record).await?;\n\n    self.next_event_id += 1;\n    Ok(event.event_id)\n}\n</code></pre>"},{"location":"crates/nori-wal/recipes/event-sourcing/#2-state-reconstruction","title":"2. State Reconstruction","text":"<p>State is derived by replaying all events:</p> <pre><code>pub async fn get_account_state(&amp;self, account_id: &amp;str) -&gt; Result&lt;Account&gt; {\n    let events = self.event_store.read_all_events().await?;\n\n    let mut account = Account::default();\n\n    for event in events {\n        // Apply event to state\n        match event {\n            AccountEvent::AccountOpened { initial_balance, .. } =&gt; {\n                account.balance = initial_balance;\n            }\n            AccountEvent::MoneyDeposited { amount, .. } =&gt; {\n                account.balance += amount;\n            }\n            // ... other events\n        }\n    }\n\n    Ok(account)\n}\n</code></pre>"},{"location":"crates/nori-wal/recipes/event-sourcing/#3-command-validation","title":"3. Command Validation","text":"<p>Commands validate against current state before appending events:</p> <pre><code>pub async fn withdraw(&amp;mut self, account_id: String, amount: i64) -&gt; Result&lt;u64&gt; {\n    // 1. Rebuild state\n    let account = self.get_account_state(&amp;account_id).await?;\n\n    // 2. Validate command\n    if account.balance &lt; amount {\n        return Err(anyhow::anyhow!(\"Insufficient balance\"));\n    }\n\n    // 3. Append event\n    let event = AccountEvent::MoneyWithdrawn { account_id, amount };\n    self.event_store.append_event(event).await\n}\n</code></pre>"},{"location":"crates/nori-wal/recipes/event-sourcing/#testing","title":"Testing","text":"<pre><code>#[cfg(test)]\nmod tests {\n    use super::*;\n    use tempfile::TempDir;\n\n    #[tokio::test]\n    async fn test_event_sourcing_basic() {\n        let dir = TempDir::new().unwrap();\n        let mut service = AccountService::new(dir.path()).await.unwrap();\n\n        // Open account\n        service.open_account(\"alice\".to_string(), 1000).await.unwrap();\n\n        // Deposit\n        service.deposit(\"alice\".to_string(), 500).await.unwrap();\n\n        // Check state\n        let account = service.get_account_state(\"alice\").await.unwrap();\n        assert_eq!(account.balance, 1500);\n    }\n\n    #[tokio::test]\n    async fn test_event_replay() {\n        let dir = TempDir::new().unwrap();\n\n        // Write events\n        {\n            let mut service = AccountService::new(dir.path()).await.unwrap();\n            service.open_account(\"bob\".to_string(), 2000).await.unwrap();\n            service.deposit(\"bob\".to_string(), 1000).await.unwrap();\n            service.withdraw(\"bob\".to_string(), 500).await.unwrap();\n            service.sync().await.unwrap();\n        }\n\n        // Reopen and verify state is reconstructed\n        {\n            let service = AccountService::new(dir.path()).await.unwrap();\n            let account = service.get_account_state(\"bob\").await.unwrap();\n            assert_eq!(account.balance, 2500);\n        }\n    }\n\n    #[tokio::test]\n    async fn test_insufficient_balance() {\n        let dir = TempDir::new().unwrap();\n        let mut service = AccountService::new(dir.path()).await.unwrap();\n\n        service.open_account(\"charlie\".to_string(), 100).await.unwrap();\n\n        // Try to withdraw more than balance\n        let result = service.withdraw(\"charlie\".to_string(), 200).await;\n        assert!(result.is_err());\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/recipes/event-sourcing/#production-considerations","title":"Production Considerations","text":""},{"location":"crates/nori-wal/recipes/event-sourcing/#1-snapshots","title":"1. Snapshots","text":"<p>Replaying millions of events is slow. Add snapshots:</p> <pre><code>pub struct EventStore {\n    wal: Wal,\n    next_event_id: u64,\n    snapshot_dir: PathBuf,\n}\n\nimpl EventStore {\n    /// Creates a snapshot at current position\n    pub async fn create_snapshot(&amp;self, state: &amp;impl Serialize) -&gt; Result&lt;u64&gt; {\n        let snapshot_id = self.next_event_id - 1;\n        let snapshot_path = self.snapshot_dir.join(format!(\"{}.snapshot\", snapshot_id));\n\n        let snapshot_bytes = serde_json::to_vec(state)?;\n        tokio::fs::write(&amp;snapshot_path, snapshot_bytes).await?;\n\n        Ok(snapshot_id)\n    }\n\n    /// Loads latest snapshot\n    pub async fn load_snapshot&lt;T: DeserializeOwned&gt;(&amp;self) -&gt; Result&lt;Option&lt;(u64, T)&gt;&gt; {\n        let mut snapshots = Vec::new();\n\n        let mut entries = tokio::fs::read_dir(&amp;self.snapshot_dir).await?;\n        while let Some(entry) = entries.next_entry().await? {\n            if let Some(name) = entry.file_name().to_str() {\n                if let Some(id_str) = name.strip_suffix(\".snapshot\") {\n                    if let Ok(id) = id_str.parse::&lt;u64&gt;() {\n                        snapshots.push(id);\n                    }\n                }\n            }\n        }\n\n        if snapshots.is_empty() {\n            return Ok(None);\n        }\n\n        // Load most recent snapshot\n        snapshots.sort();\n        let latest_id = snapshots.last().unwrap();\n        let snapshot_path = self.snapshot_dir.join(format!(\"{}.snapshot\", latest_id));\n\n        let snapshot_bytes = tokio::fs::read(&amp;snapshot_path).await?;\n        let state = serde_json::from_slice(&amp;snapshot_bytes)?;\n\n        Ok(Some((*latest_id, state)))\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/recipes/event-sourcing/#2-event-versioning","title":"2. Event Versioning","text":"<p>Events evolve over time. Use versioning:</p> <pre><code>#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum AccountEventV1 {\n    AccountOpened { account_id: String, initial_balance: i64 },\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum AccountEventV2 {\n    AccountOpened { account_id: String, initial_balance: i64, currency: String },\n    MoneyDeposited { account_id: String, amount: i64 },\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(tag = \"version\")]\npub enum VersionedEvent {\n    V1(AccountEventV1),\n    V2(AccountEventV2),\n}\n\n// Upcasting from V1 to V2\nimpl From&lt;AccountEventV1&gt; for AccountEventV2 {\n    fn from(v1: AccountEventV1) -&gt; Self {\n        match v1 {\n            AccountEventV1::AccountOpened { account_id, initial_balance } =&gt; {\n                AccountEventV2::AccountOpened {\n                    account_id,\n                    initial_balance,\n                    currency: \"USD\".to_string(), // Default for old events\n                }\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/recipes/event-sourcing/#3-projections","title":"3. Projections","text":"<p>Maintain read models for fast queries:</p> <pre><code>pub struct AccountProjection {\n    accounts: HashMap&lt;String, Account&gt;,\n    last_processed_event: u64,\n}\n\nimpl AccountProjection {\n    pub async fn update_from_events(&amp;mut self, events: Vec&lt;Event&gt;) -&gt; Result&lt;()&gt; {\n        for event in events {\n            if event.event_id &lt;= self.last_processed_event {\n                continue; // Already processed\n            }\n\n            // Apply event to projection\n            if let Ok(account_event) = serde_json::from_slice::&lt;AccountEvent&gt;(&amp;event.payload) {\n                self.apply_event(account_event);\n            }\n\n            self.last_processed_event = event.event_id;\n        }\n\n        Ok(())\n    }\n\n    fn apply_event(&amp;mut self, event: AccountEvent) {\n        // Update in-memory projection\n        match event {\n            AccountEvent::AccountOpened { account_id, initial_balance } =&gt; {\n                self.accounts.insert(account_id.clone(), Account {\n                    id: account_id,\n                    balance: initial_balance,\n                    is_closed: false,\n                });\n            }\n            // ... other events\n        }\n    }\n\n    pub fn get_account(&amp;self, account_id: &amp;str) -&gt; Option&lt;&amp;Account&gt; {\n        self.accounts.get(account_id)\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/recipes/event-sourcing/#4-monitoring","title":"4. Monitoring","text":"<p>Track event store metrics:</p> <pre><code>// Events appended\nmetrics.counter(\"events.appended\", 1);\n\n// Event types\nmetrics.counter(\"events.type\", 1, &amp;[(\"type\", event.event_type)]);\n\n// Replay time\nlet start = Instant::now();\nlet events = store.read_all_events().await?;\nmetrics.histogram(\"events.replay_ms\", start.elapsed().as_millis());\n</code></pre>"},{"location":"crates/nori-wal/recipes/event-sourcing/#enhancements","title":"Enhancements","text":""},{"location":"crates/nori-wal/recipes/event-sourcing/#time-travel-queries","title":"Time Travel Queries","text":"<p>Query state at any point in time:</p> <pre><code>pub async fn get_account_state_at(\n    &amp;self,\n    account_id: &amp;str,\n    timestamp: u64,\n) -&gt; Result&lt;Account&gt; {\n    let events = self.event_store.read_all_events().await?;\n\n    let mut account = Account::default();\n\n    for event in events {\n        if event.timestamp &gt; timestamp {\n            break; // Stop at target time\n        }\n\n        // Apply event\n        // ...\n    }\n\n    Ok(account)\n}\n</code></pre>"},{"location":"crates/nori-wal/recipes/event-sourcing/#event-subscriptions","title":"Event Subscriptions","text":"<p>Stream events to subscribers:</p> <pre><code>pub struct EventSubscriber {\n    store: EventStore,\n    last_seen_event: u64,\n}\n\nimpl EventSubscriber {\n    pub async fn poll_new_events(&amp;mut self) -&gt; Result&lt;Vec&lt;Event&gt;&gt; {\n        let events = self.store.read_from(self.last_seen_event + 1).await?;\n\n        if let Some(last) = events.last() {\n            self.last_seen_event = last.event_id;\n        }\n\n        Ok(events)\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/recipes/event-sourcing/#conclusion","title":"Conclusion","text":"<p>This recipe demonstrates: - Using WAL for event storage - Rebuilding state from events - Command validation - Event replay and recovery</p> <p>For distributed event sourcing, combine with Replication recipe.</p>"},{"location":"crates/nori-wal/recipes/key-value-store/","title":"Building a Key-Value Store","text":"<p>Complete implementation of a durable key-value store using nori-wal.</p>"},{"location":"crates/nori-wal/recipes/key-value-store/#table-of-contents","title":"Table of contents","text":""},{"location":"crates/nori-wal/recipes/key-value-store/#problem","title":"Problem","text":"<p>You want to build a simple key-value store where: - Data survives crashes and restarts - Fast in-memory reads - Durable writes - Support for PUT and DELETE operations</p>"},{"location":"crates/nori-wal/recipes/key-value-store/#solution","title":"Solution","text":"<pre><code>use nori_wal::{Wal, WalConfig, Record, Position};\nuse std::collections::HashMap;\nuse std::path::PathBuf;\nuse anyhow::Result;\nuse bytes::Bytes;\n\n/// A simple key-value store with WAL durability.\npub struct KvStore {\n    /// In-memory data structure for fast reads\n    data: HashMap&lt;Bytes, Bytes&gt;,\n    /// Write-ahead log for durability\n    wal: Wal,\n}\n\nimpl KvStore {\n    /// Opens or creates a KV store at the given path.\n    pub async fn open(path: impl Into&lt;PathBuf&gt;) -&gt; Result&lt;Self&gt; {\n        let path = path.into();\n\n        // Configure WAL\n        let config = WalConfig {\n            dir: path.join(\"wal\"),\n            max_segment_size: 128 * 1024 * 1024,  // 128 MB segments\n            fsync_policy: nori_wal::FsyncPolicy::Batch(\n                std::time::Duration::from_millis(5)\n            ),\n            preallocate: true,\n            node_id: 0,\n        };\n\n        // Open WAL (performs recovery automatically)\n        let (wal, recovery_info) = Wal::open(config).await?;\n\n        println!(\"Recovery complete:\");\n        println!(\"  Valid records: {}\", recovery_info.valid_records);\n        println!(\"  Segments scanned: {}\", recovery_info.segments_scanned);\n\n        if recovery_info.corruption_detected {\n            println!(\"  WARNING: {} bytes truncated due to corruption\",\n                recovery_info.bytes_truncated);\n        }\n\n        // Rebuild in-memory state from WAL\n        let mut data = HashMap::new();\n        let mut reader = wal.read_from(Position { segment_id: 0, offset: 0 }).await?;\n\n        while let Some((record, _position)) = reader.next_record().await? {\n            if record.tombstone {\n                // DELETE operation\n                data.remove(&amp;record.key);\n            } else {\n                // PUT operation\n                data.insert(record.key, record.value);\n            }\n        }\n\n        println!(\"Rebuilt {} keys from WAL\", data.len());\n\n        Ok(Self { data, wal })\n    }\n\n    /// Gets a value by key.\n    pub fn get(&amp;self, key: &amp;[u8]) -&gt; Option&lt;&amp;[u8]&gt; {\n        self.data.get(key).map(|v| v.as_ref())\n    }\n\n    /// Puts a key-value pair.\n    pub async fn put(&amp;mut self, key: &amp;[u8], value: &amp;[u8]) -&gt; Result&lt;()&gt; {\n        // 1. Write to WAL first (write-ahead!)\n        let record = Record::put(key, value);\n        self.wal.append(&amp;record).await?;\n\n        // 2. Update in-memory data\n        self.data.insert(Bytes::copy_from_slice(key), Bytes::copy_from_slice(value));\n\n        Ok(())\n    }\n\n    /// Deletes a key.\n    pub async fn delete(&amp;mut self, key: &amp;[u8]) -&gt; Result&lt;()&gt; {\n        // 1. Write tombstone to WAL\n        let record = Record::delete(key);\n        self.wal.append(&amp;record).await?;\n\n        // 2. Remove from in-memory data\n        self.data.remove(key);\n\n        Ok(())\n    }\n\n    /// Syncs WAL to disk.\n    pub async fn sync(&amp;self) -&gt; Result&lt;()&gt; {\n        self.wal.sync().await?;\n        Ok(())\n    }\n\n    /// Returns the number of keys in the store.\n    pub fn len(&amp;self) -&gt; usize {\n        self.data.len()\n    }\n\n    /// Returns true if the store is empty.\n    pub fn is_empty(&amp;self) -&gt; bool {\n        self.data.is_empty()\n    }\n\n    /// Returns an iterator over all keys.\n    pub fn keys(&amp;self) -&gt; impl Iterator&lt;Item = &amp;[u8]&gt; {\n        self.data.keys().map(|k| k.as_ref())\n    }\n\n    /// Gracefully closes the store.\n    pub async fn close(self) -&gt; Result&lt;()&gt; {\n        self.wal.close().await?;\n        Ok(())\n    }\n}\n\n// Example usage\n#[tokio::main]\nasync fn main() -&gt; Result&lt;()&gt; {\n    // Open store (creates if doesn't exist)\n    let mut store = KvStore::open(\"./my_kv_store\").await?;\n\n    // Write some data\n    store.put(b\"user:1\", b\"Alice\").await?;\n    store.put(b\"user:2\", b\"Bob\").await?;\n    store.put(b\"user:3\", b\"Charlie\").await?;\n\n    // Read data\n    if let Some(value) = store.get(b\"user:1\") {\n        println!(\"user:1 = {:?}\", std::str::from_utf8(value)?);\n    }\n\n    // Delete a key\n    store.delete(b\"user:2\").await?;\n\n    // Sync to ensure durability\n    store.sync().await?;\n\n    println!(\"Store has {} keys\", store.len());\n\n    // Close gracefully\n    store.close().await?;\n\n    Ok(())\n}\n</code></pre>"},{"location":"crates/nori-wal/recipes/key-value-store/#how-it-works","title":"How It Works","text":""},{"location":"crates/nori-wal/recipes/key-value-store/#1-initialization","title":"1. Initialization","text":"<pre><code>let (wal, recovery_info) = Wal::open(config).await?;\n</code></pre> <p>The WAL is opened and automatically performs recovery: - Scans all segment files - Validates CRC for each record - Truncates any corruption - Returns recovery statistics</p>"},{"location":"crates/nori-wal/recipes/key-value-store/#2-state-reconstruction","title":"2. State Reconstruction","text":"<pre><code>let mut reader = wal.read_from(Position::start()).await?;\n\nwhile let Some((record, _)) = reader.next_record().await? {\n    if record.tombstone {\n        data.remove(&amp;record.key);\n    } else {\n        data.insert(record.key, record.value);\n    }\n}\n</code></pre> <p>We replay the entire WAL to rebuild the in-memory HashMap: - PUT records insert/update keys - DELETE records (tombstones) remove keys - Last write wins for duplicate keys</p>"},{"location":"crates/nori-wal/recipes/key-value-store/#3-write-path","title":"3. Write Path","text":"<pre><code>pub async fn put(&amp;mut self, key: &amp;[u8], value: &amp;[u8]) -&gt; Result&lt;()&gt; {\n    // 1. WAL first\n    let record = Record::put(key, value);\n    self.wal.append(&amp;record).await?;\n\n    // 2. Then in-memory\n    self.data.insert(...);\n\n    Ok(())\n}\n</code></pre> <p>Critical: WAL write happens before in-memory update. If we crash after WAL write but before in-memory update, recovery will replay the WAL and the data will be correct.</p>"},{"location":"crates/nori-wal/recipes/key-value-store/#4-read-path","title":"4. Read Path","text":"<pre><code>pub fn get(&amp;self, key: &amp;[u8]) -&gt; Option&lt;&amp;[u8]&gt; {\n    self.data.get(key).map(|v| v.as_ref())\n}\n</code></pre> <p>Reads are pure in-memory lookups (fast!). The WAL is only for durability, not for reads.</p>"},{"location":"crates/nori-wal/recipes/key-value-store/#testing","title":"Testing","text":"<pre><code>#[cfg(test)]\nmod tests {\n    use super::*;\n    use tempfile::TempDir;\n\n    #[tokio::test]\n    async fn test_basic_operations() {\n        let dir = TempDir::new().unwrap();\n        let mut store = KvStore::open(dir.path()).await.unwrap();\n\n        // PUT\n        store.put(b\"key1\", b\"value1\").await.unwrap();\n        assert_eq!(store.get(b\"key1\"), Some(&amp;b\"value1\"[..]));\n\n        // UPDATE\n        store.put(b\"key1\", b\"value2\").await.unwrap();\n        assert_eq!(store.get(b\"key1\"), Some(&amp;b\"value2\"[..]));\n\n        // DELETE\n        store.delete(b\"key1\").await.unwrap();\n        assert_eq!(store.get(b\"key1\"), None);\n    }\n\n    #[tokio::test]\n    async fn test_recovery() {\n        let dir = TempDir::new().unwrap();\n\n        // Write data\n        {\n            let mut store = KvStore::open(dir.path()).await.unwrap();\n            store.put(b\"key1\", b\"value1\").await.unwrap();\n            store.put(b\"key2\", b\"value2\").await.unwrap();\n            store.sync().await.unwrap();\n            // Drop without close (simulates crash)\n        }\n\n        // Reopen and verify data\n        {\n            let store = KvStore::open(dir.path()).await.unwrap();\n            assert_eq!(store.get(b\"key1\"), Some(&amp;b\"value1\"[..]));\n            assert_eq!(store.get(b\"key2\"), Some(&amp;b\"value2\"[..]));\n            assert_eq!(store.len(), 2);\n        }\n    }\n\n    #[tokio::test]\n    async fn test_delete_recovery() {\n        let dir = TempDir::new().unwrap();\n\n        {\n            let mut store = KvStore::open(dir.path()).await.unwrap();\n            store.put(b\"key1\", b\"value1\").await.unwrap();\n            store.delete(b\"key1\").await.unwrap();\n            store.sync().await.unwrap();\n        }\n\n        {\n            let store = KvStore::open(dir.path()).await.unwrap();\n            assert_eq!(store.get(b\"key1\"), None);\n            assert_eq!(store.len(), 0);\n        }\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/recipes/key-value-store/#production-considerations","title":"Production Considerations","text":""},{"location":"crates/nori-wal/recipes/key-value-store/#1-compaction","title":"1. Compaction","text":"<p>Over time, the WAL will grow with duplicate keys and tombstones:</p> <pre><code>WAL: [put(k1,v1), put(k2,v2), put(k1,v3), delete(k2)]\n     \u2193\nIn-memory: {k1: v3}\n</code></pre> <p>The WAL has 4 records, but only 1 key in memory. You need periodic compaction:</p> <pre><code>impl KvStore {\n    /// Compacts the WAL by rewriting only current state.\n    pub async fn compact(&amp;mut self) -&gt; Result&lt;()&gt; {\n        // 1. Create new WAL directory\n        let new_dir = self.wal.config().dir.parent().unwrap().join(\"wal_new\");\n        let config = WalConfig {\n            dir: new_dir.clone(),\n            ..self.wal.config().clone()\n        };\n\n        let (new_wal, _) = Wal::open(config).await?;\n\n        // 2. Write current state to new WAL\n        for (key, value) in &amp;self.data {\n            let record = Record::put(key, value);\n            new_wal.append(&amp;record).await?;\n        }\n        new_wal.sync().await?;\n\n        // 3. Swap WALs\n        let old_dir = self.wal.config().dir.clone();\n        self.wal = new_wal;\n\n        // 4. Delete old WAL\n        tokio::fs::remove_dir_all(&amp;old_dir).await?;\n        tokio::fs::rename(&amp;new_dir, &amp;old_dir).await?;\n\n        Ok(())\n    }\n}\n</code></pre> <p>Run compaction periodically or when WAL size exceeds threshold.</p>"},{"location":"crates/nori-wal/recipes/key-value-store/#2-memory-management","title":"2. Memory Management","text":"<p>HashMap can grow large. Consider:</p> <pre><code>// Limit max size\nconst MAX_KEYS: usize = 1_000_000;\n\npub async fn put(&amp;mut self, key: &amp;[u8], value: &amp;[u8]) -&gt; Result&lt;()&gt; {\n    if self.data.len() &gt;= MAX_KEYS &amp;&amp; !self.data.contains_key(key) {\n        return Err(anyhow::anyhow!(\"Store is full\"));\n    }\n    // ...\n}\n</code></pre> <p>Or use an eviction policy (LRU, LFU).</p>"},{"location":"crates/nori-wal/recipes/key-value-store/#3-batching-for-performance","title":"3. Batching for Performance","text":"<p>Batch multiple operations before syncing:</p> <pre><code>// Batch write\nfor (key, value) in batch {\n    store.put(key, value).await?;\n}\nstore.sync().await?;  // Single fsync for all\n</code></pre> <p>This is much faster than syncing after each operation.</p>"},{"location":"crates/nori-wal/recipes/key-value-store/#4-monitoring","title":"4. Monitoring","text":"<p>Track key metrics:</p> <pre><code>// Keys in memory\nmetrics.gauge(\"kv.keys\", store.len());\n\n// WAL segments\nmetrics.gauge(\"kv.wal_segments\", count_segments()?);\n\n// WAL size\nmetrics.gauge(\"kv.wal_bytes\", total_wal_size()?);\n</code></pre> <p>Alert when: - WAL grows too large (need compaction) - Recovery takes too long - Corruption detected</p>"},{"location":"crates/nori-wal/recipes/key-value-store/#5-concurrent-access","title":"5. Concurrent Access","text":"<p>Current implementation is single-threaded. For concurrent access:</p> <pre><code>use std::sync::Arc;\nuse tokio::sync::RwLock;\n\npub struct ConcurrentKvStore {\n    data: Arc&lt;RwLock&lt;HashMap&lt;Bytes, Bytes&gt;&gt;&gt;,\n    wal: Arc&lt;Mutex&lt;Wal&gt;&gt;,\n}\n\nimpl ConcurrentKvStore {\n    pub async fn get(&amp;self, key: &amp;[u8]) -&gt; Option&lt;Bytes&gt; {\n        let data = self.data.read().await;\n        data.get(key).cloned()\n    }\n\n    pub async fn put(&amp;self, key: &amp;[u8], value: &amp;[u8]) -&gt; Result&lt;()&gt; {\n        let record = Record::put(key, value);\n\n        // WAL write (exclusive)\n        let mut wal = self.wal.lock().await;\n        wal.append(&amp;record).await?;\n        drop(wal);\n\n        // In-memory update (write lock)\n        let mut data = self.data.write().await;\n        data.insert(Bytes::copy_from_slice(key), Bytes::copy_from_slice(value));\n\n        Ok(())\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/recipes/key-value-store/#enhancements","title":"Enhancements","text":""},{"location":"crates/nori-wal/recipes/key-value-store/#add-ttl-support","title":"Add TTL Support","text":"<pre><code>use std::time::{SystemTime, Duration};\n\nstruct TtlEntry {\n    value: Bytes,\n    expires_at: SystemTime,\n}\n\npub async fn put_with_ttl(\n    &amp;mut self,\n    key: &amp;[u8],\n    value: &amp;[u8],\n    ttl: Duration\n) -&gt; Result&lt;()&gt; {\n    let record = Record::put_with_ttl(key, value, ttl);\n    self.wal.append(&amp;record).await?;\n\n    let expires_at = SystemTime::now() + ttl;\n    self.data.insert(key, TtlEntry { value, expires_at });\n\n    Ok(())\n}\n</code></pre>"},{"location":"crates/nori-wal/recipes/key-value-store/#add-range-queries","title":"Add Range Queries","text":"<p>Use <code>BTreeMap</code> instead of <code>HashMap</code>:</p> <pre><code>use std::collections::BTreeMap;\n\npub fn range(&amp;self, start: &amp;[u8], end: &amp;[u8]) -&gt; impl Iterator&lt;Item = (&amp;[u8], &amp;[u8])&gt; {\n    self.data.range(start..end)\n        .map(|(k, v)| (k.as_ref(), v.as_ref()))\n}\n</code></pre>"},{"location":"crates/nori-wal/recipes/key-value-store/#add-compression","title":"Add Compression","text":"<pre><code>use nori_wal::Compression;\n\npub async fn put_compressed(&amp;mut self, key: &amp;[u8], value: &amp;[u8]) -&gt; Result&lt;()&gt; {\n    let record = Record::put(key, value)\n        .with_compression(Compression::Lz4);\n\n    self.wal.append(&amp;record).await?;\n    self.data.insert(key, value);\n\n    Ok(())\n}\n</code></pre>"},{"location":"crates/nori-wal/recipes/key-value-store/#conclusion","title":"Conclusion","text":"<p>This recipe demonstrates: - Using WAL for durability - Rebuilding state from WAL on recovery - Write-ahead logging pattern - Testing crash recovery</p> <p>The KV store is production-ready for single-node use cases. For distributed systems, add replication using the Replication recipe.</p>"},{"location":"crates/nori-wal/recipes/message-queue/","title":"Building a Message Queue","text":"<p>Simple message queue with consumer position tracking using nori-wal.</p>"},{"location":"crates/nori-wal/recipes/message-queue/#table-of-contents","title":"Table of contents","text":""},{"location":"crates/nori-wal/recipes/message-queue/#problem","title":"Problem","text":"<p>You want to build a message queue where: - Messages are durably stored - Multiple consumers can read independently - Each consumer tracks its own position - Messages can be replayed - At-least-once delivery semantics</p>"},{"location":"crates/nori-wal/recipes/message-queue/#solution","title":"Solution","text":"<pre><code>use nori_wal::{Wal, WalConfig, Record, Position};\nuse serde::{Serialize, Deserialize};\nuse bytes::Bytes;\nuse anyhow::Result;\nuse std::collections::HashMap;\nuse std::path::PathBuf;\n\n/// A message in the queue\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Message {\n    pub id: u64,\n    pub topic: String,\n    pub payload: Bytes,\n    pub timestamp: u64,\n}\n\n/// Consumer position tracking\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ConsumerOffset {\n    pub consumer_id: String,\n    pub segment_id: u64,\n    pub offset: u64,\n    pub last_message_id: u64,\n}\n\n/// Message queue implementation\npub struct MessageQueue {\n    wal: Wal,\n    offsets: HashMap&lt;String, Position&gt;,\n    next_message_id: u64,\n}\n\nimpl MessageQueue {\n    /// Opens or creates a message queue\n    pub async fn open(path: impl Into&lt;PathBuf&gt;) -&gt; Result&lt;Self&gt; {\n        let path = path.into();\n\n        let config = WalConfig {\n            dir: path.join(\"messages\"),\n            max_segment_size: 128 * 1024 * 1024,\n            fsync_policy: nori_wal::FsyncPolicy::Batch(\n                std::time::Duration::from_millis(5)\n            ),\n            preallocate: true,\n            node_id: 0,\n        };\n\n        let (wal, recovery_info) = Wal::open(config).await?;\n\n        println!(\"Message queue recovered:\");\n        println!(\"  Messages: {}\", recovery_info.valid_records);\n        println!(\"  Segments: {}\", recovery_info.segments_scanned);\n\n        // Find highest message ID\n        let mut next_message_id = 0u64;\n        let mut reader = wal.read_from(Position { segment_id: 0, offset: 0 }).await?;\n\n        while let Some((record, _)) = reader.next_record().await? {\n            if let Ok(msg) = serde_json::from_slice::&lt;Message&gt;(&amp;record.value) {\n                next_message_id = next_message_id.max(msg.id + 1);\n            }\n        }\n\n        Ok(Self {\n            wal,\n            offsets: HashMap::new(),\n            next_message_id,\n        })\n    }\n\n    /// Publishes a message to the queue\n    pub async fn publish(&amp;mut self, topic: &amp;str, payload: Bytes) -&gt; Result&lt;u64&gt; {\n        let message = Message {\n            id: self.next_message_id,\n            topic: topic.to_string(),\n            payload,\n            timestamp: std::time::SystemTime::now()\n                .duration_since(std::time::UNIX_EPOCH)?\n                .as_secs(),\n        };\n\n        // Serialize message\n        let message_bytes = serde_json::to_vec(&amp;message)?;\n\n        // Write to WAL\n        let record = Record::put(&amp;message.id.to_le_bytes(), &amp;message_bytes);\n        self.wal.append(&amp;record).await?;\n\n        let message_id = self.next_message_id;\n        self.next_message_id += 1;\n\n        Ok(message_id)\n    }\n\n    /// Syncs messages to disk\n    pub async fn sync(&amp;self) -&gt; Result&lt;()&gt; {\n        self.wal.sync().await?;\n        Ok(())\n    }\n\n    /// Creates a consumer at the beginning of the queue\n    pub fn consumer(&amp;mut self, consumer_id: &amp;str) -&gt; Consumer {\n        let position = self.offsets.get(consumer_id).copied()\n            .unwrap_or(Position { segment_id: 0, offset: 0 });\n\n        Consumer {\n            id: consumer_id.to_string(),\n            position,\n        }\n    }\n\n    /// Consumes the next message for a consumer\n    pub async fn consume(&amp;mut self, consumer: &amp;mut Consumer) -&gt; Result&lt;Option&lt;Message&gt;&gt; {\n        let mut reader = self.wal.read_from(consumer.position).await?;\n\n        if let Some((record, position)) = reader.next_record().await? {\n            if let Ok(message) = serde_json::from_slice::&lt;Message&gt;(&amp;record.value) {\n                // Update consumer position\n                consumer.position = position;\n                self.offsets.insert(consumer.id.clone(), position);\n\n                return Ok(Some(message));\n            }\n        }\n\n        Ok(None)\n    }\n\n    /// Commits a consumer's current position\n    pub async fn commit(&amp;mut self, consumer: &amp;Consumer) -&gt; Result&lt;()&gt; {\n        self.offsets.insert(consumer.id.clone(), consumer.position);\n        Ok(())\n    }\n\n    /// Resets a consumer to the beginning\n    pub fn reset_consumer(&amp;mut self, consumer_id: &amp;str) {\n        self.offsets.insert(\n            consumer_id.to_string(),\n            Position { segment_id: 0, offset: 0 },\n        );\n    }\n\n    /// Seeks a consumer to a specific message ID\n    pub async fn seek(&amp;mut self, consumer: &amp;mut Consumer, message_id: u64) -&gt; Result&lt;()&gt; {\n        let mut reader = self.wal.read_from(Position { segment_id: 0, offset: 0 }).await?;\n\n        while let Some((record, position)) = reader.next_record().await? {\n            if let Ok(message) = serde_json::from_slice::&lt;Message&gt;(&amp;record.value) {\n                if message.id == message_id {\n                    consumer.position = position;\n                    self.offsets.insert(consumer.id.clone(), position);\n                    return Ok(());\n                }\n            }\n        }\n\n        Err(anyhow::anyhow!(\"Message ID {} not found\", message_id))\n    }\n\n    /// Returns the current lag for a consumer\n    pub async fn lag(&amp;self, consumer: &amp;Consumer) -&gt; Result&lt;u64&gt; {\n        let mut count = 0u64;\n        let mut reader = self.wal.read_from(consumer.position).await?;\n\n        while let Some(_) = reader.next_record().await? {\n            count += 1;\n        }\n\n        Ok(count)\n    }\n\n    /// Gracefully closes the queue\n    pub async fn close(self) -&gt; Result&lt;()&gt; {\n        self.wal.close().await?;\n        Ok(())\n    }\n}\n\n/// A consumer that reads from the queue\n#[derive(Debug, Clone)]\npub struct Consumer {\n    pub id: String,\n    position: Position,\n}\n\n// Example usage\n#[tokio::main]\nasync fn main() -&gt; Result&lt;()&gt; {\n    let mut queue = MessageQueue::open(\"./message_queue\").await?;\n\n    // Publish messages\n    for i in 0..10 {\n        let payload = format!(\"Message {}\", i);\n        queue.publish(\"orders\", Bytes::from(payload)).await?;\n    }\n\n    queue.sync().await?;\n\n    // Create consumers\n    let mut consumer_a = queue.consumer(\"consumer-a\");\n    let mut consumer_b = queue.consumer(\"consumer-b\");\n\n    // Consumer A reads 5 messages\n    for _ in 0..5 {\n        if let Some(msg) = queue.consume(&amp;mut consumer_a).await? {\n            println!(\"Consumer A: {:?}\", msg);\n        }\n    }\n    queue.commit(&amp;consumer_a).await?;\n\n    // Consumer B reads all messages\n    while let Some(msg) = queue.consume(&amp;mut consumer_b).await? {\n        println!(\"Consumer B: {:?}\", msg);\n    }\n    queue.commit(&amp;consumer_b).await?;\n\n    // Check lag\n    let lag = queue.lag(&amp;consumer_a).await?;\n    println!(\"Consumer A lag: {} messages\", lag);\n\n    queue.close().await?;\n\n    Ok(())\n}\n</code></pre>"},{"location":"crates/nori-wal/recipes/message-queue/#how-it-works","title":"How It Works","text":""},{"location":"crates/nori-wal/recipes/message-queue/#1-message-publishing","title":"1. Message Publishing","text":"<p>Messages are appended to the WAL:</p> <pre><code>pub async fn publish(&amp;mut self, topic: &amp;str, payload: Bytes) -&gt; Result&lt;u64&gt; {\n    let message = Message {\n        id: self.next_message_id,\n        topic: topic.to_string(),\n        payload,\n        timestamp: current_timestamp(),\n    };\n\n    let message_bytes = serde_json::to_vec(&amp;message)?;\n    let record = Record::put(&amp;message.id.to_le_bytes(), &amp;message_bytes);\n    self.wal.append(&amp;record).await?;\n\n    self.next_message_id += 1;\n    Ok(message.id)\n}\n</code></pre>"},{"location":"crates/nori-wal/recipes/message-queue/#2-consumer-position-tracking","title":"2. Consumer Position Tracking","text":"<p>Each consumer maintains its own position:</p> <pre><code>pub struct Consumer {\n    pub id: String,\n    position: Position,  // Current position in WAL\n}\n\npub async fn consume(&amp;mut self, consumer: &amp;mut Consumer) -&gt; Result&lt;Option&lt;Message&gt;&gt; {\n    let mut reader = self.wal.read_from(consumer.position).await?;\n\n    if let Some((record, new_position)) = reader.next_record().await? {\n        consumer.position = new_position;  // Update position\n        let message = serde_json::from_slice(&amp;record.value)?;\n        Ok(Some(message))\n    } else {\n        Ok(None)  // No more messages\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/recipes/message-queue/#3-offset-management","title":"3. Offset Management","text":"<p>Consumer offsets are tracked in memory and persisted on commit:</p> <pre><code>pub async fn commit(&amp;mut self, consumer: &amp;Consumer) -&gt; Result&lt;()&gt; {\n    // Store offset in HashMap\n    self.offsets.insert(consumer.id.clone(), consumer.position);\n\n    // For durability, you could also write offsets to a separate WAL\n    Ok(())\n}\n</code></pre>"},{"location":"crates/nori-wal/recipes/message-queue/#testing","title":"Testing","text":"<pre><code>#[cfg(test)]\nmod tests {\n    use super::*;\n    use tempfile::TempDir;\n\n    #[tokio::test]\n    async fn test_publish_and_consume() {\n        let dir = TempDir::new().unwrap();\n        let mut queue = MessageQueue::open(dir.path()).await.unwrap();\n\n        // Publish messages\n        queue.publish(\"test\", Bytes::from(\"msg1\")).await.unwrap();\n        queue.publish(\"test\", Bytes::from(\"msg2\")).await.unwrap();\n\n        // Consume\n        let mut consumer = queue.consumer(\"test-consumer\");\n        let msg1 = queue.consume(&amp;mut consumer).await.unwrap().unwrap();\n        let msg2 = queue.consume(&amp;mut consumer).await.unwrap().unwrap();\n\n        assert_eq!(msg1.id, 0);\n        assert_eq!(msg2.id, 1);\n    }\n\n    #[tokio::test]\n    async fn test_multiple_consumers() {\n        let dir = TempDir::new().unwrap();\n        let mut queue = MessageQueue::open(dir.path()).await.unwrap();\n\n        // Publish 10 messages\n        for i in 0..10 {\n            queue.publish(\"test\", Bytes::from(format!(\"msg{}\", i))).await.unwrap();\n        }\n\n        // Consumer A reads 5\n        let mut consumer_a = queue.consumer(\"a\");\n        for _ in 0..5 {\n            queue.consume(&amp;mut consumer_a).await.unwrap();\n        }\n        queue.commit(&amp;consumer_a).await.unwrap();\n\n        // Consumer B reads all 10\n        let mut consumer_b = queue.consumer(\"b\");\n        let mut count = 0;\n        while let Some(_) = queue.consume(&amp;mut consumer_b).await.unwrap() {\n            count += 1;\n        }\n        assert_eq!(count, 10);\n\n        // Consumer A still has 5 messages left\n        let lag = queue.lag(&amp;consumer_a).await.unwrap();\n        assert_eq!(lag, 5);\n    }\n\n    #[tokio::test]\n    async fn test_consumer_recovery() {\n        let dir = TempDir::new().unwrap();\n\n        // Write messages and consume some\n        {\n            let mut queue = MessageQueue::open(dir.path()).await.unwrap();\n            for i in 0..10 {\n                queue.publish(\"test\", Bytes::from(format!(\"msg{}\", i))).await.unwrap();\n            }\n\n            let mut consumer = queue.consumer(\"persistent\");\n            for _ in 0..3 {\n                queue.consume(&amp;mut consumer).await.unwrap();\n            }\n            queue.commit(&amp;consumer).await.unwrap();\n            queue.sync().await.unwrap();\n        }\n\n        // Reopen and verify consumer position\n        {\n            let mut queue = MessageQueue::open(dir.path()).await.unwrap();\n            let mut consumer = queue.consumer(\"persistent\");\n\n            // Should start from message 3\n            let msg = queue.consume(&amp;mut consumer).await.unwrap().unwrap();\n            assert_eq!(msg.id, 3);\n        }\n    }\n\n    #[tokio::test]\n    async fn test_seek() {\n        let dir = TempDir::new().unwrap();\n        let mut queue = MessageQueue::open(dir.path()).await.unwrap();\n\n        // Publish 10 messages\n        for i in 0..10 {\n            queue.publish(\"test\", Bytes::from(format!(\"msg{}\", i))).await.unwrap();\n        }\n\n        let mut consumer = queue.consumer(\"seeker\");\n\n        // Seek to message ID 5\n        queue.seek(&amp;mut consumer, 5).await.unwrap();\n\n        // Next message should be ID 5\n        let msg = queue.consume(&amp;mut consumer).await.unwrap().unwrap();\n        assert_eq!(msg.id, 5);\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/recipes/message-queue/#production-considerations","title":"Production Considerations","text":""},{"location":"crates/nori-wal/recipes/message-queue/#1-persistent-offset-storage","title":"1. Persistent Offset Storage","text":"<p>Store consumer offsets durably:</p> <pre><code>pub struct MessageQueue {\n    wal: Wal,\n    offset_wal: Wal,  // Separate WAL for offsets\n    offsets: HashMap&lt;String, Position&gt;,\n    next_message_id: u64,\n}\n\nimpl MessageQueue {\n    pub async fn commit(&amp;mut self, consumer: &amp;Consumer) -&gt; Result&lt;()&gt; {\n        // Update in-memory\n        self.offsets.insert(consumer.id.clone(), consumer.position);\n\n        // Persist to offset WAL\n        let offset = ConsumerOffset {\n            consumer_id: consumer.id.clone(),\n            segment_id: consumer.position.segment_id,\n            offset: consumer.position.offset,\n            last_message_id: 0, // Track if needed\n        };\n\n        let offset_bytes = serde_json::to_vec(&amp;offset)?;\n        let record = Record::put(consumer.id.as_bytes(), &amp;offset_bytes);\n        self.offset_wal.append(&amp;record).await?;\n\n        Ok(())\n    }\n\n    pub async fn load_offsets(&amp;mut self) -&gt; Result&lt;()&gt; {\n        let mut reader = self.offset_wal.read_from(Position { segment_id: 0, offset: 0 }).await?;\n\n        while let Some((record, _)) = reader.next_record().await? {\n            if let Ok(offset) = serde_json::from_slice::&lt;ConsumerOffset&gt;(&amp;record.value) {\n                self.offsets.insert(\n                    offset.consumer_id,\n                    Position {\n                        segment_id: offset.segment_id,\n                        offset: offset.offset,\n                    },\n                );\n            }\n        }\n\n        Ok(())\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/recipes/message-queue/#2-message-retention","title":"2. Message Retention","text":"<p>Delete old segments:</p> <pre><code>impl MessageQueue {\n    /// Deletes messages older than retention period\n    pub async fn cleanup(&amp;mut self, retention_seconds: u64) -&gt; Result&lt;u64&gt; {\n        let cutoff = std::time::SystemTime::now()\n            .duration_since(std::time::UNIX_EPOCH)?\n            .as_secs()\n            - retention_seconds;\n\n        let mut oldest_position = Position { segment_id: u64::MAX, offset: 0 };\n\n        // Find oldest position still in use by any consumer\n        for position in self.offsets.values() {\n            if position.segment_id &lt; oldest_position.segment_id {\n                oldest_position = *position;\n            }\n        }\n\n        // Delete segments before oldest consumer position\n        if oldest_position.segment_id &gt; 0 {\n            self.wal.delete_segments_before(oldest_position.segment_id).await?;\n        }\n\n        Ok(oldest_position.segment_id)\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/recipes/message-queue/#3-topic-filtering","title":"3. Topic Filtering","text":"<p>Filter messages by topic:</p> <pre><code>pub async fn consume_topic(\n    &amp;mut self,\n    consumer: &amp;mut Consumer,\n    topic: &amp;str,\n) -&gt; Result&lt;Option&lt;Message&gt;&gt; {\n    loop {\n        let mut reader = self.wal.read_from(consumer.position).await?;\n\n        if let Some((record, position)) = reader.next_record().await? {\n            consumer.position = position;\n\n            if let Ok(message) = serde_json::from_slice::&lt;Message&gt;(&amp;record.value) {\n                if message.topic == topic {\n                    return Ok(Some(message));\n                }\n                // Skip messages from other topics\n                continue;\n            }\n        } else {\n            return Ok(None);\n        }\n    }\n}\n</code></pre>"},{"location":"crates/nori-wal/recipes/message-queue/#4-batch-consumption","title":"4. Batch Consumption","text":"<p>Consume multiple messages at once:</p> <pre><code>pub async fn consume_batch(\n    &amp;mut self,\n    consumer: &amp;mut Consumer,\n    max_messages: usize,\n) -&gt; Result&lt;Vec&lt;Message&gt;&gt; {\n    let mut messages = Vec::new();\n    let mut reader = self.wal.read_from(consumer.position).await?;\n\n    for _ in 0..max_messages {\n        if let Some((record, position)) = reader.next_record().await? {\n            if let Ok(message) = serde_json::from_slice::&lt;Message&gt;(&amp;record.value) {\n                messages.push(message);\n                consumer.position = position;\n            }\n        } else {\n            break;\n        }\n    }\n\n    Ok(messages)\n}\n</code></pre>"},{"location":"crates/nori-wal/recipes/message-queue/#5-monitoring","title":"5. Monitoring","text":"<p>Track queue metrics:</p> <pre><code>// Messages published\nmetrics.counter(\"queue.messages.published\", 1, &amp;[(\"topic\", topic)]);\n\n// Consumer lag\nmetrics.gauge(\"queue.consumer.lag\", lag, &amp;[(\"consumer\", consumer.id)]);\n\n// Consumption rate\nmetrics.counter(\"queue.messages.consumed\", 1, &amp;[(\"consumer\", consumer.id)]);\n</code></pre>"},{"location":"crates/nori-wal/recipes/message-queue/#conclusion","title":"Conclusion","text":"<p>This recipe demonstrates: - Using WAL as a message log - Independent consumer position tracking - At-least-once delivery semantics - Message replay and seeking</p> <p>For distributed message queues, combine with Replication recipe.</p>"},{"location":"operations/","title":"Operations","text":"<p>Production deployment, monitoring, and maintenance of NoriKV clusters.</p>"},{"location":"operations/#overview","title":"Overview","text":"<p>This section covers operational aspects of running NoriKV in production:</p> <ul> <li>REST API - HTTP endpoints for health checks and metrics</li> <li>Metrics - Prometheus metrics reference and monitoring</li> <li>Configuration - Server configuration options</li> <li>Deployment - Deployment topologies and best practices</li> <li>Troubleshooting - Common issues and solutions</li> </ul>"},{"location":"operations/#quick-start","title":"Quick Start","text":""},{"location":"operations/#running-a-single-node","title":"Running a Single Node","text":"<pre><code># Start server with default configuration\nnorikv-server --node-id node0 \\\n  --rpc-addr 127.0.0.1:6000 \\\n  --http-addr 127.0.0.1:8080 \\\n  --data-dir /var/lib/norikv\n</code></pre>"},{"location":"operations/#health-check","title":"Health Check","text":"<pre><code># Quick health check (for load balancers)\ncurl http://localhost:8080/health/quick\n\n# Comprehensive health status\ncurl http://localhost:8080/health\n</code></pre>"},{"location":"operations/#metrics-collection","title":"Metrics Collection","text":"<pre><code># Prometheus metrics endpoint\ncurl http://localhost:8080/metrics\n</code></pre>"},{"location":"operations/#production-checklist","title":"Production Checklist","text":""},{"location":"operations/#before-deployment","title":"Before Deployment","text":"<ul> <li> Configure data directory with sufficient disk space</li> <li> Set up Prometheus/Grafana for metrics collection</li> <li> Configure health check endpoints in load balancer</li> <li> Review and tune LSM compaction settings</li> <li> Configure Raft timeouts for your network latency</li> <li> Set up log aggregation (structured JSON logs)</li> </ul>"},{"location":"operations/#monitoring","title":"Monitoring","text":"<ul> <li> Track <code>kv_requests_total</code> - Request volume per operation</li> <li> Monitor <code>kv_request_duration_ms</code> - Latency percentiles</li> <li> Watch <code>lsm_compaction_duration_ms</code> - Compaction performance</li> <li> Alert on <code>raft_leader_changes_total</code> - Cluster stability</li> <li> Check disk space and WAL/SSTable growth</li> </ul>"},{"location":"operations/#high-availability","title":"High Availability","text":"<ul> <li> Deploy at least 3 nodes for fault tolerance</li> <li> Configure replication factor \u22653</li> <li> Distribute nodes across availability zones</li> <li> Set up automated backups (snapshots)</li> <li> Test failure scenarios (node crash, network partition)</li> </ul>"},{"location":"operations/#architecture-integration","title":"Architecture Integration","text":""},{"location":"operations/#server-components","title":"Server Components","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  HTTP Server (Axum)                     \u2502\n\u2502  - GET /health/quick                    \u2502\n\u2502  - GET /health                          \u2502\n\u2502  - GET /metrics (Prometheus)            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  gRPC Server (Tonic)                    \u2502\n\u2502  - KV Service (Put/Get/Delete)          \u2502\n\u2502  - Meta Service (WatchCluster)          \u2502\n\u2502  - Admin Service (SnapshotShard)        \u2502\n\u2502  - Raft Service (peer-to-peer RPC)      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Multi-Shard Backend                    \u2502\n\u2502  - Routes requests to correct shard     \u2502\n\u2502  - 1024 virtual shards                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u25bc                     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Shard 0      \u2502    \u2502  Shard N      \u2502\n\u2502  - Raft       \u2502    \u2502  - Raft       \u2502\n\u2502  - LSM        \u2502    \u2502  - LSM        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"operations/#key-design-decisions","title":"Key Design Decisions","text":"<ol> <li>Separate HTTP and gRPC servers</li> <li>HTTP for ops/monitoring (health, metrics)</li> <li> <p>gRPC for client API (high performance, streaming)</p> </li> <li> <p>Lazy shard initialization</p> </li> <li>Shards created on first access</li> <li> <p>Reduces startup time and memory usage</p> </li> <li> <p>Prometheus pull model</p> </li> <li>Standard /metrics endpoint</li> <li>No agent required</li> <li> <p>Works with Kubernetes service discovery</p> </li> <li> <p>SWIM-based topology tracking</p> </li> <li>Gossip protocol for scalability</li> <li>Automatic failure detection</li> <li>Integrates with ClusterView for client routing</li> </ol>"},{"location":"operations/#next-steps","title":"Next Steps","text":"<ul> <li>REST API Reference - HTTP endpoints and usage</li> <li>Metrics Guide - All metrics explained</li> <li>Configuration - Tuning parameters</li> <li>Deployment - Production deployment patterns</li> </ul>"},{"location":"operations/configuration/","title":"Configuration Reference","text":"<p>Complete reference for all NoriKV server configuration options.</p>"},{"location":"operations/configuration/#overview","title":"Overview","text":"<p>NoriKV configuration can be loaded from: 1. YAML file - Recommended for production 2. Environment variables - Useful for containers/Docker 3. Command-line arguments - Override specific settings</p> <p>Configuration hierarchy: <pre><code>Defaults \u2192 YAML file \u2192 Environment variables \u2192 CLI args\n                       (lowest priority \u2192 highest priority)\n</code></pre></p>"},{"location":"operations/configuration/#quick-start","title":"Quick Start","text":""},{"location":"operations/configuration/#minimal-configuration","title":"Minimal Configuration","text":"<p><code>config.yaml</code>:</p> <pre><code>node_id: \"node0\"\ndata_dir: \"/var/lib/norikv\"\n</code></pre> <p>Start server:</p> <pre><code>norikv-server --config config.yaml\n</code></pre>"},{"location":"operations/configuration/#production-configuration","title":"Production Configuration","text":"<pre><code># Node identity\nnode_id: \"node0\"\nrpc_addr: \"0.0.0.0:7447\"\nhttp_addr: \"0.0.0.0:8080\"\ndata_dir: \"/var/lib/norikv\"\n\n# Cluster settings\ncluster:\n  seed_nodes:\n    - \"10.0.1.10:7447\"\n    - \"10.0.1.11:7447\"\n    - \"10.0.1.12:7447\"\n  total_shards: 1024\n  replication_factor: 3\n\n# Telemetry\ntelemetry:\n  prometheus:\n    enabled: true\n    port: 9090\n  otlp:\n    enabled: false\n    endpoint: \"http://otlp-collector:4317\"\n</code></pre>"},{"location":"operations/configuration/#server-configuration","title":"Server Configuration","text":""},{"location":"operations/configuration/#node_id","title":"node_id","text":"<p>Type: <code>string</code> (required)</p> <p>Description: Unique identifier for this server node.</p> <p>Rules: - Must be unique across the cluster - Non-empty string - Used as Raft node ID and SWIM member ID</p> <p>Examples:</p> <pre><code># Simple ID\nnode_id: \"node0\"\n\n# Hostname-based\nnode_id: \"norikv-prod-us-east-1a-0\"\n\n# UUID-based (for dynamic clusters)\nnode_id: \"550e8400-e29b-41d4-a716-446655440000\"\n</code></pre> <p>Environment variable: <code>NORIKV_NODE_ID</code></p> <pre><code>export NORIKV_NODE_ID=\"node0\"\n</code></pre>"},{"location":"operations/configuration/#rpc_addr","title":"rpc_addr","text":"<p>Type: <code>string</code> (default: <code>0.0.0.0:7447</code>)</p> <p>Description: gRPC server listen address for client requests and Raft peer-to-peer RPC.</p> <p>Format: <code>host:port</code> (must be valid SocketAddr)</p> <p>Examples:</p> <pre><code># Listen on all interfaces (production)\nrpc_addr: \"0.0.0.0:7447\"\n\n# Listen on specific interface\nrpc_addr: \"10.0.1.10:7447\"\n\n# Development (localhost only)\nrpc_addr: \"127.0.0.1:6000\"\n</code></pre> <p>Firewall rules:</p> <pre><code># Allow gRPC from clients and peers\niptables -A INPUT -p tcp --dport 7447 -j ACCEPT\n</code></pre> <p>Environment variable: <code>NORIKV_RPC_ADDR</code></p> <p>Default port: <code>7447</code> (NoriKV default)</p>"},{"location":"operations/configuration/#http_addr","title":"http_addr","text":"<p>Type: <code>string</code> (default: <code>0.0.0.0:8080</code>)</p> <p>Description: HTTP REST API listen address for health checks and metrics.</p> <p>Format: <code>host:port</code> (must be valid SocketAddr)</p> <p>Examples:</p> <pre><code># Standard HTTP port\nhttp_addr: \"0.0.0.0:8080\"\n\n# Separate monitoring network\nhttp_addr: \"192.168.1.10:8080\"\n\n# Development\nhttp_addr: \"127.0.0.1:3000\"\n</code></pre> <p>Firewall rules:</p> <pre><code># Allow HTTP from monitoring tools only\niptables -A INPUT -p tcp --dport 8080 -s 10.0.2.0/24 -j ACCEPT\niptables -A INPUT -p tcp --dport 8080 -j DROP\n</code></pre> <p>Environment variable: <code>NORIKV_HTTP_ADDR</code></p>"},{"location":"operations/configuration/#data_dir","title":"data_dir","text":"<p>Type: <code>PathBuf</code> (required)</p> <p>Description: Base directory for all persistent data (Raft WAL, LSM SSTables, manifests).</p> <p>Directory structure:</p> <pre><code>/var/lib/norikv/\n\u251c\u2500\u2500 raft/\n\u2502   \u251c\u2500\u2500 shard-0/\n\u2502   \u2502   \u251c\u2500\u2500 wal/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 000001.log\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 000002.log\n\u2502   \u2502   \u2514\u2500\u2500 snapshot/\n\u2502   \u2502       \u2514\u2500\u2500 snapshot-00012345.dat\n\u2502   \u251c\u2500\u2500 shard-1/\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 lsm/\n    \u251c\u2500\u2500 shard-0/\n    \u2502   \u251c\u2500\u2500 sst/\n    \u2502   \u2502   \u251c\u2500\u2500 L0-000001.sst\n    \u2502   \u2502   \u2514\u2500\u2500 L1-000002.sst\n    \u2502   \u251c\u2500\u2500 manifest/\n    \u2502   \u2502   \u2514\u2500\u2500 MANIFEST-000001\n    \u2502   \u2514\u2500\u2500 wal/\n    \u2502       \u2514\u2500\u2500 000001.wal\n    \u251c\u2500\u2500 shard-1/\n    \u2514\u2500\u2500 ...\n</code></pre> <p>Disk requirements: - Type: SSD strongly recommended (NVMe preferred) - Size: Plan for 3x your dataset size (replication + compaction) - IOPs: 10,000+ recommended for production</p> <p>Examples:</p> <pre><code># Production\ndata_dir: \"/var/lib/norikv\"\n\n# Development\ndata_dir: \"./data\"\n\n# Mounted volume\ndata_dir: \"/mnt/nvme0n1/norikv\"\n</code></pre> <p>Permissions:</p> <pre><code># Create directory with correct permissions\nsudo mkdir -p /var/lib/norikv\nsudo chown norikv:norikv /var/lib/norikv\nsudo chmod 750 /var/lib/norikv\n</code></pre> <p>Environment variable: <code>NORIKV_DATA_DIR</code></p>"},{"location":"operations/configuration/#cluster-configuration","title":"Cluster Configuration","text":""},{"location":"operations/configuration/#clusterseed_nodes","title":"cluster.seed_nodes","text":"<p>Type: <code>Vec&lt;String&gt;</code> (default: <code>[]</code> for single-node)</p> <p>Description: Initial seed nodes for SWIM membership bootstrap.</p> <p>Format: List of <code>host:port</code> addresses</p> <p>Rules: - Empty list = single-node mode (no SWIM) - Non-empty = multi-node cluster mode - Addresses must be reachable from this node - At least one seed must be alive to join</p> <p>Examples:</p> <p>Single-node (development):</p> <pre><code>cluster:\n  seed_nodes: []  # Empty = single-node mode\n</code></pre> <p>3-node cluster:</p> <pre><code>cluster:\n  seed_nodes:\n    - \"10.0.1.10:7447\"\n    - \"10.0.1.11:7447\"\n    - \"10.0.1.12:7447\"\n</code></pre> <p>Kubernetes (headless service):</p> <pre><code>cluster:\n  seed_nodes:\n    - \"norikv-0.norikv.default.svc.cluster.local:7447\"\n    - \"norikv-1.norikv.default.svc.cluster.local:7447\"\n    - \"norikv-2.norikv.default.svc.cluster.local:7447\"\n</code></pre> <p>Environment variable: <code>NORIKV_SEED_NODES</code> (comma-separated)</p> <pre><code>export NORIKV_SEED_NODES=\"10.0.1.10:7447,10.0.1.11:7447,10.0.1.12:7447\"\n</code></pre> <p>Bootstrapping a new cluster:</p> <ol> <li>Start node0 with empty seed_nodes (single-node mode)</li> <li>Start node1 with <code>seed_nodes: [\"node0:7447\"]</code></li> <li>Start node2 with <code>seed_nodes: [\"node0:7447\", \"node1:7447\"]</code></li> <li>All nodes converge on same membership view</li> </ol>"},{"location":"operations/configuration/#clustertotal_shards","title":"cluster.total_shards","text":"<p>Type: <code>u32</code> (default: <code>1024</code>)</p> <p>Description: Total number of virtual shards in the cluster.</p> <p>Rules: - Must be &gt; 0 - Fixed at cluster creation (cannot change later) - Power of 2 recommended (128, 256, 512, 1024, 2048)</p> <p>Tuning guidance:</p> Cluster Size Dataset Size Recommended Shards Shards/Node 1 node &lt;100GB 128-256 128-256 3 nodes 100-500GB 512-1024 170-340 9 nodes 500GB-5TB 1024-2048 113-227 27 nodes 5TB+ 2048-4096 75-151 <p>Trade-offs:</p> <p>More shards: -  Finer-grained load balancing -  Easier rebalancing (smaller units) -  More Raft overhead (more leaders, more heartbeats) -  Higher memory usage</p> <p>Fewer shards: -  Lower overhead -  Less memory usage -  Coarse-grained balancing -  Harder to rebalance</p> <p>Example:</p> <pre><code>cluster:\n  total_shards: 1024  # Default, works for most cases\n</code></pre>"},{"location":"operations/configuration/#clusterreplication_factor","title":"cluster.replication_factor","text":"<p>Type: <code>usize</code> (default: <code>3</code>)</p> <p>Description: Number of replicas per shard for fault tolerance.</p> <p>Rules: - Must be &gt; 0 - Should be \u2264 cluster size - Odd numbers preferred (3, 5, 7) for quorum</p> <p>Fault tolerance:</p> RF Tolerated Failures Quorum Size Recommended For 1 0 1 Development only 3 1 2 Standard production 5 2 3 Mission-critical 7 3 4 Maximum durability <p>Storage overhead:</p> <pre><code>Total storage = dataset_size \u00d7 replication_factor\n\nExample: 100GB dataset, RF=3 \u2192 300GB total\n</code></pre> <p>Examples:</p> <pre><code># Development (no replication)\ncluster:\n  replication_factor: 1\n\n# Production (standard)\ncluster:\n  replication_factor: 3\n\n# Mission-critical (high availability)\ncluster:\n  replication_factor: 5\n</code></pre>"},{"location":"operations/configuration/#telemetry-configuration","title":"Telemetry Configuration","text":""},{"location":"operations/configuration/#telemetryprometheusenabled","title":"telemetry.prometheus.enabled","text":"<p>Type: <code>bool</code> (default: <code>true</code>)</p> <p>Description: Enable Prometheus metrics export via <code>/metrics</code> endpoint.</p> <p>Examples:</p> <pre><code>telemetry:\n  prometheus:\n    enabled: true  # Export metrics on http_addr/metrics\n</code></pre> <p>Disable metrics:</p> <pre><code>telemetry:\n  prometheus:\n    enabled: false  # No /metrics endpoint\n</code></pre>"},{"location":"operations/configuration/#telemetryprometheusport","title":"telemetry.prometheus.port","text":"<p>Type: <code>u16</code> (default: <code>9090</code>)</p> <p>Description: Prometheus metrics port (currently unused, metrics served on <code>http_addr</code>).</p>"},{"location":"operations/configuration/#telemetryotlpenabled","title":"telemetry.otlp.enabled","text":"<p>Type: <code>bool</code> (default: <code>false</code>)</p> <p>Description: Enable OTLP (OpenTelemetry Protocol) exporter for traces and metrics.</p> <p>Examples:</p> <pre><code>telemetry:\n  otlp:\n    enabled: true\n    endpoint: \"http://otlp-collector:4317\"\n</code></pre>"},{"location":"operations/configuration/#telemetryotlpendpoint","title":"telemetry.otlp.endpoint","text":"<p>Type: <code>Option&lt;String&gt;</code> (default: <code>None</code>)</p> <p>Description: OTLP collector endpoint (gRPC).</p> <p>Format: <code>http://host:port</code> or <code>https://host:port</code></p> <p>Examples:</p> <pre><code># Local collector\ntelemetry:\n  otlp:\n    enabled: true\n    endpoint: \"http://localhost:4317\"\n\n# Jaeger\ntelemetry:\n  otlp:\n    enabled: true\n    endpoint: \"http://jaeger:4317\"\n\n# Honeycomb\ntelemetry:\n  otlp:\n    enabled: true\n    endpoint: \"https://api.honeycomb.io:443\"\n</code></pre>"},{"location":"operations/configuration/#raft-configuration-advanced","title":"Raft Configuration (Advanced)","text":"<p>Raft tuning parameters are currently set in code (not exposed via YAML). These are the defaults and their tuning guidance.</p>"},{"location":"operations/configuration/#timeouts","title":"Timeouts","text":"<p>heartbeat_interval - Default: <code>150ms</code> - Description: Leader sends AppendEntries (heartbeat) at this interval - Tuning: Must be &lt; <code>election_timeout_min</code>   - Increase for high-latency networks (WAN: 500ms)   - Decrease for low-latency (same datacenter: 50ms)</p> <p>election_timeout_min - Default: <code>300ms</code> - Description: Minimum election timeout (randomized between min and max) - Tuning:   - High-latency networks: <code>1000-2000ms</code>   - Low-latency: <code>150-300ms</code></p> <p>election_timeout_max - Default: <code>600ms</code> - Description: Maximum election timeout - Tuning: Should be 2x <code>election_timeout_min</code></p> <p>lease_duration - Default: <code>2000ms</code> - Description: Leader lease duration for fast reads - Tuning: Should be \u2265 2\u00d7 <code>heartbeat_interval</code></p> <p>Recommended network tuning:</p> Network Type heartbeat_interval election_timeout_min election_timeout_max lease_duration Same datacenter (LAN) 50ms 150ms 300ms 500ms Multi-AZ (low WAN) 150ms 300ms 600ms 2000ms Multi-region (high WAN) 500ms 1000ms 2000ms 5000ms"},{"location":"operations/configuration/#replication-settings","title":"Replication Settings","text":"<p>max_entries_per_append - Default: <code>1000 entries</code> - Description: Maximum entries per AppendEntries RPC - Tuning:   - Larger = fewer RPCs, more memory per message   - Smaller = more RPCs, less memory   - Increase for high-throughput: <code>5000-10000</code></p>"},{"location":"operations/configuration/#snapshot-settings","title":"Snapshot Settings","text":"<p>snapshot_log_size_bytes - Default: <code>256 MiB</code> - Description: Trigger snapshot when log exceeds this size - Tuning:   - Smaller = more frequent snapshots, less recovery time   - Larger = fewer snapshots, less I/O overhead   - Recommendation: <code>128 MiB</code> for fast recovery, <code>512 MiB</code> for lower overhead</p> <p>snapshot_entry_count - Default: <code>1,000,000 entries</code> - Description: Trigger snapshot when entry count exceeds this - Tuning: Depends on entry size   - Small entries (100B): <code>10,000,000</code>   - Large entries (10KB): <code>100,000</code></p> <p>snapshot_chunk_size - Default: <code>1 MiB</code> - Description: InstallSnapshot chunk size for streaming - Tuning:   - High-bandwidth networks: <code>4-8 MiB</code>   - Low-bandwidth: <code>256-512 KiB</code></p>"},{"location":"operations/configuration/#read-index-settings","title":"Read-Index Settings","text":"<p>max_pending_read_index - Default: <code>1000</code> - Description: Maximum concurrent read-index requests - Tuning: Increase for high read throughput (10,000+)</p>"},{"location":"operations/configuration/#apply-settings","title":"Apply Settings","text":"<p>apply_batch_size - Default: <code>100 commands</code> - Description: Apply commands to LSM in batches - Tuning:   - Larger = higher throughput, more latency variance   - Smaller = lower latency, less throughput   - High throughput: <code>500-1000</code>   - Low latency: <code>50-100</code></p>"},{"location":"operations/configuration/#lsm-configuration-advanced","title":"LSM Configuration (Advanced)","text":"<p>LSM tuning parameters are currently set in code. These are the defaults and tuning guidance.</p>"},{"location":"operations/configuration/#compaction-settings","title":"Compaction Settings","text":"<p>fanout (Tiering ratio) - Default: <code>10</code> - Description: Level size ratio (L1 = 10\u00d7 L0, L2 = 10\u00d7 L1, etc.) - Tuning:   - Smaller (5): More compaction, better read performance   - Larger (20): Less compaction, better write performance</p> <p>max_levels - Default: <code>7</code> - Description: Maximum LSM levels (L0-L6) - Tuning: Usually don't change (7 is sufficient for PB-scale)</p> <p>l1_slot_count - Default: <code>32</code> - Description: Number of guard-based partitions in L1 - Tuning: Increase for skewed workloads (64, 128)</p>"},{"location":"operations/configuration/#l0-settings","title":"L0 Settings","text":"<p>l0.max_files - Default: <code>12</code> - Description: Maximum L0 files before hard write stall - Tuning:   - Increase for write-heavy: <code>20-30</code>   - Decrease for stable latency: <code>8-10</code></p> <p>l0.soft_throttle_threshold - Default: <code>6</code> - Description: L0 count triggering write throttling - Tuning: Usually 50% of <code>max_files</code></p> <p>l0.soft_throttle_base_delay_ms - Default: <code>1ms</code> - Description: Base delay for throttling (linear backoff) - Tuning: Adjust based on workload   - Aggressive throttling: <code>5-10ms</code>   - Gentle throttling: <code>0.5-1ms</code></p>"},{"location":"operations/configuration/#memtable-settings","title":"Memtable Settings","text":"<p>memtable.flush_trigger_bytes - Default: <code>64 MiB</code> - Description: Trigger memtable flush at this size - Tuning:   - Larger = fewer flushes, more memory   - Smaller = more flushes, less memory   - High-memory systems: <code>128-256 MiB</code>   - Low-memory systems: <code>16-32 MiB</code></p>"},{"location":"operations/configuration/#filter-settings","title":"Filter Settings","text":"<p>filters.total_budget_mib - Default: <code>256 MiB</code> - Description: Total bloom filter memory budget - Tuning: Increase for better read performance (512 MiB, 1 GiB)</p> <p>filters.target_fp_point_lookups - Default: <code>0.001</code> (0.1% false positive rate) - Tuning:   - Lower = more memory, fewer false positives   - Higher = less memory, more false positives</p>"},{"location":"operations/configuration/#io-settings","title":"I/O Settings","text":"<p>io.max_background_compactions - Default: <code>4</code> - Description: Maximum concurrent background compactions - Tuning: Set to number of CPU cores - 2 (leave for requests)</p> <p>io.compaction_interval_sec - Default: <code>10 seconds</code> - Description: Compaction loop check interval - Tuning: Decrease for faster compaction (5s), increase for lower overhead (30s)</p> <p>io.rate_limit_mb_s - Default: <code>None</code> (no limit) - Description: Compaction I/O rate limit - Tuning: Set to prevent compaction from saturating disk   - SSD: <code>500-1000 MB/s</code>   - HDD: <code>50-100 MB/s</code></p>"},{"location":"operations/configuration/#environment-variables","title":"Environment Variables","text":"<p>All configuration can be overridden via environment variables:</p> Variable Config Field Example <code>NORIKV_NODE_ID</code> <code>node_id</code> <code>node0</code> <code>NORIKV_RPC_ADDR</code> <code>rpc_addr</code> <code>0.0.0.0:7447</code> <code>NORIKV_HTTP_ADDR</code> <code>http_addr</code> <code>0.0.0.0:8080</code> <code>NORIKV_DATA_DIR</code> <code>data_dir</code> <code>/var/lib/norikv</code> <code>NORIKV_SEED_NODES</code> <code>cluster.seed_nodes</code> <code>10.0.1.10:7447,10.0.1.11:7447</code> <p>Docker example:</p> <pre><code>docker run -d \\\n  -e NORIKV_NODE_ID=\"node0\" \\\n  -e NORIKV_RPC_ADDR=\"0.0.0.0:7447\" \\\n  -e NORIKV_HTTP_ADDR=\"0.0.0.0:8080\" \\\n  -e NORIKV_DATA_DIR=\"/data\" \\\n  -e NORIKV_SEED_NODES=\"node1:7447,node2:7447\" \\\n  -v /var/lib/norikv:/data \\\n  norikv/norikv-server:latest\n</code></pre>"},{"location":"operations/configuration/#configuration-examples","title":"Configuration Examples","text":""},{"location":"operations/configuration/#single-node-development","title":"Single-Node Development","text":"<p><code>dev-config.yaml</code>:</p> <pre><code>node_id: \"dev-node\"\nrpc_addr: \"127.0.0.1:6000\"\nhttp_addr: \"127.0.0.1:8080\"\ndata_dir: \"./data\"\n\ncluster:\n  seed_nodes: []  # Single-node mode\n  total_shards: 128  # Lower for dev\n  replication_factor: 1  # No replication\n\ntelemetry:\n  prometheus:\n    enabled: true\n</code></pre>"},{"location":"operations/configuration/#3-node-production-cluster","title":"3-Node Production Cluster","text":"<p><code>prod-node0.yaml</code>:</p> <pre><code>node_id: \"norikv-prod-node0\"\nrpc_addr: \"10.0.1.10:7447\"\nhttp_addr: \"10.0.1.10:8080\"\ndata_dir: \"/var/lib/norikv\"\n\ncluster:\n  seed_nodes:\n    - \"10.0.1.10:7447\"\n    - \"10.0.1.11:7447\"\n    - \"10.0.1.12:7447\"\n  total_shards: 1024\n  replication_factor: 3\n\ntelemetry:\n  prometheus:\n    enabled: true\n  otlp:\n    enabled: true\n    endpoint: \"http://otlp-collector:4317\"\n</code></pre> <p><code>prod-node1.yaml</code>: (similar, change node_id and rpc_addr)</p> <p><code>prod-node2.yaml</code>: (similar, change node_id and rpc_addr)</p>"},{"location":"operations/configuration/#kubernetes-statefulset","title":"Kubernetes StatefulSet","text":"<p><code>k8s-config.yaml</code> (ConfigMap):</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: norikv-config\ndata:\n  config.yaml: |\n    node_id: \"$(POD_NAME)\"  # Injected by StatefulSet\n    rpc_addr: \"0.0.0.0:7447\"\n    http_addr: \"0.0.0.0:8080\"\n    data_dir: \"/data\"\n    cluster:\n      seed_nodes:\n        - \"norikv-0.norikv:7447\"\n        - \"norikv-1.norikv:7447\"\n        - \"norikv-2.norikv:7447\"\n      total_shards: 1024\n      replication_factor: 3\n    telemetry:\n      prometheus:\n        enabled: true\n</code></pre>"},{"location":"operations/configuration/#validation","title":"Validation","text":""},{"location":"operations/configuration/#configuration-validation","title":"Configuration Validation","text":"<p>Config is validated on startup:</p> <pre><code>ServerConfig::load_from_file(\"config.yaml\")?.validate()?;\n</code></pre> <p>Validation checks: - <code>node_id</code> is non-empty - <code>rpc_addr</code> is valid SocketAddr - <code>http_addr</code> is valid SocketAddr - <code>data_dir</code> exists and is writable - <code>total_shards</code> &gt; 0 - <code>replication_factor</code> &gt; 0 - All <code>seed_nodes</code> are valid SocketAddr</p> <p>Validation errors:</p> <pre><code>Error: Invalid field: total_shards must be &gt; 0\nError: Invalid rpc_addr: invalid socket address syntax\nError: Cannot create data_dir: permission denied\n</code></pre>"},{"location":"operations/configuration/#best-practices","title":"Best Practices","text":""},{"location":"operations/configuration/#production-checklist","title":"Production Checklist","text":"<ul> <li> Set unique <code>node_id</code> for each node</li> <li> Use persistent storage for <code>data_dir</code> (not ephemeral)</li> <li> Configure <code>seed_nodes</code> for multi-node clusters</li> <li> Set <code>replication_factor</code> \u2265 3 for fault tolerance</li> <li> Enable Prometheus metrics for monitoring</li> <li> Use SSD/NVMe for <code>data_dir</code></li> <li> Allocate 3\u00d7 dataset size for storage (replication + compaction)</li> <li> Set firewall rules for <code>rpc_addr</code> and <code>http_addr</code></li> </ul>"},{"location":"operations/configuration/#security-checklist","title":"Security Checklist","text":"<ul> <li> Restrict <code>http_addr</code> to monitoring network only</li> <li> Use TLS for <code>rpc_addr</code> (future: mTLS support)</li> <li> Set file permissions on <code>data_dir</code> (750 or stricter)</li> <li> Run server as non-root user</li> <li> Enable audit logging (future feature)</li> </ul>"},{"location":"operations/configuration/#performance-tuning-checklist","title":"Performance Tuning Checklist","text":"<ul> <li> Tune Raft timeouts for network latency</li> <li> Adjust memtable size for memory availability</li> <li> Set L0 thresholds for latency/throughput trade-off</li> <li> Configure compaction concurrency for CPU cores</li> <li> Enable rate limiting to prevent compaction storms</li> </ul>"},{"location":"operations/configuration/#next-steps","title":"Next Steps","text":"<ul> <li>Deployment Guide - Production deployment patterns</li> <li>Metrics Reference - Monitor your configuration</li> <li>Troubleshooting - Common configuration issues</li> </ul>"},{"location":"operations/deployment/","title":"Deployment Guide","text":"<p>Production deployment patterns for NoriKV on bare metal, Docker, and Kubernetes.</p>"},{"location":"operations/deployment/#overview","title":"Overview","text":"<p>This guide covers deploying NoriKV in various environments:</p> <ul> <li>Single-Node - Development and testing</li> <li>3-Node Cluster (Bare Metal) - Traditional servers</li> <li>Docker - Containerized deployment</li> <li>Kubernetes - Cloud-native orchestration</li> <li>Cloud Providers - AWS, GCP, Azure</li> </ul>"},{"location":"operations/deployment/#prerequisites","title":"Prerequisites","text":""},{"location":"operations/deployment/#hardware-requirements","title":"Hardware Requirements","text":"<p>Minimum (Development): - CPU: 2 cores - RAM: 4 GB - Disk: 20 GB SSD</p> <p>Recommended (Production): - CPU: 8 cores (Intel Xeon or AMD EPYC) - RAM: 32 GB - Disk: 500 GB NVMe SSD (3000+ IOPS) - Network: 1 Gbps</p> <p>Scaling guidelines:</p> Cluster Size vCPU/node RAM/node Disk/node Network 1 node (dev) 2-4 8 GB 100 GB SSD 100 Mbps 3 nodes (small prod) 4-8 16-32 GB 500 GB NVMe 1 Gbps 9 nodes (medium prod) 8-16 32-64 GB 1 TB NVMe 10 Gbps 27 nodes (large prod) 16-32 64-128 GB 2 TB NVMe 10 Gbps"},{"location":"operations/deployment/#software-requirements","title":"Software Requirements","text":"<ul> <li>Operating System: Linux (Ubuntu 22.04, RHEL 8+, Debian 11+)</li> <li>Kernel: 5.10+ (for modern async I/O)</li> <li>systemd: For service management</li> <li>Docker: 20.10+ (if using containers)</li> <li>Kubernetes: 1.25+ (if using K8s)</li> </ul>"},{"location":"operations/deployment/#network-requirements","title":"Network Requirements","text":"<p>Ports:</p> Port Protocol Purpose Firewall Rule 7447 TCP gRPC (client + Raft) Open to clients and cluster 8080 TCP HTTP (health/metrics) Open to monitoring only <p>Bandwidth: - Intra-cluster: 1 Gbps minimum (10 Gbps recommended) - Client-to-cluster: Depends on workload (1-10 Gbps)</p> <p>Latency: - Same datacenter: &lt;1ms RTT - Multi-AZ: &lt;5ms RTT - Multi-region: &lt;50ms RTT (adjust Raft timeouts)</p>"},{"location":"operations/deployment/#single-node-deployment","title":"Single-Node Deployment","text":"<p>Perfect for development, testing, and small datasets (&lt;100GB).</p>"},{"location":"operations/deployment/#installation","title":"Installation","text":"<p>Download binary:</p> <pre><code># Download latest release\nwget https://github.com/norikv/norikv/releases/download/v0.1.0/norikv-server-linux-amd64\n\n# Make executable\nchmod +x norikv-server-linux-amd64\nsudo mv norikv-server-linux-amd64 /usr/local/bin/norikv-server\n</code></pre> <p>Or build from source:</p> <pre><code>git clone https://github.com/norikv/norikv.git\ncd norikv\ncargo build --release -p norikv-server\nsudo cp target/release/norikv-server /usr/local/bin/\n</code></pre>"},{"location":"operations/deployment/#configuration","title":"Configuration","text":"<p>Create config file:</p> <pre><code>sudo mkdir -p /etc/norikv\nsudo vim /etc/norikv/config.yaml\n</code></pre> <p><code>/etc/norikv/config.yaml</code>:</p> <pre><code>node_id: \"node0\"\nrpc_addr: \"0.0.0.0:7447\"\nhttp_addr: \"0.0.0.0:8080\"\ndata_dir: \"/var/lib/norikv\"\n\ncluster:\n  seed_nodes: []  # Single-node mode\n  total_shards: 128\n  replication_factor: 1\n\ntelemetry:\n  prometheus:\n    enabled: true\n</code></pre>"},{"location":"operations/deployment/#create-system-user","title":"Create System User","text":"<pre><code># Create norikv user\nsudo useradd -r -s /bin/false norikv\n\n# Create data directory\nsudo mkdir -p /var/lib/norikv\nsudo chown norikv:norikv /var/lib/norikv\nsudo chmod 750 /var/lib/norikv\n</code></pre>"},{"location":"operations/deployment/#systemd-service","title":"systemd Service","text":"<p>Create service file:</p> <pre><code>sudo vim /etc/systemd/system/norikv.service\n</code></pre> <p><code>/etc/systemd/system/norikv.service</code>:</p> <pre><code>[Unit]\nDescription=NoriKV Server\nDocumentation=https://docs.norikv.io\nAfter=network-online.target\nWants=network-online.target\n\n[Service]\nType=simple\nUser=norikv\nGroup=norikv\nExecStart=/usr/local/bin/norikv-server --config /etc/norikv/config.yaml\nRestart=on-failure\nRestartSec=5s\nLimitNOFILE=65536\nStandardOutput=journal\nStandardError=journal\n\n# Security hardening\nNoNewPrivileges=true\nPrivateTmp=true\nProtectSystem=strict\nProtectHome=true\nReadWritePaths=/var/lib/norikv\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>"},{"location":"operations/deployment/#start-service","title":"Start Service","text":"<pre><code># Reload systemd\nsudo systemctl daemon-reload\n\n# Enable service (start on boot)\nsudo systemctl enable norikv\n\n# Start service\nsudo systemctl start norikv\n\n# Check status\nsudo systemctl status norikv\n</code></pre>"},{"location":"operations/deployment/#verify-deployment","title":"Verify Deployment","text":"<p>Check health:</p> <pre><code>curl http://localhost:8080/health/quick\n# Expected: OK\n\ncurl http://localhost:8080/health | jq\n# Expected: {\"status\": \"healthy\", ...}\n</code></pre> <p>Check metrics:</p> <pre><code>curl http://localhost:8080/metrics | grep kv_requests_total\n</code></pre> <p>Test with client:</p> <pre><code># Install grpcurl\nbrew install grpcurl  # or apt-get install grpcurl\n\n# Test PUT\ngrpcurl -plaintext localhost:7447 norikv.Kv/Put \\\n  -d '{\"key\":\"dGVzdA==\",\"value\":\"dmFsdWU=\"}'\n\n# Test GET\ngrpcurl -plaintext localhost:7447 norikv.Kv/Get \\\n  -d '{\"key\":\"dGVzdA==\"}'\n</code></pre>"},{"location":"operations/deployment/#logs","title":"Logs","text":"<p>View logs:</p> <pre><code># Tail logs\nsudo journalctl -u norikv -f\n\n# Last 100 lines\nsudo journalctl -u norikv -n 100\n\n# Since yesterday\nsudo journalctl -u norikv --since yesterday\n\n# Filter by ERROR\nsudo journalctl -u norikv | grep ERROR\n</code></pre> <p>Log format (JSON):</p> <pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:00.123Z\",\n  \"level\": \"INFO\",\n  \"target\": \"norikv_server::node\",\n  \"message\": \"Starting node\",\n  \"fields\": {\n    \"node_id\": \"node0\"\n  }\n}\n</code></pre>"},{"location":"operations/deployment/#3-node-cluster-bare-metal","title":"3-Node Cluster (Bare Metal)","text":"<p>Production deployment with fault tolerance and high availability.</p>"},{"location":"operations/deployment/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Node 0        \u2502   \u2502   Node 1        \u2502   \u2502   Node 2        \u2502\n\u2502   10.0.1.10     \u2502   \u2502   10.0.1.11     \u2502   \u2502   10.0.1.12     \u2502\n\u2502                 \u2502   \u2502                 \u2502   \u2502                 \u2502\n\u2502   RF=3          \u2502   \u2502   RF=3          \u2502   \u2502   RF=3          \u2502\n\u2502   Shards:       \u2502   \u2502   Shards:       \u2502   \u2502   Shards:       \u2502\n\u2502   0-341         \u2502   \u2502   0-341         \u2502   \u2502   0-341         \u2502\n\u2502   (leader:      \u2502   \u2502   (leader:      \u2502   \u2502   (leader:      \u2502\n\u2502    0-341)       \u2502   \u2502    342-682)     \u2502   \u2502    683-1023)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                     \u2502                     \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       Raft + SWIM gossip\n</code></pre>"},{"location":"operations/deployment/#node-0-configuration","title":"Node 0 Configuration","text":"<p><code>/etc/norikv/config.yaml</code>:</p> <pre><code>node_id: \"node0\"\nrpc_addr: \"10.0.1.10:7447\"\nhttp_addr: \"10.0.1.10:8080\"\ndata_dir: \"/var/lib/norikv\"\n\ncluster:\n  seed_nodes:\n    - \"10.0.1.10:7447\"  # self\n    - \"10.0.1.11:7447\"  # node1\n    - \"10.0.1.12:7447\"  # node2\n  total_shards: 1024\n  replication_factor: 3\n\ntelemetry:\n  prometheus:\n    enabled: true\n</code></pre> <p>Node 1 and Node 2: Same config, change <code>node_id</code> and <code>rpc_addr</code>/<code>http_addr</code></p>"},{"location":"operations/deployment/#bootstrap-procedure","title":"Bootstrap Procedure","text":"<p>1. Start Node 0 (first node):</p> <pre><code># On node0 (10.0.1.10)\nsudo systemctl start norikv\nsudo journalctl -u norikv -f\n# Wait for \"Node started successfully\"\n</code></pre> <p>2. Start Node 1:</p> <pre><code># On node1 (10.0.1.11)\nsudo systemctl start norikv\n# Logs should show: \"Joining cluster via seed: 10.0.1.10:7447\"\n# Logs should show: \"Member joined: node0 at 10.0.1.10:7447\"\n</code></pre> <p>3. Start Node 2:</p> <pre><code># On node2 (10.0.1.12)\nsudo systemctl start norikv\n# Cluster now has 3 nodes\n</code></pre> <p>4. Verify cluster formation:</p> <pre><code># On any node\ncurl http://10.0.1.10:8080/health | jq '.nodes | length'\n# Expected: 3\n\n# Check SWIM cluster size\ncurl http://10.0.1.10:8080/metrics | grep swim_cluster_size\n# Expected: swim_cluster_size 3\n</code></pre>"},{"location":"operations/deployment/#verify-replication","title":"Verify Replication","text":"<p>Test write on node0, read from node1:</p> <pre><code># Write to node0\ngrpcurl -plaintext 10.0.1.10:7447 norikv.Kv/Put \\\n  -d '{\"key\":\"dGVzdC1yZXBs\",\"value\":\"cmVwbGljYXRlZA==\"}'\n\n# Wait for replication (1-2 seconds)\nsleep 2\n\n# Read from node1 (should succeed)\ngrpcurl -plaintext 10.0.1.11:7447 norikv.Kv/Get \\\n  -d '{\"key\":\"dGVzdC1yZXBs\"}'\n# Expected: {\"value\":\"cmVwbGljYXRlZA==\"}\n</code></pre>"},{"location":"operations/deployment/#load-balancer-setup","title":"Load Balancer Setup","text":"<p>HAProxy configuration:</p> <pre><code># /etc/haproxy/haproxy.cfg\n\nglobal\n    log /dev/log local0\n    log /dev/log local1 notice\n    chroot /var/lib/haproxy\n    stats socket /run/haproxy/admin.sock mode 660 level admin\n    stats timeout 30s\n    user haproxy\n    group haproxy\n    daemon\n\ndefaults\n    log     global\n    mode    tcp\n    option  tcplog\n    option  dontlognull\n    timeout connect 5000\n    timeout client  50000\n    timeout server  50000\n\nfrontend norikv_grpc\n    bind *:7447\n    default_backend norikv_servers\n\nbackend norikv_servers\n    balance roundrobin\n    option httpchk GET /health/quick\n    http-check expect status 200\n    server node0 10.0.1.10:7447 check port 8080 inter 5s fall 3 rise 2\n    server node1 10.0.1.11:7447 check port 8080 inter 5s fall 3 rise 2\n    server node2 10.0.1.12:7447 check port 8080 inter 5s fall 3 rise 2\n\nfrontend norikv_http\n    bind *:8080\n    default_backend norikv_http_servers\n\nbackend norikv_http_servers\n    balance roundrobin\n    option httpchk GET /health/quick\n    http-check expect status 200\n    server node0 10.0.1.10:8080 check inter 5s\n    server node1 10.0.1.11:8080 check inter 5s\n    server node2 10.0.1.12:8080 check inter 5s\n</code></pre> <p>Start HAProxy:</p> <pre><code>sudo systemctl restart haproxy\nsudo systemctl status haproxy\n</code></pre> <p>Test via load balancer:</p> <pre><code>grpcurl -plaintext localhost:7447 norikv.Kv/Put \\\n  -d '{\"key\":\"bGI=\",\"value\":\"dGVzdA==\"}'\n</code></pre>"},{"location":"operations/deployment/#docker-deployment","title":"Docker Deployment","text":""},{"location":"operations/deployment/#single-node-docker","title":"Single-Node Docker","text":"<p>Create docker-compose.yml:</p> <pre><code>version: '3.8'\n\nservices:\n  norikv:\n    image: norikv/norikv-server:latest\n    container_name: norikv-server\n    ports:\n      - \"7447:7447\"  # gRPC\n      - \"8080:8080\"  # HTTP\n    volumes:\n      - norikv-data:/data\n    environment:\n      NORIKV_NODE_ID: \"docker-node0\"\n      NORIKV_RPC_ADDR: \"0.0.0.0:7447\"\n      NORIKV_HTTP_ADDR: \"0.0.0.0:8080\"\n      NORIKV_DATA_DIR: \"/data\"\n      NORIKV_SEED_NODES: \"\"  # Single-node mode\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8080/health/quick\"]\n      interval: 10s\n      timeout: 5s\n      retries: 3\n      start_period: 30s\n\nvolumes:\n  norikv-data:\n    driver: local\n</code></pre> <p>Start:</p> <pre><code>docker-compose up -d\ndocker-compose logs -f norikv\n</code></pre>"},{"location":"operations/deployment/#3-node-docker-cluster","title":"3-Node Docker Cluster","text":"<p><code>docker-compose.yml</code>:</p> <pre><code>version: '3.8'\n\nservices:\n  norikv-node0:\n    image: norikv/norikv-server:latest\n    container_name: norikv-node0\n    hostname: norikv-node0\n    ports:\n      - \"7447:7447\"\n      - \"8080:8080\"\n    volumes:\n      - node0-data:/data\n    environment:\n      NORIKV_NODE_ID: \"node0\"\n      NORIKV_RPC_ADDR: \"0.0.0.0:7447\"\n      NORIKV_HTTP_ADDR: \"0.0.0.0:8080\"\n      NORIKV_DATA_DIR: \"/data\"\n      NORIKV_SEED_NODES: \"norikv-node0:7447,norikv-node1:7447,norikv-node2:7447\"\n    networks:\n      - norikv-cluster\n    restart: unless-stopped\n\n  norikv-node1:\n    image: norikv/norikv-server:latest\n    container_name: norikv-node1\n    hostname: norikv-node1\n    ports:\n      - \"7448:7447\"\n      - \"8081:8080\"\n    volumes:\n      - node1-data:/data\n    environment:\n      NORIKV_NODE_ID: \"node1\"\n      NORIKV_RPC_ADDR: \"0.0.0.0:7447\"\n      NORIKV_HTTP_ADDR: \"0.0.0.0:8080\"\n      NORIKV_DATA_DIR: \"/data\"\n      NORIKV_SEED_NODES: \"norikv-node0:7447,norikv-node1:7447,norikv-node2:7447\"\n    networks:\n      - norikv-cluster\n    restart: unless-stopped\n    depends_on:\n      - norikv-node0\n\n  norikv-node2:\n    image: norikv/norikv-server:latest\n    container_name: norikv-node2\n    hostname: norikv-node2\n    ports:\n      - \"7449:7447\"\n      - \"8082:8080\"\n    volumes:\n      - node2-data:/data\n    environment:\n      NORIKV_NODE_ID: \"node2\"\n      NORIKV_RPC_ADDR: \"0.0.0.0:7447\"\n      NORIKV_HTTP_ADDR: \"0.0.0.0:8080\"\n      NORIKV_DATA_DIR: \"/data\"\n      NORIKV_SEED_NODES: \"norikv-node0:7447,norikv-node1:7447,norikv-node2:7447\"\n    networks:\n      - norikv-cluster\n    restart: unless-stopped\n    depends_on:\n      - norikv-node0\n\nnetworks:\n  norikv-cluster:\n    driver: bridge\n\nvolumes:\n  node0-data:\n  node1-data:\n  node2-data:\n</code></pre> <p>Start cluster:</p> <pre><code>docker-compose up -d\ndocker-compose ps\ndocker-compose logs -f\n</code></pre>"},{"location":"operations/deployment/#kubernetes-deployment","title":"Kubernetes Deployment","text":""},{"location":"operations/deployment/#architecture_1","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  StatefulSet: norikv                           \u2502\n\u2502  Replicas: 3                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502  \u2502 norikv-0    \u2502  \u2502 norikv-1    \u2502  \u2502 norikv-2\u2502\u2502\n\u2502  \u2502 PVC: 100Gi  \u2502  \u2502 PVC: 100Gi  \u2502  \u2502 PVC: ..  \u2502\u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Headless Service: norikv  \u2502  (ClusterIP: None)\n\u2502  Port: 7447 (gRPC)         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"operations/deployment/#configmap","title":"ConfigMap","text":"<p><code>norikv-configmap.yaml</code>:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: norikv-config\n  namespace: default\ndata:\n  config.yaml: |\n    node_id: \"$(POD_NAME)\"\n    rpc_addr: \"0.0.0.0:7447\"\n    http_addr: \"0.0.0.0:8080\"\n    data_dir: \"/data\"\n    cluster:\n      seed_nodes:\n        - \"norikv-0.norikv.default.svc.cluster.local:7447\"\n        - \"norikv-1.norikv.default.svc.cluster.local:7447\"\n        - \"norikv-2.norikv.default.svc.cluster.local:7447\"\n      total_shards: 1024\n      replication_factor: 3\n    telemetry:\n      prometheus:\n        enabled: true\n</code></pre>"},{"location":"operations/deployment/#headless-service","title":"Headless Service","text":"<p><code>norikv-service.yaml</code>:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: norikv\n  namespace: default\n  labels:\n    app: norikv\nspec:\n  clusterIP: None  # Headless service\n  ports:\n    - name: grpc\n      port: 7447\n      targetPort: 7447\n      protocol: TCP\n    - name: http\n      port: 8080\n      targetPort: 8080\n      protocol: TCP\n  selector:\n    app: norikv\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: norikv-lb\n  namespace: default\n  labels:\n    app: norikv\nspec:\n  type: LoadBalancer\n  ports:\n    - name: grpc\n      port: 7447\n      targetPort: 7447\n      protocol: TCP\n  selector:\n    app: norikv\n</code></pre>"},{"location":"operations/deployment/#statefulset","title":"StatefulSet","text":"<p><code>norikv-statefulset.yaml</code>:</p> <pre><code>apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: norikv\n  namespace: default\nspec:\n  serviceName: norikv\n  replicas: 3\n  selector:\n    matchLabels:\n      app: norikv\n  template:\n    metadata:\n      labels:\n        app: norikv\n      annotations:\n        prometheus.io/scrape: \"true\"\n        prometheus.io/port: \"8080\"\n        prometheus.io/path: \"/metrics\"\n    spec:\n      containers:\n      - name: norikv\n        image: norikv/norikv-server:latest\n        ports:\n        - containerPort: 7447\n          name: grpc\n          protocol: TCP\n        - containerPort: 8080\n          name: http\n          protocol: TCP\n        env:\n        - name: POD_NAME\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: NORIKV_NODE_ID\n          value: \"$(POD_NAME)\"\n        volumeMounts:\n        - name: data\n          mountPath: /data\n        - name: config\n          mountPath: /etc/norikv\n        livenessProbe:\n          httpGet:\n            path: /health/quick\n            port: 8080\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          timeoutSeconds: 5\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /health/quick\n            port: 8080\n          initialDelaySeconds: 10\n          periodSeconds: 5\n          timeoutSeconds: 3\n          successThreshold: 1\n        resources:\n          requests:\n            cpu: \"2\"\n            memory: \"8Gi\"\n          limits:\n            cpu: \"4\"\n            memory: \"16Gi\"\n      volumes:\n      - name: config\n        configMap:\n          name: norikv-config\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n    spec:\n      accessModes: [ \"ReadWriteOnce\" ]\n      storageClassName: fast-ssd  # Adjust for your cloud\n      resources:\n        requests:\n          storage: 100Gi\n</code></pre>"},{"location":"operations/deployment/#deploy-to-kubernetes","title":"Deploy to Kubernetes","text":"<p>Apply manifests:</p> <pre><code>kubectl apply -f norikv-configmap.yaml\nkubectl apply -f norikv-service.yaml\nkubectl apply -f norikv-statefulset.yaml\n</code></pre> <p>Watch rollout:</p> <pre><code>kubectl rollout status statefulset/norikv\nkubectl get pods -l app=norikv -w\n</code></pre> <p>Verify cluster:</p> <pre><code># Check pods\nkubectl get pods -l app=norikv\n\n# Check health\nkubectl exec norikv-0 -- curl -s http://localhost:8080/health | jq\n\n# Check cluster size\nkubectl exec norikv-0 -- curl -s http://localhost:8080/metrics | grep swim_cluster_size\n# Expected: swim_cluster_size 3\n</code></pre>"},{"location":"operations/deployment/#access-from-outside-k8s","title":"Access from Outside K8s","text":"<p>Via LoadBalancer:</p> <pre><code># Get LoadBalancer IP\nkubectl get svc norikv-lb\n# NAME        TYPE           CLUSTER-IP     EXTERNAL-IP      PORT(S)\n# norikv-lb   LoadBalancer   10.100.200.1   35.123.45.67     7447:31234/TCP\n\n# Test\ngrpcurl -plaintext 35.123.45.67:7447 norikv.Kv/Put \\\n  -d '{\"key\":\"dGVzdA==\",\"value\":\"dmFsdWU=\"}'\n</code></pre> <p>Via Port-Forward (development):</p> <pre><code>kubectl port-forward svc/norikv-lb 7447:7447\ngrpcurl -plaintext localhost:7447 norikv.Kv/Put \\\n  -d '{\"key\":\"dGVzdA==\",\"value\":\"dmFsdWU=\"}'\n</code></pre>"},{"location":"operations/deployment/#cloud-provider-specific","title":"Cloud Provider Specific","text":""},{"location":"operations/deployment/#aws-eks","title":"AWS EKS","text":"<p>Storage Class (gp3 SSD):</p> <pre><code>apiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: fast-ssd\nprovisioner: ebs.csi.aws.com\nparameters:\n  type: gp3\n  iops: \"3000\"\n  throughput: \"125\"\nvolumeBindingMode: WaitForFirstConsumer\n</code></pre> <p>Node affinity (i3en instances with NVMe):</p> <pre><code>affinity:\n  nodeAffinity:\n    requiredDuringSchedulingIgnoredDuringExecution:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: node.kubernetes.io/instance-type\n          operator: In\n          values:\n          - i3en.xlarge\n          - i3en.2xlarge\n</code></pre>"},{"location":"operations/deployment/#gcp-gke","title":"GCP GKE","text":"<p>Storage Class (pd-ssd):</p> <pre><code>apiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: fast-ssd\nprovisioner: pd.csi.storage.gke.io\nparameters:\n  type: pd-ssd\n  replication-type: regional-pd\nvolumeBindingMode: WaitForFirstConsumer\n</code></pre>"},{"location":"operations/deployment/#azure-aks","title":"Azure AKS","text":"<p>Storage Class (Premium_LRS):</p> <pre><code>apiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: fast-ssd\nprovisioner: disk.csi.azure.com\nparameters:\n  skuName: Premium_LRS\nvolumeBindingMode: WaitForFirstConsumer\n</code></pre>"},{"location":"operations/deployment/#production-checklist","title":"Production Checklist","text":""},{"location":"operations/deployment/#pre-deployment","title":"Pre-Deployment","text":"<ul> <li> Size hardware (CPU, RAM, disk) based on workload</li> <li> Provision SSD/NVMe storage (not HDD)</li> <li> Configure firewall rules (ports 7447, 8080)</li> <li> Set up monitoring (Prometheus + Grafana)</li> <li> Configure log aggregation (ELK, Loki)</li> <li> Plan backup strategy (snapshots)</li> </ul>"},{"location":"operations/deployment/#post-deployment","title":"Post-Deployment","text":"<ul> <li> Verify cluster formation (3 nodes visible)</li> <li> Test replication (write on node0, read from node1)</li> <li> Load test (simulate production traffic)</li> <li> Test failure scenarios (kill node, network partition)</li> <li> Set up alerts (Prometheus Alertmanager)</li> <li> Document runbook (incident response)</li> </ul>"},{"location":"operations/deployment/#next-steps","title":"Next Steps","text":"<ul> <li>Configuration Reference - Tune server settings</li> <li>Metrics - Set up monitoring</li> <li>Troubleshooting - Common deployment issues</li> </ul>"},{"location":"operations/metrics/","title":"Metrics Reference","text":"<p>Complete reference for all Prometheus metrics exposed by NoriKV.</p>"},{"location":"operations/metrics/#overview","title":"Overview","text":"<p>NoriKV exposes metrics in Prometheus text format via the <code>/metrics</code> HTTP endpoint. Metrics are collected using the prometheus-client crate and implement the nori-observe::Meter trait for vendor-neutral instrumentation.</p> <p>Metrics Categories: - KV Metrics - Client request counters and latencies - LSM Metrics - Storage engine performance - Raft Metrics - Consensus and replication - SWIM Metrics - Membership and failure detection - System Metrics - Resource usage and health</p>"},{"location":"operations/metrics/#metrics-architecture","title":"Metrics Architecture","text":""},{"location":"operations/metrics/#design-decisions","title":"Design Decisions","text":"<p>1. Vendor-Neutral Instrumentation</p> <p>All components emit metrics via the <code>nori_observe::Meter</code> trait:</p> <pre><code>pub trait Meter: Send + Sync {\n    fn counter(&amp;self, name: &amp;'static str, labels: &amp;'static [(&amp;'static str, &amp;'static str)])\n        -&gt; Box&lt;dyn Counter&gt;;\n    fn gauge(&amp;self, name: &amp;'static str, labels: &amp;'static [(&amp;'static str, &amp;'static str)])\n        -&gt; Box&lt;dyn Gauge&gt;;\n    fn histo(&amp;self, name: &amp;'static str, buckets: &amp;'static [f64], labels: &amp;'static [(&amp;'static str, &amp;'static str)])\n        -&gt; Box&lt;dyn Histogram&gt;;\n}\n</code></pre> <p>Benefits: - Core crates (nori-lsm, nori-raft, nori-swim) have zero dependencies on Prometheus - Can swap backends (OTLP, StatsD, custom) without changing core code - Enables testing with mock meters</p> <p>2. Prometheus Implementation</p> <p>The server implements <code>Meter</code> using prometheus-client:</p> <pre><code>// apps/norikv-server/src/metrics.rs\npub struct PrometheusMeter {\n    registry: Arc&lt;Mutex&lt;Registry&gt;&gt;,\n    counters: Arc&lt;Mutex&lt;HashMap&lt;String, Family&lt;Vec&lt;(String, String)&gt;, PromCounter&gt;&gt;&gt;&gt;,\n    gauges: Arc&lt;Mutex&lt;HashMap&lt;String, Family&lt;Vec&lt;(String, String)&gt;, PromGauge&gt;&gt;&gt;&gt;,\n    histograms: Arc&lt;Mutex&lt;HashMap&lt;String, Family&lt;Vec&lt;(String, String)&gt;, PromHistogram&gt;&gt;&gt;&gt;,\n}\n</code></pre> <p>Key Features: - Thread-safe with <code>Arc&lt;Mutex&lt;...&gt;&gt;</code> for concurrent updates - Metric families for automatic label handling - Exponential histogram buckets (1.0, 2.0, 4.0, ..., 512.0) for latency - Registry for text format export</p> <p>3. Wiring</p> <p>Metrics are wired at server startup:</p> <pre><code>// Create meter\nlet meter = Arc::new(PrometheusMeter::new());\n\n// Wire to gRPC server\nlet grpc_server = GrpcServer::with_backend(addr, backend)\n    .with_meter(meter.clone() as Arc&lt;dyn Meter&gt;);\n\n// Wire to HTTP server\nlet http_server = HttpServer::new(addr, health_checker, meter.clone());\n</code></pre> <p>4. Histogram Buckets</p> <p>Exponential buckets optimized for latency distribution:</p> <pre><code>exponential_buckets(1.0, 2.0, 10)\n// \u2192 [1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0, 128.0, 256.0, 512.0]\n</code></pre> <p>Rationale: - Covers range from 1ms (fast cache hit) to 512ms (slow compaction/network) - Good precision for typical latencies (1-20ms) - Standard Prometheus practice for latency metrics</p>"},{"location":"operations/metrics/#kv-metrics","title":"KV Metrics","text":""},{"location":"operations/metrics/#kv_requests_total","title":"kv_requests_total","text":"<p>Type: Counter</p> <p>Description: Total number of KV requests by operation type.</p> <p>Labels: - <code>operation</code> - Request type: <code>put</code>, <code>get</code>, <code>delete</code>, <code>scan</code></p> <p>Example:</p> <pre><code>kv_requests_total{operation=\"put\"} 12345\nkv_requests_total{operation=\"get\"} 67890\nkv_requests_total{operation=\"delete\"} 123\nkv_requests_total{operation=\"scan\"} 456\n</code></pre> <p>Use Cases: - Calculate request rate: <code>rate(kv_requests_total[5m])</code> - Track operation mix: <code>sum by (operation) (rate(kv_requests_total[1m]))</code> - Alert on zero traffic: <code>rate(kv_requests_total[5m]) == 0</code></p> <p>PromQL Examples:</p> <pre><code># Total requests per second (all operations)\nsum(rate(kv_requests_total[5m]))\n\n# Requests per second by operation\nrate(kv_requests_total{operation=\"put\"}[5m])\n\n# Operation distribution (%)\n100 * rate(kv_requests_total[5m])\n  / ignoring(operation) group_left\n  sum(rate(kv_requests_total[5m]))\n</code></pre>"},{"location":"operations/metrics/#kv_request_duration_ms","title":"kv_request_duration_ms","text":"<p>Type: Histogram</p> <p>Description: Request latency in milliseconds, bucketed by operation, status, and result.</p> <p>Labels: - <code>operation</code> - Request type: <code>put</code>, <code>get</code>, <code>delete</code>, <code>scan</code> - <code>status</code> - Request outcome: <code>success</code>, <code>not_leader</code>, <code>error</code> - <code>result</code> - For GET: <code>found</code>, <code>not_found</code> (only for successful GETs)</p> <p>Buckets: <code>[1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0, 128.0, 256.0, 512.0]</code> (ms)</p> <p>Example:</p> <pre><code>kv_request_duration_ms_bucket{operation=\"put\",status=\"success\",le=\"1.0\"} 5000\nkv_request_duration_ms_bucket{operation=\"put\",status=\"success\",le=\"2.0\"} 8000\nkv_request_duration_ms_bucket{operation=\"put\",status=\"success\",le=\"4.0\"} 10000\nkv_request_duration_ms_bucket{operation=\"put\",status=\"success\",le=\"8.0\"} 11500\nkv_request_duration_ms_bucket{operation=\"put\",status=\"success\",le=\"16.0\"} 12000\nkv_request_duration_ms_bucket{operation=\"put\",status=\"success\",le=\"+Inf\"} 12345\nkv_request_duration_ms_sum{operation=\"put\",status=\"success\"} 123450.5\nkv_request_duration_ms_count{operation=\"put\",status=\"success\"} 12345\n</code></pre> <p>Use Cases: - Calculate p95 latency: <code>histogram_quantile(0.95, rate(kv_request_duration_ms_bucket[5m]))</code> - Alert on high latency: <code>histogram_quantile(0.95, ...) &gt; 50</code> - Track cache hit latency: filter by <code>result=\"found\"</code></p> <p>PromQL Examples:</p> <pre><code># P95 PUT latency\nhistogram_quantile(0.95,\n  rate(kv_request_duration_ms_bucket{operation=\"put\"}[5m])\n)\n\n# P99 GET latency (found vs not found)\nhistogram_quantile(0.99,\n  rate(kv_request_duration_ms_bucket{operation=\"get\",result=\"found\"}[5m])\n)\n\n# Average latency across all operations\nrate(kv_request_duration_ms_sum[5m])\n  / rate(kv_request_duration_ms_count[5m])\n\n# Slow requests (&gt;100ms)\nsum(rate(kv_request_duration_ms_bucket{le=\"128.0\"}[5m]))\n  - sum(rate(kv_request_duration_ms_bucket{le=\"64.0\"}[5m]))\n</code></pre> <p>Grafana Dashboard:</p> <pre><code>{\n  \"targets\": [\n    {\n      \"expr\": \"histogram_quantile(0.50, rate(kv_request_duration_ms_bucket{operation=\\\"put\\\"}[5m]))\",\n      \"legendFormat\": \"p50\"\n    },\n    {\n      \"expr\": \"histogram_quantile(0.95, rate(kv_request_duration_ms_bucket{operation=\\\"put\\\"}[5m]))\",\n      \"legendFormat\": \"p95\"\n    },\n    {\n      \"expr\": \"histogram_quantile(0.99, rate(kv_request_duration_ms_bucket{operation=\\\"put\\\"}[5m]))\",\n      \"legendFormat\": \"p99\"\n    }\n  ]\n}\n</code></pre>"},{"location":"operations/metrics/#lsm-metrics","title":"LSM Metrics","text":""},{"location":"operations/metrics/#lsm_compaction_duration_ms","title":"lsm_compaction_duration_ms","text":"<p>Type: Histogram</p> <p>Description: Time spent in compaction, in milliseconds.</p> <p>Labels: - <code>level</code> - Source level: <code>L0</code>, <code>L1</code>, <code>L2</code>, etc. - <code>result</code> - Compaction outcome: <code>success</code>, <code>error</code></p> <p>Buckets: Exponential from 1ms to 10 seconds</p> <p>Use Cases: - Detect compaction storms: <code>rate(lsm_compaction_duration_ms_count[1m]) &gt; 10</code> - Alert on slow compaction: <code>histogram_quantile(0.95, ...) &gt; 5000</code> - Track compaction efficiency by level</p> <p>PromQL Examples:</p> <pre><code># Compactions per minute\nrate(lsm_compaction_duration_ms_count[1m]) * 60\n\n# Average compaction time\nrate(lsm_compaction_duration_ms_sum[5m])\n  / rate(lsm_compaction_duration_ms_count[5m])\n\n# P99 L0 compaction time\nhistogram_quantile(0.99,\n  rate(lsm_compaction_duration_ms_bucket{level=\"L0\"}[5m])\n)\n</code></pre>"},{"location":"operations/metrics/#lsm_memtable_size_bytes","title":"lsm_memtable_size_bytes","text":"<p>Type: Gauge</p> <p>Description: Current memtable size in bytes.</p> <p>Labels: - <code>shard_id</code> - Shard ID</p> <p>Use Cases: - Monitor memory usage - Detect memtable bloat - Tune flush threshold</p> <p>PromQL Examples:</p> <pre><code># Total memtable memory across all shards\nsum(lsm_memtable_size_bytes)\n\n# Largest memtable\nmax(lsm_memtable_size_bytes)\n\n# Alert on memtable &gt;64MB (should flush at 4MB)\nlsm_memtable_size_bytes &gt; 67108864\n</code></pre>"},{"location":"operations/metrics/#lsm_sstable_count","title":"lsm_sstable_count","text":"<p>Type: Gauge</p> <p>Description: Number of SSTables per level.</p> <p>Labels: - <code>level</code> - Level: <code>L0</code>, <code>L1</code>, <code>L2</code>, etc. - <code>shard_id</code> - Shard ID</p> <p>Use Cases: - Monitor compaction health - Detect L0 storms (too many L0 SSTables) - Capacity planning</p> <p>PromQL Examples:</p> <pre><code># L0 SSTable count\nsum(lsm_sstable_count{level=\"L0\"})\n\n# Alert on L0 storm (&gt;10 files triggers compaction throttling)\nlsm_sstable_count{level=\"L0\"} &gt; 10\n\n# Total SSTables across all levels\nsum(lsm_sstable_count)\n</code></pre>"},{"location":"operations/metrics/#raft-metrics","title":"Raft Metrics","text":""},{"location":"operations/metrics/#raft_leader_changes_total","title":"raft_leader_changes_total","text":"<p>Type: Counter</p> <p>Description: Total number of leader changes (elections).</p> <p>Labels: - <code>shard_id</code> - Shard ID</p> <p>Use Cases: - Detect cluster instability - Alert on frequent elections - Track split-brain scenarios</p> <p>PromQL Examples:</p> <pre><code># Leader changes per hour\nrate(raft_leader_changes_total[1h]) * 3600\n\n# Alert on frequent elections (&gt;2 per hour)\nrate(raft_leader_changes_total[1h]) * 3600 &gt; 2\n</code></pre>"},{"location":"operations/metrics/#raft_commit_index","title":"raft_commit_index","text":"<p>Type: Gauge</p> <p>Description: Current committed log index.</p> <p>Labels: - <code>shard_id</code> - Shard ID - <code>node_id</code> - Node ID</p> <p>Use Cases: - Monitor replication lag - Detect stalled followers - Track write throughput</p> <p>PromQL Examples:</p> <pre><code># Replication lag (leader vs follower)\nmax(raft_commit_index{shard_id=\"0\"})\n  - raft_commit_index{shard_id=\"0\"}\n\n# Commit rate (writes per second)\nrate(raft_commit_index[1m])\n</code></pre>"},{"location":"operations/metrics/#raft_term","title":"raft_term","text":"<p>Type: Gauge</p> <p>Description: Current Raft term.</p> <p>Labels: - <code>shard_id</code> - Shard ID</p> <p>Use Cases: - Track election history - Detect term drift</p> <p>PromQL Examples:</p> <pre><code># Current term\nmax(raft_term)\n\n# Term changes (indicates elections)\ndelta(raft_term[1h])\n</code></pre>"},{"location":"operations/metrics/#swim-metrics","title":"SWIM Metrics","text":""},{"location":"operations/metrics/#swim_cluster_size","title":"swim_cluster_size","text":"<p>Type: Gauge</p> <p>Description: Number of alive members in the cluster.</p> <p>Labels: None</p> <p>Use Cases: - Monitor cluster membership - Alert on node failures - Capacity tracking</p> <p>PromQL Examples:</p> <pre><code># Current cluster size\nswim_cluster_size\n\n# Alert on cluster size drop\nswim_cluster_size &lt; 3\n</code></pre>"},{"location":"operations/metrics/#swim_failed_members_total","title":"swim_failed_members_total","text":"<p>Type: Counter</p> <p>Description: Total number of members marked as failed.</p> <p>Labels: None</p> <p>Use Cases: - Track failure rate - Alert on frequent failures - SLA reporting</p> <p>PromQL Examples:</p> <pre><code># Failures per hour\nrate(swim_failed_members_total[1h]) * 3600\n\n# Alert on &gt;1 failure per hour\nrate(swim_failed_members_total[1h]) * 3600 &gt; 1\n</code></pre>"},{"location":"operations/metrics/#swim_gossip_latency_ms","title":"swim_gossip_latency_ms","text":"<p>Type: Histogram</p> <p>Description: Gossip message round-trip time in milliseconds.</p> <p>Labels: None</p> <p>Buckets: Exponential from 1ms to 1s</p> <p>Use Cases: - Monitor network health - Detect network degradation - Tune gossip interval</p> <p>PromQL Examples:</p> <pre><code># P95 gossip latency\nhistogram_quantile(0.95,\n  rate(swim_gossip_latency_ms_bucket[5m])\n)\n\n# Alert on high gossip latency (&gt;100ms indicates network issues)\nhistogram_quantile(0.95, rate(swim_gossip_latency_ms_bucket[5m])) &gt; 100\n</code></pre>"},{"location":"operations/metrics/#system-metrics","title":"System Metrics","text":""},{"location":"operations/metrics/#process_cpu_seconds_total","title":"process_cpu_seconds_total","text":"<p>Type: Counter</p> <p>Description: Total CPU time consumed by the process (from Prometheus client library).</p> <p>Labels: None</p> <p>PromQL Examples:</p> <pre><code># CPU usage percentage\nrate(process_cpu_seconds_total[1m]) * 100\n</code></pre>"},{"location":"operations/metrics/#process_resident_memory_bytes","title":"process_resident_memory_bytes","text":"<p>Type: Gauge</p> <p>Description: Resident memory size in bytes (from Prometheus client library).</p> <p>Labels: None</p> <p>PromQL Examples:</p> <pre><code># Memory usage in GB\nprocess_resident_memory_bytes / 1024^3\n</code></pre>"},{"location":"operations/metrics/#alerting-rules","title":"Alerting Rules","text":""},{"location":"operations/metrics/#critical-alerts","title":"Critical Alerts","text":"<pre><code>groups:\n- name: norikv_critical\n  rules:\n  # Server down\n  - alert: NoriKVDown\n    expr: up{job=\"norikv\"} == 0\n    for: 1m\n    labels:\n      severity: critical\n    annotations:\n      summary: \"NoriKV instance {{ $labels.instance }} is down\"\n\n  # High error rate\n  - alert: NoriKVHighErrorRate\n    expr: |\n      rate(kv_requests_total{status=\"error\"}[5m])\n      / rate(kv_requests_total[5m]) &gt; 0.05\n    for: 2m\n    labels:\n      severity: critical\n    annotations:\n      summary: \"NoriKV error rate &gt;5% on {{ $labels.instance }}\"\n\n  # Cluster size drop\n  - alert: NoriKVClusterShrunk\n    expr: swim_cluster_size &lt; 3\n    for: 5m\n    labels:\n      severity: critical\n    annotations:\n      summary: \"NoriKV cluster size dropped to {{ $value }}\"\n</code></pre>"},{"location":"operations/metrics/#warning-alerts","title":"Warning Alerts","text":"<pre><code>groups:\n- name: norikv_warning\n  rules:\n  # High latency\n  - alert: NoriKVHighLatency\n    expr: |\n      histogram_quantile(0.95,\n        rate(kv_request_duration_ms_bucket{operation=\"put\"}[5m])\n      ) &gt; 50\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"NoriKV p95 PUT latency &gt;50ms on {{ $labels.instance }}\"\n\n  # Frequent leader elections\n  - alert: NoriKVFrequentElections\n    expr: rate(raft_leader_changes_total[1h]) * 3600 &gt; 2\n    for: 10m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"NoriKV shard {{ $labels.shard_id }} having frequent elections\"\n\n  # L0 storm\n  - alert: NoriKVL0Storm\n    expr: lsm_sstable_count{level=\"L0\"} &gt; 10\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"NoriKV shard {{ $labels.shard_id }} has {{ $value }} L0 SSTables\"\n</code></pre>"},{"location":"operations/metrics/#grafana-dashboards","title":"Grafana Dashboards","text":""},{"location":"operations/metrics/#kv-request-dashboard","title":"KV Request Dashboard","text":"<pre><code>{\n  \"dashboard\": {\n    \"title\": \"NoriKV - KV Requests\",\n    \"rows\": [\n      {\n        \"title\": \"Request Rate\",\n        \"panels\": [\n          {\n            \"type\": \"graph\",\n            \"targets\": [\n              {\n                \"expr\": \"sum(rate(kv_requests_total[5m])) by (operation)\",\n                \"legendFormat\": \"{{ operation }}\"\n              }\n            ]\n          }\n        ]\n      },\n      {\n        \"title\": \"Latency Percentiles\",\n        \"panels\": [\n          {\n            \"type\": \"graph\",\n            \"targets\": [\n              {\n                \"expr\": \"histogram_quantile(0.50, rate(kv_request_duration_ms_bucket[5m]))\",\n                \"legendFormat\": \"p50\"\n              },\n              {\n                \"expr\": \"histogram_quantile(0.95, rate(kv_request_duration_ms_bucket[5m]))\",\n                \"legendFormat\": \"p95\"\n              },\n              {\n                \"expr\": \"histogram_quantile(0.99, rate(kv_request_duration_ms_bucket[5m]))\",\n                \"legendFormat\": \"p99\"\n              }\n            ]\n          }\n        ]\n      },\n      {\n        \"title\": \"Error Rate\",\n        \"panels\": [\n          {\n            \"type\": \"graph\",\n            \"targets\": [\n              {\n                \"expr\": \"rate(kv_requests_total{status=\\\"error\\\"}[5m]) / rate(kv_requests_total[5m])\",\n                \"legendFormat\": \"error_rate\"\n              }\n            ]\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"operations/metrics/#performance-considerations","title":"Performance Considerations","text":""},{"location":"operations/metrics/#metric-collection-overhead","title":"Metric Collection Overhead","text":"<p>Counter increment: ~80ns - Lock-free atomic operations - No allocations - Negligible impact on hot path</p> <p>Histogram observation: ~200ns - Binary search for bucket - Atomic increment - Acceptable for request handlers</p> <p>Registry export (GET /metrics): ~1-5ms - Iterates all metrics - Formats as text - Called infrequently (15s scrape interval)</p>"},{"location":"operations/metrics/#best-practices","title":"Best Practices","text":"<ol> <li>Use histograms for latencies - Not averages (lose distribution)</li> <li>Scrape every 15s - Good balance of resolution and overhead</li> <li>Limit cardinality - Avoid high-cardinality labels (user IDs, keys)</li> <li>Pre-allocate labels - Use <code>&amp;'static [(&amp;'static str, &amp;'static str)]</code></li> <li>Export at /metrics - Standard Prometheus convention</li> </ol>"},{"location":"operations/metrics/#troubleshooting","title":"Troubleshooting","text":""},{"location":"operations/metrics/#missing-metrics","title":"Missing Metrics","text":"<p>Problem: Expected metrics not appearing</p> <p>Debug:</p> <pre><code># Check if server started with meter\njournalctl -u norikv-server | grep \"Enabling KV metrics\"\n\n# Verify meter is wired\ncurl http://localhost:8080/metrics | grep kv_requests_total\n</code></pre> <p>Solution: Ensure meter is passed to both GrpcServer and HttpServer</p>"},{"location":"operations/metrics/#stale-metrics","title":"Stale Metrics","text":"<p>Problem: Metrics not updating</p> <p>Debug:</p> <pre><code># Send a request\ngrpcurl -plaintext localhost:6000 norikv.Kv/Put \\\n  -d '{\"key\":\"dGVzdA==\",\"value\":\"dmFsdWU=\"}'\n\n# Check metric immediately\ncurl -s http://localhost:8080/metrics | grep kv_requests_total\n</code></pre> <p>Solution: Check if meter is being used in KvService handlers</p>"},{"location":"operations/metrics/#next-steps","title":"Next Steps","text":"<ul> <li>REST API - HTTP endpoints for metrics export</li> <li>Configuration - Tune metric collection</li> <li>Deployment - Prometheus/Grafana setup</li> </ul>"},{"location":"operations/rest-api/","title":"REST API Reference","text":"<p>HTTP endpoints for health checks, metrics, and cluster management.</p>"},{"location":"operations/rest-api/#overview","title":"Overview","text":"<p>NoriKV exposes a REST API via HTTP for operational tasks:</p> <ul> <li>Health checks - Monitor server and shard health</li> <li>Metrics - Prometheus-format metrics</li> <li>Admin operations - Cluster management (future)</li> </ul> <p>The HTTP server runs on a separate port from the gRPC API, allowing you to: - Isolate operational traffic from client traffic - Configure different firewall rules - Use load balancer health checks without authentication</p>"},{"location":"operations/rest-api/#base-configuration","title":"Base Configuration","text":"<pre><code># Start server with HTTP API on port 8080\nnorikv-server \\\n  --http-addr 0.0.0.0:8080 \\\n  --rpc-addr 0.0.0.0:6000\n</code></pre> <p>Default ports: - HTTP REST API: <code>8080</code> - gRPC client API: <code>6000</code></p>"},{"location":"operations/rest-api/#endpoints","title":"Endpoints","text":""},{"location":"operations/rest-api/#health-checks","title":"Health Checks","text":""},{"location":"operations/rest-api/#quick-health-check","title":"Quick Health Check","text":"<p>Endpoint: <code>GET /health/quick</code></p> <p>Purpose: Fast health check for load balancers and uptime monitors.</p> <p>Response: - 200 OK - Server is healthy (shard 0 is responsive) - 503 Service Unavailable - Server is unhealthy</p> <p>Response Body: Plain text <code>OK</code> or <code>UNAVAILABLE</code></p> <p>Performance: - Latency: &lt;1ms (checks only shard 0) - No disk I/O - Minimal CPU overhead</p> <p>Use Cases: - Kubernetes liveness/readiness probes - Load balancer health checks - Uptime monitoring services</p> <p>Example:</p> <pre><code># Check if server is healthy\ncurl -i http://localhost:8080/health/quick\n# HTTP/1.1 200 OK\n# OK\n\n# Use in scripts\nif curl -sf http://localhost:8080/health/quick &gt; /dev/null; then\n  echo \"Server is healthy\"\nelse\n  echo \"Server is down\"\n  exit 1\nfi\n</code></pre> <p>Kubernetes Example:</p> <pre><code>apiVersion: v1\nkind: Pod\nspec:\n  containers:\n  - name: norikv\n    livenessProbe:\n      httpGet:\n        path: /health/quick\n        port: 8080\n      initialDelaySeconds: 5\n      periodSeconds: 10\n    readinessProbe:\n      httpGet:\n        path: /health/quick\n        port: 8080\n      initialDelaySeconds: 3\n      periodSeconds: 5\n</code></pre>"},{"location":"operations/rest-api/#comprehensive-health-status","title":"Comprehensive Health Status","text":"<p>Endpoint: <code>GET /health</code></p> <p>Purpose: Detailed health status for all shards and components.</p> <p>Response: JSON object with server and shard-level health</p> <p>Response Format:</p> <pre><code>{\n  \"status\": \"healthy\",\n  \"node_id\": \"node0\",\n  \"uptime_seconds\": 3600,\n  \"total_shards\": 1024,\n  \"active_shards\": 42,\n  \"shards\": [\n    {\n      \"id\": 0,\n      \"status\": \"healthy\",\n      \"is_leader\": true,\n      \"raft_term\": 5,\n      \"commit_index\": 12345,\n      \"last_applied\": 12345\n    },\n    {\n      \"id\": 1,\n      \"status\": \"healthy\",\n      \"is_leader\": false,\n      \"raft_term\": 5,\n      \"commit_index\": 8901,\n      \"last_applied\": 8901\n    }\n  ]\n}\n</code></pre> <p>Fields:</p> Field Type Description <code>status</code> string Overall status: <code>healthy</code>, <code>degraded</code>, <code>unhealthy</code> <code>node_id</code> string Server node ID <code>uptime_seconds</code> number Seconds since server start <code>total_shards</code> number Total virtual shards (1024) <code>active_shards</code> number Number of shards currently active on this node <code>shards</code> array Health status for each active shard <p>Shard Health Fields:</p> Field Type Description <code>id</code> number Shard ID (0-1023) <code>status</code> string Shard status: <code>healthy</code>, <code>degraded</code>, <code>unavailable</code> <code>is_leader</code> boolean True if this node is the Raft leader for this shard <code>raft_term</code> number Current Raft term <code>commit_index</code> number Last committed log index <code>last_applied</code> number Last applied log index to LSM <p>Status Values:</p> <ul> <li><code>healthy</code> - All shards operational, leader elected</li> <li><code>degraded</code> - Some shards not responding or no leader</li> <li><code>unhealthy</code> - Critical failure, server not operational</li> </ul> <p>Performance: - Latency: ~5-10ms (queries all active shards) - May involve I/O if checking LSM state - Use sparingly in high-frequency monitoring</p> <p>Use Cases: - Debugging cluster issues - Capacity planning (active shard count) - Raft state inspection - Detailed dashboards</p> <p>Example:</p> <pre><code># Get detailed health status\ncurl http://localhost:8080/health | jq\n\n# Check if server is leader for shard 42\ncurl -s http://localhost:8080/health | \\\n  jq '.shards[] | select(.id == 42) | .is_leader'\n\n# Count healthy shards\ncurl -s http://localhost:8080/health | \\\n  jq '[.shards[] | select(.status == \"healthy\")] | length'\n</code></pre> <p>Monitoring Alert Example:</p> <pre><code>import requests\n\nresponse = requests.get('http://localhost:8080/health')\nhealth = response.json()\n\nif health['status'] != 'healthy':\n    alert(f\"NoriKV unhealthy: {health['status']}\")\n\nunhealthy_shards = [\n    s for s in health['shards']\n    if s['status'] != 'healthy'\n]\nif unhealthy_shards:\n    alert(f\"Unhealthy shards: {[s['id'] for s in unhealthy_shards]}\")\n</code></pre>"},{"location":"operations/rest-api/#metrics","title":"Metrics","text":""},{"location":"operations/rest-api/#prometheus-metrics-export","title":"Prometheus Metrics Export","text":"<p>Endpoint: <code>GET /metrics</code></p> <p>Purpose: Export metrics in Prometheus text format for scraping.</p> <p>Response: Plain text, Prometheus exposition format version 0.0.4</p> <p>Content-Type: <code>text/plain; version=0.0.4</code></p> <p>Example Response:</p> <pre><code># HELP kv_requests_total Total number of KV requests\n# TYPE kv_requests_total counter\nkv_requests_total{operation=\"put\"} 12345\nkv_requests_total{operation=\"get\"} 67890\nkv_requests_total{operation=\"delete\"} 123\n\n# HELP kv_request_duration_ms Request duration in milliseconds\n# TYPE kv_request_duration_ms histogram\nkv_request_duration_ms_bucket{operation=\"put\",status=\"success\",le=\"1.0\"} 5000\nkv_request_duration_ms_bucket{operation=\"put\",status=\"success\",le=\"2.0\"} 8000\nkv_request_duration_ms_bucket{operation=\"put\",status=\"success\",le=\"4.0\"} 10000\nkv_request_duration_ms_bucket{operation=\"put\",status=\"success\",le=\"+Inf\"} 12345\nkv_request_duration_ms_sum{operation=\"put\",status=\"success\"} 123450.5\nkv_request_duration_ms_count{operation=\"put\",status=\"success\"} 12345\n</code></pre> <p>Metrics Exposed:</p> <p>See Metrics Reference for complete list.</p> <p>Key Metrics: - <code>kv_requests_total</code> - Request counters by operation - <code>kv_request_duration_ms</code> - Latency histograms - <code>lsm_*</code> - LSM engine metrics (compaction, memtable) - <code>raft_*</code> - Raft consensus metrics (elections, commits) - <code>swim_*</code> - Membership metrics (cluster size, failures)</p> <p>Prometheus Scrape Configuration:</p> <pre><code>scrape_configs:\n  - job_name: 'norikv'\n    static_configs:\n      - targets: ['localhost:8080']\n    scrape_interval: 15s\n    metrics_path: /metrics\n</code></pre> <p>Kubernetes ServiceMonitor:</p> <pre><code>apiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: norikv\nspec:\n  selector:\n    matchLabels:\n      app: norikv\n  endpoints:\n  - port: http\n    path: /metrics\n    interval: 15s\n</code></pre> <p>Use Cases: - Prometheus/Grafana dashboards - Alerting on latency/error rates - Capacity planning - Performance debugging</p> <p>Example Queries:</p> <pre><code># Request rate (per second)\nrate(kv_requests_total[5m])\n\n# P95 latency\nhistogram_quantile(0.95,\n  rate(kv_request_duration_ms_bucket[5m])\n)\n\n# Error rate\nrate(kv_requests_total{status=\"error\"}[5m])\n  / rate(kv_requests_total[5m])\n</code></pre>"},{"location":"operations/rest-api/#http-server-architecture","title":"HTTP Server Architecture","text":""},{"location":"operations/rest-api/#technology-stack","title":"Technology Stack","text":"<ul> <li>Framework: Axum - Ergonomic async web framework</li> <li>Runtime: Tokio async runtime</li> <li>Serialization: Serde JSON for structured responses</li> <li>Metrics: prometheus-client for Prometheus export</li> </ul>"},{"location":"operations/rest-api/#code-organization","title":"Code Organization","text":"<pre><code>// apps/norikv-server/src/http.rs\n\npub struct HttpServer {\n    addr: SocketAddr,\n    state: HttpServerState,\n    shutdown_tx: Option&lt;tokio::sync::oneshot::Sender&lt;()&gt;&gt;,\n    server_handle: Option&lt;JoinHandle&lt;Result&lt;(), std::io::Error&gt;&gt;&gt;,\n}\n\n#[derive(Clone)]\npub struct HttpServerState {\n    health_checker: Arc&lt;HealthChecker&gt;,\n    meter: Arc&lt;PrometheusMeter&gt;,\n}\n</code></pre> <p>Key Design Decisions:</p> <ol> <li>Separate server from gRPC</li> <li>Allows different ports/firewall rules</li> <li>No authentication required for ops endpoints</li> <li> <p>Can disable in production if not needed</p> </li> <li> <p>Axum router</p> </li> <li>Type-safe route handlers</li> <li>Extractors for state/headers</li> <li> <p>Graceful shutdown support</p> </li> <li> <p>Shared state via Arc</p> </li> <li>Health checker shared with Node</li> <li>Prometheus meter shared with gRPC server</li> <li> <p>No data duplication</p> </li> <li> <p>Async handlers</p> </li> <li>Non-blocking health checks</li> <li>Concurrent metric collection</li> <li>Efficient resource usage</li> </ol>"},{"location":"operations/rest-api/#lifecycle","title":"Lifecycle","text":"<pre><code>Node::start()\n  \u2193\nCreate HttpServer { state: { health_checker, meter } }\n  \u2193\nBuild Axum router with routes\n  \u2193\nBind TcpListener on http_addr\n  \u2193\nSpawn server task with graceful shutdown\n  \u2193\nServer running (handle requests)\n  \u2193\nNode::shutdown()\n  \u2193\nSend shutdown signal\n  \u2193\nAwait server task completion\n  \u2193\nServer stopped\n</code></pre>"},{"location":"operations/rest-api/#error-handling","title":"Error Handling","text":""},{"location":"operations/rest-api/#http-status-codes","title":"HTTP Status Codes","text":"Status When Example 200 OK Request succeeded Health check passed, metrics returned 500 Internal Server Error Handler error Health check failed to query shard 503 Service Unavailable Server unhealthy Quick health check: server not ready"},{"location":"operations/rest-api/#error-response-format","title":"Error Response Format","text":"<pre><code>{\n  \"error\": \"Internal error: failed to query shard 0\"\n}\n</code></pre> <p>Handler Error Conversion:</p> <pre><code>struct AppError(anyhow::Error);\n\nimpl IntoResponse for AppError {\n    fn into_response(self) -&gt; Response {\n        tracing::error!(\"Handler error: {:?}\", self.0);\n        (\n            StatusCode::INTERNAL_SERVER_ERROR,\n            format!(\"Internal error: {}\", self.0),\n        ).into_response()\n    }\n}\n</code></pre>"},{"location":"operations/rest-api/#best-practices","title":"Best Practices","text":""},{"location":"operations/rest-api/#load-balancer-integration","title":"Load Balancer Integration","text":"<p>Use <code>/health/quick</code> for load balancer health checks:</p> <pre><code># Nginx upstream health check\nupstream norikv {\n    server 10.0.1.10:8080 max_fails=3 fail_timeout=30s;\n    server 10.0.1.11:8080 max_fails=3 fail_timeout=30s;\n    server 10.0.1.12:8080 max_fails=3 fail_timeout=30s;\n}\n\nserver {\n    location /health/quick {\n        proxy_pass http://norikv;\n        proxy_connect_timeout 1s;\n        proxy_read_timeout 1s;\n    }\n}\n</code></pre> <p>HAProxy:</p> <pre><code>backend norikv\n    balance roundrobin\n    option httpchk GET /health/quick\n    http-check expect status 200\n    server node0 10.0.1.10:8080 check inter 5s\n    server node1 10.0.1.11:8080 check inter 5s\n    server node2 10.0.1.12:8080 check inter 5s\n</code></pre>"},{"location":"operations/rest-api/#monitoring-setup","title":"Monitoring Setup","text":"<p>Scrape metrics every 15 seconds:</p> <pre><code># prometheus.yml\nglobal:\n  scrape_interval: 15s\n\nscrape_configs:\n  - job_name: 'norikv'\n    static_configs:\n      - targets:\n        - '10.0.1.10:8080'\n        - '10.0.1.11:8080'\n        - '10.0.1.12:8080'\n    scrape_interval: 15s\n    scrape_timeout: 10s\n</code></pre> <p>Alert on unhealthy status:</p> <pre><code># alerts.yml\ngroups:\n- name: norikv\n  rules:\n  - alert: NoriKVUnhealthy\n    expr: up{job=\"norikv\"} == 0\n    for: 1m\n    annotations:\n      summary: \"NoriKV instance {{ $labels.instance }} is down\"\n</code></pre>"},{"location":"operations/rest-api/#security-considerations","title":"Security Considerations","text":"<p>Firewall rules:</p> <pre><code># Allow HTTP from Prometheus/monitoring only\niptables -A INPUT -p tcp --dport 8080 -s 10.0.2.0/24 -j ACCEPT\niptables -A INPUT -p tcp --dport 8080 -j DROP\n\n# Allow gRPC from clients\niptables -A INPUT -p tcp --dport 6000 -j ACCEPT\n</code></pre> <p>Kubernetes Network Policy:</p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: norikv-http\nspec:\n  podSelector:\n    matchLabels:\n      app: norikv\n  ingress:\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: monitoring\n    ports:\n    - protocol: TCP\n      port: 8080\n</code></pre>"},{"location":"operations/rest-api/#troubleshooting","title":"Troubleshooting","text":""},{"location":"operations/rest-api/#server-wont-start","title":"Server won't start","text":"<p>Error: <code>Failed to bind: Address already in use</code></p> <p>Solution: Check if another process is using port 8080:</p> <pre><code>lsof -i :8080\n# Or change port\nnorikv-server --http-addr 0.0.0.0:9090\n</code></pre>"},{"location":"operations/rest-api/#health-check-always-returns-503","title":"Health check always returns 503","text":"<p>Symptoms: <code>/health/quick</code> returns <code>UNAVAILABLE</code></p> <p>Debugging:</p> <pre><code># Check detailed health status\ncurl http://localhost:8080/health | jq\n\n# Check if shard 0 is healthy\ncurl -s http://localhost:8080/health | \\\n  jq '.shards[] | select(.id == 0)'\n</code></pre> <p>Common causes: - Shard 0 not yet created (server starting up) - Raft leader not elected (multi-node: wait for quorum) - LSM engine not initialized</p>"},{"location":"operations/rest-api/#metrics-endpoint-empty","title":"Metrics endpoint empty","text":"<p>Symptoms: <code>/metrics</code> returns no metrics</p> <p>Debugging:</p> <pre><code># Check if meter is wired to gRPC server\n# Look for log line: \"Enabling KV metrics collection\"\njournalctl -u norikv-server | grep metrics\n\n# Send a request to generate metrics\ngrpcurl -plaintext localhost:6000 norikv.Kv/Get \\\n  -d '{\"key\":\"dGVzdA==\"}'\n\n# Check metrics again\ncurl http://localhost:8080/metrics\n</code></pre> <p>Solution: Ensure meter is passed to both GrpcServer and HttpServer in Node::start()</p>"},{"location":"operations/rest-api/#next-steps","title":"Next Steps","text":"<ul> <li>Metrics Reference - All metrics explained</li> <li>Configuration - Server configuration options</li> <li>Deployment - Production deployment patterns</li> </ul>"},{"location":"operations/troubleshooting/","title":"Troubleshooting Guide","text":"<p>Common issues and their solutions for NoriKV operations.</p>"},{"location":"operations/troubleshooting/#overview","title":"Overview","text":"<p>This guide covers common problems encountered when operating NoriKV and provides step-by-step solutions.</p> <p>Quick diagnosis:</p> <pre><code># Check if server is running\ncurl -f http://localhost:8080/health/quick || echo \"Server down\"\n\n# Check cluster status\ncurl -s http://localhost:8080/health | jq '.status'\n\n# Check recent errors\nsudo journalctl -u norikv --since \"5 minutes ago\" | grep ERROR\n\n# Check metrics for issues\ncurl -s http://localhost:8080/metrics | grep -E \"(error|failed)\"\n</code></pre>"},{"location":"operations/troubleshooting/#server-wont-start","title":"Server Won't Start","text":""},{"location":"operations/troubleshooting/#symptoms","title":"Symptoms","text":"<ul> <li><code>systemctl status norikv</code> shows \"failed\"</li> <li>No process listening on port 7447</li> <li>Logs show startup errors</li> </ul>"},{"location":"operations/troubleshooting/#port-already-in-use","title":"Port Already in Use","text":"<p>Error: <pre><code>Error: Failed to bind: Address already in use (os error 98)\n</code></pre></p> <p>Diagnosis:</p> <pre><code># Check what's using the port\nsudo lsof -i :7447\nsudo lsof -i :8080\n</code></pre> <p>Solution 1: Kill conflicting process</p> <pre><code># Find and kill process\nsudo kill $(sudo lsof -t -i:7447)\n</code></pre> <p>Solution 2: Change port</p> <pre><code># config.yaml\nrpc_addr: \"0.0.0.0:7448\"  # Use different port\nhttp_addr: \"0.0.0.0:8081\"\n</code></pre>"},{"location":"operations/troubleshooting/#permission-denied-data-directory","title":"Permission Denied (Data Directory)","text":"<p>Error: <pre><code>Error: Cannot create data_dir: Permission denied\n</code></pre></p> <p>Diagnosis:</p> <pre><code># Check permissions\nls -ld /var/lib/norikv\nls -l /var/lib/norikv\n</code></pre> <p>Solution:</p> <pre><code># Fix ownership\nsudo chown -R norikv:norikv /var/lib/norikv\n\n# Fix permissions\nsudo chmod 750 /var/lib/norikv\n</code></pre>"},{"location":"operations/troubleshooting/#invalid-configuration","title":"Invalid Configuration","text":"<p>Error: <pre><code>Error: Invalid field: node_id cannot be empty\nError: Invalid rpc_addr: invalid socket address syntax\n</code></pre></p> <p>Diagnosis:</p> <pre><code># Validate config manually\ncat /etc/norikv/config.yaml\n\n# Check for YAML syntax errors\nyamllint /etc/norikv/config.yaml\n</code></pre> <p>Common mistakes:</p> <pre><code># WRONG: Empty node_id\nnode_id: \"\"\n\n# RIGHT:\nnode_id: \"node0\"\n\n# WRONG: Missing port\nrpc_addr: \"10.0.1.10\"\n\n# RIGHT:\nrpc_addr: \"10.0.1.10:7447\"\n\n# WRONG: Invalid total_shards\ncluster:\n  total_shards: 0\n\n# RIGHT:\ncluster:\n  total_shards: 1024\n</code></pre>"},{"location":"operations/troubleshooting/#out-of-memory","title":"Out of Memory","text":"<p>Error: <pre><code>Error: Cannot allocate memory\nFATAL: Out of memory\n</code></pre></p> <p>Diagnosis:</p> <pre><code># Check available memory\nfree -h\n\n# Check server memory usage\nps aux | grep norikv-server\n</code></pre> <p>Solution 1: Increase system memory</p> <pre><code># Add swap (temporary)\nsudo fallocate -l 8G /swapfile\nsudo chmod 600 /swapfile\nsudo mkswap /swapfile\nsudo swapon /swapfile\n</code></pre> <p>Solution 2: Reduce memtable size (requires code change)</p> <p>Currently memtable size is hardcoded at 64 MiB. Future: expose in config.</p> <p>Solution 3: Reduce active shards</p> <pre><code># Reduce total shards for low-memory systems\ncluster:\n  total_shards: 128  # Instead of 1024\n</code></pre>"},{"location":"operations/troubleshooting/#cluster-formation-issues","title":"Cluster Formation Issues","text":""},{"location":"operations/troubleshooting/#nodes-cant-join-cluster","title":"Nodes Can't Join Cluster","text":"<p>Symptoms: - Node starts but doesn't join cluster - <code>swim_cluster_size</code> metric shows 1 instead of 3 - Logs show \"Failed to join cluster\" errors</p>"},{"location":"operations/troubleshooting/#network-connectivity","title":"Network Connectivity","text":"<p>Error: <pre><code>Failed to join cluster: Connection refused (os error 111)\n</code></pre></p> <p>Diagnosis:</p> <pre><code># Test connectivity from node1 to node0\ntelnet 10.0.1.10 7447\n\n# Check firewall\nsudo iptables -L -n | grep 7447\n\n# Check if seed node is up\ncurl http://10.0.1.10:8080/health/quick\n</code></pre> <p>Solution:</p> <pre><code># Open firewall (Ubuntu/Debian)\nsudo ufw allow 7447/tcp\nsudo ufw allow 8080/tcp\n\n# Open firewall (RHEL/CentOS)\nsudo firewall-cmd --permanent --add-port=7447/tcp\nsudo firewall-cmd --permanent --add-port=8080/tcp\nsudo firewall-cmd --reload\n</code></pre>"},{"location":"operations/troubleshooting/#wrong-seed-nodes","title":"Wrong Seed Nodes","text":"<p>Error: <pre><code>No seed nodes reachable\n</code></pre></p> <p>Diagnosis:</p> <pre><code># Check seed nodes in config\ngrep -A5 \"seed_nodes:\" /etc/norikv/config.yaml\n\n# Test each seed\nfor seed in 10.0.1.10:7447 10.0.1.11:7447 10.0.1.12:7447; do\n  echo \"Testing $seed...\"\n  nc -zv ${seed%:*} ${seed#*:}\ndone\n</code></pre> <p>Solution:</p> <p>Fix seed_nodes addresses:</p> <pre><code># WRONG: Using hostnames that don't resolve\ncluster:\n  seed_nodes:\n    - \"node0:7447\"  # DNS lookup fails\n\n# RIGHT: Use IP addresses or resolvable hostnames\ncluster:\n  seed_nodes:\n    - \"10.0.1.10:7447\"\n    - \"10.0.1.11:7447\"\n    - \"10.0.1.12:7447\"\n</code></pre>"},{"location":"operations/troubleshooting/#node-id-conflicts","title":"Node ID Conflicts","text":"<p>Error: <pre><code>Node with ID 'node0' already exists in cluster\n</code></pre></p> <p>Diagnosis:</p> <pre><code># Check if multiple nodes have same node_id\nfor node in node0 node1 node2; do\n  ssh $node \"grep node_id /etc/norikv/config.yaml\"\ndone\n</code></pre> <p>Solution:</p> <p>Ensure each node has unique node_id:</p> <pre><code># Node 0:\nnode_id: \"node0\"\n\n# Node 1:\nnode_id: \"node1\"  # NOT \"node0\"\n\n# Node 2:\nnode_id: \"node2\"  # NOT \"node0\"\n</code></pre>"},{"location":"operations/troubleshooting/#write-failures","title":"Write Failures","text":""},{"location":"operations/troubleshooting/#not-leader-errors","title":"\"Not Leader\" Errors","text":"<p>Error: <pre><code>ERROR: not_leader: This node is not the Raft leader for shard 42\n</code></pre></p> <p>Diagnosis:</p> <pre><code># Check shard leadership\ncurl -s http://localhost:8080/health | jq '.shards[] | select(.id == 42)'\n\n# Check Raft metrics\ncurl -s http://localhost:8080/metrics | grep 'raft_leader{shard_id=\"42\"}'\n</code></pre> <p>Root causes:</p> <ol> <li>Election in progress (wait 1-2 seconds)</li> <li>Cluster split (network partition)</li> <li>Majority offline (can't elect leader)</li> </ol> <p>Solution 1: Retry (client-side)</p> <p>SDK automatically retries on \"not_leader\" errors.</p> <p>Solution 2: Check cluster health</p> <pre><code># Ensure majority (\u22652 of 3) nodes are alive\ncurl http://10.0.1.10:8080/health/quick\ncurl http://10.0.1.11:8080/health/quick\ncurl http://10.0.1.12:8080/health/quick\n</code></pre> <p>Solution 3: Wait for election</p> <pre><code># Watch leader election\nwatch 'curl -s http://localhost:8080/metrics | grep raft_leader | grep shard_id=\\\"42\\\"'\n</code></pre>"},{"location":"operations/troubleshooting/#l0-write-stalls","title":"L0 Write Stalls","text":"<p>Error: <pre><code>ERROR: L0 stall: Too many L0 files (12), writes blocked\n</code></pre></p> <p>Diagnosis:</p> <pre><code># Check L0 file count\ncurl -s http://localhost:8080/metrics | grep 'lsm_sstable_count{level=\"L0\"}'\n\n# Check compaction rate\ncurl -s http://localhost:8080/metrics | grep 'lsm_compaction_duration_ms_count'\n</code></pre> <p>Root causes:</p> <ol> <li>Write amplification (high write rate, slow compaction)</li> <li>Slow disk (HDD instead of SSD)</li> <li>CPU bottleneck (compaction can't keep up)</li> </ol> <p>Solution 1: Wait for compaction</p> <p>L0 stall is self-resolving (compaction will reduce L0 count).</p> <p>Solution 2: Increase compaction concurrency (requires code change)</p> <p>Currently hardcoded at 4 concurrent compactions. Future: expose in config.</p> <p>Solution 3: Reduce write rate</p> <pre><code># Throttle writes from client\n# (Implement rate limiting in your application)\n</code></pre> <p>Prevention:</p> <ul> <li>Use SSD/NVMe (not HDD)</li> <li>Monitor <code>lsm_sstable_count{level=\"L0\"}</code> and alert at &gt;8</li> </ul>"},{"location":"operations/troubleshooting/#disk-full","title":"Disk Full","text":"<p>Error: <pre><code>ERROR: No space left on device (os error 28)\n</code></pre></p> <p>Diagnosis:</p> <pre><code># Check disk space\ndf -h /var/lib/norikv\n\n# Check largest directories\ndu -sh /var/lib/norikv/* | sort -rh | head -10\n</code></pre> <p>Solution 1: Free up space</p> <pre><code># Delete old snapshots (if any)\nfind /var/lib/norikv/raft/*/snapshot -name \"snapshot-*.dat\" -mtime +7 -delete\n\n# Truncate large log files\nsudo journalctl --vacuum-time=7d\n</code></pre> <p>Solution 2: Add more storage</p> <pre><code># Mount larger disk\nsudo mkdir /mnt/norikv-data\nsudo mount /dev/sdb1 /mnt/norikv-data\n\n# Update config\n# data_dir: \"/mnt/norikv-data\"\n\n# Migrate data\nsudo rsync -av /var/lib/norikv/ /mnt/norikv-data/\n</code></pre> <p>Prevention:</p> <ul> <li>Monitor disk usage: <code>disk_free_bytes &lt; 10GB</code> \u2192 alert</li> <li>Plan for 3\u00d7 dataset size (replication + compaction)</li> </ul>"},{"location":"operations/troubleshooting/#read-failures","title":"Read Failures","text":""},{"location":"operations/troubleshooting/#slow-reads","title":"Slow Reads","text":"<p>Symptoms: - p95 GET latency &gt; 50ms - Timeouts on read requests - Metrics show <code>kv_request_duration_ms</code> high</p> <p>Diagnosis:</p> <pre><code># Check latency percentiles\ncurl -s http://localhost:8080/metrics | grep kv_request_duration_ms\n\n# Check if reads hitting L0 (cache misses)\ncurl -s http://localhost:8080/metrics | grep 'lsm_sstable_count{level=\"L0\"}'\n\n# Check compaction backlog\ncurl -s http://localhost:8080/metrics | grep lsm_compaction_duration_ms_count\n</code></pre> <p>Root causes:</p> <ol> <li>L0 storm (many L0 files, poor read amplification)</li> <li>No bloom filters (checking all SSTables)</li> <li>Hot key (single key getting all traffic)</li> <li>Disk I/O bottleneck</li> </ol> <p>Solution 1: Wait for compaction</p> <p>L0 files will be compacted to lower levels automatically.</p> <p>Solution 2: Increase filter budget (requires code change)</p> <p>Currently filter budget is 256 MiB. Increasing improves read performance.</p> <p>Solution 3: Add read caching</p> <p>Use a caching layer (Redis, Memcached) in front of NoriKV for hot keys.</p> <p>Solution 4: Scale reads</p> <ul> <li>Use <code>ConsistencyLevel::Stale</code> for non-critical reads (reads from followers)</li> <li>Add more replicas to distribute read load</li> </ul>"},{"location":"operations/troubleshooting/#key-not-found-expected","title":"Key Not Found (Expected)","text":"<p>Error: <pre><code>GET(\"nonexistent_key\") \u2192 None\n</code></pre></p> <p>Diagnosis:</p> <pre><code># Verify key actually exists\ngrpcurl -plaintext localhost:7447 norikv.Kv/Get \\\n  -d '{\"key\":\"base64_encoded_key\"}'\n\n# Check if key was deleted\n# (Look for tombstone in logs)\nsudo journalctl -u norikv | grep \"delete.*nonexistent_key\"\n</code></pre> <p>Root causes:</p> <ol> <li>Key never written (typo in key name)</li> <li>Key deleted (tombstone exists)</li> <li>Wrong shard (client routing to wrong shard - SDK bug)</li> </ol> <p>Solution:</p> <p>Verify key spelling and ensure PUT succeeded before GET.</p>"},{"location":"operations/troubleshooting/#performance-degradation","title":"Performance Degradation","text":""},{"location":"operations/troubleshooting/#high-cpu-usage","title":"High CPU Usage","text":"<p>Symptoms: - Server using 100% CPU - Requests timing out - Metrics show <code>cpu_usage &gt; 90%</code></p> <p>Diagnosis:</p> <pre><code># Check CPU usage\ntop -p $(pgrep norikv-server)\n\n# Profile CPU usage\nsudo perf record -p $(pgrep norikv-server) -g -- sleep 10\nsudo perf report\n</code></pre> <p>Root causes:</p> <ol> <li>Compaction storm (too many concurrent compactions)</li> <li>Hot shard (one shard getting all traffic)</li> <li>Inefficient queries (large scans)</li> </ol> <p>Solution 1: Limit compaction concurrency</p> <p>Currently hardcoded at 4. Future: expose <code>io.max_background_compactions</code> in config.</p> <p>Solution 2: Distribute load</p> <ul> <li>Use better key distribution (avoid hot keys)</li> <li>Add more nodes to cluster</li> </ul> <p>Solution 3: Vertical scaling</p> <ul> <li>Increase CPU cores (scale up instance)</li> </ul>"},{"location":"operations/troubleshooting/#high-memory-usage","title":"High Memory Usage","text":"<p>Symptoms: - Memory usage growing unbounded - OOM kills - Metrics show <code>memory_usage &gt; 80%</code></p> <p>Diagnosis:</p> <pre><code># Check memory usage\nfree -h\nps aux | grep norikv-server\n\n# Check active shards\ncurl -s http://localhost:8080/health | jq '.active_shards'\n\n# Check memtable sizes\ncurl -s http://localhost:8080/metrics | grep lsm_memtable_size_bytes\n</code></pre> <p>Root causes:</p> <ol> <li>Too many active shards (1024 shards \u00d7 64 MiB memtable = 64 GB)</li> <li>Memtable not flushing (slow disk writes)</li> <li>Memory leak (bug - report it!)</li> </ol> <p>Solution 1: Reduce active shards</p> <p>Shards are created lazily. Workload determines active count.</p> <p>Solution 2: Force memtable flush (manual intervention)</p> <p>Currently no admin API. Future: <code>Admin.FlushShard(shard_id)</code></p> <p>Solution 3: Add more memory</p> <ul> <li>Vertical scaling (increase RAM)</li> </ul>"},{"location":"operations/troubleshooting/#frequent-leader-elections","title":"Frequent Leader Elections","text":"<p>Symptoms: - Writes timing out sporadically - Metrics show <code>raft_leader_changes_total</code> increasing rapidly - Logs show \"Starting election for term X\"</p> <p>Diagnosis:</p> <pre><code># Check election rate\ncurl -s http://localhost:8080/metrics | grep raft_leader_changes_total\n\n# Check heartbeat failures\nsudo journalctl -u norikv | grep \"Heartbeat timeout\"\n\n# Check network latency\nping -c 10 10.0.1.11\n</code></pre> <p>Root causes:</p> <ol> <li>Network instability (packet loss, high latency)</li> <li>Node overloaded (can't send heartbeats in time)</li> <li>Split brain (network partition)</li> </ol> <p>Solution 1: Tune Raft timeouts for network</p> <p>Currently timeouts are hardcoded. Future: expose in config.</p> <p>For high-latency networks: - heartbeat_interval: 500ms (default: 150ms) - election_timeout_min: 1000ms (default: 300ms) - election_timeout_max: 2000ms (default: 600ms)</p> <p>Solution 2: Fix network issues</p> <pre><code># Check for packet loss\nping -c 100 10.0.1.11 | grep loss\n\n# Check MTU mismatches\ntracepath 10.0.1.11\n</code></pre> <p>Solution 3: Scale up nodes</p> <p>Ensure nodes have sufficient CPU to handle Raft heartbeats.</p>"},{"location":"operations/troubleshooting/#health-check-failures","title":"Health Check Failures","text":""},{"location":"operations/troubleshooting/#healthquick-returns-503","title":"<code>/health/quick</code> Returns 503","text":"<p>Diagnosis:</p> <pre><code># Check shard 0 specifically\ncurl -s http://localhost:8080/health | jq '.shards[] | select(.id == 0)'\n\n# Check if shard 0 has leader\ncurl -s http://localhost:8080/metrics | grep 'raft_leader{shard_id=\"0\"}'\n</code></pre> <p>Root causes:</p> <ol> <li>Shard 0 not created (server still starting up)</li> <li>No Raft leader elected (cluster forming)</li> <li>Shard 0 unresponsive (disk I/O blocked)</li> </ol> <p>Solution:</p> <p>Wait 30-60 seconds for server initialization. If persists, check logs:</p> <pre><code>sudo journalctl -u norikv -f | grep \"shard-0\"\n</code></pre>"},{"location":"operations/troubleshooting/#health-shows-degraded-status","title":"<code>/health</code> Shows <code>degraded</code> Status","text":"<p>Diagnosis:</p> <pre><code># Check which shards are unhealthy\ncurl -s http://localhost:8080/health | \\\n  jq '.shards[] | select(.status != \"healthy\")'\n\n# Check leadership\ncurl -s http://localhost:8080/health | \\\n  jq '.shards[] | select(.is_leader == false)'\n</code></pre> <p>Root causes:</p> <ol> <li>Some shards have no leader (elections in progress)</li> <li>Raft replication lag (follower behind leader)</li> </ol> <p>Solution:</p> <p>If transient (during elections), wait. If persistent, investigate specific shards.</p>"},{"location":"operations/troubleshooting/#monitoring-alerting-issues","title":"Monitoring &amp; Alerting Issues","text":""},{"location":"operations/troubleshooting/#prometheus-not-scraping","title":"Prometheus Not Scraping","text":"<p>Symptoms: - Grafana dashboards empty - Prometheus targets showing \"DOWN\"</p> <p>Diagnosis:</p> <pre><code># Check if /metrics endpoint works\ncurl http://localhost:8080/metrics\n\n# Check Prometheus targets\ncurl http://prometheus:9090/api/v1/targets | jq\n</code></pre> <p>Root causes:</p> <ol> <li>Firewall blocking port 8080</li> <li>Wrong Prometheus scrape config</li> <li>Metrics disabled in config</li> </ol> <p>Solution 1: Fix firewall</p> <pre><code># Allow Prometheus server to access port 8080\nsudo iptables -A INPUT -p tcp --dport 8080 -s &lt;prometheus-ip&gt; -j ACCEPT\n</code></pre> <p>Solution 2: Fix Prometheus config</p> <pre><code># prometheus.yml\nscrape_configs:\n  - job_name: 'norikv'\n    static_configs:\n      - targets:\n        - '10.0.1.10:8080'  # Correct IP and port\n        - '10.0.1.11:8080'\n        - '10.0.1.12:8080'\n    scrape_interval: 15s\n</code></pre> <p>Solution 3: Enable metrics</p> <pre><code># config.yaml\ntelemetry:\n  prometheus:\n    enabled: true  # Must be true\n</code></pre>"},{"location":"operations/troubleshooting/#metrics-missing","title":"Metrics Missing","text":"<p>Symptoms: - Some metrics not showing up in Prometheus - <code>kv_requests_total</code> is 0 despite traffic</p> <p>Diagnosis:</p> <pre><code># Check all metrics\ncurl -s http://localhost:8080/metrics | sort\n\n# Check if meter is wired\nsudo journalctl -u norikv | grep \"Enabling KV metrics\"\n</code></pre> <p>Root causes:</p> <ol> <li>No traffic yet (no requests = no metrics)</li> <li>Meter not wired (code bug - should see log \"Enabling KV metrics\")</li> </ol> <p>Solution:</p> <p>Send test traffic to generate metrics:</p> <pre><code>grpcurl -plaintext localhost:7447 norikv.Kv/Put \\\n  -d '{\"key\":\"dGVzdA==\",\"value\":\"dmFsdWU=\"}'\n\n# Check metrics again\ncurl -s http://localhost:8080/metrics | grep kv_requests_total\n</code></pre>"},{"location":"operations/troubleshooting/#data-loss-corruption","title":"Data Loss / Corruption","text":""},{"location":"operations/troubleshooting/#missing-data-after-restart","title":"Missing Data After Restart","text":"<p>Symptoms: - Keys that existed before restart are now gone - <code>data_dir</code> is empty after restart</p> <p>Diagnosis:</p> <pre><code># Check if data dir exists\nls -la /var/lib/norikv/\n\n# Check for WAL/SST files\nfind /var/lib/norikv -name \"*.wal\" -o -name \"*.sst\"\n</code></pre> <p>Root causes:</p> <ol> <li>Wrong data_dir (config changed)</li> <li>Data deleted (manual deletion or script)</li> <li>Ephemeral storage (Docker volume not mounted)</li> </ol> <p>Solution:</p> <p>If data exists on disk:</p> <pre><code># Fix config to point to correct data_dir\ndata_dir: \"/var/lib/norikv\"  # Not /tmp/norikv\n</code></pre> <p>If data truly lost:</p> <p>Restore from backup (if available). If no backup, data is unrecoverable.</p> <p>Prevention:</p> <ul> <li>Use persistent storage (not tmpfs, not ephemeral Docker volumes)</li> <li>Set up daily backups (snapshot Raft + LSM dirs)</li> <li>Monitor disk usage and alerts</li> </ul>"},{"location":"operations/troubleshooting/#corrupted-sstable","title":"Corrupted SSTable","text":"<p>Error: <pre><code>ERROR: SSTable checksum mismatch: file corrupted\n</code></pre></p> <p>Diagnosis:</p> <pre><code># Find corrupted file\nsudo journalctl -u norikv | grep \"checksum mismatch\"\n\n# Check file\nls -lh /var/lib/norikv/lsm/shard-0/sst/L1-000042.sst\n</code></pre> <p>Root causes:</p> <ol> <li>Disk corruption (bad sectors)</li> <li>Incomplete write (power loss during compaction)</li> <li>Bit rot (silent data corruption over time)</li> </ol> <p>Solution:</p> <p>Currently no recovery mechanism. Future: Use Raft snapshots to rebuild lost data.</p> <p>Prevention:</p> <ul> <li>Use ECC RAM</li> <li>Use enterprise SSDs with power-loss protection</li> <li>Monitor disk SMART metrics (<code>smartctl -a /dev/sda</code>)</li> </ul>"},{"location":"operations/troubleshooting/#diagnostic-commands","title":"Diagnostic Commands","text":""},{"location":"operations/troubleshooting/#quick-health-check","title":"Quick Health Check","text":"<pre><code>#!/bin/bash\n# healthcheck.sh\n\necho \"=== NoriKV Health Check ===\"\n\n# 1. Check if server is running\nif ! pgrep norikv-server &gt; /dev/null; then\n  echo \" Server not running\"\n  exit 1\nfi\necho \" Server running (PID: $(pgrep norikv-server))\"\n\n# 2. Check HTTP endpoint\nif ! curl -sf http://localhost:8080/health/quick &gt; /dev/null; then\n  echo \" Health check failed\"\n  exit 1\nfi\necho \" Health check OK\"\n\n# 3. Check cluster size\ncluster_size=$(curl -s http://localhost:8080/metrics | grep '^swim_cluster_size' | awk '{print $2}')\nif [ \"$cluster_size\" -lt 3 ]; then\n  echo \"  Warning: Cluster size is $cluster_size (expected 3)\"\nelse\n  echo \" Cluster size: $cluster_size\"\nfi\n\n# 4. Check for errors in last 5 minutes\nerror_count=$(sudo journalctl -u norikv --since \"5 minutes ago\" | grep -c ERROR || echo 0)\nif [ \"$error_count\" -gt 0 ]; then\n  echo \"  Warning: $error_count errors in last 5 minutes\"\nelse\n  echo \" No recent errors\"\nfi\n\necho \" All checks passed\"\n</code></pre>"},{"location":"operations/troubleshooting/#performance-profiling","title":"Performance Profiling","text":"<pre><code># CPU profiling (requires perf)\nsudo perf record -F 99 -p $(pgrep norikv-server) -g -- sleep 30\nsudo perf report\n\n# Memory profiling (requires valgrind)\nvalgrind --tool=massif --massif-out-file=massif.out norikv-server --config config.yaml\n\n# Trace syscalls\nsudo strace -p $(pgrep norikv-server) -c -f\n\n# Network profiling\nsudo tcpdump -i any port 7447 -w norikv.pcap\n</code></pre>"},{"location":"operations/troubleshooting/#getting-help","title":"Getting Help","text":""},{"location":"operations/troubleshooting/#information-to-include-in-bug-reports","title":"Information to Include in Bug Reports","text":"<p>When reporting issues, please include:</p> <ol> <li>Version: <code>norikv-server --version</code></li> <li>OS: <code>uname -a</code>, <code>cat /etc/os-release</code></li> <li>Config: <code>cat /etc/norikv/config.yaml</code> (redact secrets)</li> <li>Logs: Last 1000 lines of logs (<code>sudo journalctl -u norikv -n 1000</code>)</li> <li>Metrics: <code>curl http://localhost:8080/metrics</code></li> <li>Health: <code>curl http://localhost:8080/health | jq</code></li> <li>Steps to reproduce: Exact commands that trigger the issue</li> </ol>"},{"location":"operations/troubleshooting/#where-to-ask","title":"Where to Ask","text":"<ul> <li>GitHub Issues: https://github.com/norikv/norikv/issues</li> <li>Discord: https://discord.gg/norikv (future)</li> <li>Email: support@norikv.io (enterprise support)</li> </ul>"},{"location":"operations/troubleshooting/#next-steps","title":"Next Steps","text":"<ul> <li>Configuration Reference - Fine-tune settings</li> <li>Metrics Reference - Understand metrics for debugging</li> <li>Deployment Guide - Proper deployment prevents issues</li> </ul>"},{"location":"sdks/","title":"NoriKV Client SDKs","text":"<p>Official client libraries for accessing NoriKV in your preferred programming language.</p>"},{"location":"sdks/#available-sdks","title":"Available SDKs","text":"<p>All SDKs provide the same core functionality with language-specific idioms and optimizations.</p> SDK Status Tests Documentation Best For Java Production Ready 123/123 (100%) Excellent Enterprise apps, Android Go Production Ready 102+ passing Excellent High-performance services TypeScript Production Ready 100+ passing Good Node.js, web apps Python Production Ready 40 passing Good Data science, scripting"},{"location":"sdks/#quick-start-by-language","title":"Quick Start by Language","text":""},{"location":"sdks/#java","title":"Java","text":"<pre><code>// Maven: com.norikv:norikv-client:0.1.0\ntry (NoriKVClient client = new NoriKVClient(config)) {\n    Version version = client.put(key, value, null);\n    GetResult result = client.get(key, null);\n}\n</code></pre> <p>Features: - Builder patterns for configuration - Try-with-resources support - Comprehensive Javadoc - Maven Central distribution - 4 comprehensive guides (API, Architecture, Troubleshooting, Advanced Patterns)</p> <p>\u2192 Java SDK Documentation</p>"},{"location":"sdks/#go","title":"Go","text":"<pre><code>// go get github.com/norikv/norikv-go\nclient, _ := norikv.NewClient(ctx, config)\ndefer client.Close()\n\nversion, _ := client.Put(ctx, key, value, nil)\nresult, _ := client.Get(ctx, key, nil)\n</code></pre> <p>Features: - Context-aware operations - Zero-allocation routing (23ns/op) - Goroutine-safe - Single-flight leader discovery - 4 comprehensive guides (API, Architecture, Troubleshooting, Advanced Patterns)</p> <p>\u2192 Go SDK Documentation</p>"},{"location":"sdks/#typescript","title":"TypeScript","text":"<pre><code>// npm install @norikv/client\nconst client = new NoriKVClient(config);\nawait client.connect();\n\nawait client.put(key, value);\nconst result = await client.get(key);\n</code></pre> <p>Features: - Full TypeScript types - Async/await API - ES modules + CommonJS - Browser compatible - Comprehensive inline documentation</p> <p>\u2192 TypeScript SDK Documentation</p>"},{"location":"sdks/#python","title":"Python","text":"<pre><code># pip install norikv\nasync with NoriKVClient(config) as client:\n    version = await client.put(key, value)\n    result = await client.get(key)\n</code></pre> <p>Features: - Asyncio-based - Type hints throughout - Context managers - Pythonic API - Works with Python 3.9+</p> <p>\u2192 Python SDK Documentation</p>"},{"location":"sdks/#common-features","title":"Common Features","text":"<p>All SDKs support:</p> <p>Smart Routing - Direct requests to shard leaders  Automatic Retries - Exponential backoff with jitter  Connection Pooling - Efficient resource management  CAS Operations - Compare-and-swap for optimistic locking  TTL Support - Automatic key expiration  Consistency Levels - Lease, linearizable, or stale reads  Idempotency Keys - Safe retry semantics  Topology Tracking - React to cluster changes</p>"},{"location":"sdks/#choosing-an-sdk","title":"Choosing an SDK","text":""},{"location":"sdks/#by-use-case","title":"By Use Case","text":"<p>Enterprise Applications \u2192 Use Java SDK for mature ecosystem, excellent tooling, and comprehensive documentation</p> <p>High-Performance Services \u2192 Use Go SDK for zero-allocation hot paths and native concurrency</p> <p>Web Applications \u2192 Use TypeScript SDK for type safety and seamless integration with Node.js/browsers</p> <p>Data Science &amp; Scripting \u2192 Use Python SDK for ease of use and rich data ecosystem</p>"},{"location":"sdks/#by-performance-requirements","title":"By Performance Requirements","text":"<p>Highest Throughput 1. Go (zero-allocation routing, ~2.5ns hashing) 2. Java (JIT-optimized, mature GC) 3. TypeScript (V8-optimized) 4. Python (GIL limitations)</p> <p>Lowest Latency 1. Go (native compilation, efficient runtime) 2. Java (after JIT warmup) 3. TypeScript (V8 optimization) 4. Python (interpreted overhead)</p> <p>Lowest Memory 1. Go (efficient memory model) 2. Java (after optimization) 3. TypeScript (V8 garbage collection) 4. Python (higher overhead)</p>"},{"location":"sdks/#cross-sdk-compatibility","title":"Cross-SDK Compatibility","text":"<p>All SDKs use identical hashing algorithms to ensure compatibility:</p> <ul> <li>XXHash64 (seed=0) for key hashing</li> <li>Jump Consistent Hash for shard assignment</li> <li>1024 virtual shards by default</li> </ul> <p>This means you can: - Use different SDKs for different services - Migrate between languages without data migration - Mix languages in the same cluster</p> <p>\u2192 Hash Compatibility Guide</p>"},{"location":"sdks/#installation-setup","title":"Installation &amp; Setup","text":"<p>Each SDK has detailed installation instructions:</p> <ul> <li>Java SDK Installation</li> <li>Go SDK Installation</li> <li>TypeScript SDK Installation</li> <li>Python SDK Installation</li> </ul>"},{"location":"sdks/#getting-help","title":"Getting Help","text":"<ul> <li>Issues: GitHub Issues</li> <li>Discussions: GitHub Discussions</li> <li>Documentation: This site and SDK-specific guides</li> </ul>"},{"location":"sdks/#contributing","title":"Contributing","text":"<p>Each SDK welcomes contributions:</p> <ul> <li>Bug reports and feature requests via GitHub Issues</li> <li>Code contributions via Pull Requests</li> <li>Documentation improvements</li> <li>Test coverage expansion</li> </ul> <p>See the main CONTRIBUTING.md for guidelines.</p> <p>{: .note }</p> <p>All SDKs are production-ready and maintained. Choose based on your language ecosystem and performance requirements.</p>"},{"location":"sdks/error-reference/","title":"Unified Error Reference","text":"<p>Complete error code reference for all NoriKV client SDKs.</p>"},{"location":"sdks/error-reference/#overview","title":"Overview","text":"<p>All NoriKV SDKs use consistent error types mapped from gRPC status codes. This ensures predictable error handling across languages.</p>"},{"location":"sdks/error-reference/#error-hierarchy","title":"Error Hierarchy","text":"<pre><code>NoriKVError (base)\n\u251c\u2500\u2500 KeyNotFoundError\n\u251c\u2500\u2500 VersionMismatchError\n\u251c\u2500\u2500 AlreadyExistsError\n\u251c\u2500\u2500 ConnectionError\n\u251c\u2500\u2500 TimeoutError\n\u2514\u2500\u2500 (other errors)\n</code></pre>"},{"location":"sdks/error-reference/#error-types","title":"Error Types","text":""},{"location":"sdks/error-reference/#keynotfounderror","title":"KeyNotFoundError","text":"<p>Description: The requested key does not exist.</p> <p>gRPC Status: <code>NOT_FOUND</code></p> <p>When It Occurs: - GET operation on non-existent key - DELETE operation on non-existent key (may succeed without error) - CAS operation on non-existent key</p> <p>Retry?: No - application must handle missing key</p>"},{"location":"sdks/error-reference/#java","title":"Java","text":"<pre><code>try {\n    GetResult result = client.get(key, null);\n} catch (KeyNotFoundException e) {\n    System.out.println(\"Key not found: \" + e.getMessage());\n}\n</code></pre>"},{"location":"sdks/error-reference/#go","title":"Go","text":"<pre><code>result, err := client.Get(ctx, key, nil)\nif errors.Is(err, norikv.ErrKeyNotFound) {\n    fmt.Println(\"Key not found\")\n}\n</code></pre>"},{"location":"sdks/error-reference/#typescript","title":"TypeScript","text":"<pre><code>try {\n    const result = await client.get(key);\n} catch (err) {\n    if (err instanceof KeyNotFoundError) {\n        console.log('Key not found');\n    }\n}\n</code></pre>"},{"location":"sdks/error-reference/#python","title":"Python","text":"<pre><code>try:\n    result = await client.get(key)\nexcept KeyNotFoundError:\n    print(\"Key not found\")\n</code></pre>"},{"location":"sdks/error-reference/#versionmismatcherror","title":"VersionMismatchError","text":"<p>Description: Version did not match during CAS operation.</p> <p>gRPC Status: <code>FAILED_PRECONDITION</code> with message containing \"version\"</p> <p>When It Occurs: - PUT with <code>ifMatchVersion</code> and version has changed - DELETE with <code>ifMatchVersion</code> and version has changed - Concurrent modifications to same key</p> <p>Retry?: Application must retry with updated version</p>"},{"location":"sdks/error-reference/#java_1","title":"Java","text":"<pre><code>try {\n    PutOptions options = PutOptions.builder()\n        .ifMatchVersion(expectedVersion)\n        .build();\n    client.put(key, newValue, options);\n} catch (VersionMismatchException e) {\n    // Retry: read latest version and try again\n    GetResult current = client.get(key, null);\n    // ... retry logic\n}\n</code></pre>"},{"location":"sdks/error-reference/#go_1","title":"Go","text":"<pre><code>options := &amp;norikv.PutOptions{\n    IfMatchVersion: expectedVersion,\n}\n_, err := client.Put(ctx, key, newValue, options)\nif errors.Is(err, norikv.ErrVersionMismatch) {\n    // Retry: read latest version and try again\n}\n</code></pre>"},{"location":"sdks/error-reference/#typescript_1","title":"TypeScript","text":"<pre><code>try {\n    await client.put(key, newValue, {\n        ifMatchVersion: expectedVersion,\n    });\n} catch (err) {\n    if (err instanceof VersionMismatchError) {\n        // Retry: read latest version and try again\n    }\n}\n</code></pre>"},{"location":"sdks/error-reference/#python_1","title":"Python","text":"<pre><code>try:\n    await client.put(key, new_value, PutOptions(\n        if_match_version=expected_version,\n    ))\nexcept VersionMismatchError:\n    # Retry: read latest version and try again\n    pass\n</code></pre>"},{"location":"sdks/error-reference/#alreadyexistserror","title":"AlreadyExistsError","text":"<p>Description: Key already exists during conditional creation.</p> <p>gRPC Status: <code>ALREADY_EXISTS</code></p> <p>When It Occurs: - PUT with <code>ifNotExists=true</code> on existing key</p> <p>Retry?: No - key already exists</p>"},{"location":"sdks/error-reference/#java_2","title":"Java","text":"<pre><code>try {\n    PutOptions options = PutOptions.builder()\n        .ifNotExists(true)\n        .build();\n    client.put(key, value, options);\n} catch (AlreadyExistsException e) {\n    System.out.println(\"Key already exists\");\n}\n</code></pre>"},{"location":"sdks/error-reference/#go_2","title":"Go","text":"<pre><code>options := &amp;norikv.PutOptions{\n    IfNotExists: true,\n}\n_, err := client.Put(ctx, key, value, options)\nif errors.Is(err, norikv.ErrAlreadyExists) {\n    fmt.Println(\"Key already exists\")\n}\n</code></pre>"},{"location":"sdks/error-reference/#typescript_2","title":"TypeScript","text":"<pre><code>try {\n    await client.put(key, value, {\n        ifNotExists: true,\n    });\n} catch (err) {\n    if (err instanceof AlreadyExistsError) {\n        console.log('Key already exists');\n    }\n}\n</code></pre>"},{"location":"sdks/error-reference/#python_2","title":"Python","text":"<pre><code>try:\n    await client.put(key, value, PutOptions(\n        if_not_exists=True,\n    ))\nexcept AlreadyExistsError:\n    print(\"Key already exists\")\n</code></pre>"},{"location":"sdks/error-reference/#connectionerror","title":"ConnectionError","text":"<p>Description: Network or connection failure.</p> <p>gRPC Status: <code>UNAVAILABLE</code>, <code>DEADLINE_EXCEEDED</code>, <code>CANCELLED</code></p> <p>When It Occurs: - Server unreachable - Network partition - Connection closed - Request timeout</p> <p>Retry?: Yes - with exponential backoff</p>"},{"location":"sdks/error-reference/#java_3","title":"Java","text":"<pre><code>try {\n    GetResult result = client.get(key, null);\n} catch (ConnectionException e) {\n    // Automatic retry via RetryPolicy\n    // Or manual retry:\n    Thread.sleep(1000);\n    result = client.get(key, null);\n}\n</code></pre>"},{"location":"sdks/error-reference/#go_3","title":"Go","text":"<pre><code>result, err := client.Get(ctx, key, nil)\nif errors.Is(err, norikv.ErrConnection) {\n    // Automatic retry via RetryPolicy\n    // Or manual retry:\n    time.Sleep(1 * time.Second)\n    result, err = client.Get(ctx, key, nil)\n}\n</code></pre>"},{"location":"sdks/error-reference/#typescript_3","title":"TypeScript","text":"<pre><code>try {\n    const result = await client.get(key);\n} catch (err) {\n    if (err instanceof ConnectionError) {\n        // Automatic retry via RetryPolicy\n        // Or manual retry:\n        await new Promise(r =&gt; setTimeout(r, 1000));\n        const result = await client.get(key);\n    }\n}\n</code></pre>"},{"location":"sdks/error-reference/#python_3","title":"Python","text":"<pre><code>try:\n    result = await client.get(key)\nexcept ConnectionError:\n    # Automatic retry via RetryPolicy\n    # Or manual retry:\n    await asyncio.sleep(1)\n    result = await client.get(key)\n</code></pre>"},{"location":"sdks/error-reference/#invalidargumenterror","title":"InvalidArgumentError","text":"<p>Description: Invalid request parameters.</p> <p>gRPC Status: <code>INVALID_ARGUMENT</code></p> <p>When It Occurs: - Null or empty key - Null or empty value - Invalid consistency level - Invalid options</p> <p>Retry?: No - fix client code</p>"},{"location":"sdks/error-reference/#java_4","title":"Java","text":"<pre><code>try {\n    client.put(null, value, null);  // Invalid!\n} catch (NoriKVException e) {\n    if (e.getCode().equals(\"INVALID_ARGUMENT\")) {\n        System.out.println(\"Invalid argument: \" + e.getMessage());\n    }\n}\n</code></pre>"},{"location":"sdks/error-reference/#go_4","title":"Go","text":"<pre><code>_, err := client.Put(ctx, nil, value, nil)  // Invalid!\nif err != nil {\n    fmt.Printf(\"Error: %v\\n\", err)\n}\n</code></pre>"},{"location":"sdks/error-reference/#typescript_4","title":"TypeScript","text":"<pre><code>try {\n    await client.put(null, value);  // Invalid!\n} catch (err) {\n    if (err instanceof NoriKVError &amp;&amp; err.code === 'INVALID_ARGUMENT') {\n        console.log('Invalid argument');\n    }\n}\n</code></pre>"},{"location":"sdks/error-reference/#python_4","title":"Python","text":"<pre><code>try:\n    await client.put(None, value)  # Invalid!\nexcept NoriKVError as err:\n    if err.code == \"INVALID_ARGUMENT\":\n        print(\"Invalid argument\")\n</code></pre>"},{"location":"sdks/error-reference/#permissiondeniederror","title":"PermissionDeniedError","text":"<p>Description: Authentication or authorization failure.</p> <p>gRPC Status: <code>PERMISSION_DENIED</code>, <code>UNAUTHENTICATED</code></p> <p>When It Occurs: - Missing authentication credentials - Invalid credentials - Insufficient permissions</p> <p>Retry?: No - fix credentials</p>"},{"location":"sdks/error-reference/#java_5","title":"Java","text":"<pre><code>try {\n    GetResult result = client.get(key, null);\n} catch (NoriKVException e) {\n    if (e.getCode().equals(\"PERMISSION_DENIED\")) {\n        System.out.println(\"Permission denied\");\n    }\n}\n</code></pre>"},{"location":"sdks/error-reference/#go_5","title":"Go","text":"<pre><code>result, err := client.Get(ctx, key, nil)\nif err != nil &amp;&amp; strings.Contains(err.Error(), \"permission denied\") {\n    fmt.Println(\"Permission denied\")\n}\n</code></pre>"},{"location":"sdks/error-reference/#typescript_5","title":"TypeScript","text":"<pre><code>try {\n    const result = await client.get(key);\n} catch (err) {\n    if (err instanceof NoriKVError &amp;&amp; err.code === 'PERMISSION_DENIED') {\n        console.log('Permission denied');\n    }\n}\n</code></pre>"},{"location":"sdks/error-reference/#python_5","title":"Python","text":"<pre><code>try:\n    result = await client.get(key)\nexcept NoriKVError as err:\n    if err.code == \"PERMISSION_DENIED\":\n        print(\"Permission denied\")\n</code></pre>"},{"location":"sdks/error-reference/#resourceexhaustederror","title":"ResourceExhaustedError","text":"<p>Description: Rate limit or quota exceeded.</p> <p>gRPC Status: <code>RESOURCE_EXHAUSTED</code></p> <p>When It Occurs: - Too many requests - Quota exceeded - Memory limit reached</p> <p>Retry?: Yes - with longer backoff</p>"},{"location":"sdks/error-reference/#java_6","title":"Java","text":"<pre><code>try {\n    client.put(key, value, null);\n} catch (NoriKVException e) {\n    if (e.getCode().equals(\"RESOURCE_EXHAUSTED\")) {\n        Thread.sleep(5000);  // Wait longer\n        // Retry\n    }\n}\n</code></pre>"},{"location":"sdks/error-reference/#go_6","title":"Go","text":"<pre><code>_, err := client.Put(ctx, key, value, nil)\nif err != nil &amp;&amp; strings.Contains(err.Error(), \"resource exhausted\") {\n    time.Sleep(5 * time.Second)  // Wait longer\n    // Retry\n}\n</code></pre>"},{"location":"sdks/error-reference/#typescript_6","title":"TypeScript","text":"<pre><code>try {\n    await client.put(key, value);\n} catch (err) {\n    if (err instanceof NoriKVError &amp;&amp; err.code === 'RESOURCE_EXHAUSTED') {\n        await new Promise(r =&gt; setTimeout(r, 5000));  // Wait longer\n        // Retry\n    }\n}\n</code></pre>"},{"location":"sdks/error-reference/#python_6","title":"Python","text":"<pre><code>try:\n    await client.put(key, value)\nexcept NoriKVError as err:\n    if err.code == \"RESOURCE_EXHAUSTED\":\n        await asyncio.sleep(5)  # Wait longer\n        # Retry\n</code></pre>"},{"location":"sdks/error-reference/#error-code-mapping","title":"Error Code Mapping","text":"gRPC Status Error Type Retry? SDK Error Name NOT_FOUND KeyNotFoundError No KeyNotFoundException (Java), ErrKeyNotFound (Go), KeyNotFoundError (TS/Py) FAILED_PRECONDITION (version) VersionMismatchError App-level VersionMismatchException (Java), ErrVersionMismatch (Go), VersionMismatchError (TS/Py) ALREADY_EXISTS AlreadyExistsError No AlreadyExistsException (Java), ErrAlreadyExists (Go), AlreadyExistsError (TS/Py) UNAVAILABLE ConnectionError Yes ConnectionException (Java), ErrConnection (Go), ConnectionError (TS/Py) DEADLINE_EXCEEDED TimeoutError Yes TimeoutException (Java), ErrTimeout (Go), TimeoutError (TS/Py) ABORTED NoriKVError Yes NoriKVException (Java), ErrAborted (Go), NoriKVError (TS/Py) RESOURCE_EXHAUSTED NoriKVError Yes NoriKVException (Java), ErrResourceExhausted (Go), NoriKVError (TS/Py) INVALID_ARGUMENT NoriKVError No NoriKVException (Java), ErrInvalidArgument (Go), NoriKVError (TS/Py) PERMISSION_DENIED NoriKVError No NoriKVException (Java), ErrPermissionDenied (Go), NoriKVError (TS/Py)"},{"location":"sdks/error-reference/#retry-strategy","title":"Retry Strategy","text":""},{"location":"sdks/error-reference/#retryable-errors","title":"Retryable Errors","text":"<p>These errors should be retried with exponential backoff: - ConnectionError - TimeoutError - Aborted - ResourceExhausted</p>"},{"location":"sdks/error-reference/#non-retryable-errors","title":"Non-Retryable Errors","text":"<p>These errors should NOT be automatically retried: - KeyNotFoundError - application must handle - VersionMismatchError - application must re-read and retry with new version - AlreadyExistsError - key exists, no retry needed - InvalidArgumentError - client bug, fix code - PermissionDeniedError - credentials issue, fix config</p>"},{"location":"sdks/error-reference/#cas-retry-pattern","title":"CAS Retry Pattern","text":"<p>VersionMismatchError requires special handling:</p>"},{"location":"sdks/error-reference/#java_7","title":"Java","text":"<pre><code>public void updateWithRetry(byte[] key, Function&lt;byte[], byte[]&gt; transform) {\n    int maxRetries = 10;\n    for (int attempt = 0; attempt &lt; maxRetries; attempt++) {\n        try {\n            GetResult current = client.get(key, null);\n            byte[] newValue = transform.apply(current.getValue());\n\n            PutOptions options = PutOptions.builder()\n                .ifMatchVersion(current.getVersion())\n                .build();\n\n            client.put(key, newValue, options);\n            return;  // Success\n\n        } catch (VersionMismatchException e) {\n            if (attempt == maxRetries - 1) throw e;\n            // Exponential backoff\n            Thread.sleep((long) Math.pow(2, attempt) * 10);\n        }\n    }\n}\n</code></pre>"},{"location":"sdks/error-reference/#go_7","title":"Go","text":"<pre><code>func updateWithRetry(ctx context.Context, client *norikv.Client, key []byte, transform func([]byte) []byte) error {\n    maxRetries := 10\n    for attempt := 0; attempt &lt; maxRetries; attempt++ {\n        current, err := client.Get(ctx, key, nil)\n        if err != nil {\n            return err\n        }\n\n        newValue := transform(current.Value)\n\n        options := &amp;norikv.PutOptions{\n            IfMatchVersion: current.Version,\n        }\n\n        _, err = client.Put(ctx, key, newValue, options)\n        if err == nil {\n            return nil  // Success\n        }\n\n        if !errors.Is(err, norikv.ErrVersionMismatch) {\n            return err\n        }\n\n        if attempt == maxRetries-1 {\n            return err\n        }\n\n        // Exponential backoff\n        time.Sleep(time.Duration(1&lt;&lt;attempt) * 10 * time.Millisecond)\n    }\n    return nil\n}\n</code></pre>"},{"location":"sdks/error-reference/#typescript_7","title":"TypeScript","text":"<pre><code>async function updateWithRetry(\n    key: string,\n    transform: (value: Uint8Array) =&gt; Uint8Array,\n    maxRetries: number = 10\n): Promise&lt;void&gt; {\n    for (let attempt = 0; attempt &lt; maxRetries; attempt++) {\n        try {\n            const current = await client.get(key);\n            const newValue = transform(current.value);\n\n            await client.put(key, newValue, {\n                ifMatchVersion: current.version,\n            });\n            return;  // Success\n\n        } catch (err) {\n            if (!(err instanceof VersionMismatchError)) {\n                throw err;\n            }\n\n            if (attempt === maxRetries - 1) {\n                throw err;\n            }\n\n            // Exponential backoff\n            await new Promise(r =&gt; setTimeout(r, Math.pow(2, attempt) * 10));\n        }\n    }\n}\n</code></pre>"},{"location":"sdks/error-reference/#python_7","title":"Python","text":"<pre><code>async def update_with_retry(\n    key: str,\n    transform: Callable[[bytes], bytes],\n    max_retries: int = 10,\n) -&gt; None:\n    for attempt in range(max_retries):\n        try:\n            current = await client.get(key)\n            new_value = transform(current.value)\n\n            await client.put(key, new_value, PutOptions(\n                if_match_version=current.version,\n            ))\n            return  # Success\n\n        except VersionMismatchError:\n            if attempt == max_retries - 1:\n                raise\n\n            # Exponential backoff\n            await asyncio.sleep((2 ** attempt) * 0.01)\n</code></pre>"},{"location":"sdks/error-reference/#debugging-errors","title":"Debugging Errors","text":""},{"location":"sdks/error-reference/#enable-debug-logging","title":"Enable Debug Logging","text":""},{"location":"sdks/error-reference/#java_8","title":"Java","text":"<pre><code>System.setProperty(\"org.slf4j.simpleLogger.log.com.norikv\", \"DEBUG\");\n</code></pre>"},{"location":"sdks/error-reference/#go_8","title":"Go","text":"<pre><code>import \"log\"\nlog.SetFlags(log.LstdFlags | log.Lshortfile)\n</code></pre>"},{"location":"sdks/error-reference/#typescript_8","title":"TypeScript","text":"<pre><code>process.env.DEBUG = 'norikv:*';\n</code></pre>"},{"location":"sdks/error-reference/#python_8","title":"Python","text":"<pre><code>import logging\nlogging.basicConfig(level=logging.DEBUG)\n</code></pre>"},{"location":"sdks/error-reference/#error-properties","title":"Error Properties","text":"<p>All SDK errors include:</p> Property Description message Human-readable error message code Error code (e.g., \"KEY_NOT_FOUND\") cause Original gRPC error (if applicable)"},{"location":"sdks/error-reference/#java_9","title":"Java","text":"<pre><code>catch (NoriKVException e) {\n    System.out.println(\"Message: \" + e.getMessage());\n    System.out.println(\"Code: \" + e.getCode());\n    System.out.println(\"Cause: \" + e.getCause());\n}\n</code></pre>"},{"location":"sdks/error-reference/#go_9","title":"Go","text":"<pre><code>if err != nil {\n    fmt.Printf(\"Error: %v\\n\", err)\n    // Unwrap to get cause\n    cause := errors.Unwrap(err)\n}\n</code></pre>"},{"location":"sdks/error-reference/#typescript_9","title":"TypeScript","text":"<pre><code>catch (err) {\n    if (err instanceof NoriKVError) {\n        console.log('Message:', err.message);\n        console.log('Code:', err.code);\n        console.log('Cause:', err.cause);\n    }\n}\n</code></pre>"},{"location":"sdks/error-reference/#python_9","title":"Python","text":"<pre><code>except NoriKVError as err:\n    print(f\"Message: {err}\")\n    print(f\"Code: {err.code}\")\n    print(f\"Cause: {err.cause}\")\n</code></pre>"},{"location":"sdks/error-reference/#best-practices","title":"Best Practices","text":""},{"location":"sdks/error-reference/#1-handle-specific-errors","title":"1. Handle Specific Errors","text":"<pre><code>#  Good: Handle specific errors\ntry:\n    result = await client.get(key)\nexcept KeyNotFoundError:\n    return default_value\nexcept VersionMismatchError:\n    # Retry with updated version\n    pass\n\n#  Bad: Catch all exceptions\ntry:\n    result = await client.get(key)\nexcept Exception:\n    pass  # What went wrong?\n</code></pre>"},{"location":"sdks/error-reference/#2-use-retry-policies","title":"2. Use Retry Policies","text":"<p>Configure retry policies in the client:</p> <pre><code>const client = new NoriKVClient({\n    nodes: ['localhost:9001'],\n    totalShards: 1024,\n    retry: {\n        maxAttempts: 5,\n        initialDelayMs: 100,\n        maxDelayMs: 2000,\n    },\n});\n</code></pre>"},{"location":"sdks/error-reference/#3-log-errors-with-context","title":"3. Log Errors with Context","text":"<pre><code>catch (NoriKVException e) {\n    logger.error(\"Failed to get key: key={}, error={}\",\n        new String(key), e.getMessage(), e);\n}\n</code></pre>"},{"location":"sdks/error-reference/#4-monitor-error-rates","title":"4. Monitor Error Rates","text":"<p>Track error rates by type in production:</p> <pre><code>from prometheus_client import Counter\n\nerror_counter = Counter('norikv_errors_total', 'Total errors', ['error_type'])\n\ntry:\n    result = await client.get(key)\nexcept NoriKVError as err:\n    error_counter.labels(error_type=err.code).inc()\n    raise\n</code></pre>"},{"location":"sdks/error-reference/#next-steps","title":"Next Steps","text":"<ul> <li>Getting Started - Quick start for all SDKs</li> <li>Hash Compatibility - Cross-SDK hash validation</li> <li>SDK-specific guides:</li> <li>Java API Guide</li> <li>Go API Guide</li> <li>TypeScript API Guide</li> <li>Python API Guide</li> </ul>"},{"location":"sdks/getting-started/","title":"Getting Started with NoriKV Client SDKs","text":"<p>Quick start guide for all NoriKV client SDKs.</p>"},{"location":"sdks/getting-started/#installation","title":"Installation","text":"<p>Choose your preferred language and follow the installation instructions:</p>"},{"location":"sdks/getting-started/#java","title":"Java","text":"<pre><code>&lt;!-- Maven --&gt;\n&lt;dependency&gt;\n  &lt;groupId&gt;com.norikv&lt;/groupId&gt;\n  &lt;artifactId&gt;norikv-client&lt;/artifactId&gt;\n  &lt;version&gt;0.1.0&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> <pre><code>// Gradle\nimplementation 'com.norikv:norikv-client:0.1.0'\n</code></pre>"},{"location":"sdks/getting-started/#go","title":"Go","text":"<pre><code>go get github.com/norikv/norikv-go\n</code></pre>"},{"location":"sdks/getting-started/#typescript","title":"TypeScript","text":"<pre><code>npm install @norikv/client\n# or\nyarn add @norikv/client\n</code></pre>"},{"location":"sdks/getting-started/#python","title":"Python","text":"<pre><code>pip install norikv\n</code></pre>"},{"location":"sdks/getting-started/#quick-start-examples","title":"Quick Start Examples","text":""},{"location":"sdks/getting-started/#java_1","title":"Java","text":"<pre><code>import com.norikv.client.*;\n\npublic class Example {\n    public static void main(String[] args) {\n        ClientConfig config = ClientConfig.builder()\n            .nodes(List.of(\"localhost:9001\", \"localhost:9002\"))\n            .totalShards(1024)\n            .timeout(5000)\n            .build();\n\n        try (NoriKVClient client = new NoriKVClient(config)) {\n            // Connect\n            client.connect();\n\n            // Put a value\n            byte[] key = \"user:alice\".getBytes(StandardCharsets.UTF_8);\n            byte[] value = \"Alice\".getBytes(StandardCharsets.UTF_8);\n            Version version = client.put(key, value, null);\n            System.out.println(\"Written at version: \" + version);\n\n            // Get the value\n            GetResult result = client.get(key, null);\n            String retrieved = new String(result.getValue(), StandardCharsets.UTF_8);\n            System.out.println(\"Value: \" + retrieved);\n\n            // Delete\n            boolean deleted = client.delete(key, null);\n            System.out.println(\"Deleted: \" + deleted);\n\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n</code></pre>"},{"location":"sdks/getting-started/#go_1","title":"Go","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n    \"time\"\n\n    norikv \"github.com/norikv/norikv-go\"\n)\n\nfunc main() {\n    config := norikv.ClientConfig{\n        Nodes:       []string{\"localhost:9001\", \"localhost:9002\"},\n        TotalShards: 1024,\n        Timeout:     5 * time.Second,\n    }\n\n    client, err := norikv.NewClient(config)\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer client.Close()\n\n    ctx := context.Background()\n\n    // Put a value\n    key := []byte(\"user:alice\")\n    value := []byte(\"Alice\")\n    version, err := client.Put(ctx, key, value, nil)\n    if err != nil {\n        log.Fatal(err)\n    }\n    fmt.Printf(\"Written at version: %v\\n\", version)\n\n    // Get the value\n    result, err := client.Get(ctx, key, nil)\n    if err != nil {\n        log.Fatal(err)\n    }\n    fmt.Printf(\"Value: %s\\n\", result.Value)\n\n    // Delete\n    deleted, err := client.Delete(ctx, key, nil)\n    if err != nil {\n        log.Fatal(err)\n    }\n    fmt.Printf(\"Deleted: %v\\n\", deleted)\n}\n</code></pre>"},{"location":"sdks/getting-started/#typescript_1","title":"TypeScript","text":"<pre><code>import { NoriKVClient, bytesToString } from '@norikv/client';\n\nasync function main() {\n    const client = new NoriKVClient({\n        nodes: ['localhost:9001', 'localhost:9002'],\n        totalShards: 1024,\n        timeout: 5000,\n    });\n\n    await client.connect();\n\n    try {\n        // Put a value\n        const version = await client.put('user:alice', 'Alice');\n        console.log(`Written at version: ${version}`);\n\n        // Get the value\n        const result = await client.get('user:alice');\n        console.log(`Value: ${bytesToString(result.value)}`);\n\n        // Delete\n        const deleted = await client.delete('user:alice');\n        console.log(`Deleted: ${deleted}`);\n\n    } finally {\n        await client.close();\n    }\n}\n\nmain().catch(console.error);\n</code></pre>"},{"location":"sdks/getting-started/#python_1","title":"Python","text":"<pre><code>import asyncio\nfrom norikv import NoriKVClient, ClientConfig\n\nasync def main():\n    config = ClientConfig(\n        nodes=[\"localhost:9001\", \"localhost:9002\"],\n        total_shards=1024,\n        timeout=5000,\n    )\n\n    async with NoriKVClient(config) as client:\n        # Put a value\n        version = await client.put(\"user:alice\", b\"Alice\")\n        print(f\"Written at version: {version}\")\n\n        # Get the value\n        result = await client.get(\"user:alice\")\n        print(f\"Value: {result.value.decode()}\")\n\n        # Delete\n        deleted = await client.delete(\"user:alice\")\n        print(f\"Deleted: {deleted}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"sdks/getting-started/#core-concepts","title":"Core Concepts","text":""},{"location":"sdks/getting-started/#client-configuration","title":"Client Configuration","text":"<p>All SDKs require: - nodes: List of cluster node addresses (host:port) - totalShards: Total number of virtual shards (must match cluster config, typically 1024) - timeout: Request timeout in milliseconds (default: 5000)</p> <p>Optional: - retry: Retry policy configuration for transient failures</p>"},{"location":"sdks/getting-started/#operations","title":"Operations","text":"<p>All SDKs support three core operations:</p> <ol> <li>PUT: Write a key-value pair</li> <li>Returns a <code>Version</code> for the written value</li> <li> <p>Supports optional TTL, idempotency keys, and CAS</p> </li> <li> <p>GET: Read a value by key</p> </li> <li>Returns the value and its version</li> <li> <p>Supports consistency level selection</p> </li> <li> <p>DELETE: Remove a key</p> </li> <li>Returns boolean indicating if key was deleted</li> <li>Supports idempotency keys and CAS</li> </ol>"},{"location":"sdks/getting-started/#resource-management","title":"Resource Management","text":"Language Pattern Example Java try-with-resources <code>try (NoriKVClient client = ...) { }</code> Go defer <code>defer client.Close()</code> TypeScript async close <code>await client.close()</code> or context manager Python async with <code>async with NoriKVClient(...) as client:</code>"},{"location":"sdks/getting-started/#configuration-examples","title":"Configuration Examples","text":""},{"location":"sdks/getting-started/#with-retry-policy","title":"With Retry Policy","text":""},{"location":"sdks/getting-started/#java_2","title":"Java","text":"<pre><code>ClientConfig config = ClientConfig.builder()\n    .nodes(List.of(\"localhost:9001\"))\n    .totalShards(1024)\n    .retry(RetryConfig.builder()\n        .maxAttempts(10)\n        .initialDelayMs(100)\n        .maxDelayMs(5000)\n        .build())\n    .build();\n</code></pre>"},{"location":"sdks/getting-started/#go_2","title":"Go","text":"<pre><code>config := norikv.ClientConfig{\n    Nodes:       []string{\"localhost:9001\"},\n    TotalShards: 1024,\n    Retry: &amp;norikv.RetryConfig{\n        MaxAttempts:     10,\n        InitialDelayMs:  100,\n        MaxDelayMs:      5000,\n    },\n}\n</code></pre>"},{"location":"sdks/getting-started/#typescript_2","title":"TypeScript","text":"<pre><code>const client = new NoriKVClient({\n    nodes: ['localhost:9001'],\n    totalShards: 1024,\n    retry: {\n        maxAttempts: 10,\n        initialDelayMs: 100,\n        maxDelayMs: 5000,\n    },\n});\n</code></pre>"},{"location":"sdks/getting-started/#python_2","title":"Python","text":"<pre><code>from norikv import RetryConfig\n\nconfig = ClientConfig(\n    nodes=[\"localhost:9001\"],\n    total_shards=1024,\n    retry=RetryConfig(\n        max_attempts=10,\n        initial_delay_ms=100,\n        max_delay_ms=5000,\n    ),\n)\n</code></pre>"},{"location":"sdks/getting-started/#advanced-operations","title":"Advanced Operations","text":""},{"location":"sdks/getting-started/#compare-and-swap-cas","title":"Compare-And-Swap (CAS)","text":"<p>Optimistic concurrency control using version matching:</p>"},{"location":"sdks/getting-started/#java_3","title":"Java","text":"<pre><code>GetResult current = client.get(key, null);\nPutOptions options = PutOptions.builder()\n    .ifMatchVersion(current.getVersion())\n    .build();\nclient.put(key, newValue, options);\n</code></pre>"},{"location":"sdks/getting-started/#go_3","title":"Go","text":"<pre><code>result, _ := client.Get(ctx, key, nil)\noptions := &amp;norikv.PutOptions{\n    IfMatchVersion: result.Version,\n}\nclient.Put(ctx, key, newValue, options)\n</code></pre>"},{"location":"sdks/getting-started/#typescript_3","title":"TypeScript","text":"<pre><code>const result = await client.get(key);\nawait client.put(key, newValue, {\n    ifMatchVersion: result.version,\n});\n</code></pre>"},{"location":"sdks/getting-started/#python_3","title":"Python","text":"<pre><code>result = await client.get(key)\nawait client.put(key, new_value, PutOptions(\n    if_match_version=result.version,\n))\n</code></pre>"},{"location":"sdks/getting-started/#time-to-live-ttl","title":"Time-To-Live (TTL)","text":"<p>Automatic expiration:</p>"},{"location":"sdks/getting-started/#java_4","title":"Java","text":"<pre><code>PutOptions options = PutOptions.builder()\n    .ttlMs(60000)  // 60 seconds\n    .build();\nclient.put(key, value, options);\n</code></pre>"},{"location":"sdks/getting-started/#go_4","title":"Go","text":"<pre><code>options := &amp;norikv.PutOptions{\n    TtlMs: 60000,  // 60 seconds\n}\nclient.Put(ctx, key, value, options)\n</code></pre>"},{"location":"sdks/getting-started/#typescript_4","title":"TypeScript","text":"<pre><code>await client.put(key, value, {\n    ttlMs: 60000,  // 60 seconds\n});\n</code></pre>"},{"location":"sdks/getting-started/#python_4","title":"Python","text":"<pre><code>await client.put(key, value, PutOptions(\n    ttl_ms=60000,  # 60 seconds\n))\n</code></pre>"},{"location":"sdks/getting-started/#idempotency-keys","title":"Idempotency Keys","text":"<p>Safe retries:</p>"},{"location":"sdks/getting-started/#java_5","title":"Java","text":"<pre><code>PutOptions options = PutOptions.builder()\n    .idempotencyKey(\"order-12345\")\n    .build();\nclient.put(key, value, options);\n</code></pre>"},{"location":"sdks/getting-started/#go_5","title":"Go","text":"<pre><code>options := &amp;norikv.PutOptions{\n    IdempotencyKey: \"order-12345\",\n}\nclient.Put(ctx, key, value, options)\n</code></pre>"},{"location":"sdks/getting-started/#typescript_5","title":"TypeScript","text":"<pre><code>await client.put(key, value, {\n    idempotencyKey: 'order-12345',\n});\n</code></pre>"},{"location":"sdks/getting-started/#python_5","title":"Python","text":"<pre><code>await client.put(key, value, PutOptions(\n    idempotency_key=\"order-12345\",\n))\n</code></pre>"},{"location":"sdks/getting-started/#consistency-levels","title":"Consistency Levels","text":"<p>All SDKs support three consistency levels for reads:</p> Level Description Use Case LEASE (default) Fast lease-based read Most operations LINEARIZABLE Strictest consistency Critical reads STALE_OK May return stale data High-throughput reads"},{"location":"sdks/getting-started/#java_6","title":"Java","text":"<pre><code>GetOptions options = GetOptions.builder()\n    .consistency(ConsistencyLevel.LINEARIZABLE)\n    .build();\nclient.get(key, options);\n</code></pre>"},{"location":"sdks/getting-started/#go_6","title":"Go","text":"<pre><code>options := &amp;norikv.GetOptions{\n    Consistency: norikv.ConsistencyLinearizable,\n}\nclient.Get(ctx, key, options)\n</code></pre>"},{"location":"sdks/getting-started/#typescript_6","title":"TypeScript","text":"<pre><code>await client.get(key, {\n    consistency: ConsistencyLevel.LINEARIZABLE,\n});\n</code></pre>"},{"location":"sdks/getting-started/#python_6","title":"Python","text":"<pre><code>await client.get(key, GetOptions(\n    consistency=ConsistencyLevel.LINEARIZABLE,\n))\n</code></pre>"},{"location":"sdks/getting-started/#error-handling","title":"Error Handling","text":"<p>All SDKs provide typed errors:</p>"},{"location":"sdks/getting-started/#java_7","title":"Java","text":"<pre><code>try {\n    GetResult result = client.get(key, null);\n} catch (KeyNotFoundException e) {\n    // Key not found\n} catch (VersionMismatchException e) {\n    // CAS conflict\n} catch (ConnectionException e) {\n    // Connection error\n}\n</code></pre>"},{"location":"sdks/getting-started/#go_7","title":"Go","text":"<pre><code>result, err := client.Get(ctx, key, nil)\nif errors.Is(err, norikv.ErrKeyNotFound) {\n    // Key not found\n} else if errors.Is(err, norikv.ErrVersionMismatch) {\n    // CAS conflict\n} else if errors.Is(err, norikv.ErrConnection) {\n    // Connection error\n}\n</code></pre>"},{"location":"sdks/getting-started/#typescript_7","title":"TypeScript","text":"<pre><code>try {\n    const result = await client.get(key);\n} catch (err) {\n    if (err instanceof KeyNotFoundError) {\n        // Key not found\n    } else if (err instanceof VersionMismatchError) {\n        // CAS conflict\n    } else if (err instanceof ConnectionError) {\n        // Connection error\n    }\n}\n</code></pre>"},{"location":"sdks/getting-started/#python_7","title":"Python","text":"<pre><code>try:\n    result = await client.get(key)\nexcept KeyNotFoundError:\n    # Key not found\nexcept VersionMismatchError:\n    # CAS conflict\nexcept ConnectionError:\n    # Connection error\n</code></pre>"},{"location":"sdks/getting-started/#next-steps","title":"Next Steps","text":""},{"location":"sdks/getting-started/#sdk-specific-documentation","title":"SDK-Specific Documentation","text":"<ul> <li>Java SDK Guide</li> <li>Go SDK Guide</li> <li>TypeScript SDK Guide</li> <li>Python SDK Guide</li> </ul>"},{"location":"sdks/getting-started/#cross-sdk-topics","title":"Cross-SDK Topics","text":"<ul> <li>Hash Compatibility - Cross-SDK hash validation</li> <li>Error Reference - Unified error codes</li> <li>SDK Comparison - Feature comparison</li> </ul>"},{"location":"sdks/getting-started/#common-patterns","title":"Common Patterns","text":"<p>All SDKs have comprehensive Advanced Patterns guides covering: - Distributed Counter - Session Management - Inventory Management - Caching Layer - Rate Limiting - Leader Election - Event Sourcing - Multi-Tenancy</p> <p>See each SDK's ADVANCED_PATTERNS guide for language-specific implementations.</p>"},{"location":"sdks/hash-compatibility/","title":"Cross-SDK Hash Compatibility","text":"<p>Understanding and verifying hash compatibility across all NoriKV client SDKs.</p>"},{"location":"sdks/hash-compatibility/#overview","title":"Overview","text":"<p>All NoriKV client SDKs use identical hashing algorithms to ensure that the same key is routed to the same shard, regardless of which SDK the client uses. This is critical for: - Consistent routing: Same key \u2192 same shard across all clients - Mixed deployments: Java, Go, TypeScript, and Python clients can coexist - Data migration: Switch between SDKs without data loss</p>"},{"location":"sdks/hash-compatibility/#hashing-algorithm","title":"Hashing Algorithm","text":"<p>NoriKV uses a two-stage hashing process:</p> <pre><code>Key \u2192 XXHash64(seed=0) \u2192 Jump Consistent Hash(numBuckets) \u2192 Shard ID\n</code></pre>"},{"location":"sdks/hash-compatibility/#stage-1-xxhash64","title":"Stage 1: XXHash64","text":"<ul> <li>Algorithm: XXHash64</li> <li>Seed: 0 (fixed)</li> <li>Output: 64-bit unsigned integer</li> <li>Properties: Fast, high-quality distribution, widely available</li> </ul>"},{"location":"sdks/hash-compatibility/#stage-2-jump-consistent-hash","title":"Stage 2: Jump Consistent Hash","text":"<ul> <li>Algorithm: Jump Consistent Hash by Lamping &amp; Veach (Google)</li> <li>Input: 64-bit hash from XXHash64</li> <li>Output: Integer in range [0, numBuckets)</li> <li>Properties: Minimal key movement when bucket count changes</li> </ul>"},{"location":"sdks/hash-compatibility/#implementation-verification","title":"Implementation Verification","text":"<p>All SDKs must pass the same test vectors to ensure compatibility.</p>"},{"location":"sdks/hash-compatibility/#test-vectors","title":"Test Vectors","text":"<p>These test vectors verify correct implementation:</p> Input Key XXHash64 Output Shard ID (1024 shards) <code>user:123</code> <code>14251066842453966278</code> 856 <code>order:456</code> <code>15799863842936138268</code> 982 <code>session:abc</code> <code>10368301570451808134</code> 721 <code>product:xyz</code> <code>1405181199826606771</code> 114 <code>inventory:widget-1</code> <code>7936582139014926890</code> 531 <code>cache:foo</code> <code>13831765948591136573</code> 845 `` (empty) <code>17241709254077376921</code> 1007 <code>a</code> <code>6604973303778272674</code> 527 <code>hello world</code> <code>2794345569481354659</code> 251"},{"location":"sdks/hash-compatibility/#java-implementation","title":"Java Implementation","text":"<pre><code>import xxhash.java.XXHash64;\n\npublic class HashTest {\n    private static final long XXHASH_SEED = 0L;\n\n    public static long xxhash64(byte[] key) {\n        XXHash64 hasher = XXHash64.of(XXHASH_SEED);\n        hasher.update(key);\n        return hasher.hash();\n    }\n\n    public static int jumpConsistentHash(long hash, int numBuckets) {\n        long b = -1L;\n        long j = 0L;\n\n        while (j &lt; numBuckets) {\n            b = j;\n            hash = hash * 2862933555777941757L + 1L;\n            j = (long) ((double) (b + 1L) *\n                (double) (1L &lt;&lt; 31) /\n                (double) ((hash &gt;&gt;&gt; 33) + 1L));\n        }\n\n        return (int) b;\n    }\n\n    public static void main(String[] args) {\n        String[] testKeys = {\n            \"user:123\",\n            \"order:456\",\n            \"session:abc\",\n            \"product:xyz\",\n            \"inventory:widget-1\",\n            \"cache:foo\",\n            \"\",\n            \"a\",\n            \"hello world\"\n        };\n\n        for (String key : testKeys) {\n            byte[] keyBytes = key.getBytes(StandardCharsets.UTF_8);\n            long hash = xxhash64(keyBytes);\n            int shard = jumpConsistentHash(hash, 1024);\n            System.out.printf(\"Key: '%s' -&gt; Hash: %d -&gt; Shard: %d\\n\",\n                key, hash, shard);\n        }\n    }\n}\n</code></pre>"},{"location":"sdks/hash-compatibility/#go-implementation","title":"Go Implementation","text":"<pre><code>package main\n\nimport (\n    \"fmt\"\n    \"github.com/cespare/xxhash/v2\"\n)\n\nfunc xxhash64(key []byte) uint64 {\n    return xxhash.Sum64(key)\n}\n\nfunc jumpConsistentHash(key uint64, numBuckets int) int32 {\n    var b int64 = -1\n    var j int64 = 0\n\n    for j &lt; int64(numBuckets) {\n        b = j\n        key = key*2862933555777941757 + 1\n        j = int64(float64(b+1) * (float64(int64(1)&lt;&lt;31) / float64((key&gt;&gt;33)+1)))\n    }\n\n    return int32(b)\n}\n\nfunc main() {\n    testKeys := []string{\n        \"user:123\",\n        \"order:456\",\n        \"session:abc\",\n        \"product:xyz\",\n        \"inventory:widget-1\",\n        \"cache:foo\",\n        \"\",\n        \"a\",\n        \"hello world\",\n    }\n\n    for _, key := range testKeys {\n        hash := xxhash64([]byte(key))\n        shard := jumpConsistentHash(hash, 1024)\n        fmt.Printf(\"Key: '%s' -&gt; Hash: %d -&gt; Shard: %d\\n\",\n            key, hash, shard)\n    }\n}\n</code></pre>"},{"location":"sdks/hash-compatibility/#typescript-implementation","title":"TypeScript Implementation","text":"<pre><code>import xxhash from 'xxhash-wasm';\n\nasync function initHasher() {\n    const { h64 } = await xxhash();\n\n    function xxhash64(key: Uint8Array): bigint {\n        return h64(key, 0);\n    }\n\n    function jumpConsistentHash(key: bigint, numBuckets: number): number {\n        let b = -1n;\n        let j = 0n;\n\n        while (j &lt; BigInt(numBuckets)) {\n            b = j;\n            key = key * 2862933555777941757n + 1n;\n            j = BigInt(\n                Math.floor(\n                    Number(b + 1n) *\n                    (Number(1n &lt;&lt; 31n) / Number((key &gt;&gt; 33n) + 1n))\n                )\n            );\n        }\n\n        return Number(b);\n    }\n\n    const testKeys = [\n        'user:123',\n        'order:456',\n        'session:abc',\n        'product:xyz',\n        'inventory:widget-1',\n        'cache:foo',\n        '',\n        'a',\n        'hello world',\n    ];\n\n    for (const key of testKeys) {\n        const keyBytes = new TextEncoder().encode(key);\n        const hash = xxhash64(keyBytes);\n        const shard = jumpConsistentHash(hash, 1024);\n        console.log(`Key: '${key}' -&gt; Hash: ${hash} -&gt; Shard: ${shard}`);\n    }\n}\n\ninitHasher();\n</code></pre>"},{"location":"sdks/hash-compatibility/#python-implementation","title":"Python Implementation","text":"<pre><code>import xxhash\n\ndef xxhash64(key: bytes) -&gt; int:\n    hasher = xxhash.xxh64(seed=0)\n    hasher.update(key)\n    return hasher.intdigest()\n\ndef jump_consistent_hash(key: int, num_buckets: int) -&gt; int:\n    b = -1\n    j = 0\n\n    while j &lt; num_buckets:\n        b = j\n        key = ((key * 2862933555777941757) + 1) &amp; 0xFFFFFFFFFFFFFFFF\n        j = int(float(b + 1) * (float(1 &lt;&lt; 31) / float((key &gt;&gt; 33) + 1)))\n\n    return b\n\ntest_keys = [\n    \"user:123\",\n    \"order:456\",\n    \"session:abc\",\n    \"product:xyz\",\n    \"inventory:widget-1\",\n    \"cache:foo\",\n    \"\",\n    \"a\",\n    \"hello world\",\n]\n\nfor key in test_keys:\n    key_bytes = key.encode(\"utf-8\")\n    hash_val = xxhash64(key_bytes)\n    shard = jump_consistent_hash(hash_val, 1024)\n    print(f\"Key: '{key}' -&gt; Hash: {hash_val} -&gt; Shard: {shard}\")\n</code></pre>"},{"location":"sdks/hash-compatibility/#expected-output","title":"Expected Output","text":"<p>All implementations should produce identical output:</p> <pre><code>Key: 'user:123' -&gt; Hash: 14251066842453966278 -&gt; Shard: 856\nKey: 'order:456' -&gt; Hash: 15799863842936138268 -&gt; Shard: 982\nKey: 'session:abc' -&gt; Hash: 10368301570451808134 -&gt; Shard: 721\nKey: 'product:xyz' -&gt; Hash: 1405181199826606771 -&gt; Shard: 114\nKey: 'inventory:widget-1' -&gt; Hash: 7936582139014926890 -&gt; Shard: 531\nKey: 'cache:foo' -&gt; Hash: 13831765948591136573 -&gt; Shard: 845\nKey: '' -&gt; Hash: 17241709254077376921 -&gt; Shard: 1007\nKey: 'a' -&gt; Hash: 6604973303778272674 -&gt; Shard: 527\nKey: 'hello world' -&gt; Hash: 2794345569481354659 -&gt; Shard: 251\n</code></pre>"},{"location":"sdks/hash-compatibility/#automated-testing","title":"Automated Testing","text":"<p>Each SDK includes automated tests that verify compatibility:</p>"},{"location":"sdks/hash-compatibility/#java-test","title":"Java Test","text":"<pre><code>@Test\npublic void testHashCompatibility() {\n    Map&lt;String, Integer&gt; expected = Map.of(\n        \"user:123\", 856,\n        \"order:456\", 982,\n        \"session:abc\", 721,\n        \"product:xyz\", 114,\n        \"hello world\", 251\n    );\n\n    for (Map.Entry&lt;String, Integer&gt; entry : expected.entrySet()) {\n        byte[] key = entry.getKey().getBytes(StandardCharsets.UTF_8);\n        int shard = router.getShardForKey(key);\n        assertEquals(entry.getValue().intValue(), shard);\n    }\n}\n</code></pre>"},{"location":"sdks/hash-compatibility/#go-test","title":"Go Test","text":"<pre><code>func TestHashCompatibility(t *testing.T) {\n    expected := map[string]int32{\n        \"user:123\":    856,\n        \"order:456\":   982,\n        \"session:abc\": 721,\n        \"product:xyz\": 114,\n        \"hello world\": 251,\n    }\n\n    for key, expectedShard := range expected {\n        shard := router.GetShardForKey([]byte(key))\n        if shard != expectedShard {\n            t.Errorf(\"Key %s: expected shard %d, got %d\",\n                key, expectedShard, shard)\n        }\n    }\n}\n</code></pre>"},{"location":"sdks/hash-compatibility/#typescript-test","title":"TypeScript Test","text":"<pre><code>test('hash compatibility', () =&gt; {\n    const expected = {\n        'user:123': 856,\n        'order:456': 982,\n        'session:abc': 721,\n        'product:xyz': 114,\n        'hello world': 251,\n    };\n\n    for (const [key, expectedShard] of Object.entries(expected)) {\n        const shard = router.getShardForKey(key);\n        expect(shard).toBe(expectedShard);\n    }\n});\n</code></pre>"},{"location":"sdks/hash-compatibility/#python-test","title":"Python Test","text":"<pre><code>def test_hash_compatibility():\n    expected = {\n        \"user:123\": 856,\n        \"order:456\": 982,\n        \"session:abc\": 721,\n        \"product:xyz\": 114,\n        \"hello world\": 251,\n    }\n\n    for key, expected_shard in expected.items():\n        shard = router.get_shard_for_key(key.encode())\n        assert shard == expected_shard, \\\n            f\"Key {key}: expected {expected_shard}, got {shard}\"\n</code></pre>"},{"location":"sdks/hash-compatibility/#common-pitfalls","title":"Common Pitfalls","text":""},{"location":"sdks/hash-compatibility/#1-wrong-xxhash-seed","title":"1. Wrong XXHash Seed","text":"<p>Problem: Using a non-zero seed for XXHash64</p> <pre><code>#  Wrong\nhasher = xxhash.xxh64(seed=12345)\n\n#  Correct\nhasher = xxhash.xxh64(seed=0)\n</code></pre>"},{"location":"sdks/hash-compatibility/#2-string-encoding-issues","title":"2. String Encoding Issues","text":"<p>Problem: Different UTF-8 encoding between languages</p> <pre><code>//  Correct: Use UTF-8 explicitly\nbyte[] key = \"user:123\".getBytes(StandardCharsets.UTF_8);\n</code></pre> <pre><code>//  Correct: TextEncoder uses UTF-8\nconst key = new TextEncoder().encode(\"user:123\");\n</code></pre>"},{"location":"sdks/hash-compatibility/#3-integer-overflow","title":"3. Integer Overflow","text":"<p>Problem: Integer overflow in jump consistent hash</p> <pre><code>#  Correct: Mask to 64 bits\nkey = ((key * 2862933555777941757) + 1) &amp; 0xFFFFFFFFFFFFFFFF\n</code></pre>"},{"location":"sdks/hash-compatibility/#4-floating-point-precision","title":"4. Floating Point Precision","text":"<p>Problem: Loss of precision in jump consistent hash calculation</p> <pre><code>//  Correct: Use proper type conversions\nj = int64(float64(b+1) * (float64(int64(1)&lt;&lt;31) / float64((key&gt;&gt;33)+1)))\n</code></pre>"},{"location":"sdks/hash-compatibility/#debugging-hash-mismatches","title":"Debugging Hash Mismatches","text":"<p>If you suspect hash compatibility issues:</p>"},{"location":"sdks/hash-compatibility/#1-enable-debug-logging","title":"1. Enable Debug Logging","text":"<pre><code>// Java\nLogger.getLogger(\"com.norikv.router\").setLevel(Level.DEBUG);\n</code></pre> <pre><code>// Go\nlog.Printf(\"Key: %s -&gt; Hash: %d -&gt; Shard: %d\", key, hash, shard)\n</code></pre> <pre><code>// TypeScript\nconsole.log(`Key: ${key} -&gt; Hash: ${hash} -&gt; Shard: ${shard}`);\n</code></pre> <pre><code># Python\nlogger.debug(f\"Key: {key} -&gt; Hash: {hash} -&gt; Shard: {shard}\")\n</code></pre>"},{"location":"sdks/hash-compatibility/#2-verify-test-vectors","title":"2. Verify Test Vectors","text":"<p>Run the test vector verification for your SDK and compare output with the expected values above.</p>"},{"location":"sdks/hash-compatibility/#3-check-dependencies","title":"3. Check Dependencies","text":"<p>Ensure you're using the correct hash library: - Java: <code>net.openhft:zero-allocation-hashing</code> - Go: <code>github.com/cespare/xxhash/v2</code> - TypeScript: <code>xxhash-wasm</code> - Python: <code>xxhash</code> (Python package)</p>"},{"location":"sdks/hash-compatibility/#4-validate-key-encoding","title":"4. Validate Key Encoding","text":"<pre><code># Print key bytes\nkey = \"user:123\"\nkey_bytes = key.encode(\"utf-8\")\nprint(f\"Key bytes: {list(key_bytes)}\")\n# Should output: [117, 115, 101, 114, 58, 49, 50, 51]\n</code></pre>"},{"location":"sdks/hash-compatibility/#performance-characteristics","title":"Performance Characteristics","text":"<p>Hash computation is extremely fast across all SDKs:</p> SDK Hash Time (ns/op) Allocations Java 45 ns 0 Go 23 ns 0 TypeScript 80 ns 0 Python 120 ns 0 <p>These measurements are for a 16-byte key on typical hardware.</p>"},{"location":"sdks/hash-compatibility/#shard-count-changes","title":"Shard Count Changes","text":"<p>If you need to change the number of shards:</p> <ol> <li>Jump Consistent Hash minimizes key movement</li> <li>Adding shards: ~1/n keys move</li> <li> <p>Removing shards: ~1/n keys move</p> </li> <li> <p>All clients must use the same shard count</p> </li> <li> <p>Configure <code>totalShards</code> to match cluster</p> </li> <li> <p>Rehashing is automatic</p> </li> <li>No client code changes needed</li> <li>Keys automatically route to new shards</li> </ol>"},{"location":"sdks/hash-compatibility/#references","title":"References","text":"<ul> <li>XXHash Algorithm</li> <li>Jump Consistent Hash Paper</li> <li>Test Vector Source Code</li> </ul>"},{"location":"sdks/hash-compatibility/#next-steps","title":"Next Steps","text":"<ul> <li>Getting Started - Quick start for all SDKs</li> <li>Error Reference - Unified error codes</li> <li>SDK Comparison - Feature comparison</li> </ul>"},{"location":"sdks/go/","title":"NoriKV Go Client SDK","text":"<p>High-performance Go client for NoriKV with zero-allocation routing and comprehensive documentation.</p>"},{"location":"sdks/go/#status","title":"Status","text":"<p>** PRODUCTION READY** - Fully functional Go SDK</p> <ul> <li>102+ tests passing with full coverage</li> <li>Zero-allocation routing hot path (23ns/op, 0 allocs)</li> <li>Complete API with all operations</li> <li>Comprehensive documentation (4 detailed guides)</li> <li>Cross-SDK hash validation passing</li> </ul>"},{"location":"sdks/go/#quick-start","title":"Quick Start","text":""},{"location":"sdks/go/#installation","title":"Installation","text":"<pre><code>go get github.com/norikv/norikv-go\n</code></pre>"},{"location":"sdks/go/#basic-usage","title":"Basic Usage","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n\n    norikv \"github.com/norikv/norikv-go\"\n)\n\nfunc main() {\n    ctx := context.Background()\n    config := norikv.DefaultClientConfig([]string{\"localhost:9001\"})\n\n    client, err := norikv.NewClient(ctx, config)\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer client.Close()\n\n    // Put a value\n    key := []byte(\"user:123\")\n    value := []byte(`{\"name\":\"Alice\"}`)\n    version, _ := client.Put(ctx, key, value, nil)\n\n    // Get the value\n    result, _ := client.Get(ctx, key, nil)\n    fmt.Printf(\"Value: %s\\n\", result.Value)\n\n    // Delete\n    client.Delete(ctx, key, nil)\n}\n</code></pre>"},{"location":"sdks/go/#documentation","title":"Documentation","text":"<p>The Go SDK includes comprehensive documentation:</p>"},{"location":"sdks/go/#core-guides","title":"Core Guides","text":"<ul> <li>API Guide - Complete API reference</li> <li>Installation and setup</li> <li>Client configuration with context</li> <li>All operations with Go idioms</li> <li>Advanced features</li> <li>Error handling with errors.Is</li> <li> <p>Best practices</p> </li> <li> <p>Architecture Guide - Internal design</p> </li> <li>Component architecture</li> <li>Zero-allocation routing</li> <li>Goroutine safety</li> <li>Single-flight pattern</li> <li>Connection management</li> <li> <p>Performance optimizations</p> </li> <li> <p>Troubleshooting Guide - Common issues</p> </li> <li>Connection problems</li> <li>Performance with pprof</li> <li>Version conflicts</li> <li>Error solutions</li> <li> <p>Debugging goroutines</p> </li> <li> <p>Advanced Patterns - Production patterns</p> </li> <li>Distributed Counter</li> <li>Session Management</li> <li>Inventory Management</li> <li>Caching Layer</li> <li>Rate Limiting</li> <li>Leader Election</li> <li>Event Sourcing</li> <li>Multi-Tenancy</li> </ul>"},{"location":"sdks/go/#features","title":"Features","text":""},{"location":"sdks/go/#core-features","title":"Core Features","text":"<ul> <li>Smart client-side routing</li> <li>Leader-aware routing with failover</li> <li>Retry logic with exponential backoff</li> <li>Idempotency support</li> <li>Conditional operations (CAS)</li> <li>Multiple consistency levels</li> <li>Connection pooling</li> <li>Topology tracking</li> <li>Goroutine-safe operations</li> </ul>"},{"location":"sdks/go/#go-specific","title":"Go-Specific","text":"<ul> <li>Context-aware operations</li> <li>Zero-allocation routing (0 B/op, 0 allocs/op)</li> <li>Single-flight pattern for leader discovery</li> <li>defer-based resource management</li> <li>Native error wrapping</li> <li>Efficient concurrency with goroutines</li> </ul>"},{"location":"sdks/go/#performance","title":"Performance","text":"<p>Hash Function Benchmarks: - XXHash64: ~2.5ns per operation (0 allocs) - JumpConsistentHash: ~14ns per operation (0 allocs) - GetShardForKey: ~23ns per operation (0 allocs)</p> <p>Zero Allocations in routing hot path ensures: - No garbage collection pressure - Consistent low latency - High throughput under load</p>"},{"location":"sdks/go/#requirements","title":"Requirements","text":"<ul> <li>Go: 1.19 or higher</li> <li>NoriKV Server: 0.1.x</li> </ul>"},{"location":"sdks/go/#examples","title":"Examples","text":"<p>See the source repository for complete working examples:</p> <ul> <li><code>basic/</code> - Complete basic usage patterns</li> <li><code>ephemeral/</code> - Testing with in-memory server</li> </ul>"},{"location":"sdks/go/#support","title":"Support","text":"<ul> <li>Issues: GitHub Issues</li> <li>Source: GitHub Repository</li> <li>pkg.go.dev: API Documentation</li> </ul>"},{"location":"sdks/go/#license","title":"License","text":"<p>MIT OR Apache-2.0</p> <p>{: .note }</p> <p>This SDK is optimized for high performance with zero-allocation routing and native Go concurrency patterns.</p>"},{"location":"sdks/go/ADVANCED_PATTERNS/","title":"NoriKV Go Client Advanced Patterns","text":"<p>Complex real-world usage patterns and design examples.</p>"},{"location":"sdks/go/ADVANCED_PATTERNS/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Distributed Counter</li> <li>Session Management</li> <li>Inventory Management</li> <li>Caching Layer</li> <li>Rate Limiting</li> <li>Leader Election</li> <li>Event Sourcing</li> <li>Multi-Tenancy</li> </ul>"},{"location":"sdks/go/ADVANCED_PATTERNS/#distributed-counter","title":"Distributed Counter","text":"<p>Implement a high-throughput distributed counter with sharding to reduce contention.</p>"},{"location":"sdks/go/ADVANCED_PATTERNS/#implementation","title":"Implementation","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"crypto/rand\"\n    \"encoding/binary\"\n    \"fmt\"\n    \"strconv\"\n    \"sync\"\n\n    norikv \"github.com/norikv/norikv-go\"\n)\n\ntype DistributedCounter struct {\n    client     *norikv.Client\n    name       string\n    numShards  int\n}\n\nfunc NewDistributedCounter(client *norikv.Client, name string, numShards int) *DistributedCounter {\n    return &amp;DistributedCounter{\n        client:    client,\n        name:      name,\n        numShards: numShards,\n    }\n}\n\n// Increment atomically increments the counter by 1\nfunc (c *DistributedCounter) Increment(ctx context.Context) error {\n    // Choose random shard to reduce contention\n    shardID := c.randomShard()\n    key := []byte(fmt.Sprintf(\"%s:shard:%d\", c.name, shardID))\n\n    const maxRetries = 10\n    for attempt := 0; attempt &lt; maxRetries; attempt++ {\n        // Read current value\n        result, err := c.client.Get(ctx, key, nil)\n        if err != nil &amp;&amp; !errors.Is(err, norikv.ErrKeyNotFound) {\n            return err\n        }\n\n        var currentValue int\n        if err == nil {\n            currentValue, _ = strconv.Atoi(string(result.Value))\n        }\n\n        // Increment\n        newValue := []byte(strconv.Itoa(currentValue + 1))\n\n        // CAS write\n        options := &amp;norikv.PutOptions{}\n        if err == nil {\n            options.IfMatchVersion = result.Version\n        } else {\n            options.IfNotExists = true\n        }\n\n        _, err = c.client.Put(ctx, key, newValue, options)\n        if err == nil {\n            return nil\n        }\n\n        if !errors.Is(err, norikv.ErrVersionMismatch) &amp;&amp; !errors.Is(err, norikv.ErrAlreadyExists) {\n            return err\n        }\n\n        // Exponential backoff with jitter\n        backoff := time.Duration(1&lt;&lt;attempt) * 10 * time.Millisecond\n        jitter := time.Duration(rand.Intn(10)) * time.Millisecond\n        time.Sleep(backoff + jitter)\n    }\n\n    return fmt.Errorf(\"increment failed after %d retries\", maxRetries)\n}\n\n// Get returns the total count across all shards\nfunc (c *DistributedCounter) Get(ctx context.Context) (int, error) {\n    var wg sync.WaitGroup\n    results := make(chan int, c.numShards)\n    errors := make(chan error, c.numShards)\n\n    for i := 0; i &lt; c.numShards; i++ {\n        wg.Add(1)\n        go func(shardID int) {\n            defer wg.Done()\n\n            key := []byte(fmt.Sprintf(\"%s:shard:%d\", c.name, shardID))\n            result, err := c.client.Get(ctx, key, nil)\n            if err != nil {\n                if errors.Is(err, norikv.ErrKeyNotFound) {\n                    results &lt;- 0\n                    return\n                }\n                errors &lt;- err\n                return\n            }\n\n            value, _ := strconv.Atoi(string(result.Value))\n            results &lt;- value\n        }(i)\n    }\n\n    wg.Wait()\n    close(results)\n    close(errors)\n\n    // Check for errors\n    select {\n    case err := &lt;-errors:\n        return 0, err\n    default:\n    }\n\n    // Sum all shards\n    total := 0\n    for value := range results {\n        total += value\n    }\n\n    return total, nil\n}\n\nfunc (c *DistributedCounter) randomShard() int {\n    var b [8]byte\n    rand.Read(b[:])\n    return int(binary.LittleEndian.Uint64(b[:]) % uint64(c.numShards))\n}\n</code></pre>"},{"location":"sdks/go/ADVANCED_PATTERNS/#usage","title":"Usage","text":"<pre><code>counter := NewDistributedCounter(client, \"page-views\", 10)\n\n// Increment from multiple goroutines\nvar wg sync.WaitGroup\nfor i := 0; i &lt; 1000; i++ {\n    wg.Add(1)\n    go func() {\n        defer wg.Done()\n        counter.Increment(ctx)\n    }()\n}\nwg.Wait()\n\n// Get total\ntotal, _ := counter.Get(ctx)\nfmt.Printf(\"Total: %d\\n\", total)\n</code></pre>"},{"location":"sdks/go/ADVANCED_PATTERNS/#session-management","title":"Session Management","text":"<p>Implement session storage with automatic expiration using TTL.</p>"},{"location":"sdks/go/ADVANCED_PATTERNS/#implementation_1","title":"Implementation","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"encoding/json\"\n    \"fmt\"\n    \"time\"\n\n    \"github.com/google/uuid\"\n    norikv \"github.com/norikv/norikv-go\"\n)\n\ntype Session struct {\n    ID        string\n    UserID    int\n    Data      map[string]interface{}\n    CreatedAt time.Time\n    ExpiresAt time.Time\n}\n\ntype SessionStore struct {\n    client *norikv.Client\n    ttl    time.Duration\n}\n\nfunc NewSessionStore(client *norikv.Client, ttl time.Duration) *SessionStore {\n    return &amp;SessionStore{\n        client: client,\n        ttl:    ttl,\n    }\n}\n\n// Create creates a new session\nfunc (s *SessionStore) Create(ctx context.Context, userID int, data map[string]interface{}) (*Session, error) {\n    session := &amp;Session{\n        ID:        uuid.New().String(),\n        UserID:    userID,\n        Data:      data,\n        CreatedAt: time.Now(),\n        ExpiresAt: time.Now().Add(s.ttl),\n    }\n\n    sessionData, err := json.Marshal(session)\n    if err != nil {\n        return nil, err\n    }\n\n    key := []byte(fmt.Sprintf(\"session:%s\", session.ID))\n    ttlMs := uint64(s.ttl.Milliseconds())\n\n    options := &amp;norikv.PutOptions{\n        TTLMs:          &amp;ttlMs,\n        IdempotencyKey: session.ID,\n    }\n\n    _, err = s.client.Put(ctx, key, sessionData, options)\n    if err != nil {\n        return nil, err\n    }\n\n    return session, nil\n}\n\n// Get retrieves a session by ID\nfunc (s *SessionStore) Get(ctx context.Context, sessionID string) (*Session, error) {\n    key := []byte(fmt.Sprintf(\"session:%s\", sessionID))\n\n    result, err := s.client.Get(ctx, key, nil)\n    if err != nil {\n        return nil, err\n    }\n\n    var session Session\n    if err := json.Unmarshal(result.Value, &amp;session); err != nil {\n        return nil, err\n    }\n\n    return &amp;session, nil\n}\n\n// Update updates session data\nfunc (s *SessionStore) Update(ctx context.Context, sessionID string, data map[string]interface{}) error {\n    session, err := s.Get(ctx, sessionID)\n    if err != nil {\n        return err\n    }\n\n    session.Data = data\n\n    sessionData, err := json.Marshal(session)\n    if err != nil {\n        return err\n    }\n\n    key := []byte(fmt.Sprintf(\"session:%s\", sessionID))\n    ttlMs := uint64(time.Until(session.ExpiresAt).Milliseconds())\n\n    options := &amp;norikv.PutOptions{\n        TTLMs: &amp;ttlMs,\n    }\n\n    _, err = s.client.Put(ctx, key, sessionData, options)\n    return err\n}\n\n// Delete explicitly deletes a session (logout)\nfunc (s *SessionStore) Delete(ctx context.Context, sessionID string) error {\n    key := []byte(fmt.Sprintf(\"session:%s\", sessionID))\n    return s.client.Delete(ctx, key, nil)\n}\n</code></pre>"},{"location":"sdks/go/ADVANCED_PATTERNS/#usage_1","title":"Usage","text":"<pre><code>store := NewSessionStore(client, 30*time.Minute)\n\n// Create session\nsession, _ := store.Create(ctx, 123, map[string]interface{}{\n    \"role\":       \"admin\",\n    \"last_login\": time.Now(),\n})\n\n// Get session\nretrieved, _ := store.Get(ctx, session.ID)\n\n// Update session\nstore.Update(ctx, session.ID, map[string]interface{}{\n    \"role\":       \"admin\",\n    \"last_login\": time.Now(),\n    \"page_views\": 5,\n})\n\n// Delete session (logout)\nstore.Delete(ctx, session.ID)\n</code></pre>"},{"location":"sdks/go/ADVANCED_PATTERNS/#inventory-management","title":"Inventory Management","text":"<p>Prevent overselling with atomic CAS operations.</p>"},{"location":"sdks/go/ADVANCED_PATTERNS/#implementation_2","title":"Implementation","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"encoding/json\"\n    \"fmt\"\n    \"time\"\n\n    norikv \"github.com/norikv/norikv-go\"\n)\n\ntype InventoryItem struct {\n    SKU      string\n    Quantity int\n    Reserved int\n}\n\ntype InventoryManager struct {\n    client *norikv.Client\n}\n\nfunc NewInventoryManager(client *norikv.Client) *InventoryManager {\n    return &amp;InventoryManager{client: client}\n}\n\n// Reserve atomically reserves inventory\nfunc (im *InventoryManager) Reserve(ctx context.Context, sku string, quantity int) error {\n    key := []byte(fmt.Sprintf(\"inventory:%s\", sku))\n\n    const maxRetries = 10\n    for attempt := 0; attempt &lt; maxRetries; attempt++ {\n        // Read current inventory\n        result, err := im.client.Get(ctx, key, nil)\n        if err != nil {\n            return err\n        }\n\n        var item InventoryItem\n        if err := json.Unmarshal(result.Value, &amp;item); err != nil {\n            return err\n        }\n\n        // Check availability\n        available := item.Quantity - item.Reserved\n        if available &lt; quantity {\n            return fmt.Errorf(\"insufficient inventory: need %d, have %d\", quantity, available)\n        }\n\n        // Reserve\n        item.Reserved += quantity\n\n        itemData, err := json.Marshal(item)\n        if err != nil {\n            return err\n        }\n\n        // CAS update\n        options := &amp;norikv.PutOptions{\n            IfMatchVersion: result.Version,\n        }\n\n        _, err = im.client.Put(ctx, key, itemData, options)\n        if err == nil {\n            return nil\n        }\n\n        if !errors.Is(err, norikv.ErrVersionMismatch) {\n            return err\n        }\n\n        // Exponential backoff\n        time.Sleep(time.Duration(1&lt;&lt;attempt) * 10 * time.Millisecond)\n    }\n\n    return fmt.Errorf(\"reserve failed after %d retries\", maxRetries)\n}\n\n// Commit converts reservation to sale\nfunc (im *InventoryManager) Commit(ctx context.Context, sku string, quantity int) error {\n    key := []byte(fmt.Sprintf(\"inventory:%s\", sku))\n\n    const maxRetries = 10\n    for attempt := 0; attempt &lt; maxRetries; attempt++ {\n        result, err := im.client.Get(ctx, key, nil)\n        if err != nil {\n            return err\n        }\n\n        var item InventoryItem\n        if err := json.Unmarshal(result.Value, &amp;item); err != nil {\n            return err\n        }\n\n        // Commit: reduce quantity and reserved\n        item.Quantity -= quantity\n        item.Reserved -= quantity\n\n        itemData, err := json.Marshal(item)\n        if err != nil {\n            return err\n        }\n\n        options := &amp;norikv.PutOptions{\n            IfMatchVersion: result.Version,\n        }\n\n        _, err = im.client.Put(ctx, key, itemData, options)\n        if err == nil {\n            return nil\n        }\n\n        if !errors.Is(err, norikv.ErrVersionMismatch) {\n            return err\n        }\n\n        time.Sleep(time.Duration(1&lt;&lt;attempt) * 10 * time.Millisecond)\n    }\n\n    return fmt.Errorf(\"commit failed after %d retries\", maxRetries)\n}\n\n// Release cancels a reservation\nfunc (im *InventoryManager) Release(ctx context.Context, sku string, quantity int) error {\n    key := []byte(fmt.Sprintf(\"inventory:%s\", sku))\n\n    const maxRetries = 10\n    for attempt := 0; attempt &lt; maxRetries; attempt++ {\n        result, err := im.client.Get(ctx, key, nil)\n        if err != nil {\n            return err\n        }\n\n        var item InventoryItem\n        if err := json.Unmarshal(result.Value, &amp;item); err != nil {\n            return err\n        }\n\n        // Release reservation\n        item.Reserved -= quantity\n\n        itemData, err := json.Marshal(item)\n        if err != nil {\n            return err\n        }\n\n        options := &amp;norikv.PutOptions{\n            IfMatchVersion: result.Version,\n        }\n\n        _, err = im.client.Put(ctx, key, itemData, options)\n        if err == nil {\n            return nil\n        }\n\n        if !errors.Is(err, norikv.ErrVersionMismatch) {\n            return err\n        }\n\n        time.Sleep(time.Duration(1&lt;&lt;attempt) * 10 * time.Millisecond)\n    }\n\n    return fmt.Errorf(\"release failed after %d retries\", maxRetries)\n}\n</code></pre>"},{"location":"sdks/go/ADVANCED_PATTERNS/#usage_2","title":"Usage","text":"<pre><code>im := NewInventoryManager(client)\n\n// Reserve inventory\nerr := im.Reserve(ctx, \"SKU-12345\", 2)\nif err != nil {\n    log.Printf(\"Reservation failed: %v\", err)\n    return\n}\n\n// Process payment...\n\n// Commit or release\nif paymentSucceeded {\n    im.Commit(ctx, \"SKU-12345\", 2)\n} else {\n    im.Release(ctx, \"SKU-12345\", 2)\n}\n</code></pre>"},{"location":"sdks/go/ADVANCED_PATTERNS/#caching-layer","title":"Caching Layer","text":"<p>Implement a write-through cache with NoriKV.</p>"},{"location":"sdks/go/ADVANCED_PATTERNS/#implementation_3","title":"Implementation","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"encoding/json\"\n    \"fmt\"\n    \"sync\"\n    \"time\"\n\n    norikv \"github.com/norikv/norikv-go\"\n)\n\ntype CacheEntry struct {\n    Value     []byte\n    ExpiresAt time.Time\n}\n\ntype CacheLayer struct {\n    client     *norikv.Client\n    localCache sync.Map\n    ttl        time.Duration\n}\n\nfunc NewCacheLayer(client *norikv.Client, ttl time.Duration) *CacheLayer {\n    cache := &amp;CacheLayer{\n        client: client,\n        ttl:    ttl,\n    }\n\n    // Background cleanup of expired local cache entries\n    go cache.cleanupLoop()\n\n    return cache\n}\n\n// Get retrieves a value with local cache fallback\nfunc (c *CacheLayer) Get(ctx context.Context, key []byte) ([]byte, error) {\n    keyStr := string(key)\n\n    // Check local cache first\n    if entry, ok := c.localCache.Load(keyStr); ok {\n        cached := entry.(*CacheEntry)\n        if time.Now().Before(cached.ExpiresAt) {\n            return cached.Value, nil\n        }\n        c.localCache.Delete(keyStr)\n    }\n\n    // Fetch from NoriKV\n    result, err := c.client.Get(ctx, key, &amp;norikv.GetOptions{\n        Consistency: norikv.ConsistencyStaleOK, // Allow stale for cache\n    })\n    if err != nil {\n        return nil, err\n    }\n\n    // Update local cache\n    c.localCache.Store(keyStr, &amp;CacheEntry{\n        Value:     result.Value,\n        ExpiresAt: time.Now().Add(c.ttl),\n    })\n\n    return result.Value, nil\n}\n\n// Put writes through to NoriKV and updates local cache\nfunc (c *CacheLayer) Put(ctx context.Context, key, value []byte) error {\n    // Write to NoriKV\n    ttlMs := uint64(c.ttl.Milliseconds())\n    _, err := c.client.Put(ctx, key, value, &amp;norikv.PutOptions{\n        TTLMs: &amp;ttlMs,\n    })\n    if err != nil {\n        return err\n    }\n\n    // Update local cache\n    c.localCache.Store(string(key), &amp;CacheEntry{\n        Value:     value,\n        ExpiresAt: time.Now().Add(c.ttl),\n    })\n\n    return nil\n}\n\n// Delete removes from both caches\nfunc (c *CacheLayer) Delete(ctx context.Context, key []byte) error {\n    // Delete from local cache\n    c.localCache.Delete(string(key))\n\n    // Delete from NoriKV\n    return c.client.Delete(ctx, key, nil)\n}\n\nfunc (c *CacheLayer) cleanupLoop() {\n    ticker := time.NewTicker(c.ttl / 2)\n    defer ticker.Stop()\n\n    for range ticker.C {\n        now := time.Now()\n        c.localCache.Range(func(key, value interface{}) bool {\n            entry := value.(*CacheEntry)\n            if now.After(entry.ExpiresAt) {\n                c.localCache.Delete(key)\n            }\n            return true\n        })\n    }\n}\n</code></pre>"},{"location":"sdks/go/ADVANCED_PATTERNS/#usage_3","title":"Usage","text":"<pre><code>cache := NewCacheLayer(client, 5*time.Minute)\n\n// Write (goes to both caches)\ncache.Put(ctx, []byte(\"user:123\"), userData)\n\n// Read (local cache first, then NoriKV)\ndata, _ := cache.Get(ctx, []byte(\"user:123\"))\n\n// Delete (removes from both)\ncache.Delete(ctx, []byte(\"user:123\"))\n</code></pre>"},{"location":"sdks/go/ADVANCED_PATTERNS/#rate-limiting","title":"Rate Limiting","text":"<p>Implement a distributed rate limiter using sliding window.</p>"},{"location":"sdks/go/ADVANCED_PATTERNS/#implementation_4","title":"Implementation","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"strconv\"\n    \"strings\"\n    \"time\"\n\n    norikv \"github.com/norikv/norikv-go\"\n)\n\ntype RateLimiter struct {\n    client      *norikv.Client\n    maxRequests int\n    window      time.Duration\n}\n\nfunc NewRateLimiter(client *norikv.Client, maxRequests int, window time.Duration) *RateLimiter {\n    return &amp;RateLimiter{\n        client:      client,\n        maxRequests: maxRequests,\n        window:      window,\n    }\n}\n\n// Allow checks if a request is allowed\nfunc (rl *RateLimiter) Allow(ctx context.Context, identifier string) (bool, error) {\n    now := time.Now()\n    windowStart := now.Add(-rl.window).Unix()\n\n    // Use minute bucket for rate limiting\n    bucket := now.Unix() / 60\n    key := []byte(fmt.Sprintf(\"ratelimit:%s:%d\", identifier, bucket))\n\n    const maxRetries = 5\n    for attempt := 0; attempt &lt; maxRetries; attempt++ {\n        // Get current count\n        result, err := rl.client.Get(ctx, key, nil)\n\n        var count int\n        var version *norikv.Version\n\n        if err == nil {\n            count, _ = strconv.Atoi(string(result.Value))\n            version = result.Version\n        } else if !errors.Is(err, norikv.ErrKeyNotFound) {\n            return false, err\n        }\n\n        // Check if under limit\n        if count &gt;= rl.maxRequests {\n            return false, nil\n        }\n\n        // Increment\n        count++\n        ttlMs := uint64(rl.window.Milliseconds())\n\n        options := &amp;norikv.PutOptions{\n            TTLMs: &amp;ttlMs,\n        }\n        if version != nil {\n            options.IfMatchVersion = version\n        } else {\n            options.IfNotExists = true\n        }\n\n        _, err = rl.client.Put(ctx, key, []byte(strconv.Itoa(count)), options)\n        if err == nil {\n            return true, nil\n        }\n\n        if !errors.Is(err, norikv.ErrVersionMismatch) &amp;&amp; !errors.Is(err, norikv.ErrAlreadyExists) {\n            return false, err\n        }\n\n        time.Sleep(10 * time.Millisecond)\n    }\n\n    return false, fmt.Errorf(\"rate limit check failed after retries\")\n}\n</code></pre>"},{"location":"sdks/go/ADVANCED_PATTERNS/#usage_4","title":"Usage","text":"<pre><code>limiter := NewRateLimiter(client, 100, 1*time.Minute)\n\n// Check if request is allowed\nallowed, _ := limiter.Allow(ctx, \"user:123\")\nif !allowed {\n    http.Error(w, \"Rate limit exceeded\", http.StatusTooManyRequests)\n    return\n}\n\n// Process request...\n</code></pre>"},{"location":"sdks/go/ADVANCED_PATTERNS/#next-steps","title":"Next Steps","text":"<ul> <li>API Guide - Complete API reference</li> <li>Architecture Guide - Internal design</li> <li>Troubleshooting Guide - Common issues</li> <li>Examples - Working code samples</li> </ul>"},{"location":"sdks/go/API_GUIDE/","title":"NoriKV Go Client API Guide","text":"<p>Complete reference for the NoriKV Go Client SDK.</p>"},{"location":"sdks/go/API_GUIDE/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Installation</li> <li>Quick Start</li> <li>Client Configuration</li> <li>Core Operations</li> <li>Advanced Features</li> <li>Error Handling</li> <li>Best Practices</li> </ul>"},{"location":"sdks/go/API_GUIDE/#installation","title":"Installation","text":"<pre><code>go get github.com/norikv/norikv-go\n</code></pre>"},{"location":"sdks/go/API_GUIDE/#quick-start","title":"Quick Start","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n\n    norikv \"github.com/norikv/norikv-go\"\n)\n\nfunc main() {\n    ctx := context.Background()\n\n    // Configure client\n    config := norikv.ClientConfig{\n        Nodes:       []string{\"localhost:9001\", \"localhost:9002\"},\n        TotalShards: 1024,\n        Timeout:     5 * time.Second,\n    }\n\n    // Create client\n    client, err := norikv.NewClient(ctx, &amp;config)\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer client.Close()\n\n    // Put a value\n    key := []byte(\"user:alice\")\n    value := []byte(`{\"name\":\"Alice\",\"age\":30}`)\n\n    version, err := client.Put(ctx, key, value, nil)\n    if err != nil {\n        log.Fatal(err)\n    }\n    fmt.Printf(\"Wrote version: %v\\n\", version)\n\n    // Get the value\n    result, err := client.Get(ctx, key, nil)\n    if err != nil {\n        log.Fatal(err)\n    }\n    fmt.Printf(\"Value: %s\\n\", result.Value)\n\n    // Delete\n    err = client.Delete(ctx, key, nil)\n    if err != nil {\n        log.Fatal(err)\n    }\n}\n</code></pre>"},{"location":"sdks/go/API_GUIDE/#client-configuration","title":"Client Configuration","text":""},{"location":"sdks/go/API_GUIDE/#basic-configuration","title":"Basic Configuration","text":"<pre><code>config := &amp;norikv.ClientConfig{\n    Nodes:       []string{\"node1:9001\", \"node2:9001\"},\n    TotalShards: 1024,\n    Timeout:     5 * time.Second,\n}\n</code></pre>"},{"location":"sdks/go/API_GUIDE/#configuration-options","title":"Configuration Options","text":"Field Type Default Description <code>Nodes</code> <code>[]string</code> Required List of node addresses (host:port) <code>TotalShards</code> <code>int</code> Required Total number of shards in cluster <code>Timeout</code> <code>time.Duration</code> 5s Request timeout <code>Retry</code> <code>*RetryConfig</code> See below Retry policy configuration"},{"location":"sdks/go/API_GUIDE/#retry-configuration","title":"Retry Configuration","text":"<pre><code>retryConfig := &amp;norikv.RetryConfig{\n    MaxAttempts:   10,\n    InitialDelay:  100 * time.Millisecond,\n    MaxDelay:      5 * time.Second,\n    Jitter:        100 * time.Millisecond,\n}\n\nconfig := &amp;norikv.ClientConfig{\n    Nodes:       []string{\"localhost:9001\"},\n    TotalShards: 1024,\n    Retry:       retryConfig,\n}\n</code></pre> <p>Retry Behavior: - Retries transient errors: <code>Unavailable</code>, <code>Aborted</code>, <code>DeadlineExceeded</code>, <code>ResourceExhausted</code> - Does NOT retry: <code>InvalidArgument</code>, <code>NotFound</code>, <code>FailedPrecondition</code>, <code>PermissionDenied</code> - Uses exponential backoff with jitter</p>"},{"location":"sdks/go/API_GUIDE/#default-configuration","title":"Default Configuration","text":"<pre><code>// Quick setup with defaults\nconfig := norikv.DefaultClientConfig([]string{\"localhost:9001\"})\n</code></pre>"},{"location":"sdks/go/API_GUIDE/#core-operations","title":"Core Operations","text":""},{"location":"sdks/go/API_GUIDE/#put-write-data","title":"PUT - Write Data","text":""},{"location":"sdks/go/API_GUIDE/#basic-put","title":"Basic PUT","text":"<pre><code>key := []byte(\"user:123\")\nvalue := []byte(`{\"name\":\"Alice\"}`)\n\nversion, err := client.Put(ctx, key, value, nil)\nif err != nil {\n    log.Fatal(err)\n}\nfmt.Printf(\"Written at version: %v\\n\", version)\n</code></pre>"},{"location":"sdks/go/API_GUIDE/#put-with-options","title":"PUT with Options","text":"<pre><code>ttl := uint64(60000) // 60 seconds\n\noptions := &amp;norikv.PutOptions{\n    TTLMs:          &amp;ttl,\n    IdempotencyKey: \"order-12345\",\n    IfMatchVersion: expectedVersion, // CAS\n}\n\nversion, err := client.Put(ctx, key, value, options)\n</code></pre> <p>PutOptions Fields:</p> Field Type Description <code>TTLMs</code> <code>*uint64</code> Time-to-live in milliseconds <code>IdempotencyKey</code> <code>string</code> Key for idempotent operations <code>IfMatchVersion</code> <code>*Version</code> Expected version for CAS <code>IfNotExists</code> <code>bool</code> Only write if key doesn't exist"},{"location":"sdks/go/API_GUIDE/#get-read-data","title":"GET - Read Data","text":""},{"location":"sdks/go/API_GUIDE/#basic-get","title":"Basic GET","text":"<pre><code>key := []byte(\"user:123\")\nresult, err := client.Get(ctx, key, nil)\nif err != nil {\n    log.Fatal(err)\n}\n\nvalue := result.Value\nversion := result.Version\n</code></pre>"},{"location":"sdks/go/API_GUIDE/#get-with-consistency-level","title":"GET with Consistency Level","text":"<pre><code>options := &amp;norikv.GetOptions{\n    Consistency: norikv.ConsistencyLinearizable,\n}\n\nresult, err := client.Get(ctx, key, options)\n</code></pre> <p>Consistency Levels:</p> Level Description Use Case <code>ConsistencyLease</code> Default, lease-based read Most operations (fast, usually consistent) <code>ConsistencyLinearizable</code> Strictest, always up-to-date Critical reads requiring absolute consistency <code>ConsistencyStaleOK</code> May return stale data Read-heavy workloads, caching"},{"location":"sdks/go/API_GUIDE/#delete-remove-data","title":"DELETE - Remove Data","text":""},{"location":"sdks/go/API_GUIDE/#basic-delete","title":"Basic DELETE","text":"<pre><code>key := []byte(\"user:123\")\nerr := client.Delete(ctx, key, nil)\nif err != nil {\n    log.Fatal(err)\n}\n</code></pre>"},{"location":"sdks/go/API_GUIDE/#delete-with-options","title":"DELETE with Options","text":"<pre><code>options := &amp;norikv.DeleteOptions{\n    IdempotencyKey: \"delete-order-12345\",\n    IfMatchVersion: expectedVersion,\n}\n\nerr := client.Delete(ctx, key, options)\n</code></pre>"},{"location":"sdks/go/API_GUIDE/#advanced-features","title":"Advanced Features","text":""},{"location":"sdks/go/API_GUIDE/#compare-and-swap-cas","title":"Compare-And-Swap (CAS)","text":"<p>Optimistic concurrency control using version matching:</p> <pre><code>// Read current value\nresult, err := client.Get(ctx, key, nil)\nif err != nil {\n    log.Fatal(err)\n}\n\n// Modify value\nvalue, _ := strconv.Atoi(string(result.Value))\nnewValue := []byte(strconv.Itoa(value + 1))\n\n// Update with CAS\noptions := &amp;norikv.PutOptions{\n    IfMatchVersion: result.Version,\n}\n\n_, err = client.Put(ctx, key, newValue, options)\nif errors.Is(err, norikv.ErrVersionMismatch) {\n    fmt.Println(\"CAS failed - version changed\")\n} else if err != nil {\n    log.Fatal(err)\n}\n</code></pre>"},{"location":"sdks/go/API_GUIDE/#idempotent-operations","title":"Idempotent Operations","text":"<p>Safe retries using idempotency keys:</p> <pre><code>idempotencyKey := \"payment-\" + uuid.New().String()\n\noptions := &amp;norikv.PutOptions{\n    IdempotencyKey: idempotencyKey,\n}\n\n// First attempt\nv1, err := client.Put(ctx, key, value, options)\n\n// Retry with same key (safe - returns same version)\nv2, err := client.Put(ctx, key, value, options)\n\n// v1 and v2 are equal\n</code></pre>"},{"location":"sdks/go/API_GUIDE/#time-to-live-ttl","title":"Time-To-Live (TTL)","text":"<p>Automatic expiration:</p> <pre><code>ttl := uint64(60000) // 60 seconds\n\noptions := &amp;norikv.PutOptions{\n    TTLMs: &amp;ttl,\n}\n\nclient.Put(ctx, key, value, options)\n\n// Key automatically deleted after TTL\ntime.Sleep(61 * time.Second)\n_, err := client.Get(ctx, key, nil)\nif errors.Is(err, norikv.ErrKeyNotFound) {\n    fmt.Println(\"Key expired\")\n}\n</code></pre>"},{"location":"sdks/go/API_GUIDE/#cluster-topology","title":"Cluster Topology","text":"<p>Monitor cluster changes:</p> <pre><code>// Get current cluster view\nview := client.GetClusterView()\nif view != nil {\n    fmt.Printf(\"Cluster epoch: %d\\n\", view.Epoch)\n    fmt.Printf(\"Nodes: %d\\n\", len(view.Nodes))\n}\n\n// Subscribe to topology changes\nunsubscribe := client.OnTopologyChange(func(event *norikv.TopologyChangeEvent) {\n    fmt.Printf(\"Topology changed!\\n\")\n    fmt.Printf(\"Previous epoch: %d\\n\", event.PreviousEpoch)\n    fmt.Printf(\"Current epoch: %d\\n\", event.CurrentEpoch)\n    fmt.Printf(\"Added nodes: %v\\n\", event.AddedNodes)\n    fmt.Printf(\"Removed nodes: %v\\n\", event.RemovedNodes)\n})\n\n// Later: unsubscribe\ndefer unsubscribe()\n</code></pre>"},{"location":"sdks/go/API_GUIDE/#client-statistics","title":"Client Statistics","text":"<p>Monitor client performance:</p> <pre><code>stats := client.Stats()\n\nfmt.Printf(\"Active connections: %d\\n\", stats.Pool.ActiveConnections)\nfmt.Printf(\"Total nodes: %d\\n\", stats.Router.TotalNodes)\nfmt.Printf(\"Cached leaders: %d\\n\", stats.Topology.CachedLeaders)\n</code></pre>"},{"location":"sdks/go/API_GUIDE/#error-handling","title":"Error Handling","text":""},{"location":"sdks/go/API_GUIDE/#error-types","title":"Error Types","text":"<pre><code>var (\n    ErrKeyNotFound      error // Key does not exist\n    ErrVersionMismatch  error // CAS version conflict\n    ErrAlreadyExists    error // IfNotExists conflict\n    ErrConnection       error // Network or cluster issues\n)\n</code></pre>"},{"location":"sdks/go/API_GUIDE/#handling-specific-errors","title":"Handling Specific Errors","text":"<pre><code>result, err := client.Get(ctx, key, nil)\nif err != nil {\n    switch {\n    case errors.Is(err, norikv.ErrKeyNotFound):\n        fmt.Println(\"Key not found\")\n    case errors.Is(err, norikv.ErrConnection):\n        fmt.Println(\"Connection error:\", err)\n    default:\n        fmt.Println(\"Error:\", err)\n    }\n}\n</code></pre>"},{"location":"sdks/go/API_GUIDE/#retry-pattern","title":"Retry Pattern","text":"<pre><code>maxAttempts := 3\nfor attempt := 1; attempt &lt;= maxAttempts; attempt++ {\n    _, err := client.Put(ctx, key, value, nil)\n    if err == nil {\n        break // Success\n    }\n\n    if !errors.Is(err, norikv.ErrConnection) {\n        return err // Non-retryable\n    }\n\n    if attempt == maxAttempts {\n        return err // Give up\n    }\n\n    // Exponential backoff\n    time.Sleep(time.Duration(1&lt;&lt;attempt) * 100 * time.Millisecond)\n}\n</code></pre>"},{"location":"sdks/go/API_GUIDE/#graceful-degradation","title":"Graceful Degradation","text":"<pre><code>func getWithFallback(client *norikv.Client, ctx context.Context, key, defaultValue []byte) []byte {\n    result, err := client.Get(ctx, key, nil)\n    if err != nil {\n        log.Printf(\"Failed to get key, using default: %v\", err)\n        return defaultValue\n    }\n    return result.Value\n}\n</code></pre>"},{"location":"sdks/go/API_GUIDE/#best-practices","title":"Best Practices","text":""},{"location":"sdks/go/API_GUIDE/#1-use-context-for-timeouts","title":"1. Use Context for Timeouts","text":"<p>Always pass context with timeout:</p> <pre><code>ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\ndefer cancel()\n\nresult, err := client.Get(ctx, key, nil)\n</code></pre>"},{"location":"sdks/go/API_GUIDE/#2-reuse-client-instances","title":"2. Reuse Client Instances","text":"<p>Clients manage connection pools and should be reused:</p> <pre><code>//  Good: Single client instance\nvar client *norikv.Client\n\nfunc init() {\n    config := norikv.DefaultClientConfig([]string{\"localhost:9001\"})\n    client, _ = norikv.NewClient(context.Background(), config)\n}\n\n//  Bad: Creating client per request\nfunc handleRequest() {\n    client, _ := norikv.NewClient(context.Background(), config)\n    defer client.Close() // Closes connections!\n}\n</code></pre>"},{"location":"sdks/go/API_GUIDE/#3-use-defer-for-cleanup","title":"3. Use defer for Cleanup","text":"<pre><code>client, err := norikv.NewClient(ctx, config)\nif err != nil {\n    return err\n}\ndefer client.Close()\n</code></pre>"},{"location":"sdks/go/API_GUIDE/#4-use-idempotency-keys","title":"4. Use Idempotency Keys","text":"<p>For operations that must not be duplicated:</p> <pre><code>idempotencyKey := \"order-\" + orderID\n\noptions := &amp;norikv.PutOptions{\n    IdempotencyKey: idempotencyKey,\n}\n\nclient.Put(ctx, key, value, options)\n</code></pre>"},{"location":"sdks/go/API_GUIDE/#5-choose-appropriate-consistency","title":"5. Choose Appropriate Consistency","text":"<ul> <li>Use <code>ConsistencyLease</code> (default) for most operations</li> <li>Use <code>ConsistencyLinearizable</code> for critical reads</li> <li>Use <code>ConsistencyStaleOK</code> for caching/read-heavy workloads</li> </ul>"},{"location":"sdks/go/API_GUIDE/#6-handle-version-conflicts","title":"6. Handle Version Conflicts","text":"<p>Implement retry logic for CAS operations:</p> <pre><code>maxRetries := 10\nfor i := 0; i &lt; maxRetries; i++ {\n    result, err := client.Get(ctx, key, nil)\n    if err != nil {\n        return err\n    }\n\n    // ... compute new value ...\n\n    options := &amp;norikv.PutOptions{\n        IfMatchVersion: result.Version,\n    }\n\n    _, err = client.Put(ctx, key, newValue, options)\n    if err == nil {\n        break // Success\n    }\n\n    if !errors.Is(err, norikv.ErrVersionMismatch) {\n        return err\n    }\n\n    if i == maxRetries-1 {\n        return err\n    }\n\n    time.Sleep(10 * time.Millisecond) // Small backoff\n}\n</code></pre>"},{"location":"sdks/go/API_GUIDE/#7-use-goroutines-safely","title":"7. Use Goroutines Safely","text":"<p>Client is goroutine-safe:</p> <pre><code>var wg sync.WaitGroup\n\nfor i := 0; i &lt; 100; i++ {\n    wg.Add(1)\n    go func(i int) {\n        defer wg.Done()\n        key := []byte(fmt.Sprintf(\"key-%d\", i))\n        client.Put(ctx, key, value, nil)\n    }(i)\n}\n\nwg.Wait()\n</code></pre>"},{"location":"sdks/go/API_GUIDE/#8-monitor-client-health","title":"8. Monitor Client Health","text":"<pre><code>// Periodically check stats\nstats := client.Stats()\nif stats.Pool.ActiveConnections == 0 {\n    log.Error(\"No active connections!\")\n}\n</code></pre>"},{"location":"sdks/go/API_GUIDE/#performance-tips","title":"Performance Tips","text":""},{"location":"sdks/go/API_GUIDE/#1-concurrent-access","title":"1. Concurrent Access","text":"<p>Client is optimized for concurrent use:</p> <pre><code>numWorkers := runtime.NumCPU()\nwork := make(chan []byte, 100)\n\nfor i := 0; i &lt; numWorkers; i++ {\n    go func() {\n        for key := range work {\n            client.Put(ctx, key, value, nil)\n        }\n    }()\n}\n</code></pre>"},{"location":"sdks/go/API_GUIDE/#2-zero-allocation-routing","title":"2. Zero-Allocation Routing","text":"<p>The client uses optimized routing with zero heap allocations in the hot path.</p>"},{"location":"sdks/go/API_GUIDE/#3-connection-pooling","title":"3. Connection Pooling","text":"<p>The client maintains a connection pool internally - no external pooling needed.</p>"},{"location":"sdks/go/API_GUIDE/#4-single-flight-pattern","title":"4. Single-Flight Pattern","text":"<p>Concurrent requests for the same shard's leader are deduplicated automatically.</p>"},{"location":"sdks/go/API_GUIDE/#5-use-appropriate-value-sizes","title":"5. Use Appropriate Value Sizes","text":"<ul> <li>Optimal: 100 bytes - 10 KB</li> <li>Maximum: Limited by memory and network</li> </ul>"},{"location":"sdks/go/API_GUIDE/#complete-example","title":"Complete Example","text":"<pre><code>package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n    \"time\"\n\n    norikv \"github.com/norikv/norikv-go\"\n)\n\nfunc main() {\n    ctx := context.Background()\n\n    // Configure with retry policy\n    retryConfig := &amp;norikv.RetryConfig{\n        MaxAttempts:  5,\n        InitialDelay: 100 * time.Millisecond,\n        MaxDelay:     2 * time.Second,\n    }\n\n    config := &amp;norikv.ClientConfig{\n        Nodes:       []string{\"localhost:9001\", \"localhost:9002\"},\n        TotalShards: 1024,\n        Timeout:     5 * time.Second,\n        Retry:       retryConfig,\n    }\n\n    client, err := norikv.NewClient(ctx, config)\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer client.Close()\n\n    // Write with TTL and idempotency\n    key := []byte(\"session:abc123\")\n    value := []byte(`{\"user_id\":42}`)\n    ttl := uint64(3600000) // 1 hour\n\n    putOpts := &amp;norikv.PutOptions{\n        TTLMs:          &amp;ttl,\n        IdempotencyKey: \"session-create-abc123\",\n    }\n\n    version, err := client.Put(ctx, key, value, putOpts)\n    if err != nil {\n        log.Fatal(err)\n    }\n    fmt.Printf(\"Written: %v\\n\", version)\n\n    // Read with linearizable consistency\n    getOpts := &amp;norikv.GetOptions{\n        Consistency: norikv.ConsistencyLinearizable,\n    }\n\n    result, err := client.Get(ctx, key, getOpts)\n    if err != nil {\n        log.Fatal(err)\n    }\n    fmt.Printf(\"Read: %s\\n\", result.Value)\n\n    // Update with CAS\n    newValue := []byte(`{\"user_id\":42,\"active\":true}`)\n    casOpts := &amp;norikv.PutOptions{\n        IfMatchVersion: result.Version,\n    }\n\n    _, err = client.Put(ctx, key, newValue, casOpts)\n    if err != nil {\n        if errors.Is(err, norikv.ErrVersionMismatch) {\n            fmt.Println(\"CAS failed - retry needed\")\n        } else {\n            log.Fatal(err)\n        }\n    }\n\n    // Monitor topology\n    client.OnTopologyChange(func(event *norikv.TopologyChangeEvent) {\n        fmt.Printf(\"Cluster changed: epoch %d\\n\", event.CurrentEpoch)\n    })\n\n    // Get statistics\n    stats := client.Stats()\n    fmt.Printf(\"Stats: %+v\\n\", stats)\n}\n</code></pre>"},{"location":"sdks/go/API_GUIDE/#next-steps","title":"Next Steps","text":"<ul> <li>Architecture Guide - Understanding client internals</li> <li>Troubleshooting Guide - Solving common issues</li> <li>Advanced Patterns - Complex use cases</li> <li>Examples - Working code samples</li> </ul>"},{"location":"sdks/go/ARCHITECTURE/","title":"NoriKV Go Client Architecture","text":"<p>Understanding the internal design and components of the Go client SDK.</p>"},{"location":"sdks/go/ARCHITECTURE/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>Component Architecture</li> <li>Request Flow</li> <li>Concurrency Model</li> <li>Connection Management</li> <li>Routing &amp; Sharding</li> <li>Retry Logic</li> <li>Error Handling</li> </ul>"},{"location":"sdks/go/ARCHITECTURE/#overview","title":"Overview","text":"<p>The NoriKV Go client is designed as a smart client that: - Routes requests directly to the appropriate shard leader - Maintains connection pools for efficient communication - Implements retry logic with exponential backoff - Tracks cluster topology changes - Provides goroutine-safe operations - Optimizes hot paths with zero-allocation routing</p>"},{"location":"sdks/go/ARCHITECTURE/#design-principles","title":"Design Principles","text":"<ol> <li>Zero-hop routing: Client routes directly to shard leader (no proxy)</li> <li>Goroutine-safe: Single client instance shared across goroutines</li> <li>Zero-allocation hot path: No heap allocations in routing</li> <li>Single-flight pattern: Deduplicate concurrent leader discovery</li> <li>Observable: Expose metrics and statistics</li> </ol>"},{"location":"sdks/go/ARCHITECTURE/#component-architecture","title":"Component Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      Client                              \u2502\n\u2502  (Main API: Put, Get, Delete, topology, stats)          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502          \u2502          \u2502          \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Router   \u2502 \u2502 Retry \u2502 \u2502  ConnPool\u2502 \u2502 Topology  \u2502\n\u2502            \u2502 \u2502Policy \u2502 \u2502          \u2502 \u2502 Manager   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502                         \u2502              \u2502\n     \u2502                         \u2502              \u2502\n     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500hash()\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524              \u2502\n                               \u2502              \u2502\n     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500getConn()\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524              \u2502\n     \u2502                         \u2502              \u2502\n     \u2502                    \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510         \u2502\n     \u2502                    \u2502  gRPC   \u2502         \u2502\n     \u2502                    \u2502  Conns  \u2502         \u2502\n     \u2502                    \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518         \u2502\n     \u2502                         \u2502              \u2502\n     \u2502                         \u2502              \u2502\n     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500updateView()\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"sdks/go/ARCHITECTURE/#components","title":"Components","text":""},{"location":"sdks/go/ARCHITECTURE/#1-client","title":"1. Client","text":"<p>Responsibility: Main public API and component coordination</p> <p>Key Methods: - <code>Put()</code>, <code>Get()</code>, <code>Delete()</code> - Core operations - <code>GetClusterView()</code> - Topology information - <code>OnTopologyChange()</code> - Subscribe to topology updates - <code>Stats()</code> - Client statistics - <code>Close()</code> - Resource cleanup</p> <p>Location: <code>client.go</code></p>"},{"location":"sdks/go/ARCHITECTURE/#2-router","title":"2. Router","text":"<p>Responsibility: Determine which node to send requests to</p> <p>Key Functions: - Hash key to shard: <code>xxhash64(key) \u2192 jumpConsistentHash(hash, totalShards) \u2192 shardId</code> - Map shard to leader node - Cache leader information - Single-flight pattern for leader discovery - Handle leader hints from <code>NOT_LEADER</code> errors</p> <p>Location: <code>internal/router/router.go</code></p> <p>Algorithm: <pre><code>1. Hash key using XXHash64 (seed=0)\n2. Map hash to shard using Jump Consistent Hash\n3. Look up shard leader in topology cache\n4. If unknown, use single-flight to discover leader\n5. Return leader's address\n</code></pre></p>"},{"location":"sdks/go/ARCHITECTURE/#3-connectionpool","title":"3. ConnectionPool","text":"<p>Responsibility: Manage gRPC connections to cluster nodes</p> <p>Key Functions: - Create and cache gRPC connections per node - Goroutine-safe concurrent access - Health checking - Graceful shutdown</p> <p>Location: <code>internal/conn/pool.go</code></p> <p>Design: - One <code>*grpc.ClientConn</code> per node address - Lazy initialization (created on first use) - Connections reused across requests - Automatic cleanup on client close</p>"},{"location":"sdks/go/ARCHITECTURE/#4-retrypolicy","title":"4. RetryPolicy","text":"<p>Responsibility: Handle transient failures with backoff</p> <p>Key Functions: - Exponential backoff: <code>delay = min(initialDelay * 2^attempt, maxDelay)</code> - Jitter: Add randomness to avoid thundering herd - Selective retry: Only retry transient errors - Attempt tracking</p> <p>Location: <code>internal/retry/policy.go</code></p> <p>Retryable Errors: - <code>Unavailable</code> - Server temporarily unavailable - <code>Aborted</code> - Operation aborted, safe to retry - <code>DeadlineExceeded</code> - Timeout, may succeed on retry - <code>ResourceExhausted</code> - Rate limited, backoff helps</p> <p>Non-Retryable Errors: - <code>InvalidArgument</code> - Client error, won't succeed - <code>NotFound</code> - Key doesn't exist - <code>FailedPrecondition</code> - CAS conflict, application must retry - <code>PermissionDenied</code> - Auth error</p>"},{"location":"sdks/go/ARCHITECTURE/#5-topologymanager","title":"5. TopologyManager","text":"<p>Responsibility: Track cluster membership and shard assignments</p> <p>Key Functions: - Store current <code>ClusterView</code> - Cache shard \u2192 leader mappings - Detect topology changes - Notify listeners of changes - Update leader hints</p> <p>Location: <code>internal/topology/manager.go</code></p> <p>Data Structures: - <code>ClusterView</code>: Current cluster state (epoch, nodes, shards) - <code>shardLeaderCache</code>: sync.Map for shard \u2192 leader address - <code>listeners</code>: slice of change callbacks (protected by RWMutex)</p>"},{"location":"sdks/go/ARCHITECTURE/#request-flow","title":"Request Flow","text":""},{"location":"sdks/go/ARCHITECTURE/#put-request-flow","title":"PUT Request Flow","text":"<pre><code>Client.Put(ctx, key, value, options)\n    \u2502\n    \u251c\u2500&gt; 1. Validate inputs (key, value not nil/empty)\n    \u2502\n    \u251c\u2500&gt; 2. Router.GetNodeForKey(key)\n    \u2502       \u251c\u2500&gt; hash = xxhash64(key)\n    \u2502       \u251c\u2500&gt; shardId = jumpConsistentHash(hash, totalShards)\n    \u2502       \u2514\u2500&gt; leaderAddr = topologyManager.GetShardLeader(shardId)\n    \u2502\n    \u251c\u2500&gt; 3. ConnectionPool.GetConn(leaderAddr)\n    \u2502       \u2514\u2500&gt; Return cached or create new gRPC connection\n    \u2502\n    \u251c\u2500&gt; 4. RetryPolicy.Do(func() error {\n    \u2502       \u251c\u2500&gt; Build gRPC PutRequest\n    \u2502       \u251c\u2500&gt; proto.NewKvClient(conn).Put(ctx, request)\n    \u2502       \u2514\u2500&gt; Convert response to Version\n    \u2502   })\n    \u2502       \u251c\u2500&gt; On SUCCESS: return Version\n    \u2502       \u251c\u2500&gt; On RETRYABLE_ERROR: backoff and retry\n    \u2502       \u2514\u2500&gt; On NON_RETRYABLE: return error\n    \u2502\n    \u2514\u2500&gt; 5. Return Version to caller\n</code></pre>"},{"location":"sdks/go/ARCHITECTURE/#get-request-flow","title":"GET Request Flow","text":"<p>Similar to PUT, but: - Uses <code>GetRequest</code> with consistency level - Returns <code>GetResult</code> (value + version) - Returns <code>ErrKeyNotFound</code> on NOT_FOUND</p>"},{"location":"sdks/go/ARCHITECTURE/#error-handling-in-flow","title":"Error Handling in Flow","text":"<pre><code>gRPC Status Error\n    \u2502\n    \u251c\u2500&gt; convertGrpcError()\n    \u2502   \u251c\u2500&gt; NotFound \u2192 ErrKeyNotFound\n    \u2502   \u251c\u2500&gt; FailedPrecondition + \"version\" \u2192 ErrVersionMismatch\n    \u2502   \u251c\u2500&gt; Unavailable \u2192 ErrConnection\n    \u2502   \u2514\u2500&gt; OTHER \u2192 wrapped error\n    \u2502\n    \u2514\u2500&gt; RetryPolicy decides:\n        \u251c\u2500&gt; Retryable \u2192 backoff and retry\n        \u2514\u2500&gt; Non-retryable \u2192 return to caller\n</code></pre>"},{"location":"sdks/go/ARCHITECTURE/#concurrency-model","title":"Concurrency Model","text":""},{"location":"sdks/go/ARCHITECTURE/#goroutine-safety-guarantees","title":"Goroutine Safety Guarantees","text":"<p>All client components are goroutine-safe:</p> <ol> <li>Client: Goroutine-safe, shareable across goroutines</li> <li>Router: Uses sync.Map for leader cache, immutable routing tables</li> <li>ConnectionPool: sync.Mutex for connection creation</li> <li>TopologyManager: sync.RWMutex for view updates, sync.Map for caches</li> <li>RetryPolicy: Stateless, safe for concurrent use</li> </ol>"},{"location":"sdks/go/ARCHITECTURE/#concurrency-design","title":"Concurrency Design","text":"<pre><code>//  Safe: Single client, multiple goroutines\nclient, _ := norikv.NewClient(ctx, config)\n\nvar wg sync.WaitGroup\nfor i := 0; i &lt; 100; i++ {\n    wg.Add(1)\n    go func() {\n        defer wg.Done()\n        client.Put(ctx, key, value, nil) // Goroutine-safe\n    }()\n}\nwg.Wait()\n</code></pre>"},{"location":"sdks/go/ARCHITECTURE/#synchronization-points","title":"Synchronization Points","text":"<ol> <li>TopologyManager.UpdateView(): Write lock during view update</li> <li>ConnectionPool.GetConn(): Mutex for connection creation</li> <li>Router leader cache: sync.Map for lock-free reads</li> </ol>"},{"location":"sdks/go/ARCHITECTURE/#single-flight-pattern","title":"Single-Flight Pattern","text":"<p>Concurrent requests for the same shard's leader are deduplicated:</p> <pre><code>// Multiple goroutines requesting same shard\n// Only one goroutine makes the actual RPC\n// Others wait for the result\nresult := router.getLeaderForShard(shardID)\n</code></pre>"},{"location":"sdks/go/ARCHITECTURE/#connection-management","title":"Connection Management","text":""},{"location":"sdks/go/ARCHITECTURE/#connection-lifecycle","title":"Connection Lifecycle","text":"<pre><code>Node Address\n    \u2502\n    \u251c\u2500&gt; First request \u2192 Create gRPC ClientConn\n    \u2502   \u251c\u2500&gt; Configure: insecure, keepalive, timeout\n    \u2502   \u2514\u2500&gt; Store in pool\n    \u2502\n    \u251c\u2500&gt; Subsequent requests \u2192 Reuse connection\n    \u2502\n    \u2514\u2500&gt; Client.Close() \u2192 Close all connections\n        \u2514\u2500&gt; Graceful shutdown with context timeout\n</code></pre>"},{"location":"sdks/go/ARCHITECTURE/#connection-configuration","title":"Connection Configuration","text":"<pre><code>conn, err := grpc.Dial(\n    address,\n    grpc.WithTransportCredentials(insecure.NewCredentials()),\n    grpc.WithKeepaliveParams(keepalive.ClientParameters{\n        Time:                10 * time.Second,\n        Timeout:             3 * time.Second,\n        PermitWithoutStream: true,\n    }),\n)\n</code></pre>"},{"location":"sdks/go/ARCHITECTURE/#health-checks","title":"Health Checks","text":"<ul> <li>Connections automatically reconnect on failure</li> <li>gRPC handles connection health internally</li> <li>Failed requests trigger retries (via RetryPolicy)</li> </ul>"},{"location":"sdks/go/ARCHITECTURE/#routing-sharding","title":"Routing &amp; Sharding","text":""},{"location":"sdks/go/ARCHITECTURE/#hash-function-xxhash64","title":"Hash Function: XXHash64","text":"<pre><code>hash := xxhash.Sum64(key)\n</code></pre> <p>Properties: - Fast: ~2.5ns per operation - Consistent: Same key \u2192 same hash - Zero allocations - Cross-SDK compatible</p>"},{"location":"sdks/go/ARCHITECTURE/#consistent-hashing-jump-consistent-hash","title":"Consistent Hashing: Jump Consistent Hash","text":"<pre><code>shardID := jumpConsistentHash(hash, totalShards)\n</code></pre> <p>Properties: - Minimal key movement on shard count changes - O(log n) time complexity - Uniform distribution - Zero allocations</p>"},{"location":"sdks/go/ARCHITECTURE/#shard-leader-mapping","title":"Shard \u2192 Leader Mapping","text":"<pre><code>shardID \u2192 TopologyManager.GetShardLeader(shardID) \u2192 leaderAddr\n</code></pre> <p>Leader Cache: - Populated from ClusterView - Updated on topology changes - Updated from NOT_LEADER error hints - Uses sync.Map for lock-free reads</p>"},{"location":"sdks/go/ARCHITECTURE/#not_leader-handling","title":"NOT_LEADER Handling","text":"<pre><code>1. Request sent to node A for shard X\n2. Node A returns NOT_LEADER error with hint: \"leader is node B\"\n3. Client updates leader cache: shard X \u2192 node B\n4. Retry policy re-sends request to node B\n</code></pre>"},{"location":"sdks/go/ARCHITECTURE/#retry-logic","title":"Retry Logic","text":""},{"location":"sdks/go/ARCHITECTURE/#exponential-backoff","title":"Exponential Backoff","text":"<pre><code>delay = min(initialDelay * 2^attempt, maxDelay) + jitter\n</code></pre> <p>Example (initialDelay=100ms, maxDelay=5s, jitter=100ms): <pre><code>Attempt 1: delay = 100ms  + random(0-100ms)\nAttempt 2: delay = 200ms  + random(0-100ms)\nAttempt 3: delay = 400ms  + random(0-100ms)\nAttempt 4: delay = 800ms  + random(0-100ms)\nAttempt 5: delay = 1600ms + random(0-100ms)\nAttempt 6: delay = 3200ms + random(0-100ms)\nAttempt 7: delay = 5000ms + random(0-100ms) (capped)\n</code></pre></p>"},{"location":"sdks/go/ARCHITECTURE/#jitter-benefits","title":"Jitter Benefits","text":"<ul> <li>Avoids thundering herd (all clients retry at same time)</li> <li>Spreads load during recovery</li> <li>Reduces collision probability</li> </ul>"},{"location":"sdks/go/ARCHITECTURE/#retry-decision-tree","title":"Retry Decision Tree","text":"<pre><code>Error Received\n    \u2502\n    \u251c\u2500&gt; Is retryable? (Unavailable, Aborted, etc.)\n    \u2502   \u2502\n    \u2502   \u251c\u2500&gt; YES: attempt &lt; maxAttempts?\n    \u2502   \u2502   \u251c\u2500&gt; YES: backoff and retry\n    \u2502   \u2502   \u2514\u2500&gt; NO: return RETRY_EXHAUSTED\n    \u2502   \u2502\n    \u2502   \u2514\u2500&gt; NO: return original error\n    \u2502\n    \u2514\u2500&gt; Success: return result\n</code></pre>"},{"location":"sdks/go/ARCHITECTURE/#error-handling","title":"Error Handling","text":""},{"location":"sdks/go/ARCHITECTURE/#error-types","title":"Error Types","text":"<pre><code>var (\n    ErrKeyNotFound      = errors.New(\"key not found\")\n    ErrVersionMismatch  = errors.New(\"version mismatch\")\n    ErrAlreadyExists    = errors.New(\"key already exists\")\n    ErrConnection       = errors.New(\"connection error\")\n)\n</code></pre>"},{"location":"sdks/go/ARCHITECTURE/#error-code-mapping","title":"Error Code Mapping","text":"gRPC Status NoriKV Error Retry? NotFound ErrKeyNotFound No FailedPrecondition (version) ErrVersionMismatch No FailedPrecondition (other) wrapped error No AlreadyExists ErrAlreadyExists No Unavailable ErrConnection Yes DeadlineExceeded ErrConnection Yes Aborted wrapped error Yes ResourceExhausted wrapped error Yes InvalidArgument wrapped error No PermissionDenied wrapped error No"},{"location":"sdks/go/ARCHITECTURE/#error-context","title":"Error Context","text":"<p>Errors include: - Error message - Wrapped original error (via errors.Unwrap) - Context (key, version for VersionMismatch)</p>"},{"location":"sdks/go/ARCHITECTURE/#performance-considerations","title":"Performance Considerations","text":""},{"location":"sdks/go/ARCHITECTURE/#hot-paths","title":"Hot Paths","text":"<ol> <li>Hash calculation: Optimized XXHash64 (2.5ns)</li> <li>Connection lookup: O(1) map lookup</li> <li>Leader cache: Lock-free sync.Map reads</li> <li>Protobuf serialization: Minimal overhead</li> </ol>"},{"location":"sdks/go/ARCHITECTURE/#zero-allocation-routing","title":"Zero-Allocation Routing","text":"<pre><code>GetShardForKey: 23ns/op, 0 B/op, 0 allocs/op\n</code></pre> <p>The routing hot path allocates no heap memory.</p>"},{"location":"sdks/go/ARCHITECTURE/#memory-usage","title":"Memory Usage","text":"<ul> <li>Per client: ~1-10 MB (depends on number of nodes)</li> <li>Per connection: ~100 KB (gRPC overhead)</li> <li>Per request: Minimal (request/response objects garbage collected)</li> </ul>"},{"location":"sdks/go/ARCHITECTURE/#connection-pooling","title":"Connection Pooling","text":"<ul> <li>Connections reused across requests</li> <li>No connection per request overhead</li> <li>gRPC multiplexes requests over HTTP/2</li> </ul>"},{"location":"sdks/go/ARCHITECTURE/#single-flight-optimization","title":"Single-Flight Optimization","text":"<p>Concurrent requests for the same shard's leader are deduplicated: - First request makes the RPC - Subsequent requests wait for the result - Reduces load on cluster during leader discovery</p>"},{"location":"sdks/go/ARCHITECTURE/#observability","title":"Observability","text":""},{"location":"sdks/go/ARCHITECTURE/#client-statistics","title":"Client Statistics","text":"<pre><code>stats := client.Stats()\n\n// Router stats\nfmt.Printf(\"Total nodes: %d\\n\", stats.Router.TotalNodes)\nfmt.Printf(\"Total shards: %d\\n\", stats.Router.TotalShards)\n\n// Connection pool stats\nfmt.Printf(\"Active connections: %d\\n\", stats.Pool.ActiveConnections)\n\n// Topology stats\nfmt.Printf(\"Current epoch: %d\\n\", stats.Topology.CurrentEpoch)\nfmt.Printf(\"Cached leaders: %d\\n\", stats.Topology.CachedLeaders)\n</code></pre>"},{"location":"sdks/go/ARCHITECTURE/#topology-change-events","title":"Topology Change Events","text":"<pre><code>client.OnTopologyChange(func(event *TopologyChangeEvent) {\n    log.Printf(\"Topology changed to epoch %d\", event.CurrentEpoch)\n    log.Printf(\"Added nodes: %v\", event.AddedNodes)\n    log.Printf(\"Removed nodes: %v\", event.RemovedNodes)\n    log.Printf(\"Leader changes: %v\", event.LeaderChanges)\n})\n</code></pre>"},{"location":"sdks/go/ARCHITECTURE/#extensibility","title":"Extensibility","text":""},{"location":"sdks/go/ARCHITECTURE/#custom-retry-policies","title":"Custom Retry Policies","text":"<p>Implement custom backoff strategies:</p> <pre><code>customRetry := &amp;norikv.RetryConfig{\n    MaxAttempts:  20,\n    InitialDelay: 50 * time.Millisecond,\n    MaxDelay:     10 * time.Second,\n    Jitter:       200 * time.Millisecond,\n}\n</code></pre>"},{"location":"sdks/go/ARCHITECTURE/#future-extensions","title":"Future Extensions","text":"<p>Potential areas for extension: - Custom hash functions (requires cross-SDK coordination) - TLS/SSL support - Authentication integration - Metrics export (Prometheus, OTLP) - Circuit breaker patterns - Request tracing</p>"},{"location":"sdks/go/ARCHITECTURE/#comparison-with-other-sdks","title":"Comparison with Other SDKs","text":""},{"location":"sdks/go/ARCHITECTURE/#similarities","title":"Similarities","text":"<ul> <li>Same hash functions (XXHash64 + Jump Consistent Hash)</li> <li>Same routing algorithm</li> <li>Same proto definitions</li> <li>Same error handling patterns</li> </ul>"},{"location":"sdks/go/ARCHITECTURE/#go-specific-features","title":"Go-Specific Features","text":"<ul> <li>Zero-allocation routing hot path</li> <li>Single-flight pattern for leader discovery</li> <li>Goroutine-safe concurrent access</li> <li>Context-aware operations</li> <li>defer-based resource management</li> </ul>"},{"location":"sdks/go/ARCHITECTURE/#performance","title":"Performance","text":"<p>Go SDK performance is excellent: - Hash operations: 2.5ns per operation (fastest) - Zero allocations: In routing hot path - Native concurrency: Goroutines with minimal overhead - Efficient GC: Minimal garbage collection pressure</p>"},{"location":"sdks/go/ARCHITECTURE/#references","title":"References","text":"<ul> <li>API Guide - Public API documentation</li> <li>Troubleshooting Guide - Common issues</li> <li>Advanced Patterns - Complex use cases</li> <li>Source Code - Implementation</li> </ul>"},{"location":"sdks/go/TROUBLESHOOTING/","title":"NoriKV Go Client Troubleshooting Guide","text":"<p>Solutions to common issues when using the Go client SDK.</p>"},{"location":"sdks/go/TROUBLESHOOTING/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Connection Issues</li> <li>Performance Problems</li> <li>Version Conflicts</li> <li>Error Messages</li> <li>Configuration Issues</li> <li>Debugging Tips</li> </ul>"},{"location":"sdks/go/TROUBLESHOOTING/#connection-issues","title":"Connection Issues","text":""},{"location":"sdks/go/TROUBLESHOOTING/#problem-connection-refused-or-dial-tcp-connect-connection-refused","title":"Problem: \"connection refused\" or \"dial tcp: connect: connection refused\"","text":"<p>Symptoms: <pre><code>_, err := client.Put(ctx, key, value, nil)\n// Error: rpc error: code = Unavailable desc = connection error:\n// desc = \"transport: Error while dialing dial tcp 127.0.0.1:9001:\n// connect: connection refused\"\n</code></pre></p> <p>Causes: 1. NoriKV server is not running 2. Wrong address/port in configuration 3. Firewall blocking connections</p> <p>Solutions:</p> <ol> <li> <p>Verify server is running: <pre><code># Check if server is listening\nnetstat -an | grep 9001\n\n# Or use lsof\nlsof -i :9001\n</code></pre></p> </li> <li> <p>Check client configuration: <pre><code>config := &amp;norikv.ClientConfig{\n    Nodes: []string{\"localhost:9001\"}, // Verify this address\n    // ...\n}\n</code></pre></p> </li> <li> <p>Test connectivity: <pre><code>telnet localhost 9001\n# Or\nnc -zv localhost 9001\n</code></pre></p> </li> </ol>"},{"location":"sdks/go/TROUBLESHOOTING/#problem-context-deadline-exceeded","title":"Problem: \"context deadline exceeded\"","text":"<p>Symptoms: <pre><code>ctx, cancel := context.WithTimeout(context.Background(), 100*time.Millisecond)\ndefer cancel()\n\n_, err := client.Get(ctx, key, nil)\n// Error: rpc error: code = DeadlineExceeded desc = context deadline exceeded\n</code></pre></p> <p>Causes: 1. Timeout too short 2. Server overloaded 3. Network latency 4. Leader election in progress</p> <p>Solutions:</p> <ol> <li> <p>Increase timeout: <pre><code>config := &amp;norikv.ClientConfig{\n    Timeout: 10 * time.Second, // Increase from default 5s\n    // ...\n}\n\n// Or use longer context timeout\nctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\ndefer cancel()\n</code></pre></p> </li> <li> <p>Check server health: <pre><code># Check server logs for errors\n# Check CPU/memory usage\n# Verify cluster quorum\n</code></pre></p> </li> <li> <p>Enable retries: <pre><code>config := &amp;norikv.ClientConfig{\n    Retry: &amp;norikv.RetryConfig{\n        MaxAttempts:  10,\n        InitialDelay: 100 * time.Millisecond,\n        MaxDelay:     5 * time.Second,\n    },\n    // ...\n}\n</code></pre></p> </li> </ol>"},{"location":"sdks/go/TROUBLESHOOTING/#problem-transport-is-closing","title":"Problem: \"transport is closing\"","text":"<p>Symptoms: <pre><code>_, err := client.Put(ctx, key, value, nil)\n// Error: rpc error: code = Unavailable desc = transport is closing\n</code></pre></p> <p>Causes: 1. Server restarted 2. Network interruption 3. Connection idle timeout</p> <p>Solutions:</p> <ol> <li>Enable automatic retries (already default behavior)</li> <li> <p>Configure keepalive: <pre><code>// Connections automatically have keepalive configured\n// If you need custom settings, modify internal/conn/pool.go\n</code></pre></p> </li> <li> <p>Check network stability: <pre><code>ping &lt;server-host&gt;\ntraceroute &lt;server-host&gt;\n</code></pre></p> </li> </ol>"},{"location":"sdks/go/TROUBLESHOOTING/#performance-problems","title":"Performance Problems","text":""},{"location":"sdks/go/TROUBLESHOOTING/#problem-slow-putget-operations","title":"Problem: Slow Put/Get operations","text":"<p>Symptoms: <pre><code>start := time.Now()\n_, err := client.Put(ctx, key, value, nil)\nduration := time.Since(start)\n// duration &gt; 100ms consistently\n</code></pre></p> <p>Causes: 1. Network latency 2. Large value sizes 3. Server overload 4. Wrong consistency level 5. Too many retries</p> <p>Diagnosis:</p> <ol> <li> <p>Measure network latency: <pre><code>ping &lt;server-host&gt;\n</code></pre></p> </li> <li> <p>Check value sizes: <pre><code>fmt.Printf(\"Value size: %d bytes\\n\", len(value))\n// Optimal: 100 bytes - 10 KB\n// Too large: &gt; 1 MB\n</code></pre></p> </li> <li> <p>Monitor retry count: <pre><code>// Check logs for retry attempts\n// Excessive retries indicate server issues\n</code></pre></p> </li> </ol> <p>Solutions:</p> <ol> <li> <p>Use appropriate consistency level: <pre><code>// For reads that don't need strict consistency\noptions := &amp;norikv.GetOptions{\n    Consistency: norikv.ConsistencyStaleOK, // Fastest\n}\nresult, err := client.Get(ctx, key, options)\n</code></pre></p> </li> <li> <p>Reduce value sizes: <pre><code>// Compress large values\ncompressed := compress(largeValue)\nclient.Put(ctx, key, compressed, nil)\n</code></pre></p> </li> <li> <p>Use concurrent requests: <pre><code>var wg sync.WaitGroup\nfor _, key := range keys {\n    wg.Add(1)\n    go func(k []byte) {\n        defer wg.Done()\n        client.Get(ctx, k, nil)\n    }(key)\n}\nwg.Wait()\n</code></pre></p> </li> </ol>"},{"location":"sdks/go/TROUBLESHOOTING/#problem-high-memory-usage","title":"Problem: High memory usage","text":"<p>Symptoms: <pre><code>// Client consuming excessive memory\n// Memory not being released\n</code></pre></p> <p>Causes: 1. Too many goroutines 2. Large values buffered 3. Connection leaks 4. Topology listeners not cleaned up</p> <p>Solutions:</p> <ol> <li> <p>Limit concurrent operations: <pre><code>semaphore := make(chan struct{}, 100) // Limit to 100 concurrent\nfor _, key := range keys {\n    semaphore &lt;- struct{}{}\n    go func(k []byte) {\n        defer func() { &lt;-semaphore }()\n        client.Get(ctx, k, nil)\n    }(key)\n}\n</code></pre></p> </li> <li> <p>Clean up topology listeners: <pre><code>unsubscribe := client.OnTopologyChange(handler)\ndefer unsubscribe() // Important!\n</code></pre></p> </li> <li> <p>Close client when done: <pre><code>defer client.Close()\n</code></pre></p> </li> <li> <p>Use pprof to diagnose: <pre><code>import _ \"net/http/pprof\"\nimport \"net/http\"\n\ngo func() {\n    log.Println(http.ListenAndServe(\"localhost:6060\", nil))\n}()\n\n// Visit http://localhost:6060/debug/pprof/\n</code></pre></p> </li> </ol>"},{"location":"sdks/go/TROUBLESHOOTING/#version-conflicts","title":"Version Conflicts","text":""},{"location":"sdks/go/TROUBLESHOOTING/#problem-version-mismatch-on-cas-operations","title":"Problem: \"version mismatch\" on CAS operations","text":"<p>Symptoms: <pre><code>result, _ := client.Get(ctx, key, nil)\n\noptions := &amp;norikv.PutOptions{\n    IfMatchVersion: result.Version,\n}\n\n_, err := client.Put(ctx, key, newValue, options)\nif errors.Is(err, norikv.ErrVersionMismatch) {\n    // This happens frequently\n}\n</code></pre></p> <p>Causes: 1. High contention on key 2. Concurrent updates from multiple clients 3. Insufficient retry logic</p> <p>Solutions:</p> <ol> <li> <p>Implement retry loop: <pre><code>const maxRetries = 10\nfor i := 0; i &lt; maxRetries; i++ {\n    result, err := client.Get(ctx, key, nil)\n    if err != nil {\n        return err\n    }\n\n    // Compute new value\n    newValue := transform(result.Value)\n\n    options := &amp;norikv.PutOptions{\n        IfMatchVersion: result.Version,\n    }\n\n    _, err = client.Put(ctx, key, newValue, options)\n    if err == nil {\n        break // Success\n    }\n\n    if !errors.Is(err, norikv.ErrVersionMismatch) {\n        return err\n    }\n\n    if i == maxRetries-1 {\n        return fmt.Errorf(\"failed after %d retries\", maxRetries)\n    }\n\n    // Exponential backoff\n    time.Sleep(time.Duration(1&lt;&lt;i) * 10 * time.Millisecond)\n}\n</code></pre></p> </li> <li> <p>Reduce contention by sharding: <pre><code>// Instead of single counter\nkey := []byte(\"global-counter\")\n\n// Use sharded counters\nshardID := rand.Intn(10)\nkey := []byte(fmt.Sprintf(\"counter-%d\", shardID))\n</code></pre></p> </li> <li> <p>Use idempotency keys when appropriate: <pre><code>options := &amp;norikv.PutOptions{\n    IdempotencyKey: requestID,\n    // CAS still checked, but retry is safe\n}\n</code></pre></p> </li> </ol>"},{"location":"sdks/go/TROUBLESHOOTING/#problem-lost-updates-with-concurrent-writes","title":"Problem: Lost updates with concurrent writes","text":"<p>Symptoms: <pre><code>// Multiple goroutines updating same key\n// Final value doesn't reflect all updates\n</code></pre></p> <p>Cause: Not using CAS for concurrent updates.</p> <p>Solution:</p> <p>Always use CAS for concurrent updates: <pre><code>func incrementCounter(client *norikv.Client, ctx context.Context, key []byte) error {\n    for i := 0; i &lt; 10; i++ {\n        result, err := client.Get(ctx, key, nil)\n        if err != nil {\n            return err\n        }\n\n        value, _ := strconv.Atoi(string(result.Value))\n        newValue := []byte(strconv.Itoa(value + 1))\n\n        options := &amp;norikv.PutOptions{\n            IfMatchVersion: result.Version,\n        }\n\n        _, err = client.Put(ctx, key, newValue, options)\n        if err == nil {\n            return nil\n        }\n\n        if !errors.Is(err, norikv.ErrVersionMismatch) {\n            return err\n        }\n    }\n    return fmt.Errorf(\"failed after retries\")\n}\n</code></pre></p>"},{"location":"sdks/go/TROUBLESHOOTING/#error-messages","title":"Error Messages","text":""},{"location":"sdks/go/TROUBLESHOOTING/#key-not-found","title":"\"key not found\"","text":"<p>Error: <pre><code>_, err := client.Get(ctx, key, nil)\nif errors.Is(err, norikv.ErrKeyNotFound) {\n    // Handle\n}\n</code></pre></p> <p>Meaning: Key does not exist in the database.</p> <p>Solutions: 1. Check if key was written 2. Check for typos in key name 3. Handle gracefully: <pre><code>result, err := client.Get(ctx, key, nil)\nif errors.Is(err, norikv.ErrKeyNotFound) {\n    // Use default value\n    return defaultValue\n}\n</code></pre></p>"},{"location":"sdks/go/TROUBLESHOOTING/#version-mismatch","title":"\"version mismatch\"","text":"<p>Error: <pre><code>_, err := client.Put(ctx, key, value, &amp;norikv.PutOptions{\n    IfMatchVersion: expectedVersion,\n})\nif errors.Is(err, norikv.ErrVersionMismatch) {\n    // Handle\n}\n</code></pre></p> <p>Meaning: CAS check failed - version changed between read and write.</p> <p>Solutions: See Version Conflicts above.</p>"},{"location":"sdks/go/TROUBLESHOOTING/#key-already-exists","title":"\"key already exists\"","text":"<p>Error: <pre><code>_, err := client.Put(ctx, key, value, &amp;norikv.PutOptions{\n    IfNotExists: true,\n})\nif errors.Is(err, norikv.ErrAlreadyExists) {\n    // Handle\n}\n</code></pre></p> <p>Meaning: Key already exists (used with IfNotExists).</p> <p>Solutions: <pre><code>if errors.Is(err, norikv.ErrAlreadyExists) {\n    // Get existing value\n    result, _ := client.Get(ctx, key, nil)\n    // Or ignore if duplicate is okay\n}\n</code></pre></p>"},{"location":"sdks/go/TROUBLESHOOTING/#configuration-issues","title":"Configuration Issues","text":""},{"location":"sdks/go/TROUBLESHOOTING/#problem-invalid-shard-count","title":"Problem: \"invalid shard count\"","text":"<p>Symptoms: <pre><code>client, err := norikv.NewClient(ctx, config)\n// Error: invalid shard count\n</code></pre></p> <p>Cause: TotalShards must match cluster configuration.</p> <p>Solution: <pre><code>config := &amp;norikv.ClientConfig{\n    TotalShards: 1024, // Must match server\n    // ...\n}\n</code></pre></p>"},{"location":"sdks/go/TROUBLESHOOTING/#problem-hash-mismatches-causing-wrong-routing","title":"Problem: Hash mismatches causing wrong routing","text":"<p>Symptoms: - Requests going to wrong shards - Frequent NOT_LEADER errors</p> <p>Cause: Hash function incompatibility.</p> <p>Solution:</p> <p>Verify hash compatibility: <pre><code>go test -v ./hash/...\n</code></pre></p> <p>All tests must pass to ensure compatibility with server.</p>"},{"location":"sdks/go/TROUBLESHOOTING/#problem-client-not-finding-any-nodes","title":"Problem: Client not finding any nodes","text":"<p>Symptoms: <pre><code>client, err := norikv.NewClient(ctx, config)\n// Error: no nodes available\n</code></pre></p> <p>Cause: Empty or invalid Nodes configuration.</p> <p>Solution: <pre><code>config := &amp;norikv.ClientConfig{\n    Nodes: []string{\n        \"node1:9001\",\n        \"node2:9001\",\n        \"node3:9001\",\n    },\n    // ...\n}\n</code></pre></p>"},{"location":"sdks/go/TROUBLESHOOTING/#debugging-tips","title":"Debugging Tips","text":""},{"location":"sdks/go/TROUBLESHOOTING/#enable-debug-logging","title":"Enable Debug Logging","text":"<pre><code>// Add logging to track requests\nimport \"log\"\n\ntype loggingClient struct {\n    *norikv.Client\n}\n\nfunc (c *loggingClient) Put(ctx context.Context, key, value []byte, opts *norikv.PutOptions) (*norikv.Version, error) {\n    log.Printf(\"PUT key=%s, size=%d\", key, len(value))\n    version, err := c.Client.Put(ctx, key, value, opts)\n    if err != nil {\n        log.Printf(\"PUT error: %v\", err)\n    } else {\n        log.Printf(\"PUT success: version=%v\", version)\n    }\n    return version, err\n}\n</code></pre>"},{"location":"sdks/go/TROUBLESHOOTING/#monitor-client-statistics","title":"Monitor Client Statistics","text":"<pre><code>// Periodically log stats\ngo func() {\n    ticker := time.NewTicker(10 * time.Second)\n    defer ticker.Stop()\n\n    for range ticker.C {\n        stats := client.Stats()\n        log.Printf(\"Client stats: %+v\", stats)\n    }\n}()\n</code></pre>"},{"location":"sdks/go/TROUBLESHOOTING/#test-with-ephemeral-server","title":"Test with Ephemeral Server","text":"<pre><code>import \"github.com/norikv/norikv-go/testing/ephemeral\"\n\n// Start in-memory server for testing\nserver := ephemeral.NewServer()\nerr := server.Start(\"127.0.0.1:0\")\nif err != nil {\n    log.Fatal(err)\n}\ndefer server.Stop()\n\n// Get actual address\naddress := server.Address()\n\n// Create client\nconfig := &amp;norikv.ClientConfig{\n    Nodes:       []string{address},\n    TotalShards: 1024,\n}\nclient, err := norikv.NewClient(ctx, config)\n</code></pre>"},{"location":"sdks/go/TROUBLESHOOTING/#use-pprof-for-performance-analysis","title":"Use pprof for Performance Analysis","text":"<pre><code>import (\n    _ \"net/http/pprof\"\n    \"net/http\"\n    \"runtime\"\n)\n\n// Enable pprof\ngo func() {\n    log.Println(http.ListenAndServe(\"localhost:6060\", nil))\n}()\n\n// Analyze CPU profile\n// go tool pprof http://localhost:6060/debug/pprof/profile?seconds=30\n\n// Analyze memory\n// go tool pprof http://localhost:6060/debug/pprof/heap\n\n// Check goroutines\n// go tool pprof http://localhost:6060/debug/pprof/goroutine\n</code></pre>"},{"location":"sdks/go/TROUBLESHOOTING/#trace-individual-requests","title":"Trace Individual Requests","text":"<pre><code>import \"context\"\n\n// Add trace ID to context\ntype traceKeyType string\nconst traceKey traceKeyType = \"trace-id\"\n\nfunc withTraceID(ctx context.Context, id string) context.Context {\n    return context.WithValue(ctx, traceKey, id)\n}\n\nfunc getTraceID(ctx context.Context) string {\n    if id, ok := ctx.Value(traceKey).(string); ok {\n        return id\n    }\n    return \"\"\n}\n\n// Use in requests\ntraceID := uuid.New().String()\nctx := withTraceID(context.Background(), traceID)\nlog.Printf(\"[%s] Starting request\", traceID)\nresult, err := client.Get(ctx, key, nil)\nlog.Printf(\"[%s] Request complete: err=%v\", traceID, err)\n</code></pre>"},{"location":"sdks/go/TROUBLESHOOTING/#common-pitfalls","title":"Common Pitfalls","text":""},{"location":"sdks/go/TROUBLESHOOTING/#1-not-checking-errors","title":"1. Not checking errors","text":"<pre><code>//  Bad\nresult, _ := client.Get(ctx, key, nil)\nprocess(result.Value) // May panic if result is nil\n\n//  Good\nresult, err := client.Get(ctx, key, nil)\nif err != nil {\n    log.Printf(\"Get failed: %v\", err)\n    return err\n}\nprocess(result.Value)\n</code></pre>"},{"location":"sdks/go/TROUBLESHOOTING/#2-creating-client-per-request","title":"2. Creating client per request","text":"<pre><code>//  Bad - closes connections!\nfunc handleRequest() {\n    client, _ := norikv.NewClient(ctx, config)\n    defer client.Close()\n    client.Get(ctx, key, nil)\n}\n\n//  Good - reuse client\nvar globalClient *norikv.Client\n\nfunc init() {\n    globalClient, _ = norikv.NewClient(context.Background(), config)\n}\n</code></pre>"},{"location":"sdks/go/TROUBLESHOOTING/#3-ignoring-context-cancellation","title":"3. Ignoring context cancellation","text":"<pre><code>//  Bad\n_, err := client.Get(context.Background(), key, nil)\n\n//  Good\nctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\ndefer cancel()\n_, err := client.Get(ctx, key, nil)\n</code></pre>"},{"location":"sdks/go/TROUBLESHOOTING/#4-not-using-cas-for-concurrent-updates","title":"4. Not using CAS for concurrent updates","text":"<pre><code>//  Bad - lost updates\nresult, _ := client.Get(ctx, key, nil)\nvalue, _ := strconv.Atoi(string(result.Value))\nclient.Put(ctx, key, []byte(strconv.Itoa(value+1)), nil)\n\n//  Good - CAS prevents lost updates\nresult, _ := client.Get(ctx, key, nil)\nvalue, _ := strconv.Atoi(string(result.Value))\nclient.Put(ctx, key, []byte(strconv.Itoa(value+1)), &amp;norikv.PutOptions{\n    IfMatchVersion: result.Version,\n})\n</code></pre>"},{"location":"sdks/go/TROUBLESHOOTING/#getting-help","title":"Getting Help","text":"<p>If you're still experiencing issues:</p> <ol> <li>Check the API Guide for correct usage</li> <li>Review Architecture Guide for understanding internals</li> <li>See Advanced Patterns for complex use cases</li> <li>Open an issue on GitHub with:</li> <li>Go version (<code>go version</code>)</li> <li>Client SDK version</li> <li>Minimal reproduction code</li> <li>Error messages and logs</li> <li>Server configuration</li> </ol>"},{"location":"sdks/java/","title":"NoriKV Java Client SDK","text":"<p>Production-ready Java client for NoriKV with comprehensive documentation and 100% test coverage.</p>"},{"location":"sdks/java/#status","title":"Status","text":"<p>** PRODUCTION READY** - Fully functional Java SDK</p> <ul> <li>123/123 tests passing (100% success rate)</li> <li>Maven/Gradle support with published artifacts</li> <li>Complete API with all operations (put, get, delete)</li> <li>Comprehensive documentation (4 detailed guides)</li> <li>Performance benchmarks exceeding SLO targets by 60-130x</li> </ul>"},{"location":"sdks/java/#quick-start","title":"Quick Start","text":""},{"location":"sdks/java/#installation","title":"Installation","text":"<p>Maven: <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.norikv&lt;/groupId&gt;\n    &lt;artifactId&gt;norikv-client&lt;/artifactId&gt;\n    &lt;version&gt;0.1.0&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre></p> <p>Gradle: <pre><code>implementation 'com.norikv:norikv-client:0.1.0'\n</code></pre></p>"},{"location":"sdks/java/#basic-usage","title":"Basic Usage","text":"<pre><code>import com.norikv.client.NoriKVClient;\nimport com.norikv.client.types.*;\n\n// Configure client\nClientConfig config = ClientConfig.builder()\n    .nodes(Arrays.asList(\"localhost:9001\", \"localhost:9002\"))\n    .totalShards(1024)\n    .timeoutMs(5000)\n    .build();\n\n// Use try-with-resources for automatic cleanup\ntry (NoriKVClient client = new NoriKVClient(config)) {\n    // Put a value\n    byte[] key = \"user:123\".getBytes();\n    byte[] value = \"{\\\"name\\\":\\\"Alice\\\"}\".getBytes();\n    Version version = client.put(key, value, null);\n\n    // Get the value\n    GetResult result = client.get(key, null);\n    System.out.println(\"Value: \" + new String(result.getValue()));\n\n    // Delete\n    client.delete(key, null);\n}\n</code></pre>"},{"location":"sdks/java/#documentation","title":"Documentation","text":"<p>The Java SDK includes comprehensive documentation:</p>"},{"location":"sdks/java/#core-guides","title":"Core Guides","text":"<ul> <li>API Guide - Complete API reference</li> <li>Installation and setup</li> <li>Client configuration</li> <li>All operations (PUT, GET, DELETE)</li> <li>Advanced features (CAS, TTL, consistency levels)</li> <li>Error handling</li> <li> <p>Best practices</p> </li> <li> <p>Architecture Guide - Internal design</p> </li> <li>Component architecture</li> <li>Request flow</li> <li>Threading model</li> <li>Connection management</li> <li>Routing &amp; sharding</li> <li> <p>Performance considerations</p> </li> <li> <p>Troubleshooting Guide - Common issues</p> </li> <li>Connection problems</li> <li>Performance optimization</li> <li>Version conflicts</li> <li>Error messages and solutions</li> <li> <p>Debugging tips</p> </li> <li> <p>Advanced Patterns - Real-world examples</p> </li> <li>Distributed Counter</li> <li>Session Management</li> <li>Inventory Management</li> <li>Caching Layer</li> <li>Rate Limiting</li> <li>Leader Election</li> <li>Event Sourcing</li> <li>Multi-Tenancy</li> </ul>"},{"location":"sdks/java/#features","title":"Features","text":""},{"location":"sdks/java/#core-features","title":"Core Features","text":"<ul> <li>Smart client-side routing with hash-based shard assignment</li> <li>Leader-aware routing with automatic failover</li> <li>Retry logic with exponential backoff</li> <li>Idempotency support for safe retries</li> <li>Conditional operations (CAS) with version matching</li> <li>Multiple consistency levels (lease, linearizable, stale)</li> <li>Connection pooling with graceful shutdown</li> <li>Cluster topology tracking and change notifications</li> <li>Thread-safe operations</li> <li>AutoCloseable for try-with-resources</li> </ul>"},{"location":"sdks/java/#java-specific","title":"Java-Specific","text":"<ul> <li>Builder patterns for configuration</li> <li>Comprehensive exception hierarchy</li> <li>Stream-based operations</li> <li>Javadoc for all public APIs</li> <li>Maven Central distribution</li> </ul>"},{"location":"sdks/java/#performance","title":"Performance","text":"<p>Target SLOs: - GET p95 latency: \u2264 10ms - PUT p95 latency: \u2264 20ms</p> <p>Actual Performance (against in-memory ephemeral server): - Sequential GET p95: 0.160 ms  (62x faster than target) - Sequential PUT p95: 0.153 ms  (130x faster than target) - Mixed workload p95: 0.203 ms  - CAS operations p95: 0.258 ms  - Large values (10KB) p95: 0.198 ms  - Concurrent (10 threads) p95: 0.828 ms </p> <p>Throughput: - Sequential PUT: ~8,280 ops/sec - Sequential GET: ~7,590 ops/sec - DELETE operations: ~10,466 ops/sec - Concurrent operations: ~6,164 ops/sec</p>"},{"location":"sdks/java/#requirements","title":"Requirements","text":"<ul> <li>Java: 11 or higher</li> <li>Maven: 3.6 or higher (for building from source)</li> <li>NoriKV Server: 0.1.x</li> </ul>"},{"location":"sdks/java/#examples","title":"Examples","text":"<p>See the source repository for complete working examples:</p> <ul> <li><code>BasicExample.java</code> - Simple operations with different options</li> <li><code>ConditionalOperationsExample.java</code> - CAS and version matching</li> <li><code>RetryAndErrorHandlingExample.java</code> - Error handling patterns</li> </ul>"},{"location":"sdks/java/#support","title":"Support","text":"<ul> <li>Issues: GitHub Issues</li> <li>Source: GitHub Repository</li> <li>API Docs: Javadoc (if published)</li> </ul>"},{"location":"sdks/java/#license","title":"License","text":"<p>MIT OR Apache-2.0</p> <p>{: .note }</p> <p>This SDK is production-ready with 100% test coverage. All features are fully implemented and documented.</p>"},{"location":"sdks/java/ADVANCED_PATTERNS/","title":"Advanced Patterns for NoriKV Java Client","text":"<p>Complex use cases and design patterns for production systems.</p>"},{"location":"sdks/java/ADVANCED_PATTERNS/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Distributed Counter</li> <li>Session Management</li> <li>Inventory Management</li> <li>Caching Layer</li> <li>Rate Limiting</li> <li>Leader Election</li> <li>Event Sourcing</li> <li>Multi-Tenancy</li> </ul>"},{"location":"sdks/java/ADVANCED_PATTERNS/#distributed-counter","title":"Distributed Counter","text":"<p>Implement a distributed counter with CAS for atomic increments.</p>"},{"location":"sdks/java/ADVANCED_PATTERNS/#basic-counter","title":"Basic Counter","text":"<pre><code>public class DistributedCounter {\n    private final NoriKVClient client;\n    private final byte[] key;\n    private final int maxRetries;\n\n    public DistributedCounter(NoriKVClient client, String counterName) {\n        this.client = client;\n        this.key = counterName.getBytes(StandardCharsets.UTF_8);\n        this.maxRetries = 20;\n\n        // Initialize counter if not exists\n        try {\n            client.get(key, null);\n        } catch (KeyNotFoundException e) {\n            try {\n                client.put(key, \"0\".getBytes(StandardCharsets.UTF_8), null);\n            } catch (NoriKVException ex) {\n                // Ignore - someone else may have initialized\n            }\n        }\n    }\n\n    public long increment() throws NoriKVException {\n        return incrementBy(1);\n    }\n\n    public long incrementBy(long delta) throws NoriKVException {\n        for (int attempt = 0; attempt &lt; maxRetries; attempt++) {\n            try {\n                // Read current value\n                GetResult current = client.get(key, null);\n                long value = Long.parseLong(\n                    new String(current.getValue(), StandardCharsets.UTF_8));\n\n                // Increment\n                long newValue = value + delta;\n\n                // CAS write\n                PutOptions options = PutOptions.builder()\n                    .ifMatchVersion(current.getVersion())\n                    .build();\n\n                client.put(key,\n                    String.valueOf(newValue).getBytes(StandardCharsets.UTF_8),\n                    options);\n\n                return newValue;\n\n            } catch (VersionMismatchException e) {\n                if (attempt == maxRetries - 1) {\n                    throw new NoriKVException(\"COUNTER_CONFLICT\",\n                        \"Failed to increment after \" + maxRetries + \" attempts\");\n                }\n\n                // Exponential backoff with jitter\n                try {\n                    long backoff = Math.min(1L &lt;&lt; attempt, 1000);\n                    Thread.sleep(backoff + ThreadLocalRandom.current().nextInt(100));\n                } catch (InterruptedException ie) {\n                    Thread.currentThread().interrupt();\n                    throw new NoriKVException(\"INTERRUPTED\", \"Interrupted during backoff\");\n                }\n            }\n        }\n\n        throw new NoriKVException(\"COUNTER_FAILED\", \"Should not reach here\");\n    }\n\n    public long get() throws NoriKVException {\n        GetResult result = client.get(key, null);\n        return Long.parseLong(new String(result.getValue(), StandardCharsets.UTF_8));\n    }\n}\n</code></pre>"},{"location":"sdks/java/ADVANCED_PATTERNS/#sharded-counter-high-throughput","title":"Sharded Counter (High Throughput)","text":"<p>For very high write rates, shard the counter:</p> <pre><code>public class ShardedCounter {\n    private final NoriKVClient client;\n    private final String baseName;\n    private final int numShards;\n\n    public ShardedCounter(NoriKVClient client, String counterName, int numShards) {\n        this.client = client;\n        this.baseName = counterName;\n        this.numShards = numShards;\n\n        // Initialize all shards\n        for (int i = 0; i &lt; numShards; i++) {\n            byte[] shardKey = getShardKey(i);\n            try {\n                client.put(shardKey, \"0\".getBytes(StandardCharsets.UTF_8), null);\n            } catch (NoriKVException e) {\n                // Ignore\n            }\n        }\n    }\n\n    private byte[] getShardKey(int shardId) {\n        return (baseName + \":shard:\" + shardId).getBytes(StandardCharsets.UTF_8);\n    }\n\n    public long increment() throws NoriKVException {\n        // Hash thread ID to shard\n        int shardId = (int) (Thread.currentThread().getId() % numShards);\n        byte[] shardKey = getShardKey(shardId);\n\n        // Increment specific shard\n        DistributedCounter shard = new DistributedCounter(client, new String(shardKey));\n        return shard.increment();\n    }\n\n    public long getTotal() throws NoriKVException {\n        long total = 0;\n        for (int i = 0; i &lt; numShards; i++) {\n            byte[] shardKey = getShardKey(i);\n            try {\n                GetResult result = client.get(shardKey, null);\n                long value = Long.parseLong(\n                    new String(result.getValue(), StandardCharsets.UTF_8));\n                total += value;\n            } catch (KeyNotFoundException e) {\n                // Shard not initialized\n            }\n        }\n        return total;\n    }\n}\n</code></pre>"},{"location":"sdks/java/ADVANCED_PATTERNS/#session-management","title":"Session Management","text":"<p>Manage user sessions with TTL:</p> <pre><code>public class SessionManager {\n    private final NoriKVClient client;\n    private final long sessionTTL;\n\n    public SessionManager(NoriKVClient client, long sessionTTLMs) {\n        this.client = client;\n        this.sessionTTL = sessionTTLMs;\n    }\n\n    public String createSession(String userId, Map&lt;String, Object&gt; sessionData)\n            throws NoriKVException {\n        String sessionId = UUID.randomUUID().toString();\n        byte[] key = sessionKey(sessionId);\n\n        // Serialize session data\n        String json = toJson(sessionData);\n        byte[] value = json.getBytes(StandardCharsets.UTF_8);\n\n        // Store with TTL\n        PutOptions options = PutOptions.builder()\n            .ttlMs(sessionTTL)\n            .idempotencyKey(\"create-session-\" + sessionId)\n            .build();\n\n        client.put(key, value, options);\n\n        return sessionId;\n    }\n\n    public Optional&lt;Map&lt;String, Object&gt;&gt; getSession(String sessionId)\n            throws NoriKVException {\n        byte[] key = sessionKey(sessionId);\n\n        try {\n            GetResult result = client.get(key, null);\n            String json = new String(result.getValue(), StandardCharsets.UTF_8);\n            return Optional.of(fromJson(json));\n        } catch (KeyNotFoundException e) {\n            return Optional.empty(); // Session expired or doesn't exist\n        }\n    }\n\n    public void refreshSession(String sessionId) throws NoriKVException {\n        byte[] key = sessionKey(sessionId);\n\n        try {\n            // Read current data\n            GetResult current = client.get(key, null);\n\n            // Rewrite with new TTL\n            PutOptions options = PutOptions.builder()\n                .ttlMs(sessionTTL)\n                .build();\n\n            client.put(key, current.getValue(), options);\n\n        } catch (KeyNotFoundException e) {\n            throw new NoriKVException(\"SESSION_NOT_FOUND\",\n                \"Session \" + sessionId + \" not found\");\n        }\n    }\n\n    public void deleteSession(String sessionId) throws NoriKVException {\n        byte[] key = sessionKey(sessionId);\n        client.delete(key, null);\n    }\n\n    private byte[] sessionKey(String sessionId) {\n        return (\"session:\" + sessionId).getBytes(StandardCharsets.UTF_8);\n    }\n\n    // Simplified JSON helpers (use Jackson/Gson in production)\n    private String toJson(Map&lt;String, Object&gt; data) {\n        // Implementation\n        return \"{}\";\n    }\n\n    private Map&lt;String, Object&gt; fromJson(String json) {\n        // Implementation\n        return new HashMap&lt;&gt;();\n    }\n}\n</code></pre>"},{"location":"sdks/java/ADVANCED_PATTERNS/#inventory-management","title":"Inventory Management","text":"<p>Implement inventory tracking with CAS to prevent overselling:</p> <pre><code>public class InventoryManager {\n    private final NoriKVClient client;\n\n    public InventoryManager(NoriKVClient client) {\n        this.client = client;\n    }\n\n    public void initializeProduct(String productId, int initialQuantity)\n            throws NoriKVException {\n        byte[] key = productKey(productId);\n\n        InventoryRecord record = new InventoryRecord(initialQuantity, 0);\n        byte[] value = serialize(record);\n\n        client.put(key, value, null);\n    }\n\n    public boolean reserveItems(String productId, int quantity)\n            throws NoriKVException {\n        byte[] key = productKey(productId);\n        int maxRetries = 10;\n\n        for (int attempt = 0; attempt &lt; maxRetries; attempt++) {\n            try {\n                // Read current inventory\n                GetResult current = client.get(key, null);\n                InventoryRecord record = deserialize(current.getValue());\n\n                // Check availability\n                if (record.available &lt; quantity) {\n                    return false; // Not enough inventory\n                }\n\n                // Reserve items\n                record.available -= quantity;\n                record.reserved += quantity;\n\n                // CAS write\n                PutOptions options = PutOptions.builder()\n                    .ifMatchVersion(current.getVersion())\n                    .build();\n\n                client.put(key, serialize(record), options);\n\n                return true; // Reservation succeeded\n\n            } catch (VersionMismatchException e) {\n                if (attempt == maxRetries - 1) {\n                    throw new NoriKVException(\"RESERVATION_CONFLICT\",\n                        \"Failed to reserve items after \" + maxRetries + \" attempts\");\n                }\n\n                // Backoff\n                try {\n                    Thread.sleep(10 + ThreadLocalRandom.current().nextInt(20));\n                } catch (InterruptedException ie) {\n                    Thread.currentThread().interrupt();\n                    return false;\n                }\n            }\n        }\n\n        return false;\n    }\n\n    public void confirmReservation(String productId, int quantity)\n            throws NoriKVException {\n        byte[] key = productKey(productId);\n\n        for (int attempt = 0; attempt &lt; 10; attempt++) {\n            try {\n                GetResult current = client.get(key, null);\n                InventoryRecord record = deserialize(current.getValue());\n\n                // Move from reserved to sold\n                record.reserved -= quantity;\n\n                PutOptions options = PutOptions.builder()\n                    .ifMatchVersion(current.getVersion())\n                    .build();\n\n                client.put(key, serialize(record), options);\n                return;\n\n            } catch (VersionMismatchException e) {\n                // Retry\n            }\n        }\n\n        throw new NoriKVException(\"CONFIRM_FAILED\", \"Failed to confirm reservation\");\n    }\n\n    public void cancelReservation(String productId, int quantity)\n            throws NoriKVException {\n        byte[] key = productKey(productId);\n\n        for (int attempt = 0; attempt &lt; 10; attempt++) {\n            try {\n                GetResult current = client.get(key, null);\n                InventoryRecord record = deserialize(current.getValue());\n\n                // Return to available\n                record.reserved -= quantity;\n                record.available += quantity;\n\n                PutOptions options = PutOptions.builder()\n                    .ifMatchVersion(current.getVersion())\n                    .build();\n\n                client.put(key, serialize(record), options);\n                return;\n\n            } catch (VersionMismatchException e) {\n                // Retry\n            }\n        }\n\n        throw new NoriKVException(\"CANCEL_FAILED\", \"Failed to cancel reservation\");\n    }\n\n    private byte[] productKey(String productId) {\n        return (\"inventory:\" + productId).getBytes(StandardCharsets.UTF_8);\n    }\n\n    private static class InventoryRecord {\n        int available;\n        int reserved;\n\n        InventoryRecord(int available, int reserved) {\n            this.available = available;\n            this.reserved = reserved;\n        }\n    }\n\n    private byte[] serialize(InventoryRecord record) {\n        String json = String.format(\"{\\\"available\\\":%d,\\\"reserved\\\":%d}\",\n            record.available, record.reserved);\n        return json.getBytes(StandardCharsets.UTF_8);\n    }\n\n    private InventoryRecord deserialize(byte[] data) {\n        // Simple parsing (use JSON library in production)\n        String json = new String(data, StandardCharsets.UTF_8);\n        // Parse JSON and return InventoryRecord\n        return new InventoryRecord(0, 0);\n    }\n}\n</code></pre>"},{"location":"sdks/java/ADVANCED_PATTERNS/#caching-layer","title":"Caching Layer","text":"<p>Use NoriKV as a distributed cache:</p> <pre><code>public class CacheLayer&lt;T&gt; {\n    private final NoriKVClient client;\n    private final long defaultTTL;\n    private final Function&lt;byte[], T&gt; deserializer;\n    private final Function&lt;T, byte[]&gt; serializer;\n\n    public CacheLayer(NoriKVClient client, long defaultTTLMs,\n                     Function&lt;T, byte[]&gt; serializer,\n                     Function&lt;byte[], T&gt; deserializer) {\n        this.client = client;\n        this.defaultTTL = defaultTTLMs;\n        this.serializer = serializer;\n        this.deserializer = deserializer;\n    }\n\n    public Optional&lt;T&gt; get(String key) {\n        try {\n            // Use STALE_OK for fastest reads\n            GetOptions options = GetOptions.builder()\n                .consistency(ConsistencyLevel.STALE_OK)\n                .build();\n\n            GetResult result = client.get(\n                key.getBytes(StandardCharsets.UTF_8), options);\n\n            return Optional.of(deserializer.apply(result.getValue()));\n\n        } catch (KeyNotFoundException e) {\n            return Optional.empty();\n        } catch (NoriKVException e) {\n            // Log error but return empty (graceful degradation)\n            System.err.println(\"Cache get failed: \" + e.getMessage());\n            return Optional.empty();\n        }\n    }\n\n    public void put(String key, T value, long ttlMs) {\n        try {\n            byte[] keyBytes = key.getBytes(StandardCharsets.UTF_8);\n            byte[] valueBytes = serializer.apply(value);\n\n            PutOptions options = PutOptions.builder()\n                .ttlMs(ttlMs)\n                .build();\n\n            client.put(keyBytes, valueBytes, options);\n\n        } catch (NoriKVException e) {\n            // Log error but don't throw (cache failure shouldn't break app)\n            System.err.println(\"Cache put failed: \" + e.getMessage());\n        }\n    }\n\n    public void put(String key, T value) {\n        put(key, value, defaultTTL);\n    }\n\n    public void invalidate(String key) {\n        try {\n            client.delete(key.getBytes(StandardCharsets.UTF_8), null);\n        } catch (NoriKVException e) {\n            System.err.println(\"Cache invalidate failed: \" + e.getMessage());\n        }\n    }\n\n    public T getOrCompute(String key, Supplier&lt;T&gt; computer) {\n        // Try cache first\n        Optional&lt;T&gt; cached = get(key);\n        if (cached.isPresent()) {\n            return cached.get();\n        }\n\n        // Compute value\n        T value = computer.get();\n\n        // Store in cache\n        put(key, value);\n\n        return value;\n    }\n}\n\n// Usage\nCacheLayer&lt;User&gt; userCache = new CacheLayer&lt;&gt;(\n    client,\n    3600000L, // 1 hour TTL\n    user -&gt; serialize(user),\n    bytes -&gt; deserialize(bytes)\n);\n\nUser user = userCache.getOrCompute(\"user:123\", () -&gt; {\n    return database.loadUser(123);\n});\n</code></pre>"},{"location":"sdks/java/ADVANCED_PATTERNS/#rate-limiting","title":"Rate Limiting","text":"<p>Implement distributed rate limiting:</p> <pre><code>public class RateLimiter {\n    private final NoriKVClient client;\n    private final int maxRequests;\n    private final long windowMs;\n\n    public RateLimiter(NoriKVClient client, int maxRequestsPerWindow, long windowMs) {\n        this.client = client;\n        this.maxRequests = maxRequestsPerWindow;\n        this.windowMs = windowMs;\n    }\n\n    public boolean allow(String identifier) throws NoriKVException {\n        byte[] key = rateLimitKey(identifier);\n        long now = System.currentTimeMillis();\n\n        for (int attempt = 0; attempt &lt; 10; attempt++) {\n            try {\n                // Try to get current state\n                RateLimitState state;\n                Version version;\n\n                try {\n                    GetResult current = client.get(key, null);\n                    state = deserialize(current.getValue());\n                    version = current.getVersion();\n\n                    // Check if window expired\n                    if (now - state.windowStart &gt;= windowMs) {\n                        // Start new window\n                        state = new RateLimitState(now, 0);\n                        version = null; // Treat as new key\n                    }\n\n                } catch (KeyNotFoundException e) {\n                    // First request in window\n                    state = new RateLimitState(now, 0);\n                    version = null;\n                }\n\n                // Check limit\n                if (state.count &gt;= maxRequests) {\n                    return false; // Rate limit exceeded\n                }\n\n                // Increment count\n                state.count++;\n\n                // Write with CAS or TTL\n                PutOptions options = PutOptions.builder()\n                    .ttlMs(windowMs)\n                    .ifMatchVersion(version) // null for new keys\n                    .build();\n\n                client.put(key, serialize(state), options);\n\n                return true; // Request allowed\n\n            } catch (VersionMismatchException e) {\n                // Retry\n            }\n        }\n\n        // Failed to acquire after retries - be conservative\n        return false;\n    }\n\n    private byte[] rateLimitKey(String identifier) {\n        return (\"ratelimit:\" + identifier).getBytes(StandardCharsets.UTF_8);\n    }\n\n    private static class RateLimitState {\n        long windowStart;\n        int count;\n\n        RateLimitState(long windowStart, int count) {\n            this.windowStart = windowStart;\n            this.count = count;\n        }\n    }\n\n    private byte[] serialize(RateLimitState state) {\n        String json = String.format(\"{\\\"windowStart\\\":%d,\\\"count\\\":%d}\",\n            state.windowStart, state.count);\n        return json.getBytes(StandardCharsets.UTF_8);\n    }\n\n    private RateLimitState deserialize(byte[] data) {\n        // Parse JSON\n        return new RateLimitState(0, 0);\n    }\n}\n</code></pre>"},{"location":"sdks/java/ADVANCED_PATTERNS/#leader-election","title":"Leader Election","text":"<p>Simple leader election using CAS:</p> <pre><code>public class LeaderElection {\n    private final NoriKVClient client;\n    private final String leadershipKey;\n    private final String nodeId;\n    private final long leaseDurationMs;\n    private volatile boolean isLeader;\n\n    public LeaderElection(NoriKVClient client, String group, String nodeId) {\n        this.client = client;\n        this.leadershipKey = \"leader:\" + group;\n        this.nodeId = nodeId;\n        this.leaseDurationMs = 10000; // 10 second lease\n        this.isLeader = false;\n    }\n\n    public boolean tryAcquireLeadership() throws NoriKVException {\n        byte[] key = leadershipKey.getBytes(StandardCharsets.UTF_8);\n        byte[] value = nodeId.getBytes(StandardCharsets.UTF_8);\n\n        try {\n            // Try to get current leader\n            GetResult current = client.get(key, null);\n            String currentLeader = new String(current.getValue(), StandardCharsets.UTF_8);\n\n            if (currentLeader.equals(nodeId)) {\n                // We're already leader, refresh lease\n                PutOptions options = PutOptions.builder()\n                    .ttlMs(leaseDurationMs)\n                    .build();\n\n                client.put(key, value, options);\n                isLeader = true;\n                return true;\n            }\n\n            // Someone else is leader\n            isLeader = false;\n            return false;\n\n        } catch (KeyNotFoundException e) {\n            // No current leader, try to acquire\n            PutOptions options = PutOptions.builder()\n                .ttlMs(leaseDurationMs)\n                .build();\n\n            try {\n                client.put(key, value, options);\n                isLeader = true;\n                return true;\n            } catch (NoriKVException ex) {\n                // Race - someone else acquired\n                isLeader = false;\n                return false;\n            }\n        }\n    }\n\n    public void releaseLeadership() throws NoriKVException {\n        if (!isLeader) {\n            return;\n        }\n\n        byte[] key = leadershipKey.getBytes(StandardCharsets.UTF_8);\n        client.delete(key, null);\n        isLeader = false;\n    }\n\n    public boolean isLeader() {\n        return isLeader;\n    }\n\n    // Background thread to maintain leadership\n    public void startLeadershipMaintenance() {\n        ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(1);\n        scheduler.scheduleAtFixedRate(() -&gt; {\n            try {\n                if (isLeader) {\n                    tryAcquireLeadership(); // Refresh lease\n                }\n            } catch (Exception e) {\n                System.err.println(\"Failed to maintain leadership: \" + e.getMessage());\n                isLeader = false;\n            }\n        }, 0, leaseDurationMs / 2, TimeUnit.MILLISECONDS);\n    }\n}\n</code></pre>"},{"location":"sdks/java/ADVANCED_PATTERNS/#event-sourcing","title":"Event Sourcing","text":"<p>Store events in NoriKV:</p> <pre><code>public class EventStore {\n    private final NoriKVClient client;\n    private final DistributedCounter sequenceCounter;\n\n    public EventStore(NoriKVClient client) {\n        this.client = client;\n        this.sequenceCounter = new DistributedCounter(client, \"event:sequence\");\n    }\n\n    public long appendEvent(String aggregateId, String eventType, byte[] eventData)\n            throws NoriKVException {\n        // Get next sequence number\n        long sequence = sequenceCounter.increment();\n\n        // Store event\n        byte[] key = eventKey(aggregateId, sequence);\n\n        Event event = new Event(sequence, aggregateId, eventType,\n            System.currentTimeMillis(), eventData);\n\n        byte[] value = serialize(event);\n\n        PutOptions options = PutOptions.builder()\n            .idempotencyKey(\"event-\" + aggregateId + \"-\" + sequence)\n            .build();\n\n        client.put(key, value, options);\n\n        return sequence;\n    }\n\n    public List&lt;Event&gt; getEvents(String aggregateId, long fromSequence)\n            throws NoriKVException {\n        List&lt;Event&gt; events = new ArrayList&lt;&gt;();\n\n        // Read events sequentially (could optimize with parallel reads)\n        for (long seq = fromSequence; seq &lt; fromSequence + 1000; seq++) {\n            byte[] key = eventKey(aggregateId, seq);\n\n            try {\n                GetResult result = client.get(key, null);\n                Event event = deserialize(result.getValue());\n                events.add(event);\n            } catch (KeyNotFoundException e) {\n                // No more events\n                break;\n            }\n        }\n\n        return events;\n    }\n\n    private byte[] eventKey(String aggregateId, long sequence) {\n        return String.format(\"event:%s:%010d\", aggregateId, sequence)\n            .getBytes(StandardCharsets.UTF_8);\n    }\n\n    private static class Event {\n        long sequence;\n        String aggregateId;\n        String eventType;\n        long timestamp;\n        byte[] data;\n\n        Event(long sequence, String aggregateId, String eventType,\n              long timestamp, byte[] data) {\n            this.sequence = sequence;\n            this.aggregateId = aggregateId;\n            this.eventType = eventType;\n            this.timestamp = timestamp;\n            this.data = data;\n        }\n    }\n\n    private byte[] serialize(Event event) {\n        // Serialize to bytes\n        return new byte[0];\n    }\n\n    private Event deserialize(byte[] data) {\n        // Deserialize from bytes\n        return null;\n    }\n}\n</code></pre>"},{"location":"sdks/java/ADVANCED_PATTERNS/#multi-tenancy","title":"Multi-Tenancy","text":"<p>Isolate data by tenant:</p> <pre><code>public class MultiTenantClient {\n    private final NoriKVClient client;\n    private final String tenantId;\n\n    public MultiTenantClient(NoriKVClient client, String tenantId) {\n        this.client = client;\n        this.tenantId = tenantId;\n    }\n\n    public Version put(String key, byte[] value, PutOptions options)\n            throws NoriKVException {\n        byte[] tenantKey = tenantKey(key);\n        return client.put(tenantKey, value, options);\n    }\n\n    public GetResult get(String key, GetOptions options)\n            throws NoriKVException {\n        byte[] tenantKey = tenantKey(key);\n        return client.get(tenantKey, options);\n    }\n\n    public boolean delete(String key, DeleteOptions options)\n            throws NoriKVException {\n        byte[] tenantKey = tenantKey(key);\n        return client.delete(tenantKey, options);\n    }\n\n    private byte[] tenantKey(String key) {\n        // Prefix with tenant ID for isolation\n        return (tenantId + \":\" + key).getBytes(StandardCharsets.UTF_8);\n    }\n\n    // Factory method\n    public static MultiTenantClient forTenant(NoriKVClient client, String tenantId) {\n        return new MultiTenantClient(client, tenantId);\n    }\n}\n\n// Usage\nNoriKVClient sharedClient = new NoriKVClient(config);\n\nMultiTenantClient tenant1 = MultiTenantClient.forTenant(sharedClient, \"tenant-1\");\nMultiTenantClient tenant2 = MultiTenantClient.forTenant(sharedClient, \"tenant-2\");\n\n// Data is automatically isolated\ntenant1.put(\"user:123\", data, null); // Stored as \"tenant-1:user:123\"\ntenant2.put(\"user:123\", data, null); // Stored as \"tenant-2:user:123\"\n</code></pre>"},{"location":"sdks/java/ADVANCED_PATTERNS/#see-also","title":"See Also","text":"<ul> <li>API Guide - Complete API reference</li> <li>Architecture Guide - Internal design</li> <li>Troubleshooting Guide - Common issues</li> <li>Examples - Working code samples</li> </ul>"},{"location":"sdks/java/API_GUIDE/","title":"NoriKV Java Client API Guide","text":"<p>Complete reference for the NoriKV Java Client SDK.</p>"},{"location":"sdks/java/API_GUIDE/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Installation</li> <li>Quick Start</li> <li>Client Configuration</li> <li>Core Operations</li> <li>Advanced Features</li> <li>Error Handling</li> <li>Best Practices</li> </ul>"},{"location":"sdks/java/API_GUIDE/#installation","title":"Installation","text":""},{"location":"sdks/java/API_GUIDE/#maven","title":"Maven","text":"<pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.norikv&lt;/groupId&gt;\n    &lt;artifactId&gt;norikv-client&lt;/artifactId&gt;\n    &lt;version&gt;0.1.0&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#gradle","title":"Gradle","text":"<pre><code>implementation 'com.norikv:norikv-client:0.1.0'\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#quick-start","title":"Quick Start","text":"<pre><code>import com.norikv.client.NoriKVClient;\nimport com.norikv.client.types.*;\nimport java.util.Arrays;\n\npublic class QuickStart {\n    public static void main(String[] args) throws NoriKVException {\n        // Configure client\n        ClientConfig config = ClientConfig.builder()\n            .nodes(Arrays.asList(\"localhost:9001\", \"localhost:9002\", \"localhost:9003\"))\n            .totalShards(1024)\n            .timeoutMs(5000)\n            .build();\n\n        // Use try-with-resources for automatic cleanup\n        try (NoriKVClient client = new NoriKVClient(config)) {\n            // Write\n            byte[] key = \"user:alice\".getBytes();\n            byte[] value = \"{\\\"name\\\":\\\"Alice\\\",\\\"age\\\":30}\".getBytes();\n            Version version = client.put(key, value, null);\n\n            // Read\n            GetResult result = client.get(key, null);\n            System.out.println(\"Value: \" + new String(result.getValue()));\n\n            // Delete\n            client.delete(key, null);\n        }\n    }\n}\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#client-configuration","title":"Client Configuration","text":""},{"location":"sdks/java/API_GUIDE/#basic-configuration","title":"Basic Configuration","text":"<pre><code>ClientConfig config = ClientConfig.builder()\n    .nodes(Arrays.asList(\"node1:9001\", \"node2:9001\"))\n    .totalShards(1024)\n    .timeoutMs(5000)\n    .build();\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#configuration-options","title":"Configuration Options","text":"Option Type Default Description <code>nodes</code> <code>List&lt;String&gt;</code> Required List of node addresses (host:port) <code>totalShards</code> <code>int</code> Required Total number of shards in cluster <code>timeoutMs</code> <code>long</code> 5000 Request timeout in milliseconds <code>retry</code> <code>RetryConfig</code> See below Retry policy configuration"},{"location":"sdks/java/API_GUIDE/#retry-configuration","title":"Retry Configuration","text":"<pre><code>RetryConfig retryConfig = RetryConfig.builder()\n    .maxAttempts(10)          // Max retry attempts\n    .initialDelayMs(100)      // Initial backoff delay\n    .maxDelayMs(5000)         // Maximum backoff delay\n    .jitterMs(100)            // Random jitter to add\n    .build();\n\nClientConfig config = ClientConfig.builder()\n    .nodes(Arrays.asList(\"localhost:9001\"))\n    .totalShards(1024)\n    .retry(retryConfig)\n    .build();\n</code></pre> <p>Retry Behavior: - Retries transient errors: <code>UNAVAILABLE</code>, <code>ABORTED</code>, <code>DEADLINE_EXCEEDED</code>, <code>RESOURCE_EXHAUSTED</code> - Does NOT retry: <code>INVALID_ARGUMENT</code>, <code>NOT_FOUND</code>, <code>FAILED_PRECONDITION</code>, <code>PERMISSION_DENIED</code> - Uses exponential backoff with jitter to avoid thundering herd</p>"},{"location":"sdks/java/API_GUIDE/#default-configuration","title":"Default Configuration","text":"<pre><code>// Quick setup with defaults\nClientConfig config = ClientConfig.defaultConfig(\"localhost:9001\");\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#core-operations","title":"Core Operations","text":""},{"location":"sdks/java/API_GUIDE/#put-write-data","title":"PUT - Write Data","text":""},{"location":"sdks/java/API_GUIDE/#basic-put","title":"Basic PUT","text":"<pre><code>byte[] key = \"user:123\".getBytes();\nbyte[] value = \"{\\\"name\\\":\\\"Alice\\\"}\".getBytes();\n\nVersion version = client.put(key, value, null);\nSystem.out.println(\"Written at version: \" + version);\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#put-with-options","title":"PUT with Options","text":"<pre><code>PutOptions options = PutOptions.builder()\n    .ttlMs(60000L)                          // TTL: 60 seconds\n    .idempotencyKey(\"order-12345\")          // Idempotency key\n    .ifMatchVersion(expectedVersion)        // CAS: only if version matches\n    .build();\n\nVersion version = client.put(key, value, options);\n</code></pre> <p>PutOptions Fields:</p> Field Type Description <code>ttlMs</code> <code>Long</code> Time-to-live in milliseconds <code>idempotencyKey</code> <code>String</code> Key for idempotent operations <code>ifMatchVersion</code> <code>Version</code> Expected version for CAS"},{"location":"sdks/java/API_GUIDE/#get-read-data","title":"GET - Read Data","text":""},{"location":"sdks/java/API_GUIDE/#basic-get","title":"Basic GET","text":"<pre><code>byte[] key = \"user:123\".getBytes();\nGetResult result = client.get(key, null);\n\nbyte[] value = result.getValue();\nVersion version = result.getVersion();\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#get-with-consistency-level","title":"GET with Consistency Level","text":"<pre><code>GetOptions options = GetOptions.builder()\n    .consistency(ConsistencyLevel.LINEARIZABLE)\n    .build();\n\nGetResult result = client.get(key, options);\n</code></pre> <p>Consistency Levels:</p> Level Description Use Case <code>LEASE</code> Default, lease-based read Most operations (fast, usually consistent) <code>LINEARIZABLE</code> Strictest, always up-to-date Critical reads requiring absolute consistency <code>STALE_OK</code> May return stale data Read-heavy workloads, caching"},{"location":"sdks/java/API_GUIDE/#delete-remove-data","title":"DELETE - Remove Data","text":""},{"location":"sdks/java/API_GUIDE/#basic-delete","title":"Basic DELETE","text":"<pre><code>byte[] key = \"user:123\".getBytes();\nboolean deleted = client.delete(key, null);\n\nif (deleted) {\n    System.out.println(\"Key was deleted\");\n} else {\n    System.out.println(\"Key did not exist\");\n}\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#delete-with-options","title":"DELETE with Options","text":"<pre><code>DeleteOptions options = DeleteOptions.builder()\n    .idempotencyKey(\"delete-order-12345\")\n    .ifMatchVersion(expectedVersion)\n    .build();\n\nboolean deleted = client.delete(key, options);\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#advanced-features","title":"Advanced Features","text":""},{"location":"sdks/java/API_GUIDE/#compare-and-swap-cas","title":"Compare-And-Swap (CAS)","text":"<p>Optimistic concurrency control using version matching:</p> <pre><code>// Read current value\nGetResult current = client.get(key, null);\nint value = Integer.parseInt(new String(current.getValue()));\n\n// Update with CAS\nint newValue = value + 1;\nPutOptions options = PutOptions.builder()\n    .ifMatchVersion(current.getVersion())\n    .build();\n\ntry {\n    client.put(key, String.valueOf(newValue).getBytes(), options);\n    System.out.println(\"CAS succeeded\");\n} catch (VersionMismatchException e) {\n    System.out.println(\"CAS failed - version changed\");\n}\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#idempotent-operations","title":"Idempotent Operations","text":"<p>Safe retries using idempotency keys:</p> <pre><code>String idempotencyKey = \"payment-\" + UUID.randomUUID();\n\nPutOptions options = PutOptions.builder()\n    .idempotencyKey(idempotencyKey)\n    .build();\n\n// First attempt\nVersion v1 = client.put(key, value, options);\n\n// Retry with same key (safe - returns same version)\nVersion v2 = client.put(key, value, options);\n\nassert v1.equals(v2); // Same version returned\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#time-to-live-ttl","title":"Time-To-Live (TTL)","text":"<p>Automatic expiration:</p> <pre><code>PutOptions options = PutOptions.builder()\n    .ttlMs(60000L) // Expires in 60 seconds\n    .build();\n\nclient.put(key, value, options);\n\n// Key automatically deleted after TTL\nThread.sleep(61000);\ntry {\n    client.get(key, null);\n} catch (KeyNotFoundException e) {\n    System.out.println(\"Key expired\");\n}\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#cluster-topology","title":"Cluster Topology","text":"<p>Monitor cluster changes:</p> <pre><code>// Get current cluster view\nClusterView view = client.getClusterView();\nif (view != null) {\n    System.out.println(\"Cluster epoch: \" + view.getEpoch());\n    System.out.println(\"Nodes: \" + view.getNodes().size());\n}\n\n// Subscribe to topology changes\nRunnable unsubscribe = client.onTopologyChange(event -&gt; {\n    System.out.println(\"Topology changed!\");\n    System.out.println(\"Previous epoch: \" + event.getPreviousEpoch());\n    System.out.println(\"Current epoch: \" + event.getCurrentEpoch());\n    System.out.println(\"Added nodes: \" + event.getAddedNodes());\n    System.out.println(\"Removed nodes: \" + event.getRemovedNodes());\n    System.out.println(\"Leader changes: \" + event.getLeaderChanges());\n});\n\n// Later: unsubscribe\nunsubscribe.run();\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#client-statistics","title":"Client Statistics","text":"<p>Monitor client performance:</p> <pre><code>NoriKVClient.ClientStats stats = client.getStats();\n\nSystem.out.println(\"Router stats: \" + stats.getRouterStats());\nSystem.out.println(\"Connection pool stats: \" + stats.getPoolStats());\nSystem.out.println(\"Topology stats: \" + stats.getTopologyStats());\nSystem.out.println(\"Client closed: \" + stats.isClosed());\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#error-handling","title":"Error Handling","text":""},{"location":"sdks/java/API_GUIDE/#exception-hierarchy","title":"Exception Hierarchy","text":"<pre><code>NoriKVException (base)\n\u251c\u2500\u2500 KeyNotFoundException\n\u251c\u2500\u2500 VersionMismatchException\n\u251c\u2500\u2500 AlreadyExistsException\n\u2514\u2500\u2500 ConnectionException\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#handling-specific-errors","title":"Handling Specific Errors","text":"<pre><code>try {\n    GetResult result = client.get(key, null);\n} catch (KeyNotFoundException e) {\n    // Key does not exist\n    System.out.println(\"Key not found\");\n} catch (ConnectionException e) {\n    // Network or cluster issues\n    System.out.println(\"Connection error: \" + e.getMessage());\n} catch (NoriKVException e) {\n    // Other errors\n    System.out.println(\"Error: \" + e.getCode() + \" - \" + e.getMessage());\n}\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#retry-pattern","title":"Retry Pattern","text":"<pre><code>int maxAttempts = 3;\nfor (int attempt = 1; attempt &lt;= maxAttempts; attempt++) {\n    try {\n        client.put(key, value, null);\n        break; // Success\n    } catch (ConnectionException e) {\n        if (attempt == maxAttempts) {\n            throw e; // Give up\n        }\n        // Exponential backoff\n        Thread.sleep((long) Math.pow(2, attempt) * 100);\n    }\n}\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#graceful-degradation","title":"Graceful Degradation","text":"<pre><code>public byte[] getWithFallback(NoriKVClient client, byte[] key, byte[] defaultValue) {\n    try {\n        GetResult result = client.get(key, null);\n        return result.getValue();\n    } catch (KeyNotFoundException e) {\n        return defaultValue;\n    } catch (NoriKVException e) {\n        logger.warn(\"Failed to get key, using default\", e);\n        return defaultValue;\n    }\n}\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#best-practices","title":"Best Practices","text":""},{"location":"sdks/java/API_GUIDE/#1-use-try-with-resources","title":"1. Use Try-With-Resources","text":"<p>Always use try-with-resources for automatic cleanup:</p> <pre><code>try (NoriKVClient client = new NoriKVClient(config)) {\n    // Use client\n} // Automatically closed\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#2-reuse-client-instances","title":"2. Reuse Client Instances","text":"<p>Clients are thread-safe and should be reused:</p> <pre><code>//  Good: Single client instance\nprivate final NoriKVClient client = new NoriKVClient(config);\n\n//  Bad: Creating client per request\npublic void handleRequest() {\n    try (NoriKVClient client = new NoriKVClient(config)) {\n        // ...\n    }\n}\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#3-use-idempotency-keys","title":"3. Use Idempotency Keys","text":"<p>For operations that must not be duplicated:</p> <pre><code>String idempotencyKey = \"order-\" + orderId;\nPutOptions options = PutOptions.builder()\n    .idempotencyKey(idempotencyKey)\n    .build();\n\nclient.put(key, value, options);\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#4-choose-appropriate-consistency","title":"4. Choose Appropriate Consistency","text":"<ul> <li>Use <code>LEASE</code> (default) for most operations</li> <li>Use <code>LINEARIZABLE</code> for critical reads</li> <li>Use <code>STALE_OK</code> for caching/read-heavy workloads</li> </ul>"},{"location":"sdks/java/API_GUIDE/#5-handle-version-conflicts","title":"5. Handle Version Conflicts","text":"<p>Implement retry logic for CAS operations:</p> <pre><code>int maxRetries = 10;\nfor (int i = 0; i &lt; maxRetries; i++) {\n    try {\n        GetResult current = client.get(key, null);\n        // ... compute new value ...\n\n        PutOptions options = PutOptions.builder()\n            .ifMatchVersion(current.getVersion())\n            .build();\n\n        client.put(key, newValue, options);\n        break; // Success\n    } catch (VersionMismatchException e) {\n        if (i == maxRetries - 1) throw e;\n        Thread.sleep(10); // Small backoff\n    }\n}\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#6-set-appropriate-timeouts","title":"6. Set Appropriate Timeouts","text":"<pre><code>ClientConfig config = ClientConfig.builder()\n    .nodes(nodes)\n    .totalShards(1024)\n    .timeoutMs(5000) // 5 seconds\n    .build();\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#7-monitor-client-health","title":"7. Monitor Client Health","text":"<pre><code>// Periodically check stats\nNoriKVClient.ClientStats stats = client.getStats();\nif (stats.isClosed()) {\n    logger.error(\"Client is closed!\");\n}\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#8-use-utf-8-encoding","title":"8. Use UTF-8 Encoding","text":"<p>Always use UTF-8 for string encoding:</p> <pre><code>import java.nio.charset.StandardCharsets;\n\nbyte[] key = \"user:123\".getBytes(StandardCharsets.UTF_8);\nString value = new String(bytes, StandardCharsets.UTF_8);\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#performance-tips","title":"Performance Tips","text":""},{"location":"sdks/java/API_GUIDE/#1-batch-operations","title":"1. Batch Operations","text":"<p>Process multiple operations efficiently:</p> <pre><code>// Process in batches\nList&lt;byte[]&gt; keys = getKeysToProcess();\nfor (byte[] key : keys) {\n    client.put(key, value, null);\n}\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#2-connection-pooling","title":"2. Connection Pooling","text":"<p>The client maintains a connection pool internally - no need for external pooling.</p>"},{"location":"sdks/java/API_GUIDE/#3-concurrent-access","title":"3. Concurrent Access","text":"<p>Client is thread-safe:</p> <pre><code>ExecutorService executor = Executors.newFixedThreadPool(10);\nfor (int i = 0; i &lt; 100; i++) {\n    executor.submit(() -&gt; {\n        client.put(key, value, null);\n    });\n}\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#4-use-appropriate-value-sizes","title":"4. Use Appropriate Value Sizes","text":"<ul> <li>Optimal: 100 bytes - 10 KB</li> <li>Maximum: Limited by memory and network</li> </ul>"},{"location":"sdks/java/API_GUIDE/#5-minimize-version-conflicts","title":"5. Minimize Version Conflicts","text":"<p>Reduce contention on hot keys: - Use finer-grained keys - Implement backoff strategies - Consider event sourcing patterns</p>"},{"location":"sdks/java/API_GUIDE/#complete-example","title":"Complete Example","text":"<pre><code>import com.norikv.client.NoriKVClient;\nimport com.norikv.client.types.*;\nimport java.nio.charset.StandardCharsets;\nimport java.util.Arrays;\n\npublic class CompleteExample {\n    public static void main(String[] args) {\n        // Configure with retry policy\n        RetryConfig retryConfig = RetryConfig.builder()\n            .maxAttempts(5)\n            .initialDelayMs(100)\n            .maxDelayMs(2000)\n            .build();\n\n        ClientConfig config = ClientConfig.builder()\n            .nodes(Arrays.asList(\"localhost:9001\", \"localhost:9002\"))\n            .totalShards(1024)\n            .timeoutMs(5000)\n            .retry(retryConfig)\n            .build();\n\n        try (NoriKVClient client = new NoriKVClient(config)) {\n            // Write with TTL and idempotency\n            byte[] key = \"session:abc123\".getBytes(StandardCharsets.UTF_8);\n            byte[] value = \"{\\\"user_id\\\":42}\".getBytes(StandardCharsets.UTF_8);\n\n            PutOptions putOpts = PutOptions.builder()\n                .ttlMs(3600000L) // 1 hour\n                .idempotencyKey(\"session-create-abc123\")\n                .build();\n\n            Version version = client.put(key, value, putOpts);\n            System.out.println(\"Written: \" + version);\n\n            // Read with linearizable consistency\n            GetOptions getOpts = GetOptions.builder()\n                .consistency(ConsistencyLevel.LINEARIZABLE)\n                .build();\n\n            GetResult result = client.get(key, getOpts);\n            String data = new String(result.getValue(), StandardCharsets.UTF_8);\n            System.out.println(\"Read: \" + data);\n\n            // Update with CAS\n            byte[] newValue = \"{\\\"user_id\\\":42,\\\"active\\\":true}\"\n                .getBytes(StandardCharsets.UTF_8);\n\n            PutOptions casOpts = PutOptions.builder()\n                .ifMatchVersion(result.getVersion())\n                .build();\n\n            try {\n                client.put(key, newValue, casOpts);\n                System.out.println(\"CAS succeeded\");\n            } catch (VersionMismatchException e) {\n                System.out.println(\"CAS failed - retry needed\");\n            }\n\n            // Monitor topology\n            client.onTopologyChange(event -&gt; {\n                System.out.println(\"Cluster changed: epoch \" +\n                    event.getCurrentEpoch());\n            });\n\n            // Get statistics\n            NoriKVClient.ClientStats stats = client.getStats();\n            System.out.println(\"Stats: \" + stats);\n\n        } catch (KeyNotFoundException e) {\n            System.err.println(\"Key not found\");\n        } catch (ConnectionException e) {\n            System.err.println(\"Connection failed: \" + e.getMessage());\n        } catch (NoriKVException e) {\n            System.err.println(\"Error: \" + e.getCode());\n        }\n    }\n}\n</code></pre>"},{"location":"sdks/java/API_GUIDE/#next-steps","title":"Next Steps","text":"<ul> <li>Architecture Guide - Understanding client internals</li> <li>Troubleshooting Guide - Solving common issues</li> <li>Advanced Patterns - Complex use cases</li> <li>Examples - Working code samples</li> </ul>"},{"location":"sdks/java/ARCHITECTURE/","title":"NoriKV Java Client Architecture","text":"<p>Understanding the internal design and components of the Java client SDK.</p>"},{"location":"sdks/java/ARCHITECTURE/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>Component Architecture</li> <li>Request Flow</li> <li>Threading Model</li> <li>Connection Management</li> <li>Routing &amp; Sharding</li> <li>Retry Logic</li> <li>Error Handling</li> </ul>"},{"location":"sdks/java/ARCHITECTURE/#overview","title":"Overview","text":"<p>The NoriKV Java client is designed as a smart client that: - Routes requests directly to the appropriate shard leader - Maintains connection pools for efficient communication - Implements retry logic with exponential backoff - Tracks cluster topology changes - Provides thread-safe operations</p>"},{"location":"sdks/java/ARCHITECTURE/#design-principles","title":"Design Principles","text":"<ol> <li>Zero-hop routing: Client routes directly to shard leader (no proxy)</li> <li>Thread safety: Single client instance shared across threads</li> <li>Fail-fast: Detect and handle failures quickly</li> <li>Observable: Expose metrics and statistics</li> <li>Resource efficient: Connection pooling and reuse</li> </ol>"},{"location":"sdks/java/ARCHITECTURE/#component-architecture","title":"Component Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    NoriKVClient                         \u2502\n\u2502  (Main API: put, get, delete, topology, stats)          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502          \u2502          \u2502          \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Router   \u2502 \u2502 Retry \u2502 \u2502   Pool   \u2502 \u2502 Topology  \u2502\n\u2502            \u2502 \u2502Policy \u2502 \u2502          \u2502 \u2502 Manager   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502                         \u2502              \u2502\n     \u2502                         \u2502              \u2502\n     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500hash()\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524              \u2502\n                               \u2502              \u2502\n     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500getChannel()\u2500\u2500\u2500\u2500\u2524              \u2502\n     \u2502                         \u2502              \u2502\n     \u2502                    \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510         \u2502\n     \u2502                    \u2502 gRPC    \u2502         \u2502\n     \u2502                    \u2502Channels \u2502         \u2502\n     \u2502                    \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518         \u2502\n     \u2502                         \u2502              \u2502\n     \u2502                         \u2502              \u2502\n     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500updateView()\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"sdks/java/ARCHITECTURE/#components","title":"Components","text":""},{"location":"sdks/java/ARCHITECTURE/#1-norikvclient","title":"1. NoriKVClient","text":"<p>Responsibility: Main public API and component coordination</p> <p>Key Methods: - <code>put()</code>, <code>get()</code>, <code>delete()</code> - Core operations - <code>getClusterView()</code> - Topology information - <code>onTopologyChange()</code> - Subscribe to topology updates - <code>getStats()</code> - Client statistics - <code>close()</code> - Resource cleanup</p> <p>Location: <code>src/main/java/com/norikv/client/NoriKVClient.java</code></p>"},{"location":"sdks/java/ARCHITECTURE/#2-router","title":"2. Router","text":"<p>Responsibility: Determine which node to send requests to</p> <p>Key Functions: - Hash key to shard: <code>xxhash64(key) \u2192 jumpConsistentHash(hash, totalShards) \u2192 shardId</code> - Map shard to leader node - Cache leader information - Handle leader hints from <code>NOT_LEADER</code> errors</p> <p>Location: <code>src/main/java/com/norikv/client/internal/router/Router.java</code></p> <p>Algorithm: <pre><code>1. Hash key using XXHash64 (seed=0)\n2. Map hash to shard using Jump Consistent Hash\n3. Look up shard leader in topology cache\n4. Return leader's address\n</code></pre></p>"},{"location":"sdks/java/ARCHITECTURE/#3-connectionpool","title":"3. ConnectionPool","text":"<p>Responsibility: Manage gRPC channels to cluster nodes</p> <p>Key Functions: - Create and cache gRPC channels per node - Thread-safe concurrent access - Graceful shutdown - Health monitoring</p> <p>Location: <code>src/main/java/com/norikv/client/internal/conn/ConnectionPool.java</code></p> <p>Design: - One <code>ManagedChannel</code> per node address - Lazy initialization (created on first use) - Channels reused across requests - Automatic shutdown on client close</p>"},{"location":"sdks/java/ARCHITECTURE/#4-retrypolicy","title":"4. RetryPolicy","text":"<p>Responsibility: Handle transient failures with backoff</p> <p>Key Functions: - Exponential backoff: <code>delay = min(initialDelay * 2^attempt, maxDelay)</code> - Jitter: Add randomness to avoid thundering herd - Selective retry: Only retry transient errors - Attempt tracking</p> <p>Location: <code>src/main/java/com/norikv/client/internal/retry/RetryPolicy.java</code></p> <p>Retryable Errors: - <code>UNAVAILABLE</code> - Server temporarily unavailable - <code>ABORTED</code> - Operation aborted, safe to retry - <code>DEADLINE_EXCEEDED</code> - Timeout, may succeed on retry - <code>RESOURCE_EXHAUSTED</code> - Rate limited, backoff helps</p> <p>Non-Retryable Errors: - <code>INVALID_ARGUMENT</code> - Client error, won't succeed - <code>NOT_FOUND</code> - Key doesn't exist - <code>FAILED_PRECONDITION</code> - CAS conflict, application must retry - <code>PERMISSION_DENIED</code> - Auth error</p>"},{"location":"sdks/java/ARCHITECTURE/#5-topologymanager","title":"5. TopologyManager","text":"<p>Responsibility: Track cluster membership and shard assignments</p> <p>Key Functions: - Store current <code>ClusterView</code> - Cache shard \u2192 leader mappings - Detect topology changes - Notify listeners of changes - Update leader hints</p> <p>Location: <code>src/main/java/com/norikv/client/internal/topology/TopologyManager.java</code></p> <p>Data Structures: - <code>ClusterView</code>: Current cluster state (epoch, nodes, shards) - <code>shardLeaderCache</code>: ConcurrentHashMap - <code>listeners</code>: CopyOnWriteArrayList of change callbacks"},{"location":"sdks/java/ARCHITECTURE/#request-flow","title":"Request Flow","text":""},{"location":"sdks/java/ARCHITECTURE/#put-request-flow","title":"PUT Request Flow","text":"<pre><code>Client.put(key, value, options)\n    \u2502\n    \u251c\u2500&gt; 1. Validate inputs (key, value not null/empty)\n    \u2502\n    \u251c\u2500&gt; 2. Router.getNodeForKey(key)\n    \u2502       \u251c\u2500&gt; hash = xxhash64(key)\n    \u2502       \u251c\u2500&gt; shardId = jumpConsistentHash(hash, totalShards)\n    \u2502       \u2514\u2500&gt; leaderAddr = topologyManager.getShardLeader(shardId)\n    \u2502\n    \u251c\u2500&gt; 3. ConnectionPool.getChannel(leaderAddr)\n    \u2502       \u2514\u2500&gt; Return cached or create new gRPC channel\n    \u2502\n    \u251c\u2500&gt; 4. RetryPolicy.execute(() -&gt; {\n    \u2502       \u251c\u2500&gt; Build gRPC PutRequest (via ProtoConverters)\n    \u2502       \u251c\u2500&gt; KvGrpc.newBlockingStub(channel).put(request)\n    \u2502       \u2514\u2500&gt; Convert response to Version\n    \u2502   })\n    \u2502       \u251c\u2500&gt; On SUCCESS: return Version\n    \u2502       \u251c\u2500&gt; On RETRYABLE_ERROR: backoff and retry\n    \u2502       \u2514\u2500&gt; On NON_RETRYABLE: throw exception\n    \u2502\n    \u2514\u2500&gt; 5. Return Version to caller\n</code></pre>"},{"location":"sdks/java/ARCHITECTURE/#get-request-flow","title":"GET Request Flow","text":"<p>Similar to PUT, but: - Uses <code>GetRequest</code> with consistency level - Returns <code>GetResult</code> (value + version) - Throws <code>KeyNotFoundException</code> on NOT_FOUND</p>"},{"location":"sdks/java/ARCHITECTURE/#error-handling-in-flow","title":"Error Handling in Flow","text":"<pre><code>gRPC StatusRuntimeException\n    \u2502\n    \u251c\u2500&gt; convertGrpcException()\n    \u2502   \u251c\u2500&gt; NOT_FOUND \u2192 KeyNotFoundException\n    \u2502   \u251c\u2500&gt; FAILED_PRECONDITION + \"version\" \u2192 VersionMismatchException\n    \u2502   \u251c\u2500&gt; UNAVAILABLE \u2192 ConnectionException\n    \u2502   \u2514\u2500&gt; OTHER \u2192 NoriKVException\n    \u2502\n    \u2514\u2500&gt; RetryPolicy decides:\n        \u251c\u2500&gt; Retryable \u2192 backoff and retry\n        \u2514\u2500&gt; Non-retryable \u2192 throw to caller\n</code></pre>"},{"location":"sdks/java/ARCHITECTURE/#threading-model","title":"Threading Model","text":""},{"location":"sdks/java/ARCHITECTURE/#thread-safety-guarantees","title":"Thread Safety Guarantees","text":"<p>All client components are thread-safe:</p> <ol> <li>NoriKVClient: Thread-safe, shareable across threads</li> <li>Router: Uses immutable routing tables, atomic leader cache updates</li> <li>ConnectionPool: ConcurrentHashMap for channel storage</li> <li>TopologyManager: ReadWriteLock for view updates, ConcurrentHashMap for caches</li> <li>RetryPolicy: Stateless, safe for concurrent use</li> </ol>"},{"location":"sdks/java/ARCHITECTURE/#concurrency-design","title":"Concurrency Design","text":"<pre><code>//  Safe: Single client, multiple threads\nNoriKVClient client = new NoriKVClient(config);\n\nExecutorService executor = Executors.newFixedThreadPool(10);\nfor (int i = 0; i &lt; 100; i++) {\n    executor.submit(() -&gt; {\n        client.put(key, value, null); // Thread-safe\n    });\n}\n</code></pre>"},{"location":"sdks/java/ARCHITECTURE/#synchronization-points","title":"Synchronization Points","text":"<ol> <li>TopologyManager.updateView(): Write lock during view update</li> <li>ConnectionPool.getOrCreateChannel(): Double-checked locking for channel creation</li> <li>Router leader cache: ConcurrentHashMap for atomic updates</li> </ol>"},{"location":"sdks/java/ARCHITECTURE/#connection-management","title":"Connection Management","text":""},{"location":"sdks/java/ARCHITECTURE/#channel-lifecycle","title":"Channel Lifecycle","text":"<pre><code>Node Address\n    \u2502\n    \u251c\u2500&gt; First request \u2192 Create ManagedChannel\n    \u2502   \u251c\u2500&gt; Configure: plaintext, timeouts, keepalive\n    \u2502   \u2514\u2500&gt; Store in pool\n    \u2502\n    \u251c\u2500&gt; Subsequent requests \u2192 Reuse channel\n    \u2502\n    \u2514\u2500&gt; Client.close() \u2192 Shutdown all channels\n        \u251c\u2500&gt; Graceful shutdown (5s timeout)\n        \u2514\u2500&gt; Force shutdown if needed\n</code></pre>"},{"location":"sdks/java/ARCHITECTURE/#channel-configuration","title":"Channel Configuration","text":"<pre><code>ManagedChannel channel = ManagedChannelBuilder\n    .forTarget(address)\n    .usePlaintext() // No TLS (for now)\n    .build();\n</code></pre>"},{"location":"sdks/java/ARCHITECTURE/#health-checks","title":"Health Checks","text":"<ul> <li>Channels automatically reconnect on failure</li> <li>gRPC handles connection health internally</li> <li>Failed requests trigger retries (via RetryPolicy)</li> </ul>"},{"location":"sdks/java/ARCHITECTURE/#routing-sharding","title":"Routing &amp; Sharding","text":""},{"location":"sdks/java/ARCHITECTURE/#hash-function-xxhash64","title":"Hash Function: XXHash64","text":"<pre><code>long hash = xxhash64(key, seed=0);\n</code></pre> <p>Properties: - Fast: ~10GB/s throughput - Consistent: Same key \u2192 same hash - Cross-SDK compatible: Identical to Go/Python/TypeScript implementations</p>"},{"location":"sdks/java/ARCHITECTURE/#consistent-hashing-jump-consistent-hash","title":"Consistent Hashing: Jump Consistent Hash","text":"<pre><code>int shardId = jumpConsistentHash(hash, totalShards);\n</code></pre> <p>Properties: - Minimal key movement on shard count changes - O(log n) time complexity - Uniform distribution</p>"},{"location":"sdks/java/ARCHITECTURE/#shard-leader-mapping","title":"Shard \u2192 Leader Mapping","text":"<pre><code>shardId \u2192 TopologyManager.getShardLeader(shardId) \u2192 leaderAddr\n</code></pre> <p>Leader Cache: - Populated from ClusterView - Updated on topology changes - Updated from NOT_LEADER error hints</p>"},{"location":"sdks/java/ARCHITECTURE/#not_leader-handling","title":"NOT_LEADER Handling","text":"<pre><code>1. Request sent to node A for shard X\n2. Node A returns NOT_LEADER error with hint: \"leader is node B\"\n3. Client updates leader cache: shard X \u2192 node B\n4. Retry policy re-sends request to node B\n</code></pre>"},{"location":"sdks/java/ARCHITECTURE/#retry-logic","title":"Retry Logic","text":""},{"location":"sdks/java/ARCHITECTURE/#exponential-backoff","title":"Exponential Backoff","text":"<pre><code>delay = min(initialDelay * 2^attempt, maxDelay) + jitter\n</code></pre> <p>Example (initialDelay=100ms, maxDelay=5000ms, jitter=100ms): <pre><code>Attempt 1: delay = 100ms  + random(0-100ms)\nAttempt 2: delay = 200ms  + random(0-100ms)\nAttempt 3: delay = 400ms  + random(0-100ms)\nAttempt 4: delay = 800ms  + random(0-100ms)\nAttempt 5: delay = 1600ms + random(0-100ms)\nAttempt 6: delay = 3200ms + random(0-100ms)\nAttempt 7: delay = 5000ms + random(0-100ms) (capped)\n</code></pre></p>"},{"location":"sdks/java/ARCHITECTURE/#jitter-benefits","title":"Jitter Benefits","text":"<ul> <li>Avoids thundering herd (all clients retry at same time)</li> <li>Spreads load during recovery</li> <li>Reduces collision probability</li> </ul>"},{"location":"sdks/java/ARCHITECTURE/#retry-decision-tree","title":"Retry Decision Tree","text":"<pre><code>Error Received\n    \u2502\n    \u251c\u2500&gt; Is retryable? (UNAVAILABLE, ABORTED, etc.)\n    \u2502   \u2502\n    \u2502   \u251c\u2500&gt; YES: attempt &lt; maxAttempts?\n    \u2502   \u2502   \u251c\u2500&gt; YES: backoff and retry\n    \u2502   \u2502   \u2514\u2500&gt; NO: throw RETRY_EXHAUSTED\n    \u2502   \u2502\n    \u2502   \u2514\u2500&gt; NO: throw original exception\n    \u2502\n    \u2514\u2500&gt; Success: return result\n</code></pre>"},{"location":"sdks/java/ARCHITECTURE/#error-handling","title":"Error Handling","text":""},{"location":"sdks/java/ARCHITECTURE/#exception-hierarchy","title":"Exception Hierarchy","text":"<pre><code>NoriKVException (checked)\n\u251c\u2500\u2500 KeyNotFoundException\n\u251c\u2500\u2500 VersionMismatchException\n\u251c\u2500\u2500 AlreadyExistsException\n\u2514\u2500\u2500 ConnectionException\n</code></pre>"},{"location":"sdks/java/ARCHITECTURE/#error-code-mapping","title":"Error Code Mapping","text":"gRPC Status NoriKV Exception Retry? NOT_FOUND KeyNotFoundException No FAILED_PRECONDITION (version) VersionMismatchException No FAILED_PRECONDITION (other) NoriKVException No ALREADY_EXISTS AlreadyExistsException No UNAVAILABLE ConnectionException Yes DEADLINE_EXCEEDED ConnectionException Yes ABORTED NoriKVException Yes RESOURCE_EXHAUSTED NoriKVException Yes INVALID_ARGUMENT NoriKVException No PERMISSION_DENIED NoriKVException No OTHER NoriKVException No"},{"location":"sdks/java/ARCHITECTURE/#error-context","title":"Error Context","text":"<p>Exceptions include: - Error code (string) - Descriptive message - Cause (original exception) - Context (key, version for VersionMismatchException)</p>"},{"location":"sdks/java/ARCHITECTURE/#performance-considerations","title":"Performance Considerations","text":""},{"location":"sdks/java/ARCHITECTURE/#hot-paths","title":"Hot Paths","text":"<ol> <li>Hash calculation: Optimized XXHash64 implementation</li> <li>Channel lookup: O(1) ConcurrentHashMap lookup</li> <li>Leader cache: O(1) lookup, populated eagerly</li> <li>Protobuf serialization: Minimal overhead</li> </ol>"},{"location":"sdks/java/ARCHITECTURE/#memory-usage","title":"Memory Usage","text":"<ul> <li>Per client: ~1-10 MB (depends on number of nodes)</li> <li>Per channel: ~100 KB (gRPC overhead)</li> <li>Per request: Minimal (request/response objects garbage collected)</li> </ul>"},{"location":"sdks/java/ARCHITECTURE/#connection-pooling","title":"Connection Pooling","text":"<ul> <li>Channels reused across requests</li> <li>No connection per request overhead</li> <li>gRPC multiplexes requests over HTTP/2</li> </ul>"},{"location":"sdks/java/ARCHITECTURE/#benchmarks","title":"Benchmarks","text":"<p>See Performance Benchmarks for detailed metrics.</p>"},{"location":"sdks/java/ARCHITECTURE/#observability","title":"Observability","text":""},{"location":"sdks/java/ARCHITECTURE/#client-statistics","title":"Client Statistics","text":"<pre><code>ClientStats stats = client.getStats();\n\n// Router stats\nstats.getRouterStats().getTotalNodes();\nstats.getRouterStats().getTotalShards();\n\n// Connection pool stats\nstats.getPoolStats().getActiveChannels();\n\n// Topology stats\nstats.getTopologyStats().getCurrentEpoch();\nstats.getTopologyStats().getCachedLeaders();\n</code></pre>"},{"location":"sdks/java/ARCHITECTURE/#topology-change-events","title":"Topology Change Events","text":"<pre><code>client.onTopologyChange(event -&gt; {\n    logger.info(\"Topology changed to epoch {}\", event.getCurrentEpoch());\n    logger.info(\"Added nodes: {}\", event.getAddedNodes());\n    logger.info(\"Removed nodes: {}\", event.getRemovedNodes());\n    logger.info(\"Leader changes: {}\", event.getLeaderChanges());\n});\n</code></pre>"},{"location":"sdks/java/ARCHITECTURE/#logging","title":"Logging","text":"<p>Client uses <code>System.err</code> for internal errors (listener failures, etc.). Consider adding proper logging framework integration in production.</p>"},{"location":"sdks/java/ARCHITECTURE/#extensibility","title":"Extensibility","text":""},{"location":"sdks/java/ARCHITECTURE/#custom-retry-policies","title":"Custom Retry Policies","text":"<p>Implement custom backoff strategies:</p> <pre><code>RetryConfig custom = RetryConfig.builder()\n    .maxAttempts(20)\n    .initialDelayMs(50)\n    .maxDelayMs(10000)\n    .jitterMs(200)\n    .build();\n</code></pre>"},{"location":"sdks/java/ARCHITECTURE/#future-extensions","title":"Future Extensions","text":"<p>Potential areas for extension: - Custom hash functions (requires cross-SDK coordination) - TLS/SSL support - Authentication integration - Metrics export (Prometheus, OTLP) - Circuit breaker patterns - Request tracing</p>"},{"location":"sdks/java/ARCHITECTURE/#comparison-with-other-sdks","title":"Comparison with Other SDKs","text":""},{"location":"sdks/java/ARCHITECTURE/#similarities","title":"Similarities","text":"<ul> <li>Same hash functions (XXHash64 + Jump Consistent Hash)</li> <li>Same routing algorithm</li> <li>Same proto definitions</li> <li>Same error handling patterns</li> </ul>"},{"location":"sdks/java/ARCHITECTURE/#java-specific-features","title":"Java-Specific Features","text":"<ul> <li>Builder pattern for configuration</li> <li>Try-with-resources (AutoCloseable)</li> <li>Java streams and functional interfaces</li> <li>Strong typing with generics</li> </ul>"},{"location":"sdks/java/ARCHITECTURE/#performance","title":"Performance","text":"<p>Java SDK performance is comparable to other SDKs: - Go: Fastest (native concurrency, minimal GC) - Java: Fast (JIT optimization, mature runtime) - TypeScript: Good (V8 optimization) - Python: Slower (GIL limitations, interpreted)</p>"},{"location":"sdks/java/ARCHITECTURE/#references","title":"References","text":"<ul> <li>API Guide - Public API documentation</li> <li>Troubleshooting Guide - Common issues</li> <li>Advanced Patterns - Complex use cases</li> <li>Source Code - Implementation</li> </ul>"},{"location":"sdks/java/TROUBLESHOOTING/","title":"NoriKV Java Client Troubleshooting Guide","text":"<p>Solutions to common issues and debugging tips.</p>"},{"location":"sdks/java/TROUBLESHOOTING/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Connection Issues</li> <li>Performance Problems</li> <li>Error Messages</li> <li>Configuration Issues</li> <li>Debugging Tips</li> <li>Common Pitfalls</li> </ul>"},{"location":"sdks/java/TROUBLESHOOTING/#connection-issues","title":"Connection Issues","text":""},{"location":"sdks/java/TROUBLESHOOTING/#problem-connectionexception-unavailable","title":"Problem: <code>ConnectionException: UNAVAILABLE</code>","text":"<p>Symptoms: <pre><code>ConnectionException: UNAVAILABLE: io exception\n</code></pre></p> <p>Possible Causes: 1. Server is not running 2. Incorrect node addresses 3. Network connectivity issues 4. Firewall blocking connections</p> <p>Solutions:</p> <pre><code># 1. Verify server is running\ncurl http://localhost:9001/health\n\n# 2. Check network connectivity\ntelnet localhost 9001\n\n# 3. Verify addresses in config\nClientConfig config = ClientConfig.builder()\n    .nodes(Arrays.asList(\"localhost:9001\"))  // Check port!\n    .build();\n</code></pre>"},{"location":"sdks/java/TROUBLESHOOTING/#problem-connectionexception-deadline_exceeded","title":"Problem: <code>ConnectionException: DEADLINE_EXCEEDED</code>","text":"<p>Symptoms: <pre><code>ConnectionException: DEADLINE_EXCEEDED: deadline exceeded after 5s\n</code></pre></p> <p>Cause: Request timeout exceeded</p> <p>Solutions:</p> <pre><code>// 1. Increase timeout\nClientConfig config = ClientConfig.builder()\n    .nodes(nodes)\n    .totalShards(1024)\n    .timeoutMs(10000) // Increase from 5s to 10s\n    .build();\n\n// 2. Check server performance\n// - Is server overloaded?\n// - Are operations taking too long?\n// - Network latency issues?\n\n// 3. Optimize operations\n// - Reduce value sizes\n// - Use batch operations\n// - Check consistency level (STALE_OK is fastest)\n</code></pre>"},{"location":"sdks/java/TROUBLESHOOTING/#problem-cannot-connect-to-cluster","title":"Problem: Cannot Connect to Cluster","text":"<p>Symptoms: <pre><code>NoriKVException: RETRY_EXHAUSTED: Failed after 10 attempts\n</code></pre></p> <p>Debug Steps:</p> <pre><code>// 1. Enable verbose logging\nSystem.setProperty(\"java.util.logging.SimpleFormatter.format\",\n    \"[%1$tF %1$tT] [%4$-7s] %5$s %n\");\n\n// 2. Test connectivity manually\ntry (Socket socket = new Socket(\"localhost\", 9001)) {\n    System.out.println(\"Connection successful\");\n} catch (IOException e) {\n    System.err.println(\"Cannot connect: \" + e.getMessage());\n}\n\n// 3. Verify gRPC works\nManagedChannel channel = ManagedChannelBuilder\n    .forAddress(\"localhost\", 9001)\n    .usePlaintext()\n    .build();\n\ntry {\n    // Try health check if available\n    channel.getState(true);\n    System.out.println(\"Channel state: \" + channel.getState(false));\n} finally {\n    channel.shutdown();\n}\n</code></pre>"},{"location":"sdks/java/TROUBLESHOOTING/#performance-problems","title":"Performance Problems","text":""},{"location":"sdks/java/TROUBLESHOOTING/#problem-slow-operations","title":"Problem: Slow Operations","text":"<p>Symptoms: - Operations taking &gt; 100ms - High p95/p99 latencies - Timeouts under load</p> <p>Diagnosis:</p> <pre><code>// Measure operation latency\nlong start = System.nanoTime();\ntry {\n    client.get(key, null);\n} finally {\n    long latency = System.nanoTime() - start;\n    System.out.println(\"Latency: \" + (latency / 1_000_000.0) + \" ms\");\n}\n\n// Check client stats\nClientStats stats = client.getStats();\nSystem.out.println(\"Active channels: \" + stats.getPoolStats().getActiveChannels());\nSystem.out.println(\"Cached leaders: \" + stats.getTopologyStats().getCachedLeaders());\n</code></pre> <p>Solutions:</p> <ol> <li> <p>Use appropriate consistency level: <pre><code>// STALE_OK is fastest (may return stale data)\nGetOptions options = GetOptions.builder()\n    .consistency(ConsistencyLevel.STALE_OK)\n    .build();\n</code></pre></p> </li> <li> <p>Check value sizes: <pre><code>// Large values slow down operations\nGetResult result = client.get(key, null);\nSystem.out.println(\"Value size: \" + result.getValue().length + \" bytes\");\n\n// Consider compressing large values\nbyte[] compressed = compress(largeValue);\nclient.put(key, compressed, null);\n</code></pre></p> </li> <li> <p>Verify network latency: <pre><code># Measure network round-trip time\nping -c 10 server-host\n</code></pre></p> </li> <li> <p>Check server load:</p> </li> <li>Monitor server CPU/memory</li> <li>Check server logs for errors</li> <li>Verify server is not overloaded</li> </ol>"},{"location":"sdks/java/TROUBLESHOOTING/#problem-high-memory-usage","title":"Problem: High Memory Usage","text":"<p>Symptoms: - OutOfMemoryError - Frequent garbage collection - Growing heap size</p> <p>Causes &amp; Solutions:</p> <ol> <li> <p>Large values: <pre><code>//  Bad: Storing large values\nbyte[] huge = new byte[100 * 1024 * 1024]; // 100 MB\nclient.put(key, huge, null);\n\n//  Good: Keep values small\nbyte[] reasonable = new byte[10 * 1024]; // 10 KB\nclient.put(key, reasonable, null);\n</code></pre></p> </li> <li> <p>Not closing clients: <pre><code>//  Bad: Leaking clients\npublic void handleRequest() {\n    NoriKVClient client = new NoriKVClient(config);\n    client.get(key, null);\n    // Never closed!\n}\n\n//  Good: Use try-with-resources\npublic void handleRequest() {\n    try (NoriKVClient client = new NoriKVClient(config)) {\n        client.get(key, null);\n    } // Automatically closed\n}\n</code></pre></p> </li> <li> <p>Creating too many clients: <pre><code>//  Bad: Client per request\nfor (int i = 0; i &lt; 1000; i++) {\n    try (NoriKVClient client = new NoriKVClient(config)) {\n        client.get(key, null);\n    }\n}\n\n//  Good: Reuse single client\nNoriKVClient client = new NoriKVClient(config);\nfor (int i = 0; i &lt; 1000; i++) {\n    client.get(key, null);\n}\nclient.close();\n</code></pre></p> </li> </ol>"},{"location":"sdks/java/TROUBLESHOOTING/#problem-version-conflicts-cas-failures","title":"Problem: Version Conflicts / CAS Failures","text":"<p>Symptoms: <pre><code>VersionMismatchException: Version mismatch\n</code></pre></p> <p>Cause: High contention on hot keys</p> <p>Solutions:</p> <ol> <li> <p>Implement retry with backoff: <pre><code>int maxRetries = 20;\nfor (int attempt = 0; attempt &lt; maxRetries; attempt++) {\n    try {\n        GetResult current = client.get(key, null);\n        int value = Integer.parseInt(new String(current.getValue()));\n\n        PutOptions options = PutOptions.builder()\n            .ifMatchVersion(current.getVersion())\n            .build();\n\n        client.put(key, String.valueOf(value + 1).getBytes(), options);\n        break; // Success\n    } catch (VersionMismatchException e) {\n        if (attempt == maxRetries - 1) throw e;\n\n        // Exponential backoff with jitter\n        long backoff = Math.min(1L &lt;&lt; attempt, 1000);\n        Thread.sleep(backoff + random.nextInt(100));\n    }\n}\n</code></pre></p> </li> <li> <p>Reduce contention: <pre><code>//  Bad: Single hot key\nclient.put(\"global_counter\".getBytes(), value, null);\n\n//  Good: Shard across multiple keys\nint shardId = threadId % 10;\nclient.put((\"counter_shard_\" + shardId).getBytes(), value, null);\n</code></pre></p> </li> <li> <p>Use idempotency for writes that don't need CAS: <pre><code>// If you don't need version checking, use idempotency instead\nPutOptions options = PutOptions.builder()\n    .idempotencyKey(\"order-\" + orderId)\n    .build();\n\nclient.put(key, value, options); // Safe to retry\n</code></pre></p> </li> </ol>"},{"location":"sdks/java/TROUBLESHOOTING/#error-messages","title":"Error Messages","text":""},{"location":"sdks/java/TROUBLESHOOTING/#keynotfoundexception-key-not-found","title":"<code>KeyNotFoundException: Key not found</code>","text":"<p>Meaning: Key does not exist in the store</p> <p>Solutions: <pre><code>// 1. Handle gracefully\ntry {\n    GetResult result = client.get(key, null);\n} catch (KeyNotFoundException e) {\n    // Use default value or create key\n    client.put(key, defaultValue, null);\n}\n\n// 2. Check if key was deleted\n// Keys with TTL expire automatically\n\n// 3. Verify key encoding\nbyte[] key = \"user:123\".getBytes(StandardCharsets.UTF_8);\n//  Not: \"user:123\".getBytes() // Uses platform default!\n</code></pre></p>"},{"location":"sdks/java/TROUBLESHOOTING/#versionmismatchexception-version-mismatch","title":"<code>VersionMismatchException: Version mismatch</code>","text":"<p>Meaning: CAS operation failed - version changed</p> <p>Normal behavior: Expected under concurrent access</p> <p>Handling: <pre><code>// This is not an error - it's how CAS works!\n// Just retry the operation\n\nfor (int retry = 0; retry &lt; 10; retry++) {\n    try {\n        GetResult current = client.get(key, null);\n        // ... compute new value ...\n\n        PutOptions options = PutOptions.builder()\n            .ifMatchVersion(current.getVersion())\n            .build();\n\n        client.put(key, newValue, options);\n        break; // Success\n    } catch (VersionMismatchException e) {\n        // Expected - someone else modified the key\n        // Loop will retry\n    }\n}\n</code></pre></p>"},{"location":"sdks/java/TROUBLESHOOTING/#illegalargumentexception-key-cannot-be-null","title":"<code>IllegalArgumentException: key cannot be null</code>","text":"<p>Meaning: Validation failed - key/value is null or empty</p> <p>Fix: <pre><code>//  Bad\nbyte[] key = null;\nclient.put(key, value, null); // IllegalArgumentException\n\n//  Good\nbyte[] key = \"user:123\".getBytes(StandardCharsets.UTF_8);\nif (key.length &gt; 0) {\n    client.put(key, value, null);\n}\n</code></pre></p>"},{"location":"sdks/java/TROUBLESHOOTING/#norikvexception-retry_exhausted","title":"<code>NoriKVException: RETRY_EXHAUSTED</code>","text":"<p>Meaning: All retry attempts failed</p> <p>Causes: - Server is down - Network issues - Persistent errors</p> <p>Diagnosis: <pre><code>try {\n    client.put(key, value, null);\n} catch (NoriKVException e) {\n    System.err.println(\"Error code: \" + e.getCode());\n    System.err.println(\"Message: \" + e.getMessage());\n\n    if (e.getCause() != null) {\n        System.err.println(\"Underlying cause:\");\n        e.getCause().printStackTrace();\n    }\n}\n</code></pre></p>"},{"location":"sdks/java/TROUBLESHOOTING/#configuration-issues","title":"Configuration Issues","text":""},{"location":"sdks/java/TROUBLESHOOTING/#problem-wrong-total-shards","title":"Problem: Wrong Total Shards","text":"<p>Symptoms: - Keys not found even though they exist - Inconsistent behavior</p> <p>Cause: <code>totalShards</code> doesn't match cluster configuration</p> <p>Fix: <pre><code>//  Wrong\nClientConfig config = ClientConfig.builder()\n    .nodes(nodes)\n    .totalShards(512) // Cluster has 1024!\n    .build();\n\n//  Correct\nClientConfig config = ClientConfig.builder()\n    .nodes(nodes)\n    .totalShards(1024) // Match cluster config\n    .build();\n\n// Query server for actual shard count if unsure\n</code></pre></p>"},{"location":"sdks/java/TROUBLESHOOTING/#problem-missing-nodes","title":"Problem: Missing Nodes","text":"<p>Symptoms: - Some operations fail - Uneven load distribution</p> <p>Fix: <pre><code>//  Bad: Missing nodes\nClientConfig config = ClientConfig.builder()\n    .nodes(Arrays.asList(\"node1:9001\")) // Only 1 of 3 nodes!\n    .build();\n\n//  Good: All nodes\nClientConfig config = ClientConfig.builder()\n    .nodes(Arrays.asList(\n        \"node1:9001\",\n        \"node2:9001\",\n        \"node3:9001\"\n    ))\n    .build();\n</code></pre></p>"},{"location":"sdks/java/TROUBLESHOOTING/#problem-retry-configuration-too-aggressive","title":"Problem: Retry Configuration Too Aggressive","text":"<p>Symptoms: - Operations take very long to fail - High latency on errors</p> <p>Fix: <pre><code>//  Too many retries\nRetryConfig config = RetryConfig.builder()\n    .maxAttempts(100) // Way too many!\n    .maxDelayMs(60000) // 60 second backoff!\n    .build();\n\n//  Reasonable\nRetryConfig config = RetryConfig.builder()\n    .maxAttempts(5)\n    .initialDelayMs(100)\n    .maxDelayMs(2000)\n    .build();\n</code></pre></p>"},{"location":"sdks/java/TROUBLESHOOTING/#debugging-tips","title":"Debugging Tips","text":""},{"location":"sdks/java/TROUBLESHOOTING/#enable-detailed-logging","title":"Enable Detailed Logging","text":"<pre><code>// Enable gRPC logging\nimport java.util.logging.*;\n\nLogger grpcLogger = Logger.getLogger(\"io.grpc\");\ngrpcLogger.setLevel(Level.FINE);\n\nConsoleHandler handler = new ConsoleHandler();\nhandler.setLevel(Level.FINE);\ngrpcLogger.addHandler(handler);\n</code></pre>"},{"location":"sdks/java/TROUBLESHOOTING/#capture-network-traffic","title":"Capture Network Traffic","text":"<pre><code># Use tcpdump to capture gRPC traffic\nsudo tcpdump -i any -w norikv.pcap port 9001\n\n# Analyze with Wireshark\nwireshark norikv.pcap\n</code></pre>"},{"location":"sdks/java/TROUBLESHOOTING/#inspect-protobuf-messages","title":"Inspect Protobuf Messages","text":"<pre><code>// Log protobuf messages\nNorikv.PutRequest request = ProtoConverters.buildPutRequest(key, value, options);\nSystem.out.println(\"Request: \" + request);\n</code></pre>"},{"location":"sdks/java/TROUBLESHOOTING/#monitor-client-stats","title":"Monitor Client Stats","text":"<pre><code>// Periodic stats monitoring\nScheduledExecutorService scheduler = Executors.newScheduledThreadPool(1);\nscheduler.scheduleAtFixedRate(() -&gt; {\n    ClientStats stats = client.getStats();\n    System.out.println(\"=== Client Stats ===\");\n    System.out.println(\"Closed: \" + stats.isClosed());\n    System.out.println(\"Channels: \" + stats.getPoolStats().getActiveChannels());\n    System.out.println(\"Epoch: \" + stats.getTopologyStats().getCurrentEpoch());\n}, 0, 10, TimeUnit.SECONDS);\n</code></pre>"},{"location":"sdks/java/TROUBLESHOOTING/#test-with-ephemeral-server","title":"Test with Ephemeral Server","text":"<pre><code>// Use ephemeral server for testing\nimport com.norikv.client.testing.EphemeralServer;\n\nEphemeralServer server = EphemeralServer.start(9001);\ntry {\n    ClientConfig config = ClientConfig.builder()\n        .nodes(Arrays.asList(server.getAddress()))\n        .totalShards(1024)\n        .build();\n\n    try (NoriKVClient client = new NoriKVClient(config)) {\n        // Test operations\n        client.put(\"test\".getBytes(), \"value\".getBytes(), null);\n    }\n} finally {\n    server.stop();\n}\n</code></pre>"},{"location":"sdks/java/TROUBLESHOOTING/#measure-operation-latency","title":"Measure Operation Latency","text":"<pre><code>public class LatencyMonitor {\n    public static void measureOperation(String name, Runnable operation) {\n        long start = System.nanoTime();\n        try {\n            operation.run();\n        } finally {\n            long latency = System.nanoTime() - start;\n            double ms = latency / 1_000_000.0;\n            System.out.printf(\"%s: %.3f ms%n\", name, ms);\n        }\n    }\n}\n\n// Usage\nLatencyMonitor.measureOperation(\"PUT\", () -&gt; {\n    try {\n        client.put(key, value, null);\n    } catch (NoriKVException e) {\n        // Handle error\n    }\n});\n</code></pre>"},{"location":"sdks/java/TROUBLESHOOTING/#common-pitfalls","title":"Common Pitfalls","text":""},{"location":"sdks/java/TROUBLESHOOTING/#1-not-using-utf-8-encoding","title":"1. Not Using UTF-8 Encoding","text":"<pre><code>//  Bad: Platform default encoding\nbyte[] key = \"user:123\".getBytes();\n\n//  Good: Explicit UTF-8\nbyte[] key = \"user:123\".getBytes(StandardCharsets.UTF_8);\n</code></pre>"},{"location":"sdks/java/TROUBLESHOOTING/#2-forgetting-to-close-client","title":"2. Forgetting to Close Client","text":"<pre><code>//  Bad: Resource leak\nNoriKVClient client = new NoriKVClient(config);\nclient.get(key, null);\n// Never closed!\n\n//  Good: Always close\ntry (NoriKVClient client = new NoriKVClient(config)) {\n    client.get(key, null);\n} // Automatically closed\n</code></pre>"},{"location":"sdks/java/TROUBLESHOOTING/#3-creating-client-per-request","title":"3. Creating Client Per Request","text":"<pre><code>//  Bad: Expensive\npublic void handleRequest() {\n    try (NoriKVClient client = new NoriKVClient(config)) {\n        client.get(key, null);\n    }\n}\n\n//  Good: Reuse client\nprivate final NoriKVClient client = new NoriKVClient(config);\n\npublic void handleRequest() {\n    client.get(key, null);\n}\n</code></pre>"},{"location":"sdks/java/TROUBLESHOOTING/#4-not-handling-version-conflicts","title":"4. Not Handling Version Conflicts","text":"<pre><code>//  Bad: No retry\ntry {\n    client.put(key, newValue, casOptions);\n} catch (VersionMismatchException e) {\n    // Just fail? Should retry!\n}\n\n//  Good: Retry with backoff\nfor (int i = 0; i &lt; maxRetries; i++) {\n    try {\n        GetResult current = client.get(key, null);\n        PutOptions opts = PutOptions.builder()\n            .ifMatchVersion(current.getVersion())\n            .build();\n        client.put(key, newValue, opts);\n        break;\n    } catch (VersionMismatchException e) {\n        if (i == maxRetries - 1) throw e;\n        Thread.sleep(backoff);\n    }\n}\n</code></pre>"},{"location":"sdks/java/TROUBLESHOOTING/#5-ignoring-client-statistics","title":"5. Ignoring Client Statistics","text":"<pre><code>//  Monitor health\nClientStats stats = client.getStats();\nif (stats.isClosed()) {\n    throw new IllegalStateException(\"Client is closed!\");\n}\n\nif (stats.getPoolStats().getActiveChannels() == 0) {\n    logger.warn(\"No active connections!\");\n}\n</code></pre>"},{"location":"sdks/java/TROUBLESHOOTING/#6-using-wrong-consistency-level","title":"6. Using Wrong Consistency Level","text":"<pre><code>//  Bad: Always linearizable (slow)\nGetOptions options = GetOptions.builder()\n    .consistency(ConsistencyLevel.LINEARIZABLE)\n    .build();\n\n//  Good: Use appropriate level\n// - LEASE (default): Most operations\n// - LINEARIZABLE: Critical reads only\n// - STALE_OK: Caching, read-heavy\n</code></pre>"},{"location":"sdks/java/TROUBLESHOOTING/#7-not-setting-timeouts","title":"7. Not Setting Timeouts","text":"<pre><code>//  Bad: Default might be too short/long\nClientConfig config = ClientConfig.builder()\n    .nodes(nodes)\n    .totalShards(1024)\n    .build(); // Uses default 5s\n\n//  Good: Set appropriate timeout\nClientConfig config = ClientConfig.builder()\n    .nodes(nodes)\n    .totalShards(1024)\n    .timeoutMs(10000) // 10s for slow operations\n    .build();\n</code></pre>"},{"location":"sdks/java/TROUBLESHOOTING/#8-large-keys","title":"8. Large Keys","text":"<pre><code>//  Bad: Huge keys\nString hugeKey = \"x\".repeat(1000000); // 1MB key!\nclient.put(hugeKey.getBytes(), value, null);\n\n//  Good: Reasonable key sizes\nString key = \"user:123\"; // &lt; 1KB\nclient.put(key.getBytes(StandardCharsets.UTF_8), value, null);\n</code></pre>"},{"location":"sdks/java/TROUBLESHOOTING/#getting-help","title":"Getting Help","text":"<p>If you're still stuck:</p> <ol> <li> <p>Check Examples: src/main/java/com/norikv/client/examples/</p> </li> <li> <p>Read API Guide: API_GUIDE.md</p> </li> <li> <p>Check Architecture: ARCHITECTURE.md</p> </li> <li> <p>Run Tests: Verify SDK works in your environment    <pre><code>mvn test\n</code></pre></p> </li> <li> <p>Enable Debug Logging: See detailed error messages</p> </li> <li> <p>File an Issue: GitHub Issues</p> </li> <li>Include: Java version, SDK version, error messages, configuration</li> <li>Provide: Minimal reproducible example</li> </ol>"},{"location":"sdks/java/TROUBLESHOOTING/#see-also","title":"See Also","text":"<ul> <li>API Guide - Complete API reference</li> <li>Architecture Guide - Internal design</li> <li>Advanced Patterns - Complex use cases</li> </ul>"},{"location":"sdks/python/","title":"NoriKV Python Client SDK","text":"<p>Pythonic async client for NoriKV with type hints and context managers.</p>"},{"location":"sdks/python/#status","title":"Status","text":"<p>** PRODUCTION READY** - Fully functional Python SDK</p> <ul> <li>40 tests passing with comprehensive coverage</li> <li>Async/await API built on asyncio</li> <li>Full type hints for mypy checking</li> <li>Context managers for automatic cleanup</li> <li>Cross-SDK hash validation passing</li> </ul>"},{"location":"sdks/python/#quick-start","title":"Quick Start","text":""},{"location":"sdks/python/#installation","title":"Installation","text":"<pre><code>pip install norikv\n</code></pre>"},{"location":"sdks/python/#basic-usage","title":"Basic Usage","text":"<pre><code>import asyncio\nfrom norikv import NoriKVClient, ClientConfig\n\nasync def main():\n    config = ClientConfig(\n        nodes=[\"localhost:9001\", \"localhost:9002\"],\n        total_shards=1024,\n        timeout=5000,\n    )\n\n    async with NoriKVClient(config) as client:\n        # Put a value\n        version = await client.put(\"user:123\", \"Alice\")\n\n        # Get a value\n        result = await client.get(\"user:123\")\n        print(f\"Value: {result.value.decode()}\")\n\n        # Delete\n        await client.delete(\"user:123\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"sdks/python/#documentation","title":"Documentation","text":""},{"location":"sdks/python/#core-guides","title":"Core Guides","text":"<ul> <li>API Guide - Complete API reference</li> <li>Architecture Guide - Internal design</li> <li>Troubleshooting Guide - Common issues</li> <li>Advanced Patterns - Real-world examples</li> </ul>"},{"location":"sdks/python/#features","title":"Features","text":""},{"location":"sdks/python/#core-features","title":"Core Features","text":"<ul> <li>Smart client-side routing</li> <li>Leader-aware routing with failover</li> <li>Automatic retries with exponential backoff</li> <li>Idempotency support</li> <li>CAS operations with version matching</li> <li>Multiple consistency levels</li> <li>Connection pooling</li> <li>Topology tracking</li> </ul>"},{"location":"sdks/python/#python-specific","title":"Python-Specific","text":"<ul> <li>Async/await API with asyncio</li> <li>Type hints throughout</li> <li>Context managers (async with)</li> <li>Pythonic API following PEP 8</li> <li>Compatible with type checkers (mypy, pyright)</li> </ul>"},{"location":"sdks/python/#requirements","title":"Requirements","text":"<ul> <li>Python: 3.9 or higher</li> <li>NoriKV Server: 0.1.x</li> </ul>"},{"location":"sdks/python/#support","title":"Support","text":"<ul> <li>Issues: GitHub Issues</li> <li>Source: GitHub Repository</li> <li>PyPI: norikv</li> </ul>"},{"location":"sdks/python/#license","title":"License","text":"<p>MIT OR Apache-2.0</p>"},{"location":"sdks/python/ADVANCED_PATTERNS/","title":"NoriKV Python Client Advanced Patterns","text":"<p>Complex real-world usage patterns and production-ready design examples with async/await.</p>"},{"location":"sdks/python/ADVANCED_PATTERNS/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Distributed Counter</li> <li>Session Management</li> <li>Inventory Management</li> <li>Caching Layer</li> <li>Rate Limiting</li> <li>Leader Election</li> <li>Event Sourcing</li> <li>Multi-Tenancy</li> </ul>"},{"location":"sdks/python/ADVANCED_PATTERNS/#distributed-counter","title":"Distributed Counter","text":"<p>Implement a high-throughput distributed counter with sharding to reduce contention.</p>"},{"location":"sdks/python/ADVANCED_PATTERNS/#basic-counter","title":"Basic Counter","text":"<pre><code>import asyncio\nfrom norikv import NoriKVClient, VersionMismatchError, KeyNotFoundError\n\nclass DistributedCounter:\n    def __init__(self, client: NoriKVClient, counter_name: str):\n        self.client = client\n        self.key = counter_name\n        self.max_retries = 20\n\n    async def initialize(self) -&gt; None:\n        \"\"\"Initialize counter to 0 if not exists.\"\"\"\n        try:\n            await self.client.get(self.key)\n        except KeyNotFoundError:\n            try:\n                await self.client.put(self.key, b\"0\")\n            except Exception:\n                # Ignore - someone else may have initialized\n                pass\n\n    async def increment(self) -&gt; int:\n        \"\"\"Increment counter by 1.\"\"\"\n        return await self.increment_by(1)\n\n    async def increment_by(self, delta: int) -&gt; int:\n        \"\"\"Increment counter by delta.\"\"\"\n        for attempt in range(self.max_retries):\n            try:\n                # Read current value\n                current = await self.client.get(self.key)\n                value = int(current.value.decode())\n\n                # Increment\n                new_value = value + delta\n\n                # CAS write\n                await self.client.put(\n                    self.key,\n                    str(new_value).encode(),\n                    PutOptions(if_match_version=current.version),\n                )\n\n                return new_value\n\n            except VersionMismatchError:\n                if attempt == self.max_retries - 1:\n                    raise RuntimeError(\n                        f\"Failed to increment after {self.max_retries} attempts\"\n                    )\n\n                # Exponential backoff with jitter\n                backoff = min(2 ** attempt, 1000) / 1000.0\n                jitter = random.random() * 0.1\n                await asyncio.sleep(backoff + jitter)\n\n        raise RuntimeError(\"Should not reach here\")\n\n    async def get(self) -&gt; int:\n        \"\"\"Get current counter value.\"\"\"\n        result = await self.client.get(self.key)\n        return int(result.value.decode())\n</code></pre>"},{"location":"sdks/python/ADVANCED_PATTERNS/#sharded-counter-high-throughput","title":"Sharded Counter (High Throughput)","text":"<p>For very high write rates, distribute writes across multiple shards:</p> <pre><code>import random\nfrom typing import List\n\nclass ShardedCounter:\n    def __init__(\n        self,\n        client: NoriKVClient,\n        name: str,\n        num_shards: int = 10,\n    ):\n        self.client = client\n        self.name = name\n        self.num_shards = num_shards\n\n    def _shard_key(self, shard_id: int) -&gt; str:\n        return f\"{self.name}:shard:{shard_id}\"\n\n    def _random_shard(self) -&gt; int:\n        return random.randint(0, self.num_shards - 1)\n\n    async def increment(self) -&gt; None:\n        \"\"\"Increment counter by 1 on a random shard.\"\"\"\n        shard_id = self._random_shard()\n        key = self._shard_key(shard_id)\n\n        max_retries = 10\n        for attempt in range(max_retries):\n            try:\n                # Read current value\n                current_value = 0\n                current_version = None\n\n                try:\n                    result = await self.client.get(key)\n                    current_value = int(result.value.decode())\n                    current_version = result.version\n                except KeyNotFoundError:\n                    pass\n\n                # Increment\n                new_value = current_value + 1\n                options = (\n                    PutOptions(if_match_version=current_version)\n                    if current_version\n                    else PutOptions()\n                )\n\n                await self.client.put(key, str(new_value).encode(), options)\n                return\n\n            except VersionMismatchError:\n                # Exponential backoff\n                await asyncio.sleep((2 ** attempt) * 0.01)\n\n        raise RuntimeError(\"Increment failed after retries\")\n\n    async def get(self) -&gt; int:\n        \"\"\"Get total count across all shards.\"\"\"\n        # Fetch all shards concurrently\n        tasks = [\n            self._get_shard(i) for i in range(self.num_shards)\n        ]\n        values = await asyncio.gather(*tasks)\n        return sum(values)\n\n    async def _get_shard(self, shard_id: int) -&gt; int:\n        try:\n            result = await self.client.get(self._shard_key(shard_id))\n            return int(result.value.decode())\n        except KeyNotFoundError:\n            return 0\n</code></pre>"},{"location":"sdks/python/ADVANCED_PATTERNS/#usage-example","title":"Usage Example","text":"<pre><code>async def main():\n    async with NoriKVClient(config) as client:\n        # Basic counter\n        counter = DistributedCounter(client, \"api:requests\")\n        await counter.initialize()\n\n        new_count = await counter.increment()\n        print(f\"Request count: {new_count}\")\n\n        # Sharded counter for high throughput\n        sharded = ShardedCounter(client, \"page:views\", num_shards=20)\n\n        # Many concurrent increments\n        await asyncio.gather(\n            *[sharded.increment() for _ in range(1000)]\n        )\n\n        total = await sharded.get()\n        print(f\"Total views: {total}\")\n</code></pre>"},{"location":"sdks/python/ADVANCED_PATTERNS/#session-management","title":"Session Management","text":"<p>Implement secure session storage with automatic expiration using TTL.</p>"},{"location":"sdks/python/ADVANCED_PATTERNS/#session-manager","title":"Session Manager","text":"<pre><code>import json\nimport uuid\nfrom dataclasses import dataclass, asdict\nfrom typing import Optional, Callable\n\n@dataclass\nclass SessionData:\n    user_id: str\n    email: str\n    roles: list[str]\n    created_at: int\n    last_accessed_at: int\n\nclass SessionManager:\n    def __init__(self, client: NoriKVClient, ttl_ms: int = 3600000):\n        self.client = client\n        self.ttl_ms = ttl_ms  # Default: 1 hour\n        self.prefix = \"session\"\n\n    def _session_key(self, session_id: str) -&gt; str:\n        return f\"{self.prefix}:{session_id}\"\n\n    async def create(\n        self,\n        user_id: str,\n        email: str,\n        roles: list[str],\n    ) -&gt; str:\n        \"\"\"Create a new session.\"\"\"\n        session_id = str(uuid.uuid4())\n        key = self._session_key(session_id)\n\n        data = SessionData(\n            user_id=user_id,\n            email=email,\n            roles=roles,\n            created_at=int(time.time() * 1000),\n            last_accessed_at=int(time.time() * 1000),\n        )\n\n        await self.client.put(\n            key,\n            json.dumps(asdict(data)).encode(),\n            PutOptions(\n                ttl_ms=self.ttl_ms,\n                idempotency_key=f\"session-create-{session_id}\",\n            ),\n        )\n\n        return session_id\n\n    async def get(self, session_id: str) -&gt; Optional[SessionData]:\n        \"\"\"Get session data, updating last accessed time.\"\"\"\n        try:\n            result = await self.client.get(self._session_key(session_id))\n            data_dict = json.loads(result.value.decode())\n            data = SessionData(**data_dict)\n\n            # Update last accessed time\n            data.last_accessed_at = int(time.time() * 1000)\n            await self.client.put(\n                self._session_key(session_id),\n                json.dumps(asdict(data)).encode(),\n                PutOptions(ttl_ms=self.ttl_ms),  # Reset TTL\n            )\n\n            return data\n\n        except KeyNotFoundError:\n            return None\n\n    async def update(\n        self,\n        session_id: str,\n        update_fn: Callable[[SessionData], SessionData],\n    ) -&gt; bool:\n        \"\"\"Update session with CAS.\"\"\"\n        max_retries = 5\n\n        for attempt in range(max_retries):\n            try:\n                result = await self.client.get(self._session_key(session_id))\n                data_dict = json.loads(result.value.decode())\n                data = SessionData(**data_dict)\n\n                # Apply update\n                updated = update_fn(data)\n                updated.last_accessed_at = int(time.time() * 1000)\n\n                # CAS write\n                await self.client.put(\n                    self._session_key(session_id),\n                    json.dumps(asdict(updated)).encode(),\n                    PutOptions(\n                        if_match_version=result.version,\n                        ttl_ms=self.ttl_ms,\n                    ),\n                )\n\n                return True\n\n            except KeyNotFoundError:\n                return False\n\n            except VersionMismatchError:\n                await asyncio.sleep((2 ** attempt) * 0.01)\n\n        return False\n\n    async def destroy(self, session_id: str) -&gt; bool:\n        \"\"\"Delete session.\"\"\"\n        try:\n            return await self.client.delete(\n                self._session_key(session_id),\n                DeleteOptions(idempotency_key=f\"session-destroy-{session_id}\"),\n            )\n        except KeyNotFoundError:\n            return False\n\n    async def validate(self, session_id: str) -&gt; bool:\n        \"\"\"Check if session exists.\"\"\"\n        try:\n            await self.client.get(self._session_key(session_id))\n            return True\n        except KeyNotFoundError:\n            return False\n</code></pre>"},{"location":"sdks/python/ADVANCED_PATTERNS/#usage-example_1","title":"Usage Example","text":"<pre><code>import time\n\nsessions = SessionManager(client, ttl_ms=1800000)  # 30 min\n\n# Create session\nsession_id = await sessions.create(\n    \"user123\",\n    \"alice@example.com\",\n    [\"user\", \"admin\"],\n)\n\n# Middleware: validate session\nasync def auth_middleware(request):\n    session_id = request.cookies.get(\"session_id\")\n\n    session_data = await sessions.get(session_id)\n    if not session_data:\n        raise Unauthorized(\"Invalid session\")\n\n    request.user = session_data\n\n# Update session\nawait sessions.update(\n    session_id,\n    lambda data: SessionData(\n        **{**asdict(data), \"roles\": data.roles + [\"premium\"]}\n    ),\n)\n\n# Destroy session\nawait sessions.destroy(session_id)\n</code></pre>"},{"location":"sdks/python/ADVANCED_PATTERNS/#inventory-management","title":"Inventory Management","text":"<p>Prevent overselling with optimistic concurrency control.</p>"},{"location":"sdks/python/ADVANCED_PATTERNS/#inventory-system","title":"Inventory System","text":"<pre><code>from dataclasses import dataclass\nimport time\n\n@dataclass\nclass InventoryItem:\n    sku: str\n    quantity: int\n    reserved: int\n    last_updated: int\n\nclass InventoryManager:\n    def __init__(self, client: NoriKVClient):\n        self.client = client\n        self.prefix = \"inventory\"\n\n    def _item_key(self, sku: str) -&gt; str:\n        return f\"{self.prefix}:{sku}\"\n\n    def _reservation_key(self, reservation_id: str) -&gt; str:\n        return f\"{self.prefix}:reservation:{reservation_id}\"\n\n    async def create_item(self, sku: str, initial_quantity: int) -&gt; None:\n        \"\"\"Create inventory item.\"\"\"\n        item = InventoryItem(\n            sku=sku,\n            quantity=initial_quantity,\n            reserved=0,\n            last_updated=int(time.time() * 1000),\n        )\n\n        await self.client.put(\n            self._item_key(sku),\n            json.dumps(asdict(item)).encode(),\n        )\n\n    async def reserve(self, sku: str, quantity: int) -&gt; str:\n        \"\"\"Reserve quantity for purchase.\"\"\"\n        reservation_id = str(uuid.uuid4())\n        max_retries = 10\n\n        for attempt in range(max_retries):\n            try:\n                # Read current inventory\n                result = await self.client.get(self._item_key(sku))\n                item_dict = json.loads(result.value.decode())\n                item = InventoryItem(**item_dict)\n\n                # Check availability\n                available = item.quantity - item.reserved\n                if available &lt; quantity:\n                    raise ValueError(\n                        f\"Insufficient inventory: need {quantity}, have {available}\"\n                    )\n\n                # Reserve quantity\n                item.reserved += quantity\n                item.last_updated = int(time.time() * 1000)\n\n                # CAS write\n                await self.client.put(\n                    self._item_key(sku),\n                    json.dumps(asdict(item)).encode(),\n                    PutOptions(if_match_version=result.version),\n                )\n\n                # Store reservation\n                reservation = {\n                    \"sku\": sku,\n                    \"quantity\": quantity,\n                    \"created_at\": int(time.time() * 1000),\n                }\n                await self.client.put(\n                    self._reservation_key(reservation_id),\n                    json.dumps(reservation).encode(),\n                    PutOptions(ttl_ms=600000),  # 10 min expiration\n                )\n\n                return reservation_id\n\n            except VersionMismatchError:\n                if attempt == max_retries - 1:\n                    raise RuntimeError(\"Failed to reserve after retries\")\n\n                await asyncio.sleep((2 ** attempt) * 0.01)\n\n        raise RuntimeError(\"Should not reach here\")\n\n    async def commit(self, reservation_id: str) -&gt; None:\n        \"\"\"Commit reservation (finalize purchase).\"\"\"\n        max_retries = 10\n\n        # Get reservation details\n        reservation_key = self._reservation_key(reservation_id)\n        res_result = await self.client.get(reservation_key)\n        reservation = json.loads(res_result.value.decode())\n\n        for attempt in range(max_retries):\n            try:\n                # Read current inventory\n                result = await self.client.get(self._item_key(reservation[\"sku\"]))\n                item_dict = json.loads(result.value.decode())\n                item = InventoryItem(**item_dict)\n\n                # Commit: reduce both quantity and reserved\n                item.quantity -= reservation[\"quantity\"]\n                item.reserved -= reservation[\"quantity\"]\n                item.last_updated = int(time.time() * 1000)\n\n                # CAS write\n                await self.client.put(\n                    self._item_key(reservation[\"sku\"]),\n                    json.dumps(asdict(item)).encode(),\n                    PutOptions(if_match_version=result.version),\n                )\n\n                # Delete reservation\n                await self.client.delete(reservation_key)\n                return\n\n            except VersionMismatchError:\n                await asyncio.sleep((2 ** attempt) * 0.01)\n\n        raise RuntimeError(\"Failed to commit reservation\")\n\n    async def release(self, reservation_id: str) -&gt; None:\n        \"\"\"Release reservation (cancel purchase).\"\"\"\n        max_retries = 10\n\n        # Get reservation details\n        reservation_key = self._reservation_key(reservation_id)\n        res_result = await self.client.get(reservation_key)\n        reservation = json.loads(res_result.value.decode())\n\n        for attempt in range(max_retries):\n            try:\n                # Read current inventory\n                result = await self.client.get(self._item_key(reservation[\"sku\"]))\n                item_dict = json.loads(result.value.decode())\n                item = InventoryItem(**item_dict)\n\n                # Release: reduce reserved only\n                item.reserved -= reservation[\"quantity\"]\n                item.last_updated = int(time.time() * 1000)\n\n                # CAS write\n                await self.client.put(\n                    self._item_key(reservation[\"sku\"]),\n                    json.dumps(asdict(item)).encode(),\n                    PutOptions(if_match_version=result.version),\n                )\n\n                # Delete reservation\n                await self.client.delete(reservation_key)\n                return\n\n            except VersionMismatchError:\n                await asyncio.sleep((2 ** attempt) * 0.01)\n\n        raise RuntimeError(\"Failed to release reservation\")\n\n    async def get_available(self, sku: str) -&gt; int:\n        \"\"\"Get available quantity.\"\"\"\n        result = await self.client.get(self._item_key(sku))\n        item_dict = json.loads(result.value.decode())\n        item = InventoryItem(**item_dict)\n        return item.quantity - item.reserved\n</code></pre>"},{"location":"sdks/python/ADVANCED_PATTERNS/#usage-example_2","title":"Usage Example","text":"<pre><code>inventory = InventoryManager(client)\n\n# Initialize inventory\nawait inventory.create_item(\"SKU-12345\", 100)\n\n# Purchase flow\nasync def purchase_item(sku: str, quantity: int):\n    # 1. Reserve inventory\n    reservation_id = await inventory.reserve(sku, quantity)\n\n    try:\n        # 2. Process payment\n        await process_payment()\n\n        # 3. Commit reservation\n        await inventory.commit(reservation_id)\n        print(\"Purchase successful\")\n\n    except Exception as err:\n        # 4. Release reservation on failure\n        await inventory.release(reservation_id)\n        print(f\"Purchase failed: {err}\")\n        raise\n\n# Check availability\navailable = await inventory.get_available(\"SKU-12345\")\nprint(f\"Available: {available}\")\n</code></pre>"},{"location":"sdks/python/ADVANCED_PATTERNS/#caching-layer","title":"Caching Layer","text":"<p>Implement a write-through cache with automatic invalidation.</p>"},{"location":"sdks/python/ADVANCED_PATTERNS/#cache-implementation","title":"Cache Implementation","text":"<pre><code>from typing import TypeVar, Generic, Callable, Optional\nfrom dataclasses import dataclass\nimport time\n\nT = TypeVar(\"T\")\n\n@dataclass\nclass CacheEntry(Generic[T]):\n    value: T\n    version: Version\n    cached_at: int\n\nclass CachedClient(Generic[T]):\n    def __init__(\n        self,\n        client: NoriKVClient,\n        ttl_ms: int = 60000,\n        max_size: int = 1000,\n    ):\n        self.client = client\n        self.cache: dict[str, CacheEntry[T]] = {}\n        self.ttl_ms = ttl_ms\n        self.max_size = max_size\n\n    async def get(\n        self,\n        key: str,\n        parser: Callable[[bytes], T],\n    ) -&gt; T:\n        \"\"\"Get value with caching.\"\"\"\n        # Check cache\n        cached = self.cache.get(key)\n        now = int(time.time() * 1000)\n\n        if cached and (now - cached.cached_at) &lt; self.ttl_ms:\n            return cached.value\n\n        # Cache miss - fetch from NoriKV\n        result = await self.client.get(key)\n        value = parser(result.value)\n\n        # Update cache\n        self._set_cache(key, CacheEntry(\n            value=value,\n            version=result.version,\n            cached_at=now,\n        ))\n\n        return value\n\n    async def put(\n        self,\n        key: str,\n        value: T,\n        serializer: Callable[[T], bytes],\n    ) -&gt; Version:\n        \"\"\"Write-through to NoriKV.\"\"\"\n        # Write-through to NoriKV\n        version = await self.client.put(key, serializer(value))\n\n        # Update cache\n        self._set_cache(key, CacheEntry(\n            value=value,\n            version=version,\n            cached_at=int(time.time() * 1000),\n        ))\n\n        return version\n\n    async def delete(self, key: str) -&gt; bool:\n        \"\"\"Delete with cache invalidation.\"\"\"\n        # Invalidate cache\n        self.cache.pop(key, None)\n\n        # Delete from NoriKV\n        return await self.client.delete(key)\n\n    def invalidate(self, key: str) -&gt; None:\n        \"\"\"Invalidate cache entry.\"\"\"\n        self.cache.pop(key, None)\n\n    def invalidate_all(self) -&gt; None:\n        \"\"\"Invalidate all cache entries.\"\"\"\n        self.cache.clear()\n\n    def _set_cache(self, key: str, entry: CacheEntry[T]) -&gt; None:\n        \"\"\"LRU eviction.\"\"\"\n        if len(self.cache) &gt;= self.max_size:\n            # Remove oldest entry (first key)\n            first_key = next(iter(self.cache))\n            self.cache.pop(first_key)\n\n        self.cache[key] = entry\n\n    def get_stats(self) -&gt; dict:\n        return {\n            \"size\": len(self.cache),\n            \"max_size\": self.max_size,\n            \"ttl_ms\": self.ttl_ms,\n        }\n</code></pre>"},{"location":"sdks/python/ADVANCED_PATTERNS/#usage-example_3","title":"Usage Example","text":"<pre><code>@dataclass\nclass UserProfile:\n    id: str\n    name: str\n    email: str\n\ncache = CachedClient[UserProfile](client, ttl_ms=60000, max_size=1000.md)\n\n# Get with automatic caching\nprofile = await cache.get(\n    \"user:123\",\n    lambda b: UserProfile(**json.loads(b.decode())),\n)\n\n# Write-through cache\nawait cache.put(\n    \"user:123\",\n    UserProfile(id=\"123\", name=\"Alice\", email=\"alice@example.com\"),\n    lambda p: json.dumps(asdict(p)).encode(),\n)\n\n# Manual invalidation\ncache.invalidate(\"user:123\")\n\n# Check stats\nstats = cache.get_stats()\nprint(f\"Cache stats: {stats}\")\n</code></pre>"},{"location":"sdks/python/ADVANCED_PATTERNS/#rate-limiting","title":"Rate Limiting","text":"<p>Implement sliding window rate limiting for API throttling.</p>"},{"location":"sdks/python/ADVANCED_PATTERNS/#rate-limiter","title":"Rate Limiter","text":"<pre><code>from dataclasses import dataclass\n\n@dataclass\nclass RateLimitConfig:\n    max_requests: int\n    window_ms: int\n\nclass RateLimiter:\n    def __init__(self, client: NoriKVClient):\n        self.client = client\n        self.prefix = \"ratelimit\"\n\n    def _key(self, identifier: str) -&gt; str:\n        return f\"{self.prefix}:{identifier}\"\n\n    async def check_limit(\n        self,\n        identifier: str,\n        config: RateLimitConfig,\n    ) -&gt; dict:\n        \"\"\"Check if request is within rate limit.\"\"\"\n        key = self._key(identifier)\n        now = int(time.time() * 1000)\n        window_start = now - config.window_ms\n\n        max_retries = 5\n        for attempt in range(max_retries):\n            try:\n                timestamps: list[int] = []\n                version = None\n\n                # Read current timestamps\n                try:\n                    result = await self.client.get(key)\n                    timestamps = json.loads(result.value.decode())\n                    version = result.version\n                except KeyNotFoundError:\n                    pass\n\n                # Remove old timestamps outside window\n                timestamps = [ts for ts in timestamps if ts &gt; window_start]\n\n                # Check if limit exceeded\n                allowed = len(timestamps) &lt; config.max_requests\n\n                if allowed:\n                    # Add current timestamp\n                    timestamps.append(now)\n\n                    # Save updated timestamps\n                    options = (\n                        PutOptions(\n                            if_match_version=version,\n                            ttl_ms=config.window_ms,\n                        )\n                        if version\n                        else PutOptions(ttl_ms=config.window_ms)\n                    )\n\n                    await self.client.put(\n                        key,\n                        json.dumps(timestamps).encode(),\n                        options,\n                    )\n\n                return {\n                    \"allowed\": allowed,\n                    \"remaining\": max(0, config.max_requests - len(timestamps)),\n                    \"reset_at\": (\n                        min(timestamps) + config.window_ms\n                        if timestamps\n                        else now + config.window_ms\n                    ),\n                }\n\n            except VersionMismatchError:\n                await asyncio.sleep((2 ** attempt) * 0.01)\n\n        raise RuntimeError(\"Rate limit check failed after retries\")\n\n    async def reset(self, identifier: str) -&gt; None:\n        \"\"\"Reset rate limit for identifier.\"\"\"\n        await self.client.delete(self._key(identifier))\n</code></pre>"},{"location":"sdks/python/ADVANCED_PATTERNS/#fastapi-middleware-example","title":"FastAPI Middleware Example","text":"<pre><code>from fastapi import FastAPI, Request, HTTPException\nfrom fastapi.responses import JSONResponse\n\napp = FastAPI()\nrate_limiter = RateLimiter(client)\n\n@app.middleware(\"http\")\nasync def rate_limit_middleware(request: Request, call_next):\n    # Use IP address or user ID as identifier\n    identifier = request.client.host\n\n    config = RateLimitConfig(\n        max_requests=100,\n        window_ms=60000,  # 100 requests per minute\n    )\n\n    try:\n        result = await rate_limiter.check_limit(identifier, config)\n\n        # Set rate limit headers\n        response = await call_next(request)\n        response.headers[\"X-RateLimit-Limit\"] = str(config.max_requests)\n        response.headers[\"X-RateLimit-Remaining\"] = str(result[\"remaining\"])\n        response.headers[\"X-RateLimit-Reset\"] = str(result[\"reset_at\"])\n\n        if not result[\"allowed\"]:\n            return JSONResponse(\n                status_code=429,\n                content={\n                    \"error\": \"Too Many Requests\",\n                    \"retry_after\": (result[\"reset_at\"] - int(time.time() * 1000)) // 1000,\n                },\n            )\n\n        return response\n\n    except Exception as err:\n        print(f\"Rate limit error: {err}\")\n        return await call_next(request)  # Fail open\n</code></pre>"},{"location":"sdks/python/ADVANCED_PATTERNS/#leader-election","title":"Leader Election","text":"<p>Implement distributed leader election with automatic failover.</p>"},{"location":"sdks/python/ADVANCED_PATTERNS/#leader-election_1","title":"Leader Election","text":"<pre><code>class LeaderElection:\n    def __init__(\n        self,\n        client: NoriKVClient,\n        election_name: str,\n        node_id: str,\n        lease_ttl_ms: int = 10000,\n    ):\n        self.client = client\n        self.name = election_name\n        self.node_id = node_id\n        self.lease_ttl_ms = lease_ttl_ms\n        self.running = False\n        self.is_leader = False\n        self.heartbeat_task: Optional[asyncio.Task] = None\n\n    def _leader_key(self) -&gt; str:\n        return f\"leader:{self.name}\"\n\n    async def start(\n        self,\n        on_became_leader: Optional[Callable[[], None]] = None,\n        on_lost_leadership: Optional[Callable[[], None]] = None,\n    ) -&gt; None:\n        \"\"\"Start leader election.\"\"\"\n        self.running = True\n\n        while self.running:\n            try:\n                await self._try_acquire_lease()\n\n                if self.is_leader:\n                    if on_became_leader:\n                        on_became_leader()\n\n                    # Start heartbeat\n                    await self._maintain_lease()\n                else:\n                    # Wait before retrying\n                    await asyncio.sleep(self.lease_ttl_ms / 2000.0)\n\n            except Exception as err:\n                print(f\"Leader election error: {err}\")\n\n                if self.is_leader and on_lost_leadership:\n                    on_lost_leadership()\n\n                self.is_leader = False\n                await asyncio.sleep(1)\n\n    async def stop(self) -&gt; None:\n        \"\"\"Stop leader election.\"\"\"\n        self.running = False\n\n        if self.heartbeat_task:\n            self.heartbeat_task.cancel()\n            try:\n                await self.heartbeat_task\n            except asyncio.CancelledError:\n                pass\n\n        if self.is_leader:\n            await self._release_lease()\n\n    async def _try_acquire_lease(self) -&gt; None:\n        \"\"\"Try to acquire leadership lease.\"\"\"\n        key = self._leader_key()\n\n        try:\n            # Try to read current leader\n            result = await self.client.get(key)\n            current_leader = result.value.decode()\n\n            if current_leader == self.node_id:\n                self.is_leader = True\n\n        except KeyNotFoundError:\n            # No leader - try to become leader\n            try:\n                await self.client.put(\n                    key,\n                    self.node_id.encode(),\n                    PutOptions(ttl_ms=self.lease_ttl_ms),\n                )\n                self.is_leader = True\n            except Exception:\n                # Someone else became leader\n                self.is_leader = False\n\n    async def _maintain_lease(self) -&gt; None:\n        \"\"\"Maintain leadership lease with heartbeat.\"\"\"\n        refresh_interval = self.lease_ttl_ms / 3000.0\n\n        while self.is_leader and self.running:\n            try:\n                await asyncio.sleep(refresh_interval)\n\n                await self.client.put(\n                    self._leader_key(),\n                    self.node_id.encode(),\n                    PutOptions(ttl_ms=self.lease_ttl_ms),\n                )\n\n            except Exception as err:\n                print(f\"Failed to refresh lease: {err}\")\n                self.is_leader = False\n                break\n\n    async def _release_lease(self) -&gt; None:\n        \"\"\"Release leadership lease.\"\"\"\n        try:\n            await self.client.delete(self._leader_key())\n        except Exception as err:\n            print(f\"Failed to release lease: {err}\")\n\n    def get_is_leader(self) -&gt; bool:\n        return self.is_leader\n</code></pre>"},{"location":"sdks/python/ADVANCED_PATTERNS/#usage-example_4","title":"Usage Example","text":"<pre><code>election = LeaderElection(client, \"my-service\", \"node-1\", lease_ttl_ms=10000)\n\ndef on_became_leader():\n    print(\"Became leader - starting background tasks\")\n    start_background_jobs()\n\ndef on_lost_leadership():\n    print(\"Lost leadership - stopping background tasks\")\n    stop_background_jobs()\n\n# Start election in background\nasyncio.create_task(election.start(on_became_leader, on_lost_leadership))\n\n# Check leadership\nif election.get_is_leader():\n    print(\"I am the leader\")\n\n# Graceful shutdown\nawait election.stop()\n</code></pre>"},{"location":"sdks/python/ADVANCED_PATTERNS/#event-sourcing","title":"Event Sourcing","text":"<p>Implement event sourcing pattern for audit logs and state reconstruction.</p>"},{"location":"sdks/python/ADVANCED_PATTERNS/#event-store","title":"Event Store","text":"<pre><code>from dataclasses import dataclass\nfrom typing import Any\n\n@dataclass\nclass Event:\n    id: str\n    aggregate_id: str\n    type: str\n    data: dict[str, Any]\n    timestamp: int\n    version: int\n\nclass EventStore:\n    def __init__(self, client: NoriKVClient):\n        self.client = client\n        self.prefix = \"events\"\n\n    def _event_key(self, aggregate_id: str, version: int) -&gt; str:\n        return f\"{self.prefix}:{aggregate_id}:{version}\"\n\n    def _metadata_key(self, aggregate_id: str) -&gt; str:\n        return f\"{self.prefix}:meta:{aggregate_id}\"\n\n    async def append(\n        self,\n        aggregate_id: str,\n        event_type: str,\n        data: dict[str, Any],\n    ) -&gt; Event:\n        \"\"\"Append event to aggregate.\"\"\"\n        max_retries = 10\n\n        for attempt in range(max_retries):\n            try:\n                # Read current version\n                current_version = 0\n                meta_version = None\n\n                try:\n                    meta = await self.client.get(self._metadata_key(aggregate_id))\n                    metadata = json.loads(meta.value.decode())\n                    current_version = metadata[\"version\"]\n                    meta_version = meta.version\n                except KeyNotFoundError:\n                    pass\n\n                new_version = current_version + 1\n\n                # Create event\n                event = Event(\n                    id=str(uuid.uuid4()),\n                    aggregate_id=aggregate_id,\n                    type=event_type,\n                    data=data,\n                    timestamp=int(time.time() * 1000),\n                    version=new_version,\n                )\n\n                # Write event\n                await self.client.put(\n                    self._event_key(aggregate_id, new_version),\n                    json.dumps(asdict(event)).encode(),\n                )\n\n                # Update metadata with CAS\n                options = (\n                    PutOptions(if_match_version=meta_version)\n                    if meta_version\n                    else PutOptions()\n                )\n                await self.client.put(\n                    self._metadata_key(aggregate_id),\n                    json.dumps({\"version\": new_version}).encode(),\n                    options,\n                )\n\n                return event\n\n            except VersionMismatchError:\n                await asyncio.sleep((2 ** attempt) * 0.01)\n\n        raise RuntimeError(\"Failed to append event after retries\")\n\n    async def get_events(self, aggregate_id: str) -&gt; list[Event]:\n        \"\"\"Get all events for aggregate.\"\"\"\n        try:\n            meta = await self.client.get(self._metadata_key(aggregate_id))\n            metadata = json.loads(meta.value.decode())\n            current_version = metadata[\"version\"]\n\n            # Fetch all events concurrently\n            tasks = [\n                self.client.get(self._event_key(aggregate_id, i + 1))\n                for i in range(current_version)\n            ]\n\n            results = await asyncio.gather(*tasks)\n            return [\n                Event(**json.loads(r.value.decode()))\n                for r in results\n            ]\n\n        except KeyNotFoundError:\n            return []\n\n    async def get_events_after(\n        self,\n        aggregate_id: str,\n        after_version: int,\n    ) -&gt; list[Event]:\n        \"\"\"Get events after specific version.\"\"\"\n        all_events = await self.get_events(aggregate_id)\n        return [e for e in all_events if e.version &gt; after_version]\n</code></pre>"},{"location":"sdks/python/ADVANCED_PATTERNS/#aggregate-example","title":"Aggregate Example","text":"<pre><code>@dataclass\nclass BankAccount:\n    id: str\n    balance: int\n    is_open: bool\n\nclass BankAccountAggregate:\n    def __init__(self, store: EventStore, account_id: str):\n        self.store = store\n        self.state = BankAccount(\n            id=account_id,\n            balance=0,\n            is_open=False,\n        )\n\n    async def load(self) -&gt; None:\n        \"\"\"Load aggregate from event history.\"\"\"\n        events = await self.store.get_events(self.state.id)\n\n        for event in events:\n            self._apply(event)\n\n    async def open_account(self) -&gt; None:\n        \"\"\"Open bank account.\"\"\"\n        if self.state.is_open:\n            raise ValueError(\"Account already open\")\n\n        event = await self.store.append(self.state.id, \"AccountOpened\", {})\n        self._apply(event)\n\n    async def deposit(self, amount: int) -&gt; None:\n        \"\"\"Deposit money.\"\"\"\n        if not self.state.is_open:\n            raise ValueError(\"Account not open\")\n\n        event = await self.store.append(\n            self.state.id,\n            \"MoneyDeposited\",\n            {\"amount\": amount},\n        )\n        self._apply(event)\n\n    async def withdraw(self, amount: int) -&gt; None:\n        \"\"\"Withdraw money.\"\"\"\n        if not self.state.is_open:\n            raise ValueError(\"Account not open\")\n\n        if self.state.balance &lt; amount:\n            raise ValueError(\"Insufficient funds\")\n\n        event = await self.store.append(\n            self.state.id,\n            \"MoneyWithdrawn\",\n            {\"amount\": amount},\n        )\n        self._apply(event)\n\n    def _apply(self, event: Event) -&gt; None:\n        \"\"\"Apply event to state.\"\"\"\n        if event.type == \"AccountOpened\":\n            self.state.is_open = True\n        elif event.type == \"MoneyDeposited\":\n            self.state.balance += event.data[\"amount\"]\n        elif event.type == \"MoneyWithdrawn\":\n            self.state.balance -= event.data[\"amount\"]\n\n    def get_balance(self) -&gt; int:\n        return self.state.balance\n</code></pre>"},{"location":"sdks/python/ADVANCED_PATTERNS/#usage-example_5","title":"Usage Example","text":"<pre><code>event_store = EventStore(client)\n\naccount = BankAccountAggregate(event_store, \"account-123\")\n\n# Replay history\nawait account.load()\n\n# Execute commands (generates events)\nawait account.open_account()\nawait account.deposit(100)\nawait account.withdraw(30)\n\nprint(f\"Balance: {account.get_balance()}\")  # 70\n\n# Audit trail\nevents = await event_store.get_events(\"account-123\")\nprint(f\"Event history: {events}\")\n</code></pre>"},{"location":"sdks/python/ADVANCED_PATTERNS/#multi-tenancy","title":"Multi-Tenancy","text":"<p>Implement tenant isolation with namespace prefixing.</p>"},{"location":"sdks/python/ADVANCED_PATTERNS/#tenant-client","title":"Tenant Client","text":"<pre><code>class TenantClient:\n    def __init__(self, client: NoriKVClient, tenant_id: str):\n        self.client = client\n        self.tenant_id = tenant_id\n\n    def _tenant_key(self, key: str) -&gt; str:\n        return f\"tenant:{self.tenant_id}:{key}\"\n\n    async def put(\n        self,\n        key: str,\n        value: bytes,\n        options: Optional[PutOptions] = None,\n    ) -&gt; Version:\n        return await self.client.put(self._tenant_key(key), value, options)\n\n    async def get(\n        self,\n        key: str,\n        options: Optional[GetOptions] = None,\n    ) -&gt; GetResult:\n        return await self.client.get(self._tenant_key(key), options)\n\n    async def delete(\n        self,\n        key: str,\n        options: Optional[DeleteOptions] = None,\n    ) -&gt; bool:\n        return await self.client.delete(self._tenant_key(key), options)\n\n    def get_tenant_id(self) -&gt; str:\n        return self.tenant_id\n</code></pre>"},{"location":"sdks/python/ADVANCED_PATTERNS/#tenant-manager","title":"Tenant Manager","text":"<pre><code>from typing import Literal\n\n@dataclass\nclass TenantMetadata:\n    id: str\n    name: str\n    plan: Literal[\"free\", \"pro\", \"enterprise\"]\n    created_at: int\n    limits: dict[str, int]\n\nclass TenantManager:\n    def __init__(self, client: NoriKVClient):\n        self.client = client\n        self.prefix = \"tenant-meta\"\n\n    def _metadata_key(self, tenant_id: str) -&gt; str:\n        return f\"{self.prefix}:{tenant_id}\"\n\n    async def create(\n        self,\n        tenant_id: str,\n        name: str,\n        plan: Literal[\"free\", \"pro\", \"enterprise\"],\n    ) -&gt; TenantMetadata:\n        \"\"\"Create tenant.\"\"\"\n        limits = self._get_limits_for_plan(plan)\n\n        metadata = TenantMetadata(\n            id=tenant_id,\n            name=name,\n            plan=plan,\n            created_at=int(time.time() * 1000),\n            limits=limits,\n        )\n\n        await self.client.put(\n            self._metadata_key(tenant_id),\n            json.dumps(asdict(metadata)).encode(),\n        )\n\n        return metadata\n\n    async def get(self, tenant_id: str) -&gt; Optional[TenantMetadata]:\n        \"\"\"Get tenant metadata.\"\"\"\n        try:\n            result = await self.client.get(self._metadata_key(tenant_id))\n            data = json.loads(result.value.decode())\n            return TenantMetadata(**data)\n        except KeyNotFoundError:\n            return None\n\n    async def get_client(self, tenant_id: str) -&gt; TenantClient:\n        \"\"\"Get tenant-scoped client.\"\"\"\n        metadata = await self.get(tenant_id)\n        if not metadata:\n            raise ValueError(f\"Tenant not found: {tenant_id}\")\n\n        return TenantClient(self.client, tenant_id)\n\n    def _get_limits_for_plan(self, plan: str) -&gt; dict[str, int]:\n        limits_map = {\n            \"free\": {\"max_keys\": 1000, \"max_storage_mb\": 10},\n            \"pro\": {\"max_keys\": 100000, \"max_storage_mb\": 1000},\n            \"enterprise\": {\"max_keys\": float(\"inf\"), \"max_storage_mb\": float(\"inf\")},\n        }\n        return limits_map.get(plan, limits_map[\"free\"])\n</code></pre>"},{"location":"sdks/python/ADVANCED_PATTERNS/#fastapi-integration","title":"FastAPI Integration","text":"<pre><code>from fastapi import FastAPI, Header, HTTPException\n\napp = FastAPI()\ntenant_manager = TenantManager(client)\n\nasync def get_tenant_client(x_tenant_id: str = Header(...)) -&gt; TenantClient:\n    \"\"\"Dependency to extract tenant client from header.\"\"\"\n    try:\n        return await tenant_manager.get_client(x_tenant_id)\n    except ValueError:\n        raise HTTPException(status_code=404, detail=\"Tenant not found\")\n\n@app.get(\"/api/data/{key}\")\nasync def get_data(key: str, tenant_client: TenantClient = Depends(get_tenant_client)):\n    try:\n        result = await tenant_client.get(key)\n        return {\"value\": result.value.decode()}\n    except KeyNotFoundError:\n        raise HTTPException(status_code=404, detail=\"Not found\")\n\n@app.post(\"/api/data/{key}\")\nasync def set_data(\n    key: str,\n    value: str,\n    tenant_client: TenantClient = Depends(get_tenant_client),\n):\n    await tenant_client.put(key, value.encode())\n    return {\"success\": True}\n</code></pre>"},{"location":"sdks/python/ADVANCED_PATTERNS/#usage-example_6","title":"Usage Example","text":"<pre><code># Create tenants\nawait tenant_manager.create(\"tenant-acme\", \"Acme Corp\", \"pro\")\nawait tenant_manager.create(\"tenant-widgets\", \"Widgets Inc\", \"enterprise\")\n\n# Get tenant-scoped clients\nacme_client = await tenant_manager.get_client(\"tenant-acme\")\nwidgets_client = await tenant_manager.get_client(\"tenant-widgets\")\n\n# Isolated operations\nawait acme_client.put(\"config\", b\"acme-config\")\nawait widgets_client.put(\"config\", b\"widgets-config\")\n\n# Data is isolated\nacme_config = await acme_client.get(\"config\")  # b\"acme-config\"\nwidgets_config = await widgets_client.get(\"config\")  # b\"widgets-config\"\n</code></pre>"},{"location":"sdks/python/ADVANCED_PATTERNS/#best-practices","title":"Best Practices","text":""},{"location":"sdks/python/ADVANCED_PATTERNS/#1-always-use-context-managers","title":"1. Always Use Context Managers","text":"<pre><code>async with NoriKVClient(config) as client:\n    await client.put(key, value)\n</code></pre>"},{"location":"sdks/python/ADVANCED_PATTERNS/#2-implement-retry-logic-for-cas","title":"2. Implement Retry Logic for CAS","text":"<pre><code>async def cas_retry(operation, max_retries: int = 10):\n    for attempt in range(max_retries):\n        try:\n            return await operation()\n        except VersionMismatchError:\n            if attempt == max_retries - 1:\n                raise\n            await asyncio.sleep((2 ** attempt) * 0.01)\n</code></pre>"},{"location":"sdks/python/ADVANCED_PATTERNS/#3-use-type-hints","title":"3. Use Type Hints","text":"<pre><code>from typing import Optional\n\nasync def get_user(key: str) -&gt; Optional[dict]:\n    try:\n        result = await client.get(key)\n        return json.loads(result.value.decode())\n    except KeyNotFoundError:\n        return None\n</code></pre>"},{"location":"sdks/python/ADVANCED_PATTERNS/#4-clean-up-resources","title":"4. Clean Up Resources","text":"<pre><code>async with NoriKVClient(config) as client:\n    # Client automatically closed\n    await client.put(key, value)\n</code></pre>"},{"location":"sdks/python/ADVANCED_PATTERNS/#5-use-idempotency-keys-for-critical-operations","title":"5. Use Idempotency Keys for Critical Operations","text":"<pre><code>await client.put(\n    key,\n    value,\n    PutOptions(idempotency_key=f\"operation-{operation_id}\"),\n)\n</code></pre>"},{"location":"sdks/python/ADVANCED_PATTERNS/#next-steps","title":"Next Steps","text":"<ul> <li>API Guide - Core API reference</li> <li>Architecture Guide - Internal design</li> <li>Troubleshooting Guide - Common issues</li> <li>GitHub Examples - More code samples</li> </ul>"},{"location":"sdks/python/API_GUIDE/","title":"NoriKV Python Client API Guide","text":"<p>Complete reference for the NoriKV Python Client SDK with async/await support.</p>"},{"location":"sdks/python/API_GUIDE/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Installation</li> <li>Quick Start</li> <li>Client Configuration</li> <li>Core Operations</li> <li>Advanced Features</li> <li>Error Handling</li> <li>Best Practices</li> </ul>"},{"location":"sdks/python/API_GUIDE/#installation","title":"Installation","text":"<pre><code>pip install norikv\n# or\npoetry add norikv\n# or\npipenv install norikv\n</code></pre> <p>Requirements: - Python 3.9 or higher - asyncio support</p>"},{"location":"sdks/python/API_GUIDE/#quick-start","title":"Quick Start","text":"<pre><code>import asyncio\nfrom norikv import NoriKVClient, ClientConfig\n\nasync def main():\n    config = ClientConfig(\n        nodes=[\"localhost:9001\", \"localhost:9002\"],\n        total_shards=1024,\n        timeout=5000,\n    )\n\n    async with NoriKVClient(config) as client:\n        # Put a value\n        version = await client.put(\"user:alice\", \"Alice\")\n\n        # Get the value\n        result = await client.get(\"user:alice\")\n        print(f\"Value: {result.value.decode()}\")\n\n        # Delete\n        await client.delete(\"user:alice\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"sdks/python/API_GUIDE/#client-configuration","title":"Client Configuration","text":""},{"location":"sdks/python/API_GUIDE/#basic-configuration","title":"Basic Configuration","text":"<pre><code>from norikv import NoriKVClient, ClientConfig\n\nconfig = ClientConfig(\n    nodes=[\"node1:9001\", \"node2:9001\"],\n    total_shards=1024,\n    timeout=5000,\n)\n\nclient = NoriKVClient(config)\n</code></pre>"},{"location":"sdks/python/API_GUIDE/#configuration-options","title":"Configuration Options","text":"Option Type Default Description <code>nodes</code> <code>list[str]</code> Required List of node addresses (host:port) <code>total_shards</code> <code>int</code> Required Total number of shards in cluster <code>timeout</code> <code>int</code> 5000 Request timeout in milliseconds <code>retry</code> <code>RetryConfig</code> See below Retry policy configuration"},{"location":"sdks/python/API_GUIDE/#retry-configuration","title":"Retry Configuration","text":"<pre><code>from norikv import RetryConfig\n\nretry_config = RetryConfig(\n    max_attempts=10,\n    initial_delay_ms=100,\n    max_delay_ms=5000,\n    jitter_ms=100,\n)\n\nconfig = ClientConfig(\n    nodes=[\"localhost:9001\"],\n    total_shards=1024,\n    retry=retry_config,\n)\n</code></pre> <p>Retry Behavior: - Retries transient errors: <code>Unavailable</code>, <code>Aborted</code>, <code>DeadlineExceeded</code> - Does NOT retry: <code>InvalidArgument</code>, <code>NotFound</code>, <code>FailedPrecondition</code> - Uses exponential backoff with jitter</p>"},{"location":"sdks/python/API_GUIDE/#core-operations","title":"Core Operations","text":""},{"location":"sdks/python/API_GUIDE/#put-write-data","title":"PUT - Write Data","text":""},{"location":"sdks/python/API_GUIDE/#basic-put","title":"Basic PUT","text":"<pre><code>key = \"user:123\"\nvalue = json.dumps({\"name\": \"Alice\"})\n\nversion = await client.put(key, value)\nprint(f\"Written at version: {version}\")\n</code></pre>"},{"location":"sdks/python/API_GUIDE/#put-with-options","title":"PUT with Options","text":"<pre><code>from norikv import PutOptions\n\noptions = PutOptions(\n    ttl_ms=60000,                    # TTL: 60 seconds\n    idempotency_key=\"order-12345\",   # Idempotency key\n    if_match_version=expected_version, # CAS\n)\n\nversion = await client.put(key, value, options)\n</code></pre> <p>PutOptions Fields:</p> Field Type Description <code>ttl_ms</code> <code>int \\| None</code> Time-to-live in milliseconds <code>idempotency_key</code> <code>str \\| None</code> Key for idempotent operations <code>if_match_version</code> <code>Version \\| None</code> Expected version for CAS"},{"location":"sdks/python/API_GUIDE/#get-read-data","title":"GET - Read Data","text":""},{"location":"sdks/python/API_GUIDE/#basic-get","title":"Basic GET","text":"<pre><code>result = await client.get(\"user:123\")\n\nvalue = result.value.decode(\"utf-8\")\nversion = result.version\n</code></pre>"},{"location":"sdks/python/API_GUIDE/#get-with-consistency-level","title":"GET with Consistency Level","text":"<pre><code>from norikv import GetOptions, ConsistencyLevel\n\noptions = GetOptions(\n    consistency=ConsistencyLevel.LINEARIZABLE,\n)\n\nresult = await client.get(key, options)\n</code></pre> <p>Consistency Levels:</p> Level Description Use Case <code>LEASE</code> Default, lease-based read Most operations (fast, usually consistent) <code>LINEARIZABLE</code> Strictest, always up-to-date Critical reads requiring absolute consistency <code>STALE_OK</code> May return stale data Read-heavy workloads, caching"},{"location":"sdks/python/API_GUIDE/#delete-remove-data","title":"DELETE - Remove Data","text":""},{"location":"sdks/python/API_GUIDE/#basic-delete","title":"Basic DELETE","text":"<pre><code>deleted = await client.delete(\"user:123\")\nprint(f\"Deleted: {deleted}\")\n</code></pre>"},{"location":"sdks/python/API_GUIDE/#delete-with-options","title":"DELETE with Options","text":"<pre><code>from norikv import DeleteOptions\n\noptions = DeleteOptions(\n    idempotency_key=\"delete-order-12345\",\n    if_match_version=expected_version,\n)\n\nawait client.delete(key, options)\n</code></pre>"},{"location":"sdks/python/API_GUIDE/#advanced-features","title":"Advanced Features","text":""},{"location":"sdks/python/API_GUIDE/#compare-and-swap-cas","title":"Compare-And-Swap (CAS)","text":"<p>Optimistic concurrency control using version matching:</p> <pre><code># Read current value\ncurrent = await client.get(key)\nvalue = int(current.value.decode())\n\n# Update with CAS\nnew_value = str(value + 1)\ntry:\n    await client.put(\n        key,\n        new_value,\n        PutOptions(if_match_version=current.version),\n    )\n    print(\"CAS succeeded\")\nexcept VersionMismatchError:\n    print(\"CAS failed - version changed\")\n</code></pre>"},{"location":"sdks/python/API_GUIDE/#idempotent-operations","title":"Idempotent Operations","text":"<p>Safe retries using idempotency keys:</p> <pre><code>import uuid\n\nidempotency_key = f\"payment-{uuid.uuid4()}\"\n\n# First attempt\nv1 = await client.put(key, value, PutOptions(idempotency_key=idempotency_key))\n\n# Retry with same key (safe - returns same version)\nv2 = await client.put(key, value, PutOptions(idempotency_key=idempotency_key))\n\nprint(v1 == v2)  # True\n</code></pre>"},{"location":"sdks/python/API_GUIDE/#time-to-live-ttl","title":"Time-To-Live (TTL)","text":"<p>Automatic expiration:</p> <pre><code>await client.put(key, value, PutOptions(ttl_ms=60000))  # Expires in 60 seconds\n\n# Key automatically deleted after TTL\nawait asyncio.sleep(61)\n\ntry:\n    await client.get(key)\nexcept KeyNotFoundError:\n    print(\"Key expired\")\n</code></pre>"},{"location":"sdks/python/API_GUIDE/#cluster-topology","title":"Cluster Topology","text":"<p>Monitor cluster changes:</p> <pre><code># Get current cluster view\nview = client.get_cluster_view()\nif view:\n    print(f\"Cluster epoch: {view.epoch}\")\n    print(f\"Nodes: {len(view.nodes)}\")\n\n# Subscribe to topology changes\ndef on_topology_change(event):\n    print(\"Topology changed!\")\n    print(f\"Previous epoch: {event.previous_epoch}\")\n    print(f\"Current epoch: {event.current_epoch}\")\n    print(f\"Added nodes: {event.added_nodes}\")\n    print(f\"Removed nodes: {event.removed_nodes}\")\n\nunsubscribe = client.on_topology_change(on_topology_change)\n\n# Later: unsubscribe\nunsubscribe()\n</code></pre>"},{"location":"sdks/python/API_GUIDE/#client-statistics","title":"Client Statistics","text":"<p>Monitor client performance:</p> <pre><code>stats = client.get_stats()\n\nprint(f\"Active connections: {stats.pool.active_connections}\")\nprint(f\"Total nodes: {stats.router.total_nodes}\")\nprint(f\"Cached leaders: {stats.topology.cached_leaders}\")\n</code></pre>"},{"location":"sdks/python/API_GUIDE/#error-handling","title":"Error Handling","text":""},{"location":"sdks/python/API_GUIDE/#error-types","title":"Error Types","text":"<pre><code>from norikv import (\n    KeyNotFoundError,\n    VersionMismatchError,\n    AlreadyExistsError,\n    ConnectionError,\n    NoriKVError,\n)\n</code></pre>"},{"location":"sdks/python/API_GUIDE/#handling-specific-errors","title":"Handling Specific Errors","text":"<pre><code>try:\n    result = await client.get(key)\nexcept KeyNotFoundError:\n    print(\"Key not found\")\nexcept ConnectionError as err:\n    print(f\"Connection error: {err}\")\nexcept NoriKVError as err:\n    print(f\"Error: {err.code} - {err}\")\n</code></pre>"},{"location":"sdks/python/API_GUIDE/#retry-pattern","title":"Retry Pattern","text":"<pre><code>from typing import TypeVar, Callable, Awaitable\n\nT = TypeVar(\"T\")\n\nasync def retry_operation(\n    operation: Callable[[], Awaitable[T]],\n    max_attempts: int = 3,\n) -&gt; T:\n    for attempt in range(1, max_attempts + 1):\n        try:\n            return await operation()\n        except ConnectionError as err:\n            if attempt == max_attempts:\n                raise  # Give up\n\n            # Exponential backoff\n            await asyncio.sleep((2 ** attempt) * 0.1)\n\n    raise RuntimeError(\"Unreachable\")\n\n# Usage\nresult = await retry_operation(lambda: client.put(key, value))\n</code></pre>"},{"location":"sdks/python/API_GUIDE/#graceful-degradation","title":"Graceful Degradation","text":"<pre><code>async def get_with_fallback(\n    client: NoriKVClient,\n    key: str,\n    default_value: str,\n) -&gt; str:\n    try:\n        result = await client.get(key)\n        return result.value.decode()\n    except Exception as err:\n        print(f\"Failed to get key, using default: {err}\")\n        return default_value\n</code></pre>"},{"location":"sdks/python/API_GUIDE/#best-practices","title":"Best Practices","text":""},{"location":"sdks/python/API_GUIDE/#1-use-context-managers","title":"1. Use Context Managers","text":"<pre><code>#  Good: Context manager ensures cleanup\nasync with NoriKVClient(config) as client:\n    await client.put(key, value)\n\n#  Bad: Manual cleanup required\nclient = NoriKVClient(config)\nawait client.connect()\nawait client.put(key, value)\nawait client.close()\n</code></pre>"},{"location":"sdks/python/API_GUIDE/#2-reuse-client-instances","title":"2. Reuse Client Instances","text":"<pre><code>#  Good: Single client instance\nclient: NoriKVClient | None = None\n\nasync def init():\n    global client\n    config = ClientConfig(nodes=[\"localhost:9001\"], total_shards=1024)\n    client = NoriKVClient(config)\n    await client.connect()\n\n#  Bad: Creating client per request\nasync def handle_request():\n    async with NoriKVClient(config) as client:\n        await client.put(key, value)\n    # Closes connections!\n</code></pre>"},{"location":"sdks/python/API_GUIDE/#3-use-type-hints","title":"3. Use Type Hints","text":"<pre><code>from typing import Any\nfrom dataclasses import dataclass\n\n@dataclass\nclass UserData:\n    id: str\n    name: str\n    email: str\n\nasync def update_user(user_id: str, data: UserData) -&gt; Version:\n    key = f\"user:{user_id}\"\n    value = json.dumps(data.__dict__)\n\n    options = PutOptions(ttl_ms=3600000)\n    return await client.put(key, value, options)\n</code></pre>"},{"location":"sdks/python/API_GUIDE/#4-handle-errors-properly","title":"4. Handle Errors Properly","text":"<pre><code>async def safe_get(key: str) -&gt; str | None:\n    try:\n        result = await client.get(key)\n        return result.value.decode()\n    except KeyNotFoundError:\n        return None\n</code></pre>"},{"location":"sdks/python/API_GUIDE/#5-use-asyncio-consistently","title":"5. Use asyncio Consistently","text":"<pre><code>#  Good: Clean async/await\nasync def process_user(user_id: str):\n    user_data = await client.get(f\"user:{user_id}\")\n    processed = await process_data(user_data.value)\n    await client.put(f\"processed:{user_id}\", processed)\n\n#  Bad: Mixing sync and async\ndef process_user_bad(user_id: str):\n    loop = asyncio.get_event_loop()\n    user_data = loop.run_until_complete(client.get(f\"user:{user_id}\"))\n    # This blocks the event loop\n</code></pre>"},{"location":"sdks/python/API_GUIDE/#6-use-idempotency-keys-for-important-operations","title":"6. Use Idempotency Keys for Important Operations","text":"<pre><code>async def create_order(order_id: str, data: dict[str, Any]):\n    await client.put(\n        f\"order:{order_id}\",\n        json.dumps(data),\n        PutOptions(idempotency_key=f\"create-order-{order_id}\"),\n    )\n</code></pre>"},{"location":"sdks/python/API_GUIDE/#7-choose-appropriate-consistency","title":"7. Choose Appropriate Consistency","text":"<pre><code># For critical reads\nresult = await client.get(\n    key,\n    GetOptions(consistency=ConsistencyLevel.LINEARIZABLE),\n)\n\n# For cache-like reads\nresult = await client.get(\n    key,\n    GetOptions(consistency=ConsistencyLevel.STALE_OK),\n)\n</code></pre>"},{"location":"sdks/python/API_GUIDE/#8-use-proper-encoding","title":"8. Use Proper Encoding","text":"<pre><code># Always specify encoding\nvalue_bytes = \"Hello, World!\".encode(\"utf-8\")\nawait client.put(key, value_bytes)\n\nresult = await client.get(key)\ntext = result.value.decode(\"utf-8\")\n</code></pre>"},{"location":"sdks/python/API_GUIDE/#performance-tips","title":"Performance Tips","text":""},{"location":"sdks/python/API_GUIDE/#1-batch-operations-with-gather","title":"1. Batch Operations with gather","text":"<pre><code># Process multiple operations concurrently\nawait asyncio.gather(\n    *[client.put(key, value) for key in keys]\n)\n</code></pre>"},{"location":"sdks/python/API_GUIDE/#2-connection-pooling-automatic","title":"2. Connection Pooling (Automatic)","text":"<p>The client maintains connection pools internally - no external pooling needed.</p>"},{"location":"sdks/python/API_GUIDE/#3-avoid-creating-clients-per-request","title":"3. Avoid Creating Clients Per Request","text":"<p>Reuse client instances across requests for better performance.</p>"},{"location":"sdks/python/API_GUIDE/#4-use-appropriate-value-sizes","title":"4. Use Appropriate Value Sizes","text":"<ul> <li>Optimal: 100 bytes - 10 KB</li> <li>Maximum: Limited by memory and network</li> </ul>"},{"location":"sdks/python/API_GUIDE/#5-monitor-performance","title":"5. Monitor Performance","text":"<pre><code>import time\n\nstart = time.time()\nawait client.put(key, value)\nduration = time.time() - start\nprint(f\"PUT took {duration * 1000:.2f}ms\")\n</code></pre>"},{"location":"sdks/python/API_GUIDE/#complete-example","title":"Complete Example","text":"<pre><code>import asyncio\nimport json\nfrom typing import Any\n\nfrom norikv import (\n    NoriKVClient,\n    ClientConfig,\n    PutOptions,\n    GetOptions,\n    ConsistencyLevel,\n    RetryConfig,\n    VersionMismatchError,\n)\n\nasync def main():\n    # Configure with retry policy\n    config = ClientConfig(\n        nodes=[\"localhost:9001\", \"localhost:9002\"],\n        total_shards=1024,\n        timeout=5000,\n        retry=RetryConfig(\n            max_attempts=5,\n            initial_delay_ms=100,\n            max_delay_ms=2000,\n        ),\n    )\n\n    async with NoriKVClient(config) as client:\n        # Write with TTL and idempotency\n        key = \"session:abc123\"\n        value = json.dumps({\"userId\": 42})\n\n        put_opts = PutOptions(\n            ttl_ms=3600000,  # 1 hour\n            idempotency_key=\"session-create-abc123\",\n        )\n\n        version = await client.put(key, value.encode(), put_opts)\n        print(f\"Written: {version}\")\n\n        # Read with linearizable consistency\n        get_opts = GetOptions(\n            consistency=ConsistencyLevel.LINEARIZABLE,\n        )\n\n        result = await client.get(key, get_opts)\n        print(f\"Read: {result.value.decode()}\")\n\n        # Update with CAS\n        new_value = json.dumps({\"userId\": 42, \"active\": True})\n\n        try:\n            await client.put(\n                key,\n                new_value.encode(),\n                PutOptions(if_match_version=result.version),\n            )\n            print(\"CAS succeeded\")\n        except VersionMismatchError:\n            print(\"CAS failed - retry needed\")\n\n        # Monitor topology\n        def on_change(event):\n            print(f\"Cluster changed: epoch {event.current_epoch}\")\n\n        client.on_topology_change(on_change)\n\n        # Get statistics\n        stats = client.get_stats()\n        print(f\"Stats: {stats}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"sdks/python/API_GUIDE/#async-context-manager-pattern","title":"Async Context Manager Pattern","text":"<pre><code># Proper pattern for long-lived applications\nclass Application:\n    def __init__(self):\n        self.client: NoriKVClient | None = None\n\n    async def startup(self):\n        config = ClientConfig(\n            nodes=[\"localhost:9001\"],\n            total_shards=1024,\n        )\n        self.client = NoriKVClient(config)\n        await self.client.connect()\n\n    async def shutdown(self):\n        if self.client:\n            await self.client.close()\n\n    async def handle_request(self, key: str, value: str):\n        if not self.client:\n            raise RuntimeError(\"Client not initialized\")\n\n        await self.client.put(key, value)\n\n# Usage\napp = Application()\nawait app.startup()\n\ntry:\n    await app.handle_request(\"key\", \"value\")\nfinally:\n    await app.shutdown()\n</code></pre>"},{"location":"sdks/python/API_GUIDE/#next-steps","title":"Next Steps","text":"<ul> <li>Architecture Guide - Understanding client internals</li> <li>Troubleshooting Guide - Solving common issues</li> <li>Advanced Patterns - Complex use cases</li> <li>Examples - Working code samples</li> </ul>"},{"location":"sdks/python/ARCHITECTURE/","title":"NoriKV Python Client Architecture","text":"<p>Understanding the internal design and components of the Python client SDK.</p>"},{"location":"sdks/python/ARCHITECTURE/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>Component Architecture</li> <li>Request Flow</li> <li>Asyncio Model</li> <li>Connection Management</li> <li>Routing &amp; Sharding</li> <li>Retry Logic</li> <li>Error Handling</li> </ul>"},{"location":"sdks/python/ARCHITECTURE/#overview","title":"Overview","text":"<p>The NoriKV Python client is designed as a smart async client that: - Routes requests directly to the appropriate shard leader - Maintains connection pools for efficient communication - Implements retry logic with exponential backoff - Tracks cluster topology changes - Provides async/await operations with asyncio - Optimizes for CPython runtime</p>"},{"location":"sdks/python/ARCHITECTURE/#design-principles","title":"Design Principles","text":"<ol> <li>Zero-hop routing: Client routes directly to shard leader (no proxy)</li> <li>Async-first: All I/O operations use async/await</li> <li>Type-safe: Full type hints for static analysis (mypy, pyright)</li> <li>Observable: Expose metrics and statistics</li> <li>Pythonic: Follows PEP 8 and Python best practices</li> </ol>"},{"location":"sdks/python/ARCHITECTURE/#component-architecture","title":"Component Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    NoriKVClient                          \u2502\n\u2502  (Main API: put, get, delete, topology, stats)          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502          \u2502          \u2502          \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Router   \u2502 \u2502 Retry \u2502 \u2502   Pool   \u2502 \u2502 Topology  \u2502\n\u2502            \u2502 \u2502Policy \u2502 \u2502          \u2502 \u2502 Manager   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502                         \u2502              \u2502\n     \u2502                         \u2502              \u2502\n     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500hash()\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524              \u2502\n                               \u2502              \u2502\n     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500get_channel()\u2500\u2500\u2500\u2524              \u2502\n     \u2502                         \u2502              \u2502\n     \u2502                    \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510         \u2502\n     \u2502                    \u2502  gRPC   \u2502         \u2502\n     \u2502                    \u2502Channels \u2502         \u2502\n     \u2502                    \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518         \u2502\n     \u2502                         \u2502              \u2502\n     \u2502                         \u2502              \u2502\n     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500update_view()\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"sdks/python/ARCHITECTURE/#components","title":"Components","text":""},{"location":"sdks/python/ARCHITECTURE/#1-norikvclient","title":"1. NoriKVClient","text":"<p>Responsibility: Main public API and component coordination</p> <p>Key Methods: - <code>put()</code>, <code>get()</code>, <code>delete()</code> - Core operations (all async) - <code>get_cluster_view()</code> - Topology information - <code>on_topology_change()</code> - Subscribe to topology updates - <code>get_stats()</code> - Client statistics - <code>close()</code> - Resource cleanup - <code>__aenter__()</code>, <code>__aexit__()</code> - Context manager support</p> <p>Location: <code>norikv/client.py</code></p>"},{"location":"sdks/python/ARCHITECTURE/#2-router","title":"2. Router","text":"<p>Responsibility: Determine which node to send requests to</p> <p>Key Functions: - Hash key to shard: <code>xxhash64(key) \u2192 jump_consistent_hash(hash, total_shards) \u2192 shard_id</code> - Map shard to leader node - Cache leader information - Handle leader hints from <code>NOT_LEADER</code> errors</p> <p>Location: <code>norikv/internal/router.py</code></p> <p>Algorithm: <pre><code>1. Hash key using XXHash64 (seed=0) via xxhash Python package\n2. Map hash to shard using Jump Consistent Hash\n3. Look up shard leader in topology cache\n4. Return leader's address\n</code></pre></p>"},{"location":"sdks/python/ARCHITECTURE/#3-connectionpool","title":"3. ConnectionPool","text":"<p>Responsibility: Manage gRPC channels to cluster nodes</p> <p>Key Functions: - Create and cache gRPC channels per node - Thread-safe concurrent access (asyncio locks) - Graceful shutdown</p> <p>Location: <code>norikv/internal/conn/pool.py</code></p> <p>Design: - One gRPC <code>Channel</code> per node address - Lazy initialization (created on first use) - Channels reused across requests - Automatic cleanup on client close</p>"},{"location":"sdks/python/ARCHITECTURE/#4-retrypolicy","title":"4. RetryPolicy","text":"<p>Responsibility: Handle transient failures with backoff</p> <p>Key Functions: - Exponential backoff: <code>delay = min(initial_delay * 2^attempt, max_delay)</code> - Jitter: Add randomness to avoid thundering herd - Selective retry: Only retry transient errors - Attempt tracking</p> <p>Location: <code>norikv/internal/retry/policy.py</code></p> <p>Retryable Errors: - <code>Unavailable</code> - Server temporarily unavailable - <code>Aborted</code> - Operation aborted, safe to retry - <code>DeadlineExceeded</code> - Timeout, may succeed on retry - <code>ResourceExhausted</code> - Rate limited, backoff helps</p> <p>Non-Retryable Errors: - <code>InvalidArgument</code> - Client error, won't succeed - <code>NotFound</code> - Key doesn't exist - <code>FailedPrecondition</code> - CAS conflict, application must retry - <code>PermissionDenied</code> - Auth error</p>"},{"location":"sdks/python/ARCHITECTURE/#5-topologymanager","title":"5. TopologyManager","text":"<p>Responsibility: Track cluster membership and shard assignments</p> <p>Key Functions: - Store current <code>ClusterView</code> - Cache shard \u2192 leader mappings - Detect topology changes - Notify listeners of changes - Update leader hints</p> <p>Location: <code>norikv/internal/topology/manager.py</code></p> <p>Data Structures: - <code>ClusterView</code>: Current cluster state (epoch, nodes, shards) - <code>shard_leader_cache</code>: dict[int, str] - <code>listeners</code>: list of change callbacks</p>"},{"location":"sdks/python/ARCHITECTURE/#request-flow","title":"Request Flow","text":""},{"location":"sdks/python/ARCHITECTURE/#put-request-flow","title":"PUT Request Flow","text":"<pre><code>Client.put(key, value, options)\n    \u2502\n    \u251c\u2500&gt; 1. Validate inputs (key, value not null/empty)\n    \u2502\n    \u251c\u2500&gt; 2. Router.get_node_for_key(key)\n    \u2502       \u251c\u2500&gt; hash = xxhash64(key)\n    \u2502       \u251c\u2500&gt; shard_id = jump_consistent_hash(hash, total_shards)\n    \u2502       \u2514\u2500&gt; leader_addr = topology_manager.get_shard_leader(shard_id)\n    \u2502\n    \u251c\u2500&gt; 3. ConnectionPool.get_channel(leader_addr)\n    \u2502       \u2514\u2500&gt; Return cached or create new gRPC channel\n    \u2502\n    \u251c\u2500&gt; 4. RetryPolicy.execute(async lambda: {\n    \u2502       \u251c\u2500&gt; Build gRPC PutRequest\n    \u2502       \u251c\u2500&gt; await grpc_client.put(request)\n    \u2502       \u2514\u2500&gt; Convert response to Version\n    \u2502   })\n    \u2502       \u251c\u2500&gt; On SUCCESS: return Version\n    \u2502       \u251c\u2500&gt; On RETRYABLE_ERROR: backoff and retry\n    \u2502       \u2514\u2500&gt; On NON_RETRYABLE: raise error\n    \u2502\n    \u2514\u2500&gt; 5. Return Version to caller\n</code></pre>"},{"location":"sdks/python/ARCHITECTURE/#get-request-flow","title":"GET Request Flow","text":"<p>Similar to PUT, but: - Uses <code>GetRequest</code> with consistency level - Returns <code>GetResult</code> (value + version) - Raises <code>KeyNotFoundError</code> on NOT_FOUND</p>"},{"location":"sdks/python/ARCHITECTURE/#error-handling-in-flow","title":"Error Handling in Flow","text":"<pre><code>gRPC Status Error\n    \u2502\n    \u251c\u2500&gt; convert_grpc_error()\n    \u2502   \u251c\u2500&gt; NOT_FOUND \u2192 KeyNotFoundError\n    \u2502   \u251c\u2500&gt; FAILED_PRECONDITION + \"version\" \u2192 VersionMismatchError\n    \u2502   \u251c\u2500&gt; UNAVAILABLE \u2192 ConnectionError\n    \u2502   \u2514\u2500&gt; OTHER \u2192 NoriKVError\n    \u2502\n    \u2514\u2500&gt; RetryPolicy decides:\n        \u251c\u2500&gt; Retryable \u2192 backoff and retry\n        \u2514\u2500&gt; Non-retryable \u2192 raise to caller\n</code></pre>"},{"location":"sdks/python/ARCHITECTURE/#asyncio-model","title":"Asyncio Model","text":""},{"location":"sdks/python/ARCHITECTURE/#asyncawait-api","title":"Async/Await API","text":"<p>All client operations are async coroutines:</p> <pre><code># All methods are async\nasync def put(self, key: str | bytes, value: str | bytes, options: PutOptions | None = None) -&gt; Version\nasync def get(self, key: str | bytes, options: GetOptions | None = None) -&gt; GetResult\nasync def delete(self, key: str | bytes, options: DeleteOptions | None = None) -&gt; bool\n</code></pre>"},{"location":"sdks/python/ARCHITECTURE/#event-loop-integration","title":"Event Loop Integration","text":"<pre><code># Modern async/await\nasync def example():\n    version = await client.put(key, value)\n    result = await client.get(key)\n    await client.delete(key)\n\n# Sequential operations\nv1 = await client.put(\"k1\", \"v1\")\nv2 = await client.put(\"k2\", \"v2\")  # Waits for v1\n\n# Concurrent operations\nv1, v2 = await asyncio.gather(\n    client.put(\"k1\", \"v1\"),\n    client.put(\"k2\", \"v2\"),  # Runs concurrently\n)\n</code></pre>"},{"location":"sdks/python/ARCHITECTURE/#context-manager-support","title":"Context Manager Support","text":"<pre><code># Automatic resource cleanup\nasync with NoriKVClient(config) as client:\n    await client.put(key, value)\n# Client automatically closed\n\n# Manual management\nclient = NoriKVClient(config)\nawait client.connect()\ntry:\n    await client.put(key, value)\nfinally:\n    await client.close()\n</code></pre>"},{"location":"sdks/python/ARCHITECTURE/#error-handling","title":"Error Handling","text":"<pre><code>try:\n    result = await client.get(key)\nexcept KeyNotFoundError:\n    # Handle not found\n    pass\nexcept ConnectionError:\n    # Handle connection error\n    pass\nexcept Exception as err:\n    # Handle other errors\n    raise\n</code></pre>"},{"location":"sdks/python/ARCHITECTURE/#connection-management","title":"Connection Management","text":""},{"location":"sdks/python/ARCHITECTURE/#channel-lifecycle","title":"Channel Lifecycle","text":"<pre><code>Node Address\n    \u2502\n    \u251c\u2500&gt; First request \u2192 Create gRPC Channel\n    \u2502   \u251c\u2500&gt; Configure: credentials, options\n    \u2502   \u2514\u2500&gt; Store in pool\n    \u2502\n    \u251c\u2500&gt; Subsequent requests \u2192 Reuse channel\n    \u2502\n    \u2514\u2500&gt; Client.close() \u2192 Close all channels\n        \u2514\u2500&gt; Graceful shutdown with timeout\n</code></pre>"},{"location":"sdks/python/ARCHITECTURE/#channel-configuration","title":"Channel Configuration","text":"<pre><code>import grpc\n\nchannel = grpc.aio.insecure_channel(\n    address,\n    options=[\n        (\"grpc.keepalive_time_ms\", 10000),\n        (\"grpc.keepalive_timeout_ms\", 3000),\n    ],\n)\n</code></pre>"},{"location":"sdks/python/ARCHITECTURE/#health-checks","title":"Health Checks","text":"<ul> <li>Channels automatically reconnect on failure</li> <li>gRPC handles connection health internally</li> <li>Failed requests trigger retries (via RetryPolicy)</li> </ul>"},{"location":"sdks/python/ARCHITECTURE/#routing-sharding","title":"Routing &amp; Sharding","text":""},{"location":"sdks/python/ARCHITECTURE/#hash-function-xxhash64","title":"Hash Function: XXHash64","text":"<pre><code>import xxhash\n\ndef hash_key(key: bytes) -&gt; int:\n    hasher = xxhash.xxh64(seed=0)\n    hasher.update(key)\n    return hasher.intdigest()\n</code></pre> <p>Properties: - Fast: Optimized C implementation - Consistent: Same key \u2192 same hash - Cross-SDK compatible</p>"},{"location":"sdks/python/ARCHITECTURE/#consistent-hashing-jump-consistent-hash","title":"Consistent Hashing: Jump Consistent Hash","text":"<pre><code>def jump_consistent_hash(key: int, num_buckets: int) -&gt; int:\n    b = -1\n    j = 0\n    while j &lt; num_buckets:\n        b = j\n        key = ((key * 2862933555777941757) + 1) &amp; 0xFFFFFFFFFFFFFFFF\n        j = int(float(b + 1) * (float(1 &lt;&lt; 31) / float((key &gt;&gt; 33) + 1)))\n    return b\n</code></pre> <p>Properties: - Minimal key movement on shard count changes - O(log n) time complexity - Uniform distribution</p>"},{"location":"sdks/python/ARCHITECTURE/#shard-leader-mapping","title":"Shard \u2192 Leader Mapping","text":"<pre><code>shard_id \u2192 TopologyManager.get_shard_leader(shard_id) \u2192 leader_addr\n</code></pre> <p>Leader Cache: - Populated from ClusterView - Updated on topology changes - Updated from NOT_LEADER error hints</p>"},{"location":"sdks/python/ARCHITECTURE/#retry-logic","title":"Retry Logic","text":""},{"location":"sdks/python/ARCHITECTURE/#exponential-backoff","title":"Exponential Backoff","text":"<pre><code>import random\n\ndelay = min(\n    initial_delay * (2 ** attempt),\n    max_delay\n) + random.random() * jitter\n\nawait asyncio.sleep(delay / 1000.0)  # Convert ms to seconds\n</code></pre> <p>Example (initial_delay=100ms, max_delay=5s, jitter=100ms): <pre><code>Attempt 1: delay = 100ms  + random(0-100ms)\nAttempt 2: delay = 200ms  + random(0-100ms)\nAttempt 3: delay = 400ms  + random(0-100ms)\nAttempt 4: delay = 800ms  + random(0-100ms)\nAttempt 5: delay = 1600ms + random(0-100ms)\nAttempt 6: delay = 3200ms + random(0-100ms)\nAttempt 7: delay = 5000ms + random(0-100ms) (capped)\n</code></pre></p>"},{"location":"sdks/python/ARCHITECTURE/#jitter-benefits","title":"Jitter Benefits","text":"<ul> <li>Avoids thundering herd (all clients retry at same time)</li> <li>Spreads load during recovery</li> <li>Reduces collision probability</li> </ul>"},{"location":"sdks/python/ARCHITECTURE/#error-handling_1","title":"Error Handling","text":""},{"location":"sdks/python/ARCHITECTURE/#error-hierarchy","title":"Error Hierarchy","text":"<pre><code>class NoriKVError(Exception):\n    \"\"\"Base error for all NoriKV errors.\"\"\"\n\n    def __init__(self, message: str, code: str, cause: Exception | None = None):\n        super().__init__(message)\n        self.code = code\n        self.cause = cause\n\nclass KeyNotFoundError(NoriKVError):\n    \"\"\"Key was not found.\"\"\"\n\nclass VersionMismatchError(NoriKVError):\n    \"\"\"Version mismatch during CAS operation.\"\"\"\n\nclass AlreadyExistsError(NoriKVError):\n    \"\"\"Key already exists.\"\"\"\n\nclass ConnectionError(NoriKVError):\n    \"\"\"Connection error.\"\"\"\n</code></pre>"},{"location":"sdks/python/ARCHITECTURE/#error-code-mapping","title":"Error Code Mapping","text":"gRPC Status NoriKV Error Retry? NOT_FOUND KeyNotFoundError No FAILED_PRECONDITION (version) VersionMismatchError No FAILED_PRECONDITION (other) NoriKVError No ALREADY_EXISTS AlreadyExistsError No UNAVAILABLE ConnectionError Yes DEADLINE_EXCEEDED ConnectionError Yes ABORTED NoriKVError Yes RESOURCE_EXHAUSTED NoriKVError Yes INVALID_ARGUMENT NoriKVError No PERMISSION_DENIED NoriKVError No"},{"location":"sdks/python/ARCHITECTURE/#performance-considerations","title":"Performance Considerations","text":""},{"location":"sdks/python/ARCHITECTURE/#hot-paths","title":"Hot Paths","text":"<ol> <li>Hash calculation: Fast XXHash64 via C extension</li> <li>Channel lookup: O(1) dict lookup</li> <li>Leader cache: O(1) dict lookup</li> <li>Protobuf serialization: Native C++ implementation</li> </ol>"},{"location":"sdks/python/ARCHITECTURE/#memory-usage","title":"Memory Usage","text":"<ul> <li>Per client: ~5-20 MB (depends on number of nodes)</li> <li>Per channel: ~1-2 MB (gRPC overhead)</li> <li>Per request: Minimal (garbage collected)</li> </ul>"},{"location":"sdks/python/ARCHITECTURE/#cpython-gil-considerations","title":"CPython GIL Considerations","text":"<ul> <li>I/O operations: Release GIL during network calls</li> <li>Hash computation: XXHash C extension releases GIL</li> <li>Multiple clients: Can run in different threads</li> </ul>"},{"location":"sdks/python/ARCHITECTURE/#connection-pooling","title":"Connection Pooling","text":"<ul> <li>Channels reused across requests</li> <li>No connection per request overhead</li> <li>HTTP/2 multiplexing</li> </ul>"},{"location":"sdks/python/ARCHITECTURE/#python-specific-features","title":"Python-Specific Features","text":""},{"location":"sdks/python/ARCHITECTURE/#full-type-hints","title":"Full Type Hints","text":"<pre><code>from norikv import NoriKVClient, GetResult, Version\n\nclient: NoriKVClient = NoriKVClient(config)\nresult: GetResult = await client.get(key)\nversion: Version = result.version\n</code></pre>"},{"location":"sdks/python/ARCHITECTURE/#context-managers","title":"Context Managers","text":"<pre><code># Async context manager\nasync with NoriKVClient(config) as client:\n    await client.put(key, value)\n\n# Equivalent to:\nclient = NoriKVClient(config)\nawait client.__aenter__()\ntry:\n    await client.put(key, value)\nfinally:\n    await client.__aexit__(None, None, None)\n</code></pre>"},{"location":"sdks/python/ARCHITECTURE/#dataclasses","title":"Dataclasses","text":"<pre><code>from dataclasses import dataclass\n\n@dataclass\nclass ClientConfig:\n    nodes: list[str]\n    total_shards: int\n    timeout: int = 5000\n    retry: RetryConfig | None = None\n</code></pre>"},{"location":"sdks/python/ARCHITECTURE/#type-guards","title":"Type Guards","text":"<pre><code>from typing import TypeGuard\n\ndef is_bytes(value: str | bytes) -&gt; TypeGuard[bytes]:\n    return isinstance(value, bytes)\n\nif is_bytes(value):\n    # Type checker knows value is bytes here\n    hasher.update(value)\n</code></pre>"},{"location":"sdks/python/ARCHITECTURE/#asyncio-best-practices","title":"Asyncio Best Practices","text":""},{"location":"sdks/python/ARCHITECTURE/#1-use-async-with-for-cleanup","title":"1. Use async with for Cleanup","text":"<pre><code>async with NoriKVClient(config) as client:\n    await client.put(key, value)\n</code></pre>"},{"location":"sdks/python/ARCHITECTURE/#2-use-gather-for-concurrency","title":"2. Use gather for Concurrency","text":"<pre><code>results = await asyncio.gather(\n    client.put(\"k1\", \"v1\"),\n    client.put(\"k2\", \"v2\"),\n    client.put(\"k3\", \"v3\"),\n)\n</code></pre>"},{"location":"sdks/python/ARCHITECTURE/#3-use-create_task-for-background-work","title":"3. Use create_task for Background Work","text":"<pre><code>task = asyncio.create_task(client.put(key, value))\n# Do other work\nawait task\n</code></pre>"},{"location":"sdks/python/ARCHITECTURE/#4-use-timeouts","title":"4. Use Timeouts","text":"<pre><code>try:\n    result = await asyncio.wait_for(\n        client.get(key),\n        timeout=5.0,\n    )\nexcept asyncio.TimeoutError:\n    print(\"Operation timed out\")\n</code></pre>"},{"location":"sdks/python/ARCHITECTURE/#5-handle-cancellation","title":"5. Handle Cancellation","text":"<pre><code>try:\n    result = await client.get(key)\nexcept asyncio.CancelledError:\n    print(\"Operation cancelled\")\n    raise\n</code></pre>"},{"location":"sdks/python/ARCHITECTURE/#threading-considerations","title":"Threading Considerations","text":""},{"location":"sdks/python/ARCHITECTURE/#thread-safety","title":"Thread Safety","text":"<p>The client is not thread-safe by default. Each thread should have its own client instance or use explicit synchronization.</p>"},{"location":"sdks/python/ARCHITECTURE/#running-in-thread-pool","title":"Running in Thread Pool","text":"<pre><code>import asyncio\nfrom concurrent.futures import ThreadPoolExecutor\n\ndef sync_operation(key: str, value: str):\n    loop = asyncio.new_event_loop()\n    asyncio.set_event_loop(loop)\n\n    async def async_work():\n        async with NoriKVClient(config) as client:\n            await client.put(key, value)\n\n    loop.run_until_complete(async_work())\n    loop.close()\n\n# Run in thread pool\nwith ThreadPoolExecutor() as executor:\n    future = executor.submit(sync_operation, \"key\", \"value\")\n    future.result()\n</code></pre>"},{"location":"sdks/python/ARCHITECTURE/#performance-optimizations","title":"Performance Optimizations","text":""},{"location":"sdks/python/ARCHITECTURE/#1-reuse-client-instances","title":"1. Reuse Client Instances","text":"<pre><code>#  Good: Reuse client\nclass Application:\n    def __init__(self):\n        self.client = NoriKVClient(config)\n\n    async def handle_request(self):\n        await self.client.put(key, value)\n\n#  Bad: Create client per request\nasync def handle_request():\n    async with NoriKVClient(config) as client:\n        await client.put(key, value)\n</code></pre>"},{"location":"sdks/python/ARCHITECTURE/#2-batch-with-gather","title":"2. Batch with gather","text":"<pre><code># Concurrent operations\nawait asyncio.gather(\n    *[client.put(f\"key{i}\", f\"value{i}\") for i in range(100)]\n)\n</code></pre>"},{"location":"sdks/python/ARCHITECTURE/#3-use-bytes-directly","title":"3. Use bytes Directly","text":"<pre><code>#  Good: No encoding overhead\nawait client.put(b\"key\", b\"value\")\n\n#  Less efficient: Encoding overhead\nawait client.put(\"key\", \"value\")\n</code></pre>"},{"location":"sdks/python/ARCHITECTURE/#4-monitor-with-stats","title":"4. Monitor with Stats","text":"<pre><code>stats = client.get_stats()\nprint(f\"Active connections: {stats.pool.active_connections}\")\n</code></pre>"},{"location":"sdks/python/ARCHITECTURE/#references","title":"References","text":"<ul> <li>API Guide - Public API documentation</li> <li>Troubleshooting Guide - Common issues</li> <li>Advanced Patterns - Complex use cases</li> <li>Source Code - Implementation</li> </ul>"},{"location":"sdks/python/TROUBLESHOOTING/","title":"NoriKV Python Client Troubleshooting Guide","text":"<p>Solutions to common issues when using the Python client SDK.</p>"},{"location":"sdks/python/TROUBLESHOOTING/#connection-issues","title":"Connection Issues","text":""},{"location":"sdks/python/TROUBLESHOOTING/#connection-refused-or-connectionrefusederror","title":"\"Connection refused\" or ConnectionRefusedError","text":"<p>Symptoms: <pre><code>await client.connect()\n# ConnectionRefusedError: [Errno 61] Connection refused\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Verify server is running: <pre><code>netstat -an | grep 9001\nlsof -i :9001\n</code></pre></p> </li> <li> <p>Check client configuration: <pre><code>config = ClientConfig(\n    nodes=[\"localhost:9001\"],  # Verify this address\n    total_shards=1024,\n)\n</code></pre></p> </li> <li> <p>Test connectivity: <pre><code>telnet localhost 9001\nnc -zv localhost 9001\n</code></pre></p> </li> </ol>"},{"location":"sdks/python/TROUBLESHOOTING/#deadline-exceeded-or-timeout-errors","title":"\"Deadline exceeded\" or timeout errors","text":"<p>Symptoms: <pre><code>result = await client.get(key)\n# grpc.aio._call.AioRpcError: Deadline exceeded\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Increase timeout: <pre><code>config = ClientConfig(\n    nodes=[\"localhost:9001\"],\n    total_shards=1024,\n    timeout=10000,  # 10 seconds\n)\n</code></pre></p> </li> <li> <p>Enable retries: <pre><code>from norikv import RetryConfig\n\nconfig = ClientConfig(\n    nodes=[\"localhost:9001\"],\n    total_shards=1024,\n    retry=RetryConfig(\n        max_attempts=10,\n        initial_delay_ms=100,\n        max_delay_ms=5000,\n    ),\n)\n</code></pre></p> </li> </ol>"},{"location":"sdks/python/TROUBLESHOOTING/#performance-problems","title":"Performance Problems","text":""},{"location":"sdks/python/TROUBLESHOOTING/#slow-operations","title":"Slow operations","text":"<p>Diagnosis: <pre><code>import time\n\nstart = time.time()\nawait client.put(key, value)\nduration = time.time() - start\nprint(f\"PUT took {duration * 1000:.2f}ms\")  # &gt; 100ms consistently\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Use appropriate consistency level: <pre><code>from norikv import GetOptions, ConsistencyLevel\n\nresult = await client.get(\n    key,\n    GetOptions(consistency=ConsistencyLevel.STALE_OK),  # Fastest\n)\n</code></pre></p> </li> <li> <p>Batch operations: <pre><code>await asyncio.gather(\n    *[client.put(k, value) for k in keys]\n)\n</code></pre></p> </li> <li> <p>Check value sizes: <pre><code>print(f\"Value size: {len(value)} bytes\")\n# Optimal: 100 bytes - 10 KB\n</code></pre></p> </li> </ol>"},{"location":"sdks/python/TROUBLESHOOTING/#high-memory-usage","title":"High memory usage","text":"<p>Solutions:</p> <ol> <li> <p>Close client when done: <pre><code>await client.close()  # Important!\n</code></pre></p> </li> <li> <p>Clean up topology listeners: <pre><code>unsubscribe = client.on_topology_change(handler)\nunsubscribe()  # Clean up when done\n</code></pre></p> </li> <li> <p>Use memory profiler: <pre><code>pip install memory_profiler\npython -m memory_profiler script.py\n</code></pre></p> </li> </ol>"},{"location":"sdks/python/TROUBLESHOOTING/#version-conflicts","title":"Version Conflicts","text":""},{"location":"sdks/python/TROUBLESHOOTING/#frequent-versionmismatcherror","title":"Frequent VersionMismatchError","text":"<p>Symptoms: <pre><code>await client.put(key, new_value, PutOptions(if_match_version=version))\n# VersionMismatchError: Version mismatch\n</code></pre></p> <p>Solution - Implement retry loop: <pre><code>from norikv import VersionMismatchError\n\nasync def cas_with_retry(\n    key: str,\n    transform: callable,\n    max_retries: int = 10,\n) -&gt; None:\n    for attempt in range(max_retries):\n        try:\n            result = await client.get(key)\n            current_value = result.value.decode()\n            new_value = transform(current_value)\n\n            await client.put(\n                key,\n                new_value.encode(),\n                PutOptions(if_match_version=result.version),\n            )\n            return  # Success\n\n        except VersionMismatchError:\n            if attempt == max_retries - 1:\n                raise RuntimeError(\"CAS failed after retries\")\n\n            # Exponential backoff\n            await asyncio.sleep((2 ** attempt) * 0.01)\n</code></pre></p>"},{"location":"sdks/python/TROUBLESHOOTING/#error-messages","title":"Error Messages","text":""},{"location":"sdks/python/TROUBLESHOOTING/#key-not-found","title":"\"Key not found\"","text":"<p>Handling: <pre><code>from norikv import KeyNotFoundError\n\ntry:\n    result = await client.get(key)\nexcept KeyNotFoundError:\n    # Use default value or create key\n    return default_value\n</code></pre></p>"},{"location":"sdks/python/TROUBLESHOOTING/#version-mismatch","title":"\"Version mismatch\"","text":"<p>Handling: See Version Conflicts above.</p>"},{"location":"sdks/python/TROUBLESHOOTING/#connection-error","title":"\"Connection error\"","text":"<p>Handling: <pre><code>from norikv import ConnectionError\n\nasync def with_retry(operation: callable):\n    max_attempts = 3\n    for attempt in range(max_attempts):\n        try:\n            return await operation()\n        except ConnectionError:\n            if attempt == max_attempts - 1:\n                raise\n            await asyncio.sleep((2 ** attempt) * 0.1)\n</code></pre></p>"},{"location":"sdks/python/TROUBLESHOOTING/#python-specific-issues","title":"Python-Specific Issues","text":""},{"location":"sdks/python/TROUBLESHOOTING/#asynciorun-issues","title":"asyncio.run() issues","text":"<p>Problem: <pre><code>asyncio.run(main())\n# RuntimeError: asyncio.run() cannot be called from a running event loop\n</code></pre></p> <p>Solution: <pre><code># In Jupyter notebooks or existing event loop\nawait main()\n\n# Or use nest_asyncio\nimport nest_asyncio\nnest_asyncio.apply()\nasyncio.run(main())\n</code></pre></p>"},{"location":"sdks/python/TROUBLESHOOTING/#type-errors-with-mypy","title":"Type errors with mypy","text":"<p>Problem: <pre><code>value = b\"hello\"\nawait client.put(key, value)\n# mypy error: Argument 2 has incompatible type \"bytes\"\n</code></pre></p> <p>Solution: <pre><code># Check type hints in library\nfrom norikv import NoriKVClient\n\n# Verify signature accepts bytes\nasync def put(self, key: str | bytes, value: str | bytes, ...) -&gt; Version\n</code></pre></p>"},{"location":"sdks/python/TROUBLESHOOTING/#context-manager-not-cleaning-up","title":"Context manager not cleaning up","text":"<p>Problem: <pre><code>async with NoriKVClient(config) as client:\n    await client.put(key, value)\n# Client not properly closed\n</code></pre></p> <p>Solution: <pre><code># Ensure __aexit__ is called\ntry:\n    async with NoriKVClient(config) as client:\n        await client.put(key, value)\nexcept Exception as err:\n    print(f\"Error: {err}\")\n    raise\n</code></pre></p>"},{"location":"sdks/python/TROUBLESHOOTING/#module-import-errors","title":"Module import errors","text":"<p>Problem: <pre><code>from norikv import NoriKVClient\n# ModuleNotFoundError: No module named 'norikv'\n</code></pre></p> <p>Solution:</p> <ol> <li> <p>Install package: <pre><code>pip install norikv\n</code></pre></p> </li> <li> <p>Check virtual environment: <pre><code>which python\npip list | grep norikv\n</code></pre></p> </li> <li> <p>Verify PYTHONPATH: <pre><code>echo $PYTHONPATH\n</code></pre></p> </li> </ol>"},{"location":"sdks/python/TROUBLESHOOTING/#asyncio-event-loop-issues","title":"Asyncio Event Loop Issues","text":""},{"location":"sdks/python/TROUBLESHOOTING/#event-loop-is-closed","title":"\"Event loop is closed\"","text":"<p>Problem: <pre><code>await client.put(key, value)\n# RuntimeError: Event loop is closed\n</code></pre></p> <p>Solution: <pre><code># Create new event loop\nloop = asyncio.new_event_loop()\nasyncio.set_event_loop(loop)\n\ntry:\n    loop.run_until_complete(main())\nfinally:\n    loop.close()\n</code></pre></p>"},{"location":"sdks/python/TROUBLESHOOTING/#task-was-destroyed-but-it-is-pending","title":"\"Task was destroyed but it is pending\"","text":"<p>Problem: <pre><code># Warning: Task was destroyed but it is pending!\n</code></pre></p> <p>Solution: <pre><code># Properly await all tasks\ntask = asyncio.create_task(client.put(key, value))\nawait task\n\n# Or cancel and wait\ntask.cancel()\ntry:\n    await task\nexcept asyncio.CancelledError:\n    pass\n</code></pre></p>"},{"location":"sdks/python/TROUBLESHOOTING/#coroutine-was-never-awaited","title":"\"coroutine was never awaited\"","text":"<p>Problem: <pre><code>client.put(key, value)  # Not awaited\n# RuntimeWarning: coroutine 'NoriKVClient.put' was never awaited\n</code></pre></p> <p>Solution: <pre><code># Always await async functions\nawait client.put(key, value)\n</code></pre></p>"},{"location":"sdks/python/TROUBLESHOOTING/#dependency-issues","title":"Dependency Issues","text":""},{"location":"sdks/python/TROUBLESHOOTING/#grpc-installation-problems","title":"gRPC installation problems","text":"<p>Problem: <pre><code>pip install grpcio\n# ERROR: Failed building wheel for grpcio\n</code></pre></p> <p>Solution:</p> <ol> <li> <p>Install build dependencies: <pre><code># macOS\nbrew install cmake\n\n# Ubuntu/Debian\nsudo apt-get install build-essential python3-dev\n\n# Fedora\nsudo dnf install gcc-c++ python3-devel\n</code></pre></p> </li> <li> <p>Use binary wheels: <pre><code>pip install --only-binary :all: grpcio\n</code></pre></p> </li> </ol>"},{"location":"sdks/python/TROUBLESHOOTING/#xxhash-installation-problems","title":"xxhash installation problems","text":"<p>Problem: <pre><code>pip install xxhash\n# ERROR: Failed building wheel for xxhash\n</code></pre></p> <p>Solution:</p> <ol> <li> <p>Install from binary: <pre><code>pip install --only-binary :all: xxhash\n</code></pre></p> </li> <li> <p>Or install build tools: <pre><code># macOS\nxcode-select --install\n\n# Ubuntu/Debian\nsudo apt-get install python3-dev\n</code></pre></p> </li> </ol>"},{"location":"sdks/python/TROUBLESHOOTING/#virtual-environment-issues","title":"Virtual Environment Issues","text":""},{"location":"sdks/python/TROUBLESHOOTING/#wrong-python-version","title":"Wrong Python version","text":"<p>Problem: <pre><code>python --version\n# Python 3.8.0  (need 3.9+)\n</code></pre></p> <p>Solution: <pre><code># Install Python 3.9+\npyenv install 3.9.0\npyenv local 3.9.0\n\n# Or use system Python\npython3.9 -m venv venv\nsource venv/bin/activate\n</code></pre></p>"},{"location":"sdks/python/TROUBLESHOOTING/#package-not-found-in-venv","title":"Package not found in venv","text":"<p>Problem: <pre><code>import norikv\n# ModuleNotFoundError\n</code></pre></p> <p>Solution: <pre><code># Ensure venv is activated\nsource venv/bin/activate\n\n# Install in venv\npip install norikv\n\n# Verify installation\npip show norikv\n</code></pre></p>"},{"location":"sdks/python/TROUBLESHOOTING/#common-pitfalls","title":"Common Pitfalls","text":""},{"location":"sdks/python/TROUBLESHOOTING/#1-not-awaiting-async-functions","title":"1. Not awaiting async functions","text":"<pre><code>#  Bad\nclient.put(key, value)  # Returns coroutine, not executed\n\n#  Good\nawait client.put(key, value)\n</code></pre>"},{"location":"sdks/python/TROUBLESHOOTING/#2-creating-client-per-request","title":"2. Creating client per request","text":"<pre><code>#  Bad\nasync def handle_request():\n    async with NoriKVClient(config) as client:\n        await client.put(key, value)\n    # Closes connections!\n\n#  Good\nclient = NoriKVClient(config)\nawait client.connect()\n# Reuse client across requests\n</code></pre>"},{"location":"sdks/python/TROUBLESHOOTING/#3-not-handling-errors","title":"3. Not handling errors","text":"<pre><code>#  Bad\nresult = await client.get(key)  # May raise\n\n#  Good\ntry:\n    result = await client.get(key)\nexcept KeyNotFoundError:\n    return None\n</code></pre>"},{"location":"sdks/python/TROUBLESHOOTING/#4-blocking-the-event-loop","title":"4. Blocking the event loop","text":"<pre><code>#  Bad\nasync def handler():\n    time.sleep(1)  # Blocks event loop\n    await client.put(key, value)\n\n#  Good\nasync def handler():\n    await asyncio.sleep(1)  # Non-blocking\n    await client.put(key, value)\n</code></pre>"},{"location":"sdks/python/TROUBLESHOOTING/#5-not-using-context-managers","title":"5. Not using context managers","text":"<pre><code>#  Bad\nclient = NoriKVClient(config)\nawait client.connect()\nawait client.put(key, value)\n# Forgot to close!\n\n#  Good\nasync with NoriKVClient(config) as client:\n    await client.put(key, value)\n</code></pre>"},{"location":"sdks/python/TROUBLESHOOTING/#debugging-tips","title":"Debugging Tips","text":""},{"location":"sdks/python/TROUBLESHOOTING/#enable-debug-logging","title":"Enable debug logging","text":"<pre><code>import logging\n\nlogging.basicConfig(level=logging.DEBUG)\nlogger = logging.getLogger(\"norikv\")\nlogger.setLevel(logging.DEBUG)\n</code></pre>"},{"location":"sdks/python/TROUBLESHOOTING/#use-asyncio-debug-mode","title":"Use asyncio debug mode","text":"<pre><code>import asyncio\n\nasyncio.run(main(), debug=True)\n</code></pre>"},{"location":"sdks/python/TROUBLESHOOTING/#profile-async-operations","title":"Profile async operations","text":"<pre><code>import time\n\nasync def profile_operation(name: str, operation):\n    start = time.time()\n    result = await operation\n    duration = time.time() - start\n    print(f\"{name} took {duration * 1000:.2f}ms\")\n    return result\n\nawait profile_operation(\"PUT\", client.put(key, value))\n</code></pre>"},{"location":"sdks/python/TROUBLESHOOTING/#check-client-stats","title":"Check client stats","text":"<pre><code>stats = client.get_stats()\nprint(f\"Stats: {stats}\")\n</code></pre>"},{"location":"sdks/python/TROUBLESHOOTING/#use-python-debugger","title":"Use Python debugger","text":"<pre><code>import pdb\n\nasync def debug_example():\n    pdb.set_trace()\n    await client.put(key, value)\n\nasyncio.run(debug_example())\n</code></pre>"},{"location":"sdks/python/TROUBLESHOOTING/#type-checking-issues","title":"Type Checking Issues","text":""},{"location":"sdks/python/TROUBLESHOOTING/#mypy-strict-mode","title":"mypy strict mode","text":"<p>Problem: <pre><code>mypy script.py --strict\n# error: Missing type annotation\n</code></pre></p> <p>Solution: <pre><code>from norikv import NoriKVClient, ClientConfig, Version\n\nclient: NoriKVClient = NoriKVClient(config)\nversion: Version = await client.put(key, value)\n</code></pre></p>"},{"location":"sdks/python/TROUBLESHOOTING/#pyright-issues","title":"pyright issues","text":"<p>Problem: <pre><code>pyright script.py\n# Type \"bytes\" cannot be assigned to type \"str\"\n</code></pre></p> <p>Solution: <pre><code># Use union types\nkey: str | bytes = b\"key\"\nvalue: str | bytes = b\"value\"\nawait client.put(key, value)\n</code></pre></p>"},{"location":"sdks/python/TROUBLESHOOTING/#jupyter-notebook-issues","title":"Jupyter Notebook Issues","text":""},{"location":"sdks/python/TROUBLESHOOTING/#event-loop-conflicts","title":"Event loop conflicts","text":"<p>Problem: <pre><code>asyncio.run(main())\n# RuntimeError: asyncio.run() cannot be called from a running event loop\n</code></pre></p> <p>Solution: <pre><code># Jupyter already has event loop running\nawait main()\n\n# Or use nest_asyncio\nimport nest_asyncio\nnest_asyncio.apply()\n</code></pre></p>"},{"location":"sdks/python/TROUBLESHOOTING/#kernel-restart-needed","title":"Kernel restart needed","text":"<p>Problem: <pre><code># Client not responding after changes\n</code></pre></p> <p>Solution: <pre><code># Restart kernel\n# Jupyter: Kernel \u2192 Restart\n\n# Or recreate client\nawait client.close()\nclient = NoriKVClient(config)\nawait client.connect()\n</code></pre></p>"},{"location":"sdks/python/TROUBLESHOOTING/#production-debugging","title":"Production Debugging","text":""},{"location":"sdks/python/TROUBLESHOOTING/#monitor-connection-pool","title":"Monitor connection pool","text":"<pre><code>stats = client.get_stats()\nprint(f\"Active connections: {stats.pool.active_connections}\")\nprint(f\"Total nodes: {stats.router.total_nodes}\")\n</code></pre>"},{"location":"sdks/python/TROUBLESHOOTING/#track-operation-latency","title":"Track operation latency","text":"<pre><code>import time\nfrom collections import defaultdict\n\nlatencies = defaultdict(list)\n\nasync def tracked_put(key: str, value: str):\n    start = time.time()\n    try:\n        version = await client.put(key, value)\n        latencies[\"put\"].append(time.time() - start)\n        return version\n    except Exception as err:\n        print(f\"PUT failed: {err}\")\n        raise\n\n# Analyze latencies\nimport statistics\nprint(f\"p50: {statistics.median(latencies['put']) * 1000:.2f}ms\")\nprint(f\"p95: {statistics.quantiles(latencies['put'], n=20)[18] * 1000:.2f}ms\")\n</code></pre>"},{"location":"sdks/python/TROUBLESHOOTING/#log-errors-with-context","title":"Log errors with context","text":"<pre><code>import logging\nimport traceback\n\nlogger = logging.getLogger(__name__)\n\ntry:\n    await client.put(key, value)\nexcept Exception as err:\n    logger.error(\n        \"PUT failed\",\n        extra={\n            \"key\": key,\n            \"error\": str(err),\n            \"traceback\": traceback.format_exc(),\n        },\n    )\n    raise\n</code></pre>"},{"location":"sdks/python/TROUBLESHOOTING/#getting-help","title":"Getting Help","text":"<ul> <li>Issues: GitHub Issues</li> <li>Documentation: API Guide, Architecture Guide</li> <li>Examples: GitHub Examples</li> </ul>"},{"location":"sdks/typescript/","title":"NoriKV TypeScript Client SDK","text":"<p>Type-safe TypeScript/JavaScript client for NoriKV with full async/await support.</p>"},{"location":"sdks/typescript/#status","title":"Status","text":"<p>** PRODUCTION READY** - Fully functional TypeScript SDK</p> <ul> <li>100+ tests passing with comprehensive coverage</li> <li>Full TypeScript types for compile-time safety</li> <li>Async/await Promise-based API</li> <li>Dual package support (ESM + CommonJS)</li> <li>Browser compatible with polyfills</li> </ul>"},{"location":"sdks/typescript/#quick-start","title":"Quick Start","text":""},{"location":"sdks/typescript/#installation","title":"Installation","text":"<pre><code>npm install @norikv/client\n# or\nyarn add @norikv/client\n# or\npnpm add @norikv/client\n</code></pre>"},{"location":"sdks/typescript/#basic-usage","title":"Basic Usage","text":"<pre><code>import { NoriKVClient, bytesToString } from '@norikv/client';\n\nconst client = new NoriKVClient({\n  nodes: ['localhost:9001', 'localhost:9002'],\n  totalShards: 1024,\n  timeout: 5000,\n});\n\nawait client.connect();\n\n// Put a value\nawait client.put('user:123', 'Alice');\n\n// Get a value\nconst result = await client.get('user:123');\nconsole.log(bytesToString(result.value)); // 'Alice'\n\n// Delete\nawait client.delete('user:123');\n\nawait client.close();\n</code></pre>"},{"location":"sdks/typescript/#documentation","title":"Documentation","text":""},{"location":"sdks/typescript/#core-guides","title":"Core Guides","text":"<ul> <li>API Guide - Complete API reference</li> <li>Architecture Guide - Internal design</li> <li>Troubleshooting Guide - Common issues</li> <li>Advanced Patterns - Real-world examples</li> </ul>"},{"location":"sdks/typescript/#features","title":"Features","text":""},{"location":"sdks/typescript/#core-features","title":"Core Features","text":"<ul> <li>Smart client-side routing</li> <li>Leader-aware routing with failover</li> <li>Automatic retries with exponential backoff</li> <li>Idempotency support</li> <li>CAS operations with version matching</li> <li>Multiple consistency levels</li> <li>Connection pooling</li> <li>Topology tracking</li> </ul>"},{"location":"sdks/typescript/#typescript-specific","title":"TypeScript-Specific","text":"<ul> <li>Full TypeScript types</li> <li>Async/await Promise API</li> <li>ESM + CommonJS dual package</li> <li>Browser compatible</li> <li>JSDoc inline documentation</li> <li>Tree-shakeable exports</li> </ul>"},{"location":"sdks/typescript/#requirements","title":"Requirements","text":"<ul> <li>Node.js: 16 or higher</li> <li>TypeScript: 4.5 or higher (if using TypeScript)</li> <li>NoriKV Server: 0.1.x</li> </ul>"},{"location":"sdks/typescript/#support","title":"Support","text":"<ul> <li>Issues: GitHub Issues</li> <li>Source: GitHub Repository</li> <li>npm: @norikv/client</li> </ul>"},{"location":"sdks/typescript/#license","title":"License","text":"<p>MIT OR Apache-2.0</p>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/","title":"NoriKV TypeScript Client Advanced Patterns","text":"<p>Complex real-world usage patterns and production-ready design examples.</p>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Distributed Counter</li> <li>Session Management</li> <li>Inventory Management</li> <li>Caching Layer</li> <li>Rate Limiting</li> <li>Leader Election</li> <li>Event Sourcing</li> <li>Multi-Tenancy</li> </ul>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#distributed-counter","title":"Distributed Counter","text":"<p>Implement a high-throughput distributed counter with sharding to reduce contention.</p>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#basic-counter","title":"Basic Counter","text":"<pre><code>import {\n  NoriKVClient,\n  GetResult,\n  VersionMismatchError,\n  KeyNotFoundError,\n  stringToBytes,\n  bytesToString,\n} from '@norikv/client';\n\nexport class DistributedCounter {\n  private client: NoriKVClient;\n  private key: string;\n  private maxRetries: number;\n\n  constructor(client: NoriKVClient, counterName: string) {\n    this.client = client;\n    this.key = counterName;\n    this.maxRetries = 20;\n  }\n\n  async initialize(): Promise&lt;void&gt; {\n    try {\n      await this.client.get(this.key);\n    } catch (err) {\n      if (err instanceof KeyNotFoundError) {\n        try {\n          await this.client.put(this.key, '0');\n        } catch (putErr) {\n          // Ignore - someone else may have initialized\n        }\n      } else {\n        throw err;\n      }\n    }\n  }\n\n  async increment(): Promise&lt;number&gt; {\n    return this.incrementBy(1);\n  }\n\n  async incrementBy(delta: number): Promise&lt;number&gt; {\n    for (let attempt = 0; attempt &lt; this.maxRetries; attempt++) {\n      try {\n        // Read current value\n        const current = await this.client.get(this.key);\n        const value = parseInt(bytesToString(current.value));\n\n        // Increment\n        const newValue = value + delta;\n\n        // CAS write\n        await this.client.put(this.key, newValue.toString(), {\n          ifMatchVersion: current.version,\n        });\n\n        return newValue;\n\n      } catch (err) {\n        if (!(err instanceof VersionMismatchError)) {\n          throw err;\n        }\n\n        if (attempt === this.maxRetries - 1) {\n          throw new Error(`Failed to increment after ${this.maxRetries} attempts`);\n        }\n\n        // Exponential backoff with jitter\n        const backoff = Math.min(Math.pow(2, attempt), 1000);\n        const jitter = Math.random() * 100;\n        await new Promise(resolve =&gt; setTimeout(resolve, backoff + jitter));\n      }\n    }\n\n    throw new Error('Should not reach here');\n  }\n\n  async get(): Promise&lt;number&gt; {\n    const result = await this.client.get(this.key);\n    return parseInt(bytesToString(result.value));\n  }\n}\n</code></pre>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#sharded-counter-high-throughput","title":"Sharded Counter (High Throughput)","text":"<p>For very high write rates, distribute writes across multiple shards:</p> <pre><code>export class ShardedCounter {\n  private client: NoriKVClient;\n  private name: string;\n  private numShards: number;\n\n  constructor(client: NoriKVClient, name: string, numShards: number = 10) {\n    this.client = client;\n    this.name = name;\n    this.numShards = numShards;\n  }\n\n  private randomShard(): number {\n    return Math.floor(Math.random() * this.numShards);\n  }\n\n  private shardKey(shardId: number): string {\n    return `${this.name}:shard:${shardId}`;\n  }\n\n  async increment(): Promise&lt;void&gt; {\n    // Randomly select a shard to reduce contention\n    const shardId = this.randomShard();\n    const key = this.shardKey(shardId);\n\n    const maxRetries = 10;\n    for (let attempt = 0; attempt &lt; maxRetries; attempt++) {\n      try {\n        let currentValue = 0;\n        let currentVersion = null;\n\n        try {\n          const result = await this.client.get(key);\n          currentValue = parseInt(bytesToString(result.value));\n          currentVersion = result.version;\n        } catch (err) {\n          if (!(err instanceof KeyNotFoundError)) {\n            throw err;\n          }\n          // Key doesn't exist yet - start at 0\n        }\n\n        const newValue = currentValue + 1;\n        const options = currentVersion ? { ifMatchVersion: currentVersion } : {};\n\n        await this.client.put(key, newValue.toString(), options);\n        return;\n\n      } catch (err) {\n        if (!(err instanceof VersionMismatchError)) {\n          throw err;\n        }\n\n        // Exponential backoff\n        const backoff = Math.pow(2, attempt) * 10;\n        const jitter = Math.random() * 10;\n        await new Promise(resolve =&gt; setTimeout(resolve, backoff + jitter));\n      }\n    }\n\n    throw new Error('Increment failed after retries');\n  }\n\n  async get(): Promise&lt;number&gt; {\n    // Sum all shards concurrently\n    const promises = Array.from({ length: this.numShards }, async (_, i) =&gt; {\n      try {\n        const result = await this.client.get(this.shardKey(i));\n        return parseInt(bytesToString(result.value));\n      } catch (err) {\n        if (err instanceof KeyNotFoundError) {\n          return 0;\n        }\n        throw err;\n      }\n    });\n\n    const values = await Promise.all(promises);\n    return values.reduce((sum, val) =&gt; sum + val, 0);\n  }\n}\n</code></pre>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#usage-example","title":"Usage Example","text":"<pre><code>const client = new NoriKVClient(config);\nawait client.connect();\n\n// Basic counter\nconst counter = new DistributedCounter(client, 'api:requests');\nawait counter.initialize();\n\nconst newCount = await counter.increment();\nconsole.log('Request count:', newCount);\n\n// Sharded counter for high throughput\nconst sharded = new ShardedCounter(client, 'page:views', 20);\n\n// Many concurrent increments\nawait Promise.all(\n  Array(1000).fill(0).map(() =&gt; sharded.increment())\n);\n\nconst total = await sharded.get();\nconsole.log('Total views:', total);\n</code></pre>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#session-management","title":"Session Management","text":"<p>Implement secure session storage with automatic expiration using TTL.</p>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#session-manager","title":"Session Manager","text":"<pre><code>import { v4 as uuidv4 } from 'uuid';\n\ninterface SessionData {\n  userId: string;\n  email: string;\n  roles: string[];\n  createdAt: number;\n  lastAccessedAt: number;\n}\n\nexport class SessionManager {\n  private client: NoriKVClient;\n  private ttlMs: number;\n  private prefix: string;\n\n  constructor(client: NoriKVClient, ttlMs: number = 3600000) {\n    this.client = client;\n    this.ttlMs = ttlMs; // Default: 1 hour\n    this.prefix = 'session';\n  }\n\n  private sessionKey(sessionId: string): string {\n    return `${this.prefix}:${sessionId}`;\n  }\n\n  async create(userId: string, email: string, roles: string[]): Promise&lt;string&gt; {\n    const sessionId = uuidv4();\n    const key = this.sessionKey(sessionId);\n\n    const data: SessionData = {\n      userId,\n      email,\n      roles,\n      createdAt: Date.now(),\n      lastAccessedAt: Date.now(),\n    };\n\n    await this.client.put(key, JSON.stringify(data), {\n      ttlMs: this.ttlMs,\n      idempotencyKey: `session-create-${sessionId}`,\n    });\n\n    return sessionId;\n  }\n\n  async get(sessionId: string): Promise&lt;SessionData | null&gt; {\n    try {\n      const result = await this.client.get(this.sessionKey(sessionId));\n      const data: SessionData = JSON.parse(bytesToString(result.value));\n\n      // Update last accessed time\n      data.lastAccessedAt = Date.now();\n      await this.client.put(this.sessionKey(sessionId), JSON.stringify(data), {\n        ttlMs: this.ttlMs, // Reset TTL\n      });\n\n      return data;\n    } catch (err) {\n      if (err instanceof KeyNotFoundError) {\n        return null;\n      }\n      throw err;\n    }\n  }\n\n  async update(sessionId: string, updateFn: (data: SessionData) =&gt; SessionData): Promise&lt;boolean&gt; {\n    const maxRetries = 5;\n\n    for (let attempt = 0; attempt &lt; maxRetries; attempt++) {\n      try {\n        const result = await this.client.get(this.sessionKey(sessionId));\n        const data: SessionData = JSON.parse(bytesToString(result.value));\n\n        // Apply update\n        const updated = updateFn(data);\n        updated.lastAccessedAt = Date.now();\n\n        // CAS write\n        await this.client.put(\n          this.sessionKey(sessionId),\n          JSON.stringify(updated),\n          {\n            ifMatchVersion: result.version,\n            ttlMs: this.ttlMs,\n          }\n        );\n\n        return true;\n\n      } catch (err) {\n        if (err instanceof KeyNotFoundError) {\n          return false;\n        }\n\n        if (!(err instanceof VersionMismatchError)) {\n          throw err;\n        }\n\n        // Retry with backoff\n        await new Promise(resolve =&gt;\n          setTimeout(resolve, Math.pow(2, attempt) * 10)\n        );\n      }\n    }\n\n    return false;\n  }\n\n  async destroy(sessionId: string): Promise&lt;boolean&gt; {\n    try {\n      return await this.client.delete(this.sessionKey(sessionId), {\n        idempotencyKey: `session-destroy-${sessionId}`,\n      });\n    } catch (err) {\n      if (err instanceof KeyNotFoundError) {\n        return false;\n      }\n      throw err;\n    }\n  }\n\n  async validate(sessionId: string): Promise&lt;boolean&gt; {\n    try {\n      await this.client.get(this.sessionKey(sessionId));\n      return true;\n    } catch (err) {\n      if (err instanceof KeyNotFoundError) {\n        return false;\n      }\n      throw err;\n    }\n  }\n}\n</code></pre>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#usage-example_1","title":"Usage Example","text":"<pre><code>const sessions = new SessionManager(client, 1800000); // 30 min\n\n// Create session\nconst sessionId = await sessions.create('user123', 'alice@example.com', ['user', 'admin']);\n\n// Middleware: validate session\nasync function authMiddleware(req, res, next) {\n  const sessionId = req.cookies.sessionId;\n\n  const sessionData = await sessions.get(sessionId);\n  if (!sessionData) {\n    return res.status(401).json({ error: 'Unauthorized' });\n  }\n\n  req.user = sessionData;\n  next();\n}\n\n// Update session\nawait sessions.update(sessionId, (data) =&gt; ({\n  ...data,\n  roles: [...data.roles, 'premium'],\n}));\n\n// Destroy session\nawait sessions.destroy(sessionId);\n</code></pre>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#inventory-management","title":"Inventory Management","text":"<p>Prevent overselling with optimistic concurrency control.</p>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#inventory-system","title":"Inventory System","text":"<pre><code>interface InventoryItem {\n  sku: string;\n  quantity: number;\n  reserved: number;\n  lastUpdated: number;\n}\n\nexport class InventoryManager {\n  private client: NoriKVClient;\n  private prefix: string;\n\n  constructor(client: NoriKVClient) {\n    this.client = client;\n    this.prefix = 'inventory';\n  }\n\n  private itemKey(sku: string): string {\n    return `${this.prefix}:${sku}`;\n  }\n\n  async createItem(sku: string, initialQuantity: number): Promise&lt;void&gt; {\n    const item: InventoryItem = {\n      sku,\n      quantity: initialQuantity,\n      reserved: 0,\n      lastUpdated: Date.now(),\n    };\n\n    await this.client.put(this.itemKey(sku), JSON.stringify(item));\n  }\n\n  async reserve(sku: string, quantity: number): Promise&lt;string&gt; {\n    const reservationId = uuidv4();\n    const maxRetries = 10;\n\n    for (let attempt = 0; attempt &lt; maxRetries; attempt++) {\n      try {\n        // Read current inventory\n        const result = await this.client.get(this.itemKey(sku));\n        const item: InventoryItem = JSON.parse(bytesToString(result.value));\n\n        // Check availability\n        const available = item.quantity - item.reserved;\n        if (available &lt; quantity) {\n          throw new Error(`Insufficient inventory: need ${quantity}, have ${available}`);\n        }\n\n        // Reserve quantity\n        item.reserved += quantity;\n        item.lastUpdated = Date.now();\n\n        // CAS write\n        await this.client.put(\n          this.itemKey(sku),\n          JSON.stringify(item),\n          { ifMatchVersion: result.version }\n        );\n\n        // Store reservation\n        await this.client.put(\n          `${this.prefix}:reservation:${reservationId}`,\n          JSON.stringify({ sku, quantity, createdAt: Date.now() }),\n          { ttlMs: 600000 } // 10 min expiration\n        );\n\n        return reservationId;\n\n      } catch (err) {\n        if (!(err instanceof VersionMismatchError)) {\n          throw err;\n        }\n\n        if (attempt === maxRetries - 1) {\n          throw new Error('Failed to reserve after retries');\n        }\n\n        // Exponential backoff\n        await new Promise(resolve =&gt;\n          setTimeout(resolve, Math.pow(2, attempt) * 10)\n        );\n      }\n    }\n\n    throw new Error('Should not reach here');\n  }\n\n  async commit(reservationId: string): Promise&lt;void&gt; {\n    const maxRetries = 10;\n\n    // Get reservation details\n    const reservationKey = `${this.prefix}:reservation:${reservationId}`;\n    const resResult = await this.client.get(reservationKey);\n    const reservation = JSON.parse(bytesToString(resResult.value));\n\n    for (let attempt = 0; attempt &lt; maxRetries; attempt++) {\n      try {\n        // Read current inventory\n        const result = await this.client.get(this.itemKey(reservation.sku));\n        const item: InventoryItem = JSON.parse(bytesToString(result.value));\n\n        // Commit: reduce both quantity and reserved\n        item.quantity -= reservation.quantity;\n        item.reserved -= reservation.quantity;\n        item.lastUpdated = Date.now();\n\n        // CAS write\n        await this.client.put(\n          this.itemKey(reservation.sku),\n          JSON.stringify(item),\n          { ifMatchVersion: result.version }\n        );\n\n        // Delete reservation\n        await this.client.delete(reservationKey);\n        return;\n\n      } catch (err) {\n        if (!(err instanceof VersionMismatchError)) {\n          throw err;\n        }\n\n        await new Promise(resolve =&gt;\n          setTimeout(resolve, Math.pow(2, attempt) * 10)\n        );\n      }\n    }\n\n    throw new Error('Failed to commit reservation');\n  }\n\n  async release(reservationId: string): Promise&lt;void&gt; {\n    const maxRetries = 10;\n\n    // Get reservation details\n    const reservationKey = `${this.prefix}:reservation:${reservationId}`;\n    const resResult = await this.client.get(reservationKey);\n    const reservation = JSON.parse(bytesToString(resResult.value));\n\n    for (let attempt = 0; attempt &lt; maxRetries; attempt++) {\n      try {\n        // Read current inventory\n        const result = await this.client.get(this.itemKey(reservation.sku));\n        const item: InventoryItem = JSON.parse(bytesToString(result.value));\n\n        // Release: reduce reserved only\n        item.reserved -= reservation.quantity;\n        item.lastUpdated = Date.now();\n\n        // CAS write\n        await this.client.put(\n          this.itemKey(reservation.sku),\n          JSON.stringify(item),\n          { ifMatchVersion: result.version }\n        );\n\n        // Delete reservation\n        await this.client.delete(reservationKey);\n        return;\n\n      } catch (err) {\n        if (!(err instanceof VersionMismatchError)) {\n          throw err;\n        }\n\n        await new Promise(resolve =&gt;\n          setTimeout(resolve, Math.pow(2, attempt) * 10)\n        );\n      }\n    }\n\n    throw new Error('Failed to release reservation');\n  }\n\n  async getAvailable(sku: string): Promise&lt;number&gt; {\n    const result = await this.client.get(this.itemKey(sku));\n    const item: InventoryItem = JSON.parse(bytesToString(result.value));\n    return item.quantity - item.reserved;\n  }\n}\n</code></pre>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#usage-example_2","title":"Usage Example","text":"<pre><code>const inventory = new InventoryManager(client);\n\n// Initialize inventory\nawait inventory.createItem('SKU-12345', 100);\n\n// Purchase flow\nasync function purchaseItem(sku: string, quantity: number) {\n  // 1. Reserve inventory\n  const reservationId = await inventory.reserve(sku, quantity);\n\n  try {\n    // 2. Process payment\n    await processPayment();\n\n    // 3. Commit reservation\n    await inventory.commit(reservationId);\n    console.log('Purchase successful');\n\n  } catch (err) {\n    // 4. Release reservation on failure\n    await inventory.release(reservationId);\n    console.error('Purchase failed:', err);\n    throw err;\n  }\n}\n\n// Check availability\nconst available = await inventory.getAvailable('SKU-12345');\nconsole.log('Available:', available);\n</code></pre>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#caching-layer","title":"Caching Layer","text":"<p>Implement a write-through cache with automatic invalidation.</p>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#cache-implementation","title":"Cache Implementation","text":"<pre><code>interface CacheEntry&lt;T&gt; {\n  value: T;\n  version: Version;\n  cachedAt: number;\n}\n\nexport class CachedClient&lt;T&gt; {\n  private client: NoriKVClient;\n  private cache: Map&lt;string, CacheEntry&lt;T&gt;&gt;;\n  private ttlMs: number;\n  private maxSize: number;\n\n  constructor(client: NoriKVClient, ttlMs: number = 60000, maxSize: number = 1000) {\n    this.client = client;\n    this.cache = new Map();\n    this.ttlMs = ttlMs;\n    this.maxSize = maxSize;\n  }\n\n  async get(key: string, parser: (bytes: Uint8Array) =&gt; T): Promise&lt;T&gt; {\n    // Check cache\n    const cached = this.cache.get(key);\n    if (cached &amp;&amp; Date.now() - cached.cachedAt &lt; this.ttlMs) {\n      return cached.value;\n    }\n\n    // Cache miss - fetch from NoriKV\n    const result = await this.client.get(key);\n    const value = parser(result.value);\n\n    // Update cache\n    this.setCache(key, {\n      value,\n      version: result.version,\n      cachedAt: Date.now(),\n    });\n\n    return value;\n  }\n\n  async put(key: string, value: T, serializer: (val: T) =&gt; string | Uint8Array): Promise&lt;Version&gt; {\n    // Write-through to NoriKV\n    const version = await this.client.put(key, serializer(value));\n\n    // Update cache\n    this.setCache(key, {\n      value,\n      version,\n      cachedAt: Date.now(),\n    });\n\n    return version;\n  }\n\n  async delete(key: string): Promise&lt;boolean&gt; {\n    // Invalidate cache\n    this.cache.delete(key);\n\n    // Delete from NoriKV\n    return await this.client.delete(key);\n  }\n\n  invalidate(key: string): void {\n    this.cache.delete(key);\n  }\n\n  invalidateAll(): void {\n    this.cache.clear();\n  }\n\n  private setCache(key: string, entry: CacheEntry&lt;T&gt;): void {\n    // LRU eviction\n    if (this.cache.size &gt;= this.maxSize) {\n      const firstKey = this.cache.keys().next().value;\n      this.cache.delete(firstKey);\n    }\n\n    this.cache.set(key, entry);\n  }\n\n  getStats() {\n    return {\n      size: this.cache.size,\n      maxSize: this.maxSize,\n      ttlMs: this.ttlMs,\n    };\n  }\n}\n</code></pre>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#usage-example_3","title":"Usage Example","text":"<pre><code>interface UserProfile {\n  id: string;\n  name: string;\n  email: string;\n}\n\nconst cache = new CachedClient&lt;UserProfile&gt;(client, 60000, 1000);\n\n// Get with automatic caching\nconst profile = await cache.get(\n  'user:123',\n  (bytes) =&gt; JSON.parse(bytesToString(bytes)) as UserProfile\n);\n\n// Write-through cache\nawait cache.put(\n  'user:123',\n  { id: '123', name: 'Alice', email: 'alice@example.com' },\n  (val) =&gt; JSON.stringify(val)\n);\n\n// Manual invalidation\ncache.invalidate('user:123');\n\n// Check stats\nconst stats = cache.getStats();\nconsole.log('Cache stats:', stats);\n</code></pre>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#rate-limiting","title":"Rate Limiting","text":"<p>Implement sliding window rate limiting for API throttling.</p>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#rate-limiter","title":"Rate Limiter","text":"<pre><code>interface RateLimitConfig {\n  maxRequests: number;\n  windowMs: number;\n}\n\nexport class RateLimiter {\n  private client: NoriKVClient;\n  private prefix: string;\n\n  constructor(client: NoriKVClient) {\n    this.client = client;\n    this.prefix = 'ratelimit';\n  }\n\n  private key(identifier: string): string {\n    return `${this.prefix}:${identifier}`;\n  }\n\n  async checkLimit(\n    identifier: string,\n    config: RateLimitConfig\n  ): Promise&lt;{ allowed: boolean; remaining: number; resetAt: number }&gt; {\n    const key = this.key(identifier);\n    const now = Date.now();\n    const windowStart = now - config.windowMs;\n\n    const maxRetries = 5;\n    for (let attempt = 0; attempt &lt; maxRetries; attempt++) {\n      try {\n        let timestamps: number[] = [];\n        let version = null;\n\n        // Read current timestamps\n        try {\n          const result = await this.client.get(key);\n          timestamps = JSON.parse(bytesToString(result.value));\n          version = result.version;\n        } catch (err) {\n          if (!(err instanceof KeyNotFoundError)) {\n            throw err;\n          }\n        }\n\n        // Remove old timestamps outside window\n        timestamps = timestamps.filter(ts =&gt; ts &gt; windowStart);\n\n        // Check if limit exceeded\n        const allowed = timestamps.length &lt; config.maxRequests;\n\n        if (allowed) {\n          // Add current timestamp\n          timestamps.push(now);\n\n          // Save updated timestamps\n          const options = version ? { ifMatchVersion: version } : {};\n          await this.client.put(\n            key,\n            JSON.stringify(timestamps),\n            {\n              ...options,\n              ttlMs: config.windowMs,\n            }\n          );\n        }\n\n        return {\n          allowed,\n          remaining: Math.max(0, config.maxRequests - timestamps.length),\n          resetAt: timestamps.length &gt; 0\n            ? Math.min(...timestamps) + config.windowMs\n            : now + config.windowMs,\n        };\n\n      } catch (err) {\n        if (!(err instanceof VersionMismatchError)) {\n          throw err;\n        }\n\n        // Retry with backoff\n        await new Promise(resolve =&gt;\n          setTimeout(resolve, Math.pow(2, attempt) * 10)\n        );\n      }\n    }\n\n    throw new Error('Rate limit check failed after retries');\n  }\n\n  async reset(identifier: string): Promise&lt;void&gt; {\n    await this.client.delete(this.key(identifier));\n  }\n}\n</code></pre>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#express-middleware-example","title":"Express Middleware Example","text":"<pre><code>const rateLimiter = new RateLimiter(client);\n\nfunction rateLimitMiddleware(config: RateLimitConfig) {\n  return async (req, res, next) =&gt; {\n    // Use IP address or user ID as identifier\n    const identifier = req.user?.id || req.ip;\n\n    try {\n      const result = await rateLimiter.checkLimit(identifier, config);\n\n      // Set rate limit headers\n      res.setHeader('X-RateLimit-Limit', config.maxRequests);\n      res.setHeader('X-RateLimit-Remaining', result.remaining);\n      res.setHeader('X-RateLimit-Reset', result.resetAt);\n\n      if (!result.allowed) {\n        return res.status(429).json({\n          error: 'Too Many Requests',\n          retryAfter: Math.ceil((result.resetAt - Date.now()) / 1000),\n        });\n      }\n\n      next();\n    } catch (err) {\n      console.error('Rate limit error:', err);\n      next(); // Fail open\n    }\n  };\n}\n\n// Usage\napp.use('/api', rateLimitMiddleware({\n  maxRequests: 100,\n  windowMs: 60000, // 100 requests per minute\n}));\n</code></pre>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#leader-election","title":"Leader Election","text":"<p>Implement distributed leader election with automatic failover.</p>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#leader-election_1","title":"Leader Election","text":"<pre><code>export class LeaderElection {\n  private client: NoriKVClient;\n  private name: string;\n  private nodeId: string;\n  private leaseTtlMs: number;\n  private running: boolean;\n  private isLeader: boolean;\n  private heartbeatInterval: NodeJS.Timeout | null;\n\n  constructor(client: NoriKVClient, electionName: string, nodeId: string, leaseTtlMs: number = 10000) {\n    this.client = client;\n    this.name = electionName;\n    this.nodeId = nodeId;\n    this.leaseTtlMs = leaseTtlMs;\n    this.running = false;\n    this.isLeader = false;\n    this.heartbeatInterval = null;\n  }\n\n  private leaderKey(): string {\n    return `leader:${this.name}`;\n  }\n\n  async start(onBecameLeader?: () =&gt; void, onLostLeadership?: () =&gt; void): Promise&lt;void&gt; {\n    this.running = true;\n\n    while (this.running) {\n      try {\n        await this.tryAcquireLease();\n\n        if (this.isLeader) {\n          if (onBecameLeader) {\n            onBecameLeader();\n          }\n\n          // Start heartbeat\n          await this.maintainLease();\n        } else {\n          // Wait before retrying\n          await new Promise(resolve =&gt; setTimeout(resolve, this.leaseTtlMs / 2));\n        }\n\n      } catch (err) {\n        console.error('Leader election error:', err);\n\n        if (this.isLeader &amp;&amp; onLostLeadership) {\n          onLostLeadership();\n        }\n\n        this.isLeader = false;\n        await new Promise(resolve =&gt; setTimeout(resolve, 1000));\n      }\n    }\n  }\n\n  async stop(): Promise&lt;void&gt; {\n    this.running = false;\n\n    if (this.heartbeatInterval) {\n      clearInterval(this.heartbeatInterval);\n      this.heartbeatInterval = null;\n    }\n\n    if (this.isLeader) {\n      await this.releaseLease();\n    }\n  }\n\n  private async tryAcquireLease(): Promise&lt;void&gt; {\n    const key = this.leaderKey();\n\n    try {\n      // Try to read current leader\n      const result = await this.client.get(key);\n      const currentLeader = bytesToString(result.value);\n\n      if (currentLeader === this.nodeId) {\n        this.isLeader = true;\n      }\n\n    } catch (err) {\n      if (err instanceof KeyNotFoundError) {\n        // No leader - try to become leader\n        try {\n          await this.client.put(key, this.nodeId, {\n            ttlMs: this.leaseTtlMs,\n          });\n          this.isLeader = true;\n        } catch (putErr) {\n          // Someone else became leader\n          this.isLeader = false;\n        }\n      } else {\n        throw err;\n      }\n    }\n  }\n\n  private async maintainLease(): Promise&lt;void&gt; {\n    const refreshInterval = this.leaseTtlMs / 3;\n\n    return new Promise((resolve) =&gt; {\n      this.heartbeatInterval = setInterval(async () =&gt; {\n        try {\n          await this.client.put(this.leaderKey(), this.nodeId, {\n            ttlMs: this.leaseTtlMs,\n          });\n        } catch (err) {\n          console.error('Failed to refresh lease:', err);\n          this.isLeader = false;\n\n          if (this.heartbeatInterval) {\n            clearInterval(this.heartbeatInterval);\n            this.heartbeatInterval = null;\n          }\n\n          resolve();\n        }\n      }, refreshInterval);\n    });\n  }\n\n  private async releaseLease(): Promise&lt;void&gt; {\n    try {\n      await this.client.delete(this.leaderKey());\n    } catch (err) {\n      console.error('Failed to release lease:', err);\n    }\n  }\n\n  getIsLeader(): boolean {\n    return this.isLeader;\n  }\n}\n</code></pre>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#usage-example_4","title":"Usage Example","text":"<pre><code>const election = new LeaderElection(client, 'my-service', 'node-1', 10000);\n\nawait election.start(\n  () =&gt; {\n    console.log('Became leader - starting background tasks');\n    startBackgroundJobs();\n  },\n  () =&gt; {\n    console.log('Lost leadership - stopping background tasks');\n    stopBackgroundJobs();\n  }\n);\n\n// Check leadership\nif (election.getIsLeader()) {\n  console.log('I am the leader');\n}\n\n// Graceful shutdown\nprocess.on('SIGTERM', async () =&gt; {\n  await election.stop();\n  await client.close();\n});\n</code></pre>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#event-sourcing","title":"Event Sourcing","text":"<p>Implement event sourcing pattern for audit logs and state reconstruction.</p>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#event-store","title":"Event Store","text":"<pre><code>interface Event {\n  id: string;\n  aggregateId: string;\n  type: string;\n  data: any;\n  timestamp: number;\n  version: number;\n}\n\nexport class EventStore {\n  private client: NoriKVClient;\n  private prefix: string;\n\n  constructor(client: NoriKVClient) {\n    this.client = client;\n    this.prefix = 'events';\n  }\n\n  private eventKey(aggregateId: string, version: number): string {\n    return `${this.prefix}:${aggregateId}:${version}`;\n  }\n\n  private metadataKey(aggregateId: string): string {\n    return `${this.prefix}:meta:${aggregateId}`;\n  }\n\n  async append(aggregateId: string, type: string, data: any): Promise&lt;Event&gt; {\n    const maxRetries = 10;\n\n    for (let attempt = 0; attempt &lt; maxRetries; attempt++) {\n      try {\n        // Read current version\n        let currentVersion = 0;\n        let metaVersion = null;\n\n        try {\n          const meta = await this.client.get(this.metadataKey(aggregateId));\n          const metadata = JSON.parse(bytesToString(meta.value));\n          currentVersion = metadata.version;\n          metaVersion = meta.version;\n        } catch (err) {\n          if (!(err instanceof KeyNotFoundError)) {\n            throw err;\n          }\n        }\n\n        const newVersion = currentVersion + 1;\n\n        // Create event\n        const event: Event = {\n          id: uuidv4(),\n          aggregateId,\n          type,\n          data,\n          timestamp: Date.now(),\n          version: newVersion,\n        };\n\n        // Write event\n        await this.client.put(\n          this.eventKey(aggregateId, newVersion),\n          JSON.stringify(event)\n        );\n\n        // Update metadata with CAS\n        const options = metaVersion ? { ifMatchVersion: metaVersion } : {};\n        await this.client.put(\n          this.metadataKey(aggregateId),\n          JSON.stringify({ version: newVersion }),\n          options\n        );\n\n        return event;\n\n      } catch (err) {\n        if (!(err instanceof VersionMismatchError)) {\n          throw err;\n        }\n\n        await new Promise(resolve =&gt;\n          setTimeout(resolve, Math.pow(2, attempt) * 10)\n        );\n      }\n    }\n\n    throw new Error('Failed to append event after retries');\n  }\n\n  async getEvents(aggregateId: string): Promise&lt;Event[]&gt; {\n    // Get current version\n    try {\n      const meta = await this.client.get(this.metadataKey(aggregateId));\n      const metadata = JSON.parse(bytesToString(meta.value));\n      const currentVersion = metadata.version;\n\n      // Fetch all events concurrently\n      const promises = Array.from({ length: currentVersion }, (_, i) =&gt;\n        this.client.get(this.eventKey(aggregateId, i + 1))\n      );\n\n      const results = await Promise.all(promises);\n      return results.map(r =&gt; JSON.parse(bytesToString(r.value)));\n\n    } catch (err) {\n      if (err instanceof KeyNotFoundError) {\n        return [];\n      }\n      throw err;\n    }\n  }\n\n  async getEventsAfter(aggregateId: string, afterVersion: number): Promise&lt;Event[]&gt; {\n    const allEvents = await this.getEvents(aggregateId);\n    return allEvents.filter(e =&gt; e.version &gt; afterVersion);\n  }\n}\n</code></pre>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#aggregate-example","title":"Aggregate Example","text":"<pre><code>interface BankAccount {\n  id: string;\n  balance: number;\n  isOpen: boolean;\n}\n\nclass BankAccountAggregate {\n  private store: EventStore;\n  private state: BankAccount;\n\n  constructor(store: EventStore, accountId: string) {\n    this.store = store;\n    this.state = {\n      id: accountId,\n      balance: 0,\n      isOpen: false,\n    };\n  }\n\n  async load(): Promise&lt;void&gt; {\n    const events = await this.store.getEvents(this.state.id);\n\n    for (const event of events) {\n      this.apply(event);\n    }\n  }\n\n  async openAccount(): Promise&lt;void&gt; {\n    if (this.state.isOpen) {\n      throw new Error('Account already open');\n    }\n\n    const event = await this.store.append(this.state.id, 'AccountOpened', {});\n    this.apply(event);\n  }\n\n  async deposit(amount: number): Promise&lt;void&gt; {\n    if (!this.state.isOpen) {\n      throw new Error('Account not open');\n    }\n\n    const event = await this.store.append(this.state.id, 'MoneyDeposited', { amount });\n    this.apply(event);\n  }\n\n  async withdraw(amount: number): Promise&lt;void&gt; {\n    if (!this.state.isOpen) {\n      throw new Error('Account not open');\n    }\n\n    if (this.state.balance &lt; amount) {\n      throw new Error('Insufficient funds');\n    }\n\n    const event = await this.store.append(this.state.id, 'MoneyWithdrawn', { amount });\n    this.apply(event);\n  }\n\n  private apply(event: Event): void {\n    switch (event.type) {\n      case 'AccountOpened':\n        this.state.isOpen = true;\n        break;\n      case 'MoneyDeposited':\n        this.state.balance += event.data.amount;\n        break;\n      case 'MoneyWithdrawn':\n        this.state.balance -= event.data.amount;\n        break;\n    }\n  }\n\n  getBalance(): number {\n    return this.state.balance;\n  }\n}\n</code></pre>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#usage-example_5","title":"Usage Example","text":"<pre><code>const eventStore = new EventStore(client);\n\nconst account = new BankAccountAggregate(eventStore, 'account-123');\n\n// Replay history\nawait account.load();\n\n// Execute commands (generates events)\nawait account.openAccount();\nawait account.deposit(100);\nawait account.withdraw(30);\n\nconsole.log('Balance:', account.getBalance()); // 70\n\n// Audit trail\nconst events = await eventStore.getEvents('account-123');\nconsole.log('Event history:', events);\n</code></pre>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#multi-tenancy","title":"Multi-Tenancy","text":"<p>Implement tenant isolation with namespace prefixing.</p>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#tenant-client","title":"Tenant Client","text":"<pre><code>export class TenantClient {\n  private client: NoriKVClient;\n  private tenantId: string;\n\n  constructor(client: NoriKVClient, tenantId: string) {\n    this.client = client;\n    this.tenantId = tenantId;\n  }\n\n  private tenantKey(key: string): string {\n    return `tenant:${this.tenantId}:${key}`;\n  }\n\n  async put(key: string, value: string | Uint8Array, options?: PutOptions): Promise&lt;Version&gt; {\n    return this.client.put(this.tenantKey(key), value, options);\n  }\n\n  async get(key: string, options?: GetOptions): Promise&lt;GetResult&gt; {\n    return this.client.get(this.tenantKey(key), options);\n  }\n\n  async delete(key: string, options?: DeleteOptions): Promise&lt;boolean&gt; {\n    return this.client.delete(this.tenantKey(key), options);\n  }\n\n  getTenantId(): string {\n    return this.tenantId;\n  }\n}\n</code></pre>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#tenant-manager","title":"Tenant Manager","text":"<pre><code>interface TenantMetadata {\n  id: string;\n  name: string;\n  plan: 'free' | 'pro' | 'enterprise';\n  createdAt: number;\n  limits: {\n    maxKeys: number;\n    maxStorageMB: number;\n  };\n}\n\nexport class TenantManager {\n  private client: NoriKVClient;\n  private prefix: string;\n\n  constructor(client: NoriKVClient) {\n    this.client = client;\n    this.prefix = 'tenant-meta';\n  }\n\n  private metadataKey(tenantId: string): string {\n    return `${this.prefix}:${tenantId}`;\n  }\n\n  async create(tenantId: string, name: string, plan: 'free' | 'pro' | 'enterprise'): Promise&lt;TenantMetadata&gt; {\n    const limits = this.getLimitsForPlan(plan);\n\n    const metadata: TenantMetadata = {\n      id: tenantId,\n      name,\n      plan,\n      createdAt: Date.now(),\n      limits,\n    };\n\n    await this.client.put(\n      this.metadataKey(tenantId),\n      JSON.stringify(metadata)\n    );\n\n    return metadata;\n  }\n\n  async get(tenantId: string): Promise&lt;TenantMetadata | null&gt; {\n    try {\n      const result = await this.client.get(this.metadataKey(tenantId));\n      return JSON.parse(bytesToString(result.value));\n    } catch (err) {\n      if (err instanceof KeyNotFoundError) {\n        return null;\n      }\n      throw err;\n    }\n  }\n\n  async getClient(tenantId: string): Promise&lt;TenantClient&gt; {\n    const metadata = await this.get(tenantId);\n    if (!metadata) {\n      throw new Error(`Tenant not found: ${tenantId}`);\n    }\n\n    return new TenantClient(this.client, tenantId);\n  }\n\n  private getLimitsForPlan(plan: string) {\n    const limits = {\n      free: { maxKeys: 1000, maxStorageMB: 10 },\n      pro: { maxKeys: 100000, maxStorageMB: 1000 },\n      enterprise: { maxKeys: Infinity, maxStorageMB: Infinity },\n    };\n\n    return limits[plan] || limits.free;\n  }\n}\n</code></pre>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#express-integration","title":"Express Integration","text":"<pre><code>const tenantManager = new TenantManager(client);\n\n// Middleware: extract tenant from request\nasync function tenantMiddleware(req, res, next) {\n  const tenantId = req.headers['x-tenant-id'] || req.query.tenantId;\n\n  if (!tenantId) {\n    return res.status(400).json({ error: 'Tenant ID required' });\n  }\n\n  // Get tenant-scoped client\n  try {\n    req.tenantClient = await tenantManager.getClient(tenantId);\n    req.tenantMetadata = await tenantManager.get(tenantId);\n    next();\n  } catch (err) {\n    return res.status(404).json({ error: 'Tenant not found' });\n  }\n}\n\n// Route handlers use tenant-scoped client\napp.use('/api', tenantMiddleware);\n\napp.get('/api/data/:key', async (req, res) =&gt; {\n  try {\n    const result = await req.tenantClient.get(req.params.key);\n    res.json({ value: bytesToString(result.value) });\n  } catch (err) {\n    if (err instanceof KeyNotFoundError) {\n      return res.status(404).json({ error: 'Not found' });\n    }\n    throw err;\n  }\n});\n\napp.post('/api/data/:key', async (req, res) =&gt; {\n  await req.tenantClient.put(req.params.key, req.body.value);\n  res.json({ success: true });\n});\n</code></pre>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#usage-example_6","title":"Usage Example","text":"<pre><code>// Create tenants\nawait tenantManager.create('tenant-acme', 'Acme Corp', 'pro');\nawait tenantManager.create('tenant-widgets', 'Widgets Inc', 'enterprise');\n\n// Get tenant-scoped clients\nconst acmeClient = await tenantManager.getClient('tenant-acme');\nconst widgetsClient = await tenantManager.getClient('tenant-widgets');\n\n// Isolated operations\nawait acmeClient.put('config', 'acme-config');\nawait widgetsClient.put('config', 'widgets-config');\n\n// Data is isolated\nconst acmeConfig = await acmeClient.get('config'); // 'acme-config'\nconst widgetsConfig = await widgetsClient.get('config'); // 'widgets-config'\n</code></pre>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#best-practices","title":"Best Practices","text":""},{"location":"sdks/typescript/ADVANCED_PATTERNS/#1-always-use-try-catch-with-asyncawait","title":"1. Always Use try-catch with async/await","text":"<pre><code>try {\n  await client.put(key, value);\n} catch (err) {\n  console.error('Operation failed:', err);\n}\n</code></pre>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#2-implement-retry-logic-for-cas","title":"2. Implement Retry Logic for CAS","text":"<pre><code>async function casRetry&lt;T&gt;(\n  operation: () =&gt; Promise&lt;T&gt;,\n  maxRetries: number = 10\n): Promise&lt;T&gt; {\n  for (let attempt = 0; attempt &lt; maxRetries; attempt++) {\n    try {\n      return await operation();\n    } catch (err) {\n      if (!(err instanceof VersionMismatchError) || attempt === maxRetries - 1) {\n        throw err;\n      }\n      await new Promise(r =&gt; setTimeout(r, Math.pow(2, attempt) * 10));\n    }\n  }\n  throw new Error('Unreachable');\n}\n</code></pre>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#3-use-typescript-types","title":"3. Use TypeScript Types","text":"<pre><code>interface UserData {\n  id: string;\n  name: string;\n  email: string;\n}\n\nasync function getUser(key: string): Promise&lt;UserData&gt; {\n  const result = await client.get(key);\n  return JSON.parse(bytesToString(result.value)) as UserData;\n}\n</code></pre>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#4-clean-up-resources","title":"4. Clean Up Resources","text":"<pre><code>const client = new NoriKVClient(config);\nawait client.connect();\n\ntry {\n  // Use client\n} finally {\n  await client.close();\n}\n</code></pre>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#5-use-idempotency-keys-for-critical-operations","title":"5. Use Idempotency Keys for Critical Operations","text":"<pre><code>await client.put(key, value, {\n  idempotencyKey: `operation-${operationId}`,\n});\n</code></pre>"},{"location":"sdks/typescript/ADVANCED_PATTERNS/#next-steps","title":"Next Steps","text":"<ul> <li>API Guide - Core API reference</li> <li>Architecture Guide - Internal design</li> <li>Troubleshooting Guide - Common issues</li> <li>GitHub Examples - More code samples</li> </ul>"},{"location":"sdks/typescript/API_GUIDE/","title":"NoriKV TypeScript Client API Guide","text":"<p>Complete reference for the NoriKV TypeScript/JavaScript Client SDK.</p>"},{"location":"sdks/typescript/API_GUIDE/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Installation</li> <li>Quick Start</li> <li>Client Configuration</li> <li>Core Operations</li> <li>Advanced Features</li> <li>Error Handling</li> <li>Best Practices</li> </ul>"},{"location":"sdks/typescript/API_GUIDE/#installation","title":"Installation","text":"<pre><code>npm install @norikv/client\n# or\nyarn add @norikv/client\n# or\npnpm add @norikv/client\n</code></pre>"},{"location":"sdks/typescript/API_GUIDE/#quick-start","title":"Quick Start","text":"<pre><code>import { NoriKVClient, bytesToString } from '@norikv/client';\n\nconst client = new NoriKVClient({\n  nodes: ['localhost:9001', 'localhost:9002'],\n  totalShards: 1024,\n  timeout: 5000,\n});\n\nawait client.connect();\n\n// Put a value\nawait client.put('user:alice', 'Alice');\n\n// Get the value\nconst result = await client.get('user:alice');\nconsole.log(bytesToString(result.value)); // 'Alice'\n\n// Delete\nawait client.delete('user:alice');\n\nawait client.close();\n</code></pre>"},{"location":"sdks/typescript/API_GUIDE/#client-configuration","title":"Client Configuration","text":""},{"location":"sdks/typescript/API_GUIDE/#basic-configuration","title":"Basic Configuration","text":"<pre><code>import { NoriKVClient, ClientConfig } from '@norikv/client';\n\nconst config: ClientConfig = {\n  nodes: ['node1:9001', 'node2:9001'],\n  totalShards: 1024,\n  timeout: 5000,\n};\n\nconst client = new NoriKVClient(config);\n</code></pre>"},{"location":"sdks/typescript/API_GUIDE/#configuration-options","title":"Configuration Options","text":"Option Type Default Description <code>nodes</code> <code>string[]</code> Required List of node addresses (host:port) <code>totalShards</code> <code>number</code> Required Total number of shards in cluster <code>timeout</code> <code>number</code> 5000 Request timeout in milliseconds <code>retry</code> <code>RetryConfig</code> See below Retry policy configuration"},{"location":"sdks/typescript/API_GUIDE/#retry-configuration","title":"Retry Configuration","text":"<pre><code>import { RetryConfig } from '@norikv/client';\n\nconst retryConfig: RetryConfig = {\n  maxAttempts: 10,\n  initialDelayMs: 100,\n  maxDelayMs: 5000,\n  jitterMs: 100,\n};\n\nconst client = new NoriKVClient({\n  nodes: ['localhost:9001'],\n  totalShards: 1024,\n  retry: retryConfig,\n});\n</code></pre> <p>Retry Behavior: - Retries transient errors: <code>Unavailable</code>, <code>Aborted</code>, <code>DeadlineExceeded</code> - Does NOT retry: <code>InvalidArgument</code>, <code>NotFound</code>, <code>FailedPrecondition</code> - Uses exponential backoff with jitter</p>"},{"location":"sdks/typescript/API_GUIDE/#core-operations","title":"Core Operations","text":""},{"location":"sdks/typescript/API_GUIDE/#put-write-data","title":"PUT - Write Data","text":""},{"location":"sdks/typescript/API_GUIDE/#basic-put","title":"Basic PUT","text":"<pre><code>const key = 'user:123';\nconst value = JSON.stringify({ name: 'Alice' });\n\nconst version = await client.put(key, value);\nconsole.log('Written at version:', version);\n</code></pre>"},{"location":"sdks/typescript/API_GUIDE/#put-with-options","title":"PUT with Options","text":"<pre><code>import { PutOptions } from '@norikv/client';\n\nconst options: PutOptions = {\n  ttlMs: 60000,                    // TTL: 60 seconds\n  idempotencyKey: 'order-12345',   // Idempotency key\n  ifMatchVersion: expectedVersion, // CAS\n};\n\nconst version = await client.put(key, value, options);\n</code></pre> <p>PutOptions Fields:</p> Field Type Description <code>ttlMs</code> <code>number?</code> Time-to-live in milliseconds <code>idempotencyKey</code> <code>string?</code> Key for idempotent operations <code>ifMatchVersion</code> <code>Version?</code> Expected version for CAS"},{"location":"sdks/typescript/API_GUIDE/#get-read-data","title":"GET - Read Data","text":""},{"location":"sdks/typescript/API_GUIDE/#basic-get","title":"Basic GET","text":"<pre><code>const result = await client.get('user:123');\n\nconst value = bytesToString(result.value);\nconst version = result.version;\n</code></pre>"},{"location":"sdks/typescript/API_GUIDE/#get-with-consistency-level","title":"GET with Consistency Level","text":"<pre><code>import { GetOptions, ConsistencyLevel } from '@norikv/client';\n\nconst options: GetOptions = {\n  consistency: ConsistencyLevel.LINEARIZABLE,\n};\n\nconst result = await client.get(key, options);\n</code></pre> <p>Consistency Levels:</p> Level Description Use Case <code>LEASE</code> Default, lease-based read Most operations (fast, usually consistent) <code>LINEARIZABLE</code> Strictest, always up-to-date Critical reads requiring absolute consistency <code>STALE_OK</code> May return stale data Read-heavy workloads, caching"},{"location":"sdks/typescript/API_GUIDE/#delete-remove-data","title":"DELETE - Remove Data","text":""},{"location":"sdks/typescript/API_GUIDE/#basic-delete","title":"Basic DELETE","text":"<pre><code>const deleted = await client.delete('user:123');\nconsole.log('Deleted:', deleted);\n</code></pre>"},{"location":"sdks/typescript/API_GUIDE/#delete-with-options","title":"DELETE with Options","text":"<pre><code>import { DeleteOptions } from '@norikv/client';\n\nconst options: DeleteOptions = {\n  idempotencyKey: 'delete-order-12345',\n  ifMatchVersion: expectedVersion,\n};\n\nawait client.delete(key, options);\n</code></pre>"},{"location":"sdks/typescript/API_GUIDE/#advanced-features","title":"Advanced Features","text":""},{"location":"sdks/typescript/API_GUIDE/#compare-and-swap-cas","title":"Compare-And-Swap (CAS)","text":"<p>Optimistic concurrency control using version matching:</p> <pre><code>// Read current value\nconst current = await client.get(key);\nconst value = parseInt(bytesToString(current.value));\n\n// Update with CAS\nconst newValue = (value + 1).toString();\ntry {\n  await client.put(key, newValue, {\n    ifMatchVersion: current.version,\n  });\n  console.log('CAS succeeded');\n} catch (err) {\n  if (err instanceof VersionMismatchError) {\n    console.log('CAS failed - version changed');\n  }\n  throw err;\n}\n</code></pre>"},{"location":"sdks/typescript/API_GUIDE/#idempotent-operations","title":"Idempotent Operations","text":"<p>Safe retries using idempotency keys:</p> <pre><code>import { v4 as uuidv4 } from 'uuid';\n\nconst idempotencyKey = `payment-${uuidv4()}`;\n\n// First attempt\nconst v1 = await client.put(key, value, { idempotencyKey });\n\n// Retry with same key (safe - returns same version)\nconst v2 = await client.put(key, value, { idempotencyKey });\n\nconsole.log(v1.equals(v2)); // true\n</code></pre>"},{"location":"sdks/typescript/API_GUIDE/#time-to-live-ttl","title":"Time-To-Live (TTL)","text":"<p>Automatic expiration:</p> <pre><code>await client.put(key, value, {\n  ttlMs: 60000, // Expires in 60 seconds\n});\n\n// Key automatically deleted after TTL\nawait new Promise(resolve =&gt; setTimeout(resolve, 61000));\n\ntry {\n  await client.get(key);\n} catch (err) {\n  if (err instanceof KeyNotFoundError) {\n    console.log('Key expired');\n  }\n}\n</code></pre>"},{"location":"sdks/typescript/API_GUIDE/#cluster-topology","title":"Cluster Topology","text":"<p>Monitor cluster changes:</p> <pre><code>// Get current cluster view\nconst view = client.getClusterView();\nif (view) {\n  console.log('Cluster epoch:', view.epoch);\n  console.log('Nodes:', view.nodes.length);\n}\n\n// Subscribe to topology changes\nconst unsubscribe = client.onTopologyChange((event) =&gt; {\n  console.log('Topology changed!');\n  console.log('Previous epoch:', event.previousEpoch);\n  console.log('Current epoch:', event.currentEpoch);\n  console.log('Added nodes:', event.addedNodes);\n  console.log('Removed nodes:', event.removedNodes);\n});\n\n// Later: unsubscribe\nunsubscribe();\n</code></pre>"},{"location":"sdks/typescript/API_GUIDE/#client-statistics","title":"Client Statistics","text":"<p>Monitor client performance:</p> <pre><code>const stats = client.getStats();\n\nconsole.log('Active connections:', stats.pool.activeConnections);\nconsole.log('Total nodes:', stats.router.totalNodes);\nconsole.log('Cached leaders:', stats.topology.cachedLeaders);\n</code></pre>"},{"location":"sdks/typescript/API_GUIDE/#error-handling","title":"Error Handling","text":""},{"location":"sdks/typescript/API_GUIDE/#error-types","title":"Error Types","text":"<pre><code>import {\n  KeyNotFoundError,\n  VersionMismatchError,\n  AlreadyExistsError,\n  ConnectionError,\n  NoriKVError,\n} from '@norikv/client';\n</code></pre>"},{"location":"sdks/typescript/API_GUIDE/#handling-specific-errors","title":"Handling Specific Errors","text":"<pre><code>try {\n  const result = await client.get(key);\n} catch (err) {\n  if (err instanceof KeyNotFoundError) {\n    console.log('Key not found');\n  } else if (err instanceof ConnectionError) {\n    console.log('Connection error:', err.message);\n  } else if (err instanceof NoriKVError) {\n    console.log('Error:', err.code, err.message);\n  } else {\n    throw err;\n  }\n}\n</code></pre>"},{"location":"sdks/typescript/API_GUIDE/#retry-pattern","title":"Retry Pattern","text":"<pre><code>async function retryOperation&lt;T&gt;(\n  operation: () =&gt; Promise&lt;T&gt;,\n  maxAttempts: number = 3\n): Promise&lt;T&gt; {\n  for (let attempt = 1; attempt &lt;= maxAttempts; attempt++) {\n    try {\n      return await operation();\n    } catch (err) {\n      if (!(err instanceof ConnectionError)) {\n        throw err; // Non-retryable\n      }\n\n      if (attempt === maxAttempts) {\n        throw err; // Give up\n      }\n\n      // Exponential backoff\n      await new Promise(resolve =&gt; \n        setTimeout(resolve, Math.pow(2, attempt) * 100)\n      );\n    }\n  }\n  throw new Error('Unreachable');\n}\n\n// Usage\nconst result = await retryOperation(() =&gt; client.put(key, value));\n</code></pre>"},{"location":"sdks/typescript/API_GUIDE/#graceful-degradation","title":"Graceful Degradation","text":"<pre><code>async function getWithFallback(\n  client: NoriKVClient,\n  key: string,\n  defaultValue: string\n): Promise&lt;string&gt; {\n  try {\n    const result = await client.get(key);\n    return bytesToString(result.value);\n  } catch (err) {\n    console.warn('Failed to get key, using default:', err);\n    return defaultValue;\n  }\n}\n</code></pre>"},{"location":"sdks/typescript/API_GUIDE/#best-practices","title":"Best Practices","text":""},{"location":"sdks/typescript/API_GUIDE/#1-always-await-connect-and-close","title":"1. Always await connect() and close()","text":"<pre><code>const client = new NoriKVClient(config);\nawait client.connect();\n\ntry {\n  // Use client\n} finally {\n  await client.close();\n}\n</code></pre>"},{"location":"sdks/typescript/API_GUIDE/#2-reuse-client-instances","title":"2. Reuse Client Instances","text":"<pre><code>//  Good: Single client instance\nlet client: NoriKVClient;\n\nasync function init() {\n  client = new NoriKVClient(config);\n  await client.connect();\n}\n\n//  Bad: Creating client per request\nasync function handleRequest() {\n  const client = new NoriKVClient(config);\n  await client.connect();\n  await client.close(); // Closes connections!\n}\n</code></pre>"},{"location":"sdks/typescript/API_GUIDE/#3-use-typescript-types","title":"3. Use TypeScript Types","text":"<pre><code>import { GetResult, Version, PutOptions } from '@norikv/client';\n\nasync function updateUser(userId: string, data: UserData): Promise&lt;Version&gt; {\n  const key = `user:${userId}`;\n  const value = JSON.stringify(data);\n\n  const options: PutOptions = {\n    ttlMs: 3600000,\n  };\n\n  return await client.put(key, value, options);\n}\n</code></pre>"},{"location":"sdks/typescript/API_GUIDE/#4-handle-errors-properly","title":"4. Handle Errors Properly","text":"<pre><code>async function safeGet(key: string): Promise&lt;string | null&gt; {\n  try {\n    const result = await client.get(key);\n    return bytesToString(result.value);\n  } catch (err) {\n    if (err instanceof KeyNotFoundError) {\n      return null;\n    }\n    throw err;\n  }\n}\n</code></pre>"},{"location":"sdks/typescript/API_GUIDE/#5-use-asyncawait-consistently","title":"5. Use Async/Await Consistently","text":"<pre><code>//  Good: Clean async/await\nasync function processUser(userId: string) {\n  const userData = await client.get(`user:${userId}`);\n  const processed = await processData(userData.value);\n  await client.put(`processed:${userId}`, processed);\n}\n\n//  Bad: Mixing promises and async/await\nasync function processUserBad(userId: string) {\n  return client.get(`user:${userId}`).then(userData =&gt; {\n    return processData(userData.value).then(processed =&gt; {\n      return client.put(`processed:${userId}`, processed);\n    });\n  });\n}\n</code></pre>"},{"location":"sdks/typescript/API_GUIDE/#6-use-idempotency-keys-for-important-operations","title":"6. Use Idempotency Keys for Important Operations","text":"<pre><code>async function createOrder(orderId: string, data: OrderData) {\n  await client.put(`order:${orderId}`, JSON.stringify(data), {\n    idempotencyKey: `create-order-${orderId}`,\n  });\n}\n</code></pre>"},{"location":"sdks/typescript/API_GUIDE/#7-choose-appropriate-consistency","title":"7. Choose Appropriate Consistency","text":"<pre><code>// For critical reads\nconst result = await client.get(key, {\n  consistency: ConsistencyLevel.LINEARIZABLE,\n});\n\n// For cache-like reads\nconst result = await client.get(key, {\n  consistency: ConsistencyLevel.STALE_OK,\n});\n</code></pre>"},{"location":"sdks/typescript/API_GUIDE/#8-use-proper-encoding","title":"8. Use Proper Encoding","text":"<pre><code>import { stringToBytes, bytesToString } from '@norikv/client';\n\n// Always use UTF-8 encoding helpers\nconst value = stringToBytes('Hello, World!');\nawait client.put(key, value);\n\nconst result = await client.get(key);\nconst text = bytesToString(result.value);\n</code></pre>"},{"location":"sdks/typescript/API_GUIDE/#performance-tips","title":"Performance Tips","text":""},{"location":"sdks/typescript/API_GUIDE/#1-batch-operations-with-promiseall","title":"1. Batch Operations with Promise.all","text":"<pre><code>// Process multiple operations concurrently\nawait Promise.all(\n  keys.map(key =&gt; client.put(key, value))\n);\n</code></pre>"},{"location":"sdks/typescript/API_GUIDE/#2-connection-pooling-automatic","title":"2. Connection Pooling (Automatic)","text":"<p>The client maintains connection pools internally - no external pooling needed.</p>"},{"location":"sdks/typescript/API_GUIDE/#3-avoid-creating-clients-per-request","title":"3. Avoid Creating Clients Per Request","text":"<p>Reuse client instances across requests for better performance.</p>"},{"location":"sdks/typescript/API_GUIDE/#4-use-appropriate-value-sizes","title":"4. Use Appropriate Value Sizes","text":"<ul> <li>Optimal: 100 bytes - 10 KB</li> <li>Maximum: Limited by memory and network</li> </ul>"},{"location":"sdks/typescript/API_GUIDE/#5-monitor-performance","title":"5. Monitor Performance","text":"<pre><code>const start = Date.now();\nawait client.put(key, value);\nconst duration = Date.now() - start;\nconsole.log(`PUT took ${duration}ms`);\n</code></pre>"},{"location":"sdks/typescript/API_GUIDE/#complete-example","title":"Complete Example","text":"<pre><code>import {\n  NoriKVClient,\n  ClientConfig,\n  PutOptions,\n  GetOptions,\n  ConsistencyLevel,\n  bytesToString,\n  stringToBytes,\n} from '@norikv/client';\n\nasync function main() {\n  // Configure with retry policy\n  const config: ClientConfig = {\n    nodes: ['localhost:9001', 'localhost:9002'],\n    totalShards: 1024,\n    timeout: 5000,\n    retry: {\n      maxAttempts: 5,\n      initialDelayMs: 100,\n      maxDelayMs: 2000,\n    },\n  };\n\n  const client = new NoriKVClient(config);\n  await client.connect();\n\n  try {\n    // Write with TTL and idempotency\n    const key = 'session:abc123';\n    const value = JSON.stringify({ userId: 42 });\n\n    const putOpts: PutOptions = {\n      ttlMs: 3600000, // 1 hour\n      idempotencyKey: 'session-create-abc123',\n    };\n\n    const version = await client.put(key, stringToBytes(value), putOpts);\n    console.log('Written:', version);\n\n    // Read with linearizable consistency\n    const getOpts: GetOptions = {\n      consistency: ConsistencyLevel.LINEARIZABLE,\n    };\n\n    const result = await client.get(key, getOpts);\n    console.log('Read:', bytesToString(result.value));\n\n    // Update with CAS\n    const newValue = JSON.stringify({ userId: 42, active: true });\n\n    try {\n      await client.put(key, stringToBytes(newValue), {\n        ifMatchVersion: result.version,\n      });\n      console.log('CAS succeeded');\n    } catch (err) {\n      if (err instanceof VersionMismatchError) {\n        console.log('CAS failed - retry needed');\n      }\n    }\n\n    // Monitor topology\n    client.onTopologyChange((event) =&gt; {\n      console.log('Cluster changed: epoch', event.currentEpoch);\n    });\n\n    // Get statistics\n    const stats = client.getStats();\n    console.log('Stats:', stats);\n\n  } finally {\n    await client.close();\n  }\n}\n\nmain().catch(console.error);\n</code></pre>"},{"location":"sdks/typescript/API_GUIDE/#next-steps","title":"Next Steps","text":"<ul> <li>Architecture Guide - Understanding client internals</li> <li>Troubleshooting Guide - Solving common issues</li> <li>Advanced Patterns - Complex use cases</li> <li>Examples - Working code samples</li> </ul>"},{"location":"sdks/typescript/ARCHITECTURE/","title":"NoriKV TypeScript Client Architecture","text":"<p>Understanding the internal design and components of the TypeScript client SDK.</p>"},{"location":"sdks/typescript/ARCHITECTURE/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>Component Architecture</li> <li>Request Flow</li> <li>Async/Promise Model</li> <li>Connection Management</li> <li>Routing &amp; Sharding</li> <li>Retry Logic</li> <li>Error Handling</li> </ul>"},{"location":"sdks/typescript/ARCHITECTURE/#overview","title":"Overview","text":"<p>The NoriKV TypeScript client is designed as a smart client that: - Routes requests directly to the appropriate shard leader - Maintains connection pools for efficient communication - Implements retry logic with exponential backoff - Tracks cluster topology changes - Provides Promise-based async operations - Optimizes for V8 JavaScript engine</p>"},{"location":"sdks/typescript/ARCHITECTURE/#design-principles","title":"Design Principles","text":"<ol> <li>Zero-hop routing: Client routes directly to shard leader (no proxy)</li> <li>Async-first: All operations return Promises</li> <li>Type-safe: Full TypeScript types for compile-time safety</li> <li>Observable: Expose metrics and statistics</li> <li>Dual-package: ESM + CommonJS support</li> </ol>"},{"location":"sdks/typescript/ARCHITECTURE/#component-architecture","title":"Component Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    NoriKVClient                          \u2502\n\u2502  (Main API: put, get, delete, topology, stats)          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502          \u2502          \u2502          \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Router   \u2502 \u2502 Retry \u2502 \u2502   Pool   \u2502 \u2502 Topology  \u2502\n\u2502            \u2502 \u2502Policy \u2502 \u2502          \u2502 \u2502 Manager   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502                         \u2502              \u2502\n     \u2502                         \u2502              \u2502\n     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500hash()\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524              \u2502\n                               \u2502              \u2502\n     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500getChannel()\u2500\u2500\u2500\u2500\u2524              \u2502\n     \u2502                         \u2502              \u2502\n     \u2502                    \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510         \u2502\n     \u2502                    \u2502  gRPC   \u2502         \u2502\n     \u2502                    \u2502Channels \u2502         \u2502\n     \u2502                    \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518         \u2502\n     \u2502                         \u2502              \u2502\n     \u2502                         \u2502              \u2502\n     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500updateView()\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"sdks/typescript/ARCHITECTURE/#components","title":"Components","text":""},{"location":"sdks/typescript/ARCHITECTURE/#1-norikvclient","title":"1. NoriKVClient","text":"<p>Responsibility: Main public API and component coordination</p> <p>Key Methods: - <code>put()</code>, <code>get()</code>, <code>delete()</code> - Core operations (all async) - <code>getClusterView()</code> - Topology information - <code>onTopologyChange()</code> - Subscribe to topology updates - <code>getStats()</code> - Client statistics - <code>close()</code> - Resource cleanup</p> <p>Location: <code>src/client.ts</code></p>"},{"location":"sdks/typescript/ARCHITECTURE/#2-router","title":"2. Router","text":"<p>Responsibility: Determine which node to send requests to</p> <p>Key Functions: - Hash key to shard: <code>xxhash64(key) \u2192 jumpConsistentHash(hash, totalShards) \u2192 shardId</code> - Map shard to leader node - Cache leader information - Handle leader hints from <code>NOT_LEADER</code> errors</p> <p>Location: <code>src/internal/router.ts</code></p> <p>Algorithm: <pre><code>1. Hash key using XXHash64 (seed=0) via xxhash-wasm\n2. Map hash to shard using Jump Consistent Hash\n3. Look up shard leader in topology cache\n4. Return leader's address\n</code></pre></p>"},{"location":"sdks/typescript/ARCHITECTURE/#3-connectionpool","title":"3. ConnectionPool","text":"<p>Responsibility: Manage gRPC channels to cluster nodes</p> <p>Key Functions: - Create and cache gRPC channels per node - Thread-safe concurrent access - Graceful shutdown</p> <p>Location: <code>src/internal/conn/pool.ts</code></p> <p>Design: - One gRPC <code>Client</code> per node address - Lazy initialization (created on first use) - Channels reused across requests - Automatic cleanup on client close</p>"},{"location":"sdks/typescript/ARCHITECTURE/#4-retrypolicy","title":"4. RetryPolicy","text":"<p>Responsibility: Handle transient failures with backoff</p> <p>Key Functions: - Exponential backoff: <code>delay = min(initialDelay * 2^attempt, maxDelay)</code> - Jitter: Add randomness to avoid thundering herd - Selective retry: Only retry transient errors - Attempt tracking</p> <p>Location: <code>src/internal/retry/policy.ts</code></p> <p>Retryable Errors: - <code>Unavailable</code> - Server temporarily unavailable - <code>Aborted</code> - Operation aborted, safe to retry - <code>DeadlineExceeded</code> - Timeout, may succeed on retry - <code>ResourceExhausted</code> - Rate limited, backoff helps</p> <p>Non-Retryable Errors: - <code>InvalidArgument</code> - Client error, won't succeed - <code>NotFound</code> - Key doesn't exist - <code>FailedPrecondition</code> - CAS conflict, application must retry - <code>PermissionDenied</code> - Auth error</p>"},{"location":"sdks/typescript/ARCHITECTURE/#5-topologymanager","title":"5. TopologyManager","text":"<p>Responsibility: Track cluster membership and shard assignments</p> <p>Key Functions: - Store current <code>ClusterView</code> - Cache shard \u2192 leader mappings - Detect topology changes - Notify listeners of changes - Update leader hints</p> <p>Location: <code>src/internal/topology/manager.ts</code></p> <p>Data Structures: - <code>ClusterView</code>: Current cluster state (epoch, nodes, shards) - <code>shardLeaderCache</code>: Map - <code>listeners</code>: Array of change callbacks"},{"location":"sdks/typescript/ARCHITECTURE/#request-flow","title":"Request Flow","text":""},{"location":"sdks/typescript/ARCHITECTURE/#put-request-flow","title":"PUT Request Flow","text":"<pre><code>Client.put(key, value, options)\n    \u2502\n    \u251c\u2500&gt; 1. Validate inputs (key, value not null/empty)\n    \u2502\n    \u251c\u2500&gt; 2. Router.getNodeForKey(key)\n    \u2502       \u251c\u2500&gt; hash = xxhash64(key)\n    \u2502       \u251c\u2500&gt; shardId = jumpConsistentHash(hash, totalShards)\n    \u2502       \u2514\u2500&gt; leaderAddr = topologyManager.getShardLeader(shardId)\n    \u2502\n    \u251c\u2500&gt; 3. ConnectionPool.getChannel(leaderAddr)\n    \u2502       \u2514\u2500&gt; Return cached or create new gRPC channel\n    \u2502\n    \u251c\u2500&gt; 4. RetryPolicy.execute(async () =&gt; {\n    \u2502       \u251c\u2500&gt; Build gRPC PutRequest\n    \u2502       \u251c\u2500&gt; await grpcClient.put(request)\n    \u2502       \u2514\u2500&gt; Convert response to Version\n    \u2502   })\n    \u2502       \u251c\u2500&gt; On SUCCESS: return Version\n    \u2502       \u251c\u2500&gt; On RETRYABLE_ERROR: backoff and retry\n    \u2502       \u2514\u2500&gt; On NON_RETRYABLE: throw error\n    \u2502\n    \u2514\u2500&gt; 5. Return Version to caller\n</code></pre>"},{"location":"sdks/typescript/ARCHITECTURE/#get-request-flow","title":"GET Request Flow","text":"<p>Similar to PUT, but: - Uses <code>GetRequest</code> with consistency level - Returns <code>GetResult</code> (value + version) - Throws <code>KeyNotFoundError</code> on NOT_FOUND</p>"},{"location":"sdks/typescript/ARCHITECTURE/#error-handling-in-flow","title":"Error Handling in Flow","text":"<pre><code>gRPC Status Error\n    \u2502\n    \u251c\u2500&gt; convertGrpcError()\n    \u2502   \u251c\u2500&gt; NOT_FOUND \u2192 KeyNotFoundError\n    \u2502   \u251c\u2500&gt; FAILED_PRECONDITION + \"version\" \u2192 VersionMismatchError\n    \u2502   \u251c\u2500&gt; UNAVAILABLE \u2192 ConnectionError\n    \u2502   \u2514\u2500&gt; OTHER \u2192 NoriKVError\n    \u2502\n    \u2514\u2500&gt; RetryPolicy decides:\n        \u251c\u2500&gt; Retryable \u2192 backoff and retry\n        \u2514\u2500&gt; Non-retryable \u2192 throw to caller\n</code></pre>"},{"location":"sdks/typescript/ARCHITECTURE/#asyncpromise-model","title":"Async/Promise Model","text":""},{"location":"sdks/typescript/ARCHITECTURE/#promise-based-api","title":"Promise-Based API","text":"<p>All client operations return Promises:</p> <pre><code>// All methods are async\nasync put(key: string | Uint8Array, value: string | Uint8Array, options?: PutOptions): Promise&lt;Version&gt;\nasync get(key: string | Uint8Array, options?: GetOptions): Promise&lt;GetResult&gt;\nasync delete(key: string | Uint8Array, options?: DeleteOptions): Promise&lt;boolean&gt;\n</code></pre>"},{"location":"sdks/typescript/ARCHITECTURE/#asyncawait-pattern","title":"Async/Await Pattern","text":"<pre><code>// Modern async/await\nasync function example() {\n  const version = await client.put(key, value);\n  const result = await client.get(key);\n  await client.delete(key);\n}\n\n// Sequential operations\nconst v1 = await client.put('k1', 'v1');\nconst v2 = await client.put('k2', 'v2'); // Waits for v1\n\n// Concurrent operations\nconst [v1, v2] = await Promise.all([\n  client.put('k1', 'v1'),\n  client.put('k2', 'v2'), // Runs concurrently\n]);\n</code></pre>"},{"location":"sdks/typescript/ARCHITECTURE/#error-handling","title":"Error Handling","text":"<pre><code>try {\n  const result = await client.get(key);\n} catch (error) {\n  if (error instanceof KeyNotFoundError) {\n    // Handle not found\n  } else if (error instanceof ConnectionError) {\n    // Handle connection error\n  }\n  throw error;\n}\n</code></pre>"},{"location":"sdks/typescript/ARCHITECTURE/#connection-management","title":"Connection Management","text":""},{"location":"sdks/typescript/ARCHITECTURE/#channel-lifecycle","title":"Channel Lifecycle","text":"<pre><code>Node Address\n    \u2502\n    \u251c\u2500&gt; First request \u2192 Create gRPC Client\n    \u2502   \u251c\u2500&gt; Configure: credentials, options\n    \u2502   \u2514\u2500&gt; Store in pool\n    \u2502\n    \u251c\u2500&gt; Subsequent requests \u2192 Reuse channel\n    \u2502\n    \u2514\u2500&gt; Client.close() \u2192 Close all channels\n        \u2514\u2500&gt; Graceful shutdown with timeout\n</code></pre>"},{"location":"sdks/typescript/ARCHITECTURE/#channel-configuration","title":"Channel Configuration","text":"<pre><code>const client = new grpc.Client(\n  address,\n  grpc.credentials.createInsecure(),\n  {\n    'grpc.keepalive_time_ms': 10000,\n    'grpc.keepalive_timeout_ms': 3000,\n  }\n);\n</code></pre>"},{"location":"sdks/typescript/ARCHITECTURE/#health-checks","title":"Health Checks","text":"<ul> <li>Channels automatically reconnect on failure</li> <li>gRPC handles connection health internally</li> <li>Failed requests trigger retries (via RetryPolicy)</li> </ul>"},{"location":"sdks/typescript/ARCHITECTURE/#routing-sharding","title":"Routing &amp; Sharding","text":""},{"location":"sdks/typescript/ARCHITECTURE/#hash-function-xxhash64","title":"Hash Function: XXHash64","text":"<pre><code>import xxhash from 'xxhash-wasm';\n\nconst hash = xxhash.h64(key, 0); // seed=0\n</code></pre> <p>Properties: - Fast: Optimized for V8 - Consistent: Same key \u2192 same hash - Cross-SDK compatible</p>"},{"location":"sdks/typescript/ARCHITECTURE/#consistent-hashing-jump-consistent-hash","title":"Consistent Hashing: Jump Consistent Hash","text":"<pre><code>function jumpConsistentHash(key: bigint, numBuckets: number): number {\n  let b = -1n, j = 0n;\n  while (j &lt; BigInt(numBuckets)) {\n    b = j;\n    key = key * 2862933555777941757n + 1n;\n    j = BigInt((Number(b) + 1) * (Number((1n &lt;&lt; 31n)) / Number((key &gt;&gt; 33n) + 1n)));\n  }\n  return Number(b);\n}\n</code></pre> <p>Properties: - Minimal key movement on shard count changes - O(log n) time complexity - Uniform distribution</p>"},{"location":"sdks/typescript/ARCHITECTURE/#shard-leader-mapping","title":"Shard \u2192 Leader Mapping","text":"<pre><code>shardId \u2192 TopologyManager.getShardLeader(shardId) \u2192 leaderAddr\n</code></pre> <p>Leader Cache: - Populated from ClusterView - Updated on topology changes - Updated from NOT_LEADER error hints</p>"},{"location":"sdks/typescript/ARCHITECTURE/#retry-logic","title":"Retry Logic","text":""},{"location":"sdks/typescript/ARCHITECTURE/#exponential-backoff","title":"Exponential Backoff","text":"<pre><code>const delay = Math.min(\n  initialDelay * Math.pow(2, attempt),\n  maxDelay\n) + Math.random() * jitter;\n\nawait new Promise(resolve =&gt; setTimeout(resolve, delay));\n</code></pre> <p>Example (initialDelay=100ms, maxDelay=5s, jitter=100ms): <pre><code>Attempt 1: delay = 100ms  + random(0-100ms)\nAttempt 2: delay = 200ms  + random(0-100ms)\nAttempt 3: delay = 400ms  + random(0-100ms)\nAttempt 4: delay = 800ms  + random(0-100ms)\nAttempt 5: delay = 1600ms + random(0-100ms)\nAttempt 6: delay = 3200ms + random(0-100ms)\nAttempt 7: delay = 5000ms + random(0-100ms) (capped)\n</code></pre></p>"},{"location":"sdks/typescript/ARCHITECTURE/#jitter-benefits","title":"Jitter Benefits","text":"<ul> <li>Avoids thundering herd (all clients retry at same time)</li> <li>Spreads load during recovery</li> <li>Reduces collision probability</li> </ul>"},{"location":"sdks/typescript/ARCHITECTURE/#error-handling_1","title":"Error Handling","text":""},{"location":"sdks/typescript/ARCHITECTURE/#error-hierarchy","title":"Error Hierarchy","text":"<pre><code>export class NoriKVError extends Error {\n  constructor(\n    message: string,\n    public code: string,\n    public cause?: Error\n  ) {\n    super(message);\n    this.name = 'NoriKVError';\n  }\n}\n\nexport class KeyNotFoundError extends NoriKVError {}\nexport class VersionMismatchError extends NoriKVError {}\nexport class AlreadyExistsError extends NoriKVError {}\nexport class ConnectionError extends NoriKVError {}\n</code></pre>"},{"location":"sdks/typescript/ARCHITECTURE/#error-code-mapping","title":"Error Code Mapping","text":"gRPC Status NoriKV Error Retry? NOT_FOUND KeyNotFoundError No FAILED_PRECONDITION (version) VersionMismatchError No FAILED_PRECONDITION (other) NoriKVError No ALREADY_EXISTS AlreadyExistsError No UNAVAILABLE ConnectionError Yes DEADLINE_EXCEEDED ConnectionError Yes ABORTED NoriKVError Yes RESOURCE_EXHAUSTED NoriKVError Yes INVALID_ARGUMENT NoriKVError No PERMISSION_DENIED NoriKVError No"},{"location":"sdks/typescript/ARCHITECTURE/#performance-considerations","title":"Performance Considerations","text":""},{"location":"sdks/typescript/ARCHITECTURE/#hot-paths","title":"Hot Paths","text":"<ol> <li>Hash calculation: Optimized XXHash64 via wasm</li> <li>Channel lookup: O(1) Map lookup</li> <li>Leader cache: O(1) Map lookup</li> <li>Protobuf serialization: Native JavaScript</li> </ol>"},{"location":"sdks/typescript/ARCHITECTURE/#memory-usage","title":"Memory Usage","text":"<ul> <li>Per client: ~1-10 MB (depends on number of nodes)</li> <li>Per channel: ~100 KB (gRPC overhead)</li> <li>Per request: Minimal (garbage collected)</li> </ul>"},{"location":"sdks/typescript/ARCHITECTURE/#v8-optimizations","title":"V8 Optimizations","text":"<ul> <li>JIT compilation of hot paths</li> <li>Inline caching for property access</li> <li>Hidden classes for consistent object shapes</li> </ul>"},{"location":"sdks/typescript/ARCHITECTURE/#connection-pooling","title":"Connection Pooling","text":"<ul> <li>Channels reused across requests</li> <li>No connection per request overhead</li> <li>HTTP/2 multiplexing</li> </ul>"},{"location":"sdks/typescript/ARCHITECTURE/#typescript-specific-features","title":"TypeScript-Specific Features","text":""},{"location":"sdks/typescript/ARCHITECTURE/#full-type-safety","title":"Full Type Safety","text":"<pre><code>import { NoriKVClient, GetResult, Version } from '@norikv/client';\n\nconst client: NoriKVClient = new NoriKVClient(config);\nconst result: GetResult = await client.get(key);\nconst version: Version = result.version;\n</code></pre>"},{"location":"sdks/typescript/ARCHITECTURE/#discriminated-unions","title":"Discriminated Unions","text":"<pre><code>type Result&lt;T, E&gt; =\n  | { ok: true; value: T }\n  | { ok: false; error: E };\n</code></pre>"},{"location":"sdks/typescript/ARCHITECTURE/#generic-type-parameters","title":"Generic Type Parameters","text":"<pre><code>async function withRetry&lt;T&gt;(\n  operation: () =&gt; Promise&lt;T&gt;\n): Promise&lt;T&gt; {\n  // Implementation\n}\n</code></pre>"},{"location":"sdks/typescript/ARCHITECTURE/#browser-compatibility","title":"Browser Compatibility","text":"<p>The TypeScript SDK can run in browsers with:</p> <ol> <li>gRPC-Web: Use @grpc/grpc-js polyfill</li> <li>Webpack 5: Configure fallbacks for Node.js modules</li> <li>Buffer polyfill: Use buffer package</li> </ol> <pre><code>// webpack.config.js\nmodule.exports = {\n  resolve: {\n    fallback: {\n      buffer: require.resolve('buffer/'),\n      stream: require.resolve('stream-browserify'),\n    },\n  },\n};\n</code></pre>"},{"location":"sdks/typescript/ARCHITECTURE/#references","title":"References","text":"<ul> <li>API Guide - Public API documentation</li> <li>Troubleshooting Guide - Common issues</li> <li>Advanced Patterns - Complex use cases</li> <li>Source Code - Implementation</li> </ul>"},{"location":"sdks/typescript/TROUBLESHOOTING/","title":"NoriKV TypeScript Client Troubleshooting Guide","text":"<p>Solutions to common issues when using the TypeScript/JavaScript client SDK.</p>"},{"location":"sdks/typescript/TROUBLESHOOTING/#connection-issues","title":"Connection Issues","text":""},{"location":"sdks/typescript/TROUBLESHOOTING/#connection-refused-or-econnrefused","title":"\"Connection refused\" or ECONNREFUSED","text":"<p>Symptoms: <pre><code>await client.connect();\n// Error: connect ECONNREFUSED 127.0.0.1:9001\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Verify server is running: <pre><code>netstat -an | grep 9001\nlsof -i :9001\n</code></pre></p> </li> <li> <p>Check client configuration: <pre><code>const client = new NoriKVClient({\n  nodes: ['localhost:9001'], // Verify this address\n  totalShards: 1024,\n});\n</code></pre></p> </li> <li> <p>Test connectivity: <pre><code>telnet localhost 9001\nnc -zv localhost 9001\n</code></pre></p> </li> </ol>"},{"location":"sdks/typescript/TROUBLESHOOTING/#deadline-exceeded-or-timeout-errors","title":"\"Deadline exceeded\" or timeout errors","text":"<p>Symptoms: <pre><code>const result = await client.get(key);\n// Error: Deadline exceeded\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Increase timeout: <pre><code>const client = new NoriKVClient({\n  nodes: ['localhost:9001'],\n  timeout: 10000, // 10 seconds\n});\n</code></pre></p> </li> <li> <p>Enable retries: <pre><code>const client = new NoriKVClient({\n  nodes: ['localhost:9001'],\n  retry: {\n    maxAttempts: 10,\n    initialDelayMs: 100,\n    maxDelayMs: 5000,\n  },\n});\n</code></pre></p> </li> </ol>"},{"location":"sdks/typescript/TROUBLESHOOTING/#performance-problems","title":"Performance Problems","text":""},{"location":"sdks/typescript/TROUBLESHOOTING/#slow-operations","title":"Slow operations","text":"<p>Diagnosis: <pre><code>console.time('put');\nawait client.put(key, value);\nconsole.timeEnd('put'); // &gt; 100ms consistently\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Use appropriate consistency level: <pre><code>const result = await client.get(key, {\n  consistency: ConsistencyLevel.STALE_OK, // Fastest\n});\n</code></pre></p> </li> <li> <p>Batch operations: <pre><code>await Promise.all(\n  keys.map(k =&gt; client.put(k, value))\n);\n</code></pre></p> </li> <li> <p>Check value sizes: <pre><code>console.log('Value size:', value.length, 'bytes');\n// Optimal: 100 bytes - 10 KB\n</code></pre></p> </li> </ol>"},{"location":"sdks/typescript/TROUBLESHOOTING/#high-memory-usage","title":"High memory usage","text":"<p>Solutions:</p> <ol> <li> <p>Close client when done: <pre><code>await client.close(); // Important!\n</code></pre></p> </li> <li> <p>Clean up topology listeners: <pre><code>const unsubscribe = client.onTopologyChange(handler);\nunsubscribe(); // Clean up when done\n</code></pre></p> </li> <li> <p>Use Node.js profiling: <pre><code>node --inspect index.js\n# Open chrome://inspect\n</code></pre></p> </li> </ol>"},{"location":"sdks/typescript/TROUBLESHOOTING/#version-conflicts","title":"Version Conflicts","text":""},{"location":"sdks/typescript/TROUBLESHOOTING/#frequent-versionmismatcherror","title":"Frequent VersionMismatchError","text":"<p>Symptoms: <pre><code>await client.put(key, newValue, {\n  ifMatchVersion: version,\n});\n// Error: Version mismatch\n</code></pre></p> <p>Solution - Implement retry loop: <pre><code>async function casWithRetry(\n  key: string,\n  transform: (value: string) =&gt; string,\n  maxRetries: number = 10\n): Promise&lt;void&gt; {\n  for (let i = 0; i &lt; maxRetries; i++) {\n    try {\n      const result = await client.get(key);\n      const newValue = transform(bytesToString(result.value));\n\n      await client.put(key, newValue, {\n        ifMatchVersion: result.version,\n      });\n      return; // Success\n    } catch (err) {\n      if (!(err instanceof VersionMismatchError)) {\n        throw err;\n      }\n      if (i === maxRetries - 1) {\n        throw new Error('CAS failed after retries');\n      }\n      // Exponential backoff\n      await new Promise(r =&gt; setTimeout(r, Math.pow(2, i) * 10));\n    }\n  }\n}\n</code></pre></p>"},{"location":"sdks/typescript/TROUBLESHOOTING/#error-messages","title":"Error Messages","text":""},{"location":"sdks/typescript/TROUBLESHOOTING/#key-not-found","title":"\"Key not found\"","text":"<p>Handling: <pre><code>try {\n  const result = await client.get(key);\n} catch (err) {\n  if (err instanceof KeyNotFoundError) {\n    // Use default value or create key\n    return defaultValue;\n  }\n  throw err;\n}\n</code></pre></p>"},{"location":"sdks/typescript/TROUBLESHOOTING/#version-mismatch","title":"\"Version mismatch\"","text":"<p>Handling: See Version Conflicts above.</p>"},{"location":"sdks/typescript/TROUBLESHOOTING/#connection-error","title":"\"Connection error\"","text":"<p>Handling: <pre><code>async function withRetry&lt;T&gt;(\n  operation: () =&gt; Promise&lt;T&gt;\n): Promise&lt;T&gt; {\n  const maxAttempts = 3;\n  for (let i = 0; i &lt; maxAttempts; i++) {\n    try {\n      return await operation();\n    } catch (err) {\n      if (!(err instanceof ConnectionError) || i === maxAttempts - 1) {\n        throw err;\n      }\n      await new Promise(r =&gt; setTimeout(r, Math.pow(2, i) * 100));\n    }\n  }\n  throw new Error('Unreachable');\n}\n</code></pre></p>"},{"location":"sdks/typescript/TROUBLESHOOTING/#typescript-specific-issues","title":"TypeScript-Specific Issues","text":""},{"location":"sdks/typescript/TROUBLESHOOTING/#type-errors-with-buffers","title":"Type errors with buffers","text":"<p>Problem: <pre><code>const value = Buffer.from('hello');\nawait client.put(key, value); // Type error\n</code></pre></p> <p>Solution: <pre><code>import { stringToBytes } from '@norikv/client';\n\nconst value = stringToBytes('hello'); // Uint8Array\nawait client.put(key, value);\n</code></pre></p>"},{"location":"sdks/typescript/TROUBLESHOOTING/#asyncawait-not-working","title":"Async/await not working","text":"<p>Problem: <pre><code>client.put(key, value); // Promise not awaited\nconsole.log('Done'); // Runs before put completes\n</code></pre></p> <p>Solution: <pre><code>await client.put(key, value); // Await the promise\nconsole.log('Done'); // Runs after put completes\n</code></pre></p>"},{"location":"sdks/typescript/TROUBLESHOOTING/#module-resolution-errors","title":"Module resolution errors","text":"<p>Problem: <pre><code>import { NoriKVClient } from '@norikv/client';\n// Error: Cannot find module\n</code></pre></p> <p>Solution:</p> <ol> <li> <p>Install package: <pre><code>npm install @norikv/client\n</code></pre></p> </li> <li> <p>Check tsconfig.json: <pre><code>{\n  \"compilerOptions\": {\n    \"moduleResolution\": \"node\",\n    \"esModuleInterop\": true\n  }\n}\n</code></pre></p> </li> </ol>"},{"location":"sdks/typescript/TROUBLESHOOTING/#browser-issues","title":"Browser Issues","text":""},{"location":"sdks/typescript/TROUBLESHOOTING/#buffer-is-not-defined","title":"\"Buffer is not defined\"","text":"<p>Solution - Add buffer polyfill: <pre><code>npm install buffer\n</code></pre></p> <pre><code>import { Buffer } from 'buffer';\nglobalThis.Buffer = Buffer;\n</code></pre>"},{"location":"sdks/typescript/TROUBLESHOOTING/#grpc-not-working-in-browser","title":"gRPC not working in browser","text":"<p>Solution - Use gRPC-Web: <pre><code>import { GrpcWebFetchTransport } from '@protobuf-ts/grpcweb-transport';\n\n// Configure client for browser\nconst transport = new GrpcWebFetchTransport({\n  baseUrl: 'http://localhost:8080'\n});\n</code></pre></p>"},{"location":"sdks/typescript/TROUBLESHOOTING/#common-pitfalls","title":"Common Pitfalls","text":""},{"location":"sdks/typescript/TROUBLESHOOTING/#1-not-awaiting-promises","title":"1. Not awaiting promises","text":"<pre><code>//  Bad\nclient.put(key, value); // Promise ignored\n\n//  Good\nawait client.put(key, value);\n</code></pre>"},{"location":"sdks/typescript/TROUBLESHOOTING/#2-creating-client-per-request","title":"2. Creating client per request","text":"<pre><code>//  Bad\nasync function handleRequest() {\n  const client = new NoriKVClient(config);\n  await client.connect();\n  await client.put(key, value);\n  await client.close(); // Expensive!\n}\n\n//  Good\nconst client = new NoriKVClient(config);\nawait client.connect();\n// Reuse client across requests\n</code></pre>"},{"location":"sdks/typescript/TROUBLESHOOTING/#3-not-handling-errors","title":"3. Not handling errors","text":"<pre><code>//  Bad\nconst result = await client.get(key); // May throw\n\n//  Good\ntry {\n  const result = await client.get(key);\n} catch (err) {\n  if (err instanceof KeyNotFoundError) {\n    return null;\n  }\n  throw err;\n}\n</code></pre>"},{"location":"sdks/typescript/TROUBLESHOOTING/#4-mixing-callbacks-and-asyncawait","title":"4. Mixing callbacks and async/await","text":"<pre><code>//  Bad\nclient.put(key, value).then(() =&gt; {\n  client.get(key).then(result =&gt; {\n    console.log(result);\n  });\n});\n\n//  Good\nconst version = await client.put(key, value);\nconst result = await client.get(key);\nconsole.log(result);\n</code></pre>"},{"location":"sdks/typescript/TROUBLESHOOTING/#debugging-tips","title":"Debugging Tips","text":""},{"location":"sdks/typescript/TROUBLESHOOTING/#enable-debug-logging","title":"Enable debug logging","text":"<pre><code>// Set environment variable\nprocess.env.DEBUG = 'norikv:*';\n</code></pre>"},{"location":"sdks/typescript/TROUBLESHOOTING/#use-nodejs-debugger","title":"Use Node.js debugger","text":"<pre><code>node --inspect-brk index.js\n# Open chrome://inspect\n</code></pre>"},{"location":"sdks/typescript/TROUBLESHOOTING/#monitor-operations","title":"Monitor operations","text":"<pre><code>const start = Date.now();\nawait client.put(key, value);\nconsole.log(`PUT took ${Date.now() - start}ms`);\n</code></pre>"},{"location":"sdks/typescript/TROUBLESHOOTING/#check-client-stats","title":"Check client stats","text":"<pre><code>const stats = client.getStats();\nconsole.log('Stats:', JSON.stringify(stats, null, 2));\n</code></pre>"},{"location":"sdks/typescript/TROUBLESHOOTING/#getting-help","title":"Getting Help","text":"<ul> <li>Issues: GitHub Issues</li> <li>Documentation: API Guide, Architecture Guide</li> <li>Examples: GitHub Examples</li> </ul>"}]}